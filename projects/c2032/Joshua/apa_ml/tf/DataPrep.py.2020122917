import numpy as np
import os
import sys
import argparse

def get_data(data_root, label):
    """
    Process all files in the input directory to read sequences.
    Sequences are encoded with one-hot.
    data_root: input directory
    label: the label (True or False) for the sequences in the input directory
    """
    data1 = [] # seq
    data2 = [] # coverage
    data3 = [] # information
    
    with open(data_root,'r') as f:
        for line in f:
            line=line.rstrip('\n').split('\t')
            if (line[0]!='#pas_id')&(line[0]!='pas_id'):
                SEQUENCE=list(line[7])
                #print(SEQUENCE)
                ID=line[0]
                data3.append(ID)
                if len(SEQUENCE)==201:
                    alphabet = np.array(['A', 'T', 'C', 'G'])
                    seq = np.array(SEQUENCE, dtype = '|U1').reshape(-1, 1)
                    seq_data = (seq == alphabet).astype(np.float32)
                    data1.append(seq_data)
                    #print(seq_data)
                    COVERAGE=[int(float(x)) for x in line[8::]]
                    COVERAGE=np.array(COVERAGE)/max(COVERAGE)
                    data2.append(COVERAGE)
                else:
                    print(len(SEQUENCE),line[0])
                
    data1 = np.stack(data1).reshape([-1, 201, 1, 4])
    data2 = np.stack(data2).reshape([-1, 201, 1, 1])
    
    if label:
        labels = np.zeros(data1.shape[0])
    else:
        labels = np.ones(data1.shape[0])
    return data1, data2, data3, labels


def shuffle(dataset1, dataset2, dataset3, labels, randomState=None):
    """
    Shuffle sequences and labels jointly
    """
    if randomState is None:
        permutation = np.random.permutation(labels.shape[0])
    else:
        permutation = randomState.permutation(labels.shape[0])
    shuffled_data1 = dataset1[permutation,:,:]
    shuffled_data2 = dataset2[permutation,:,:]
    shuffled_data3 = [dataset3[x] for x in permutation]
    shuffled_labels = labels[permutation]
    return shuffled_data1, shuffled_data2 , shuffled_data3, shuffled_labels


def data_split(pos_data1, pos_data2, pos_data3, pos_labels, neg_data1, neg_data2, neg_data3, neg_labels, num_folds, split):
    """
    Split the dataset into num_folds folds.
    Then split train, valid, and test sets according to the input dict split.
    """
    pos_data1_folds = np.array_split(pos_data1, num_folds)
    pos_data2_folds = np.array_split(pos_data2, num_folds)
    pos_data3_folds = np.array_split(pos_data3, num_folds)
    neg_data1_folds = np.array_split(neg_data1, num_folds)
    neg_data2_folds = np.array_split(neg_data2, num_folds)
    neg_data3_folds = np.array_split(neg_data3, num_folds)
    pos_label_folds = np.array_split(pos_labels, num_folds)
    neg_label_folds = np.array_split(neg_labels, num_folds)

    train_pos_data1 = np.concatenate([pos_data1_folds[i] for i in split['train']], axis=0)
    train_pos_data2 = np.concatenate([pos_data2_folds[i] for i in split['train']], axis=0)
    train_pos_data3 = np.concatenate([pos_data3_folds[i] for i in split['train']], axis=0)
    train_pos_labels = np.concatenate([pos_label_folds[i] for i in split['train']], axis=0)
    valid_pos_data1 = np.concatenate([pos_data1_folds[i] for i in split['valid']], axis=0)
    valid_pos_data2 = np.concatenate([pos_data2_folds[i] for i in split['valid']], axis=0)
    valid_pos_data3 = np.concatenate([pos_data3_folds[i] for i in split['valid']], axis=0)
    valid_pos_labels = np.concatenate([pos_label_folds[i] for i in split['valid']], axis=0)

    train_neg_data1 = np.concatenate([neg_data1_folds[i] for i in split['train']], axis=0)
    train_neg_data2 = np.concatenate([neg_data2_folds[i] for i in split['train']], axis=0)
    train_neg_data3 = np.concatenate([neg_data3_folds[i] for i in split['train']], axis=0)
    train_neg_labels = np.concatenate([neg_label_folds[i] for i in split['train']], axis=0)
    valid_neg_data1 = np.concatenate([neg_data1_folds[i] for i in split['valid']], axis=0)
    valid_neg_data2 = np.concatenate([neg_data2_folds[i] for i in split['valid']], axis=0)
    valid_neg_data3 = np.concatenate([neg_data3_folds[i] for i in split['valid']], axis=0)
    valid_neg_labels = np.concatenate([neg_label_folds[i] for i in split['valid']], axis=0)

    train_data1 = np.concatenate((train_pos_data1, train_neg_data1), axis=0)
    train_data2 = np.concatenate((train_pos_data2, train_neg_data2), axis=0)
    train_data3 = np.concatenate((train_pos_data3, train_neg_data3), axis=0)
    valid_data1 = np.concatenate((valid_pos_data1, valid_neg_data1), axis=0)
    valid_data2 = np.concatenate((valid_pos_data2, valid_neg_data2), axis=0)
    valid_data3 = np.concatenate((valid_pos_data3, valid_neg_data3), axis=0)
    train_labels = np.concatenate((train_pos_labels, train_neg_labels), axis=0)
    valid_labels = np.concatenate((valid_pos_labels, valid_neg_labels), axis=0)

    data = {}
    data['train_dataset1'],data['train_dataset2'], data['train_dataset3'], data['train_labels'] = shuffle(train_data1, train_data2, train_data3 , train_labels)
    data['valid_dataset1'],data['valid_dataset2'], data['valid_dataset3'], data['valid_labels'] = shuffle(valid_data1, valid_data2, valid_data3, valid_labels)

    if 'test' in split:
        test_pos_data1 = np.concatenate([pos_data1_folds[i] for i in split['test']], axis=0)
        test_pos_data2 = np.concatenate([pos_data2_folds[i] for i in split['test']], axis=0)
        test_pos_data3 = np.concatenate([pos_data3_folds[i] for i in split['test']], axis=0)
        test_pos_labels = np.concatenate([pos_label_folds[i] for i in split['test']], axis=0)
        test_neg_data1 = np.concatenate([neg_data1_folds[i] for i in split['test']], axis=0)
        test_neg_data2 = np.concatenate([neg_data2_folds[i] for i in split['test']], axis=0)
        test_neg_data3 = np.concatenate([neg_data3_folds[i] for i in split['test']], axis=0)
        test_neg_labels = np.concatenate([neg_label_folds[i] for i in split['test']], axis=0)
        test_data1 = np.concatenate((test_pos_data1, test_neg_data1), axis=0)
        test_data2 = np.concatenate((test_pos_data2, test_neg_data2), axis=0)
        test_labels = np.concatenate((test_pos_labels, test_neg_labels), axis=0)
        data['test_dataset1'], data['test_dataset2'], data['test_dataset3'], data['test_labels'] = shuffle(test_data1, test_data2, test_data3, test_labels)

    return data


def produce_dataset(pos_path, neg_path, seed=0):
    pos_data, pos_labels = get_data(pos_path, True)
    neg_data, neg_labels = get_data(neg_path, False)
    randomState = np.random.RandomState(seed)
    pos_data, pos_labels = shuffle(pos_data, pos_labels, randomState)
    neg_data, neg_labels = shuffle(neg_data, neg_labels, randomState)
    print('Positive:', pos_data.shape, pos_labels.shape)
    print('Negative:', neg_data.shape, neg_labels.shape)
    return pos_data, pos_labels, neg_data, neg_labels


if __name__ == '__main__':
    pos_root='data/bl6.pAs.zhangbin.fibroblast.txt'
    neg_root='data/bl6.pAs.random.negative.txt'
    outfile='data/all_data'
    nfolds=5

    pos_data1, pos_data2, pos_data3, pos_labels = get_data(pos_root, True)
    neg_data1, neg_data2, neg_data3, neg_labels = get_data(neg_root, False)
    randomState = np.random.RandomState(0)
    pos_data1, pos_data2, pos_data3, pos_labels = shuffle(pos_data1, pos_data2, pos_data3, pos_labels, randomState)
    neg_data1, neg_data2, neg_data3, neg_labels = shuffle(neg_data1, neg_data2, neg_data3, neg_labels, randomState)

    print('Read %d positive sequences from %s'%(pos_labels.shape[0], pos_root))
    print('Read %d negative sequences from %s\n'%(neg_labels.shape[0], neg_root))

    num_folds = nfolds
    split_dict = {
        'train': [i for i in range(num_folds-1)],
        'valid': [num_folds-1]#,
        #'test': [num_folds-1]
    }

    dataset = data_split(pos_data1, pos_data2, pos_data3, pos_labels, neg_data1, neg_data2, neg_data3, neg_labels, num_folds, split_dict)
    print('Size of training dataset: %d'%dataset['train_labels'].shape[0])
    print('Size of validation dataset: %d'%dataset['valid_labels'].shape[0])
    #print('Size of test dataset: %d\n'%dataset['test_labels'].shape[0])

    np.savez(outfile, **dataset)
    print('Finish writing dataset to %s'%outfile)

