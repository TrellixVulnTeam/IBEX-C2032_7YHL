{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.23.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = MaxPooling1D(pool_size = 12)(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+0.05)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    #train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    #valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "group_normalization (GroupNo (None, 990, 16)           32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,289\n",
      "Trainable params: 42,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 20332\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = \\\n",
    "prep_data('coverage_data/snu398.gt.gt.txt',5,7.8)\n",
    "trainid='snu398_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16129032"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3378935 1.4571116\n",
      "1.8906846 1.6314031\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.50459 1.3668648\n",
      "1.8369073 1.6522043\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b0bae284b00>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(train_x.shape[1]),train_x[5,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6130942"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,train_id,16,LENGTH)\n",
    "validation_generator = DataGenerator(valid_x,valid_y,valid_id,0,LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(LENGTH),a[9])\n",
    "plt.xticks(np.arange(0, LENGTH, 100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 524 steps, validate for 131 steps\n",
      "Epoch 1/1000\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.8349 - mse: 0.8269 - val_loss: 0.5947 - val_mse: 0.5864\n",
      "Epoch 2/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.6878 - mse: 0.6795 - val_loss: 0.5924 - val_mse: 0.5841\n",
      "Epoch 3/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.6655 - mse: 0.6572 - val_loss: 0.5883 - val_mse: 0.5800\n",
      "Epoch 4/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.6487 - mse: 0.6404 - val_loss: 0.5539 - val_mse: 0.5456\n",
      "Epoch 5/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.6485 - mse: 0.6402 - val_loss: 0.5308 - val_mse: 0.5225\n",
      "Epoch 6/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.6425 - mse: 0.6342 - val_loss: 0.5321 - val_mse: 0.5238\n",
      "Epoch 7/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.6284 - mse: 0.6201 - val_loss: 0.5338 - val_mse: 0.5255\n",
      "Epoch 8/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.6246 - mse: 0.6163 - val_loss: 0.5127 - val_mse: 0.5044\n",
      "Epoch 9/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.6121 - mse: 0.6038 - val_loss: 0.5240 - val_mse: 0.5157\n",
      "Epoch 10/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.6169 - mse: 0.6086\n",
      "Epoch 00010: saving model to Regression_Model/snu398-0010.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.6165 - mse: 0.6082 - val_loss: 0.5386 - val_mse: 0.5303\n",
      "Epoch 11/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.6182 - mse: 0.6099 - val_loss: 0.5560 - val_mse: 0.5477\n",
      "Epoch 12/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.6100 - mse: 0.6017 - val_loss: 0.5435 - val_mse: 0.5351\n",
      "Epoch 13/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.6036 - mse: 0.5953 - val_loss: 0.5325 - val_mse: 0.5241\n",
      "Epoch 14/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5959 - mse: 0.5876 - val_loss: 0.5460 - val_mse: 0.5377\n",
      "Epoch 15/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5987 - mse: 0.5904 - val_loss: 0.5179 - val_mse: 0.5096\n",
      "Epoch 16/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.6072 - mse: 0.5989 - val_loss: 0.5285 - val_mse: 0.5202\n",
      "Epoch 17/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5971 - mse: 0.5888 - val_loss: 0.5420 - val_mse: 0.5337\n",
      "Epoch 18/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5975 - mse: 0.5892 - val_loss: 0.5092 - val_mse: 0.5009\n",
      "Epoch 19/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5955 - mse: 0.5872 - val_loss: 0.5146 - val_mse: 0.5063\n",
      "Epoch 20/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.6039 - mse: 0.5956\n",
      "Epoch 00020: saving model to Regression_Model/snu398-0020.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.6039 - mse: 0.5957 - val_loss: 0.5309 - val_mse: 0.5226\n",
      "Epoch 21/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5991 - mse: 0.5909 - val_loss: 0.5375 - val_mse: 0.5293\n",
      "Epoch 22/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5942 - mse: 0.5860 - val_loss: 0.5120 - val_mse: 0.5038\n",
      "Epoch 23/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5939 - mse: 0.5857 - val_loss: 0.5096 - val_mse: 0.5014\n",
      "Epoch 24/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5884 - mse: 0.5802 - val_loss: 0.5127 - val_mse: 0.5044\n",
      "Epoch 25/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5870 - mse: 0.5788 - val_loss: 0.5295 - val_mse: 0.5213\n",
      "Epoch 26/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5851 - mse: 0.5769 - val_loss: 0.5255 - val_mse: 0.5172\n",
      "Epoch 27/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5960 - mse: 0.5878 - val_loss: 0.5043 - val_mse: 0.4960\n",
      "Epoch 28/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5904 - mse: 0.5821 - val_loss: 0.5044 - val_mse: 0.4961\n",
      "Epoch 29/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5893 - mse: 0.5811 - val_loss: 0.5142 - val_mse: 0.5060\n",
      "Epoch 30/1000\n",
      "513/524 [============================>.] - ETA: 0s - loss: 0.5880 - mse: 0.5797\n",
      "Epoch 00030: saving model to Regression_Model/snu398-0030.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5872 - mse: 0.5790 - val_loss: 0.5075 - val_mse: 0.4993\n",
      "Epoch 31/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5844 - mse: 0.5762 - val_loss: 0.5136 - val_mse: 0.5054\n",
      "Epoch 32/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5815 - mse: 0.5733 - val_loss: 0.5071 - val_mse: 0.4989\n",
      "Epoch 33/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5823 - mse: 0.5741 - val_loss: 0.4977 - val_mse: 0.4895\n",
      "Epoch 34/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5737 - mse: 0.5655 - val_loss: 0.5023 - val_mse: 0.4941\n",
      "Epoch 35/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5804 - mse: 0.5723 - val_loss: 0.5010 - val_mse: 0.4928\n",
      "Epoch 36/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5785 - mse: 0.5703 - val_loss: 0.5129 - val_mse: 0.5048\n",
      "Epoch 37/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5766 - mse: 0.5685 - val_loss: 0.5020 - val_mse: 0.4938\n",
      "Epoch 38/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5738 - mse: 0.5656 - val_loss: 0.5199 - val_mse: 0.5117\n",
      "Epoch 39/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5702 - mse: 0.5620 - val_loss: 0.4943 - val_mse: 0.4862\n",
      "Epoch 40/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5675 - mse: 0.5594\n",
      "Epoch 00040: saving model to Regression_Model/snu398-0040.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5668 - mse: 0.5586 - val_loss: 0.4968 - val_mse: 0.4886\n",
      "Epoch 41/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5715 - mse: 0.5634 - val_loss: 0.4944 - val_mse: 0.4862\n",
      "Epoch 42/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5719 - mse: 0.5638 - val_loss: 0.5095 - val_mse: 0.5014\n",
      "Epoch 43/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5767 - mse: 0.5685 - val_loss: 0.5181 - val_mse: 0.5099\n",
      "Epoch 44/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5672 - mse: 0.5590 - val_loss: 0.5108 - val_mse: 0.5026\n",
      "Epoch 45/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5692 - mse: 0.5611 - val_loss: 0.5121 - val_mse: 0.5040\n",
      "Epoch 46/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5708 - mse: 0.5627 - val_loss: 0.5041 - val_mse: 0.4960\n",
      "Epoch 47/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5728 - mse: 0.5647 - val_loss: 0.4987 - val_mse: 0.4906\n",
      "Epoch 48/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5699 - mse: 0.5618 - val_loss: 0.4951 - val_mse: 0.4870\n",
      "Epoch 49/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5730 - mse: 0.5649 - val_loss: 0.4984 - val_mse: 0.4903\n",
      "Epoch 50/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.5691 - mse: 0.5610\n",
      "Epoch 00050: saving model to Regression_Model/snu398-0050.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5689 - mse: 0.5609 - val_loss: 0.5169 - val_mse: 0.5088\n",
      "Epoch 51/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5645 - mse: 0.5564 - val_loss: 0.4962 - val_mse: 0.4881\n",
      "Epoch 52/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5699 - mse: 0.5618 - val_loss: 0.5014 - val_mse: 0.4933\n",
      "Epoch 53/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5659 - mse: 0.5578 - val_loss: 0.4949 - val_mse: 0.4869\n",
      "Epoch 54/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5705 - mse: 0.5624 - val_loss: 0.5059 - val_mse: 0.4978\n",
      "Epoch 55/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5671 - mse: 0.5591 - val_loss: 0.5124 - val_mse: 0.5044\n",
      "Epoch 56/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5611 - mse: 0.5531 - val_loss: 0.4917 - val_mse: 0.4837\n",
      "Epoch 57/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5627 - mse: 0.5546 - val_loss: 0.4995 - val_mse: 0.4915\n",
      "Epoch 58/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5633 - mse: 0.5553 - val_loss: 0.4948 - val_mse: 0.4868\n",
      "Epoch 59/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5715 - mse: 0.5635 - val_loss: 0.5143 - val_mse: 0.5063\n",
      "Epoch 60/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5584 - mse: 0.5504\n",
      "Epoch 00060: saving model to Regression_Model/snu398-0060.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5584 - mse: 0.5504 - val_loss: 0.4999 - val_mse: 0.4919\n",
      "Epoch 61/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5622 - mse: 0.5542 - val_loss: 0.5175 - val_mse: 0.5095\n",
      "Epoch 62/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5646 - mse: 0.5566 - val_loss: 0.4998 - val_mse: 0.4918\n",
      "Epoch 63/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5567 - mse: 0.5487 - val_loss: 0.4979 - val_mse: 0.4899\n",
      "Epoch 64/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5624 - mse: 0.5544 - val_loss: 0.5065 - val_mse: 0.4985\n",
      "Epoch 65/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5688 - mse: 0.5608 - val_loss: 0.5123 - val_mse: 0.5043\n",
      "Epoch 66/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5604 - mse: 0.5524 - val_loss: 0.5005 - val_mse: 0.4925\n",
      "Epoch 67/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5631 - mse: 0.5551 - val_loss: 0.5346 - val_mse: 0.5266\n",
      "Epoch 68/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5671 - mse: 0.5592 - val_loss: 0.5078 - val_mse: 0.4999\n",
      "Epoch 69/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5670 - mse: 0.5591 - val_loss: 0.5034 - val_mse: 0.4955\n",
      "Epoch 70/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5600 - mse: 0.5521\n",
      "Epoch 00070: saving model to Regression_Model/snu398-0070.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5598 - mse: 0.5518 - val_loss: 0.4886 - val_mse: 0.4807\n",
      "Epoch 71/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5600 - mse: 0.5521 - val_loss: 0.4958 - val_mse: 0.4879\n",
      "Epoch 72/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5613 - mse: 0.5533 - val_loss: 0.4995 - val_mse: 0.4915\n",
      "Epoch 73/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5622 - mse: 0.5543 - val_loss: 0.4895 - val_mse: 0.4816\n",
      "Epoch 74/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5602 - mse: 0.5523 - val_loss: 0.4922 - val_mse: 0.4843\n",
      "Epoch 75/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5650 - mse: 0.5571 - val_loss: 0.5122 - val_mse: 0.5043\n",
      "Epoch 76/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5626 - mse: 0.5548 - val_loss: 0.5039 - val_mse: 0.4960\n",
      "Epoch 77/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5581 - mse: 0.5502 - val_loss: 0.4973 - val_mse: 0.4894\n",
      "Epoch 78/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5634 - mse: 0.5556 - val_loss: 0.4970 - val_mse: 0.4891\n",
      "Epoch 79/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5591 - mse: 0.5512 - val_loss: 0.5027 - val_mse: 0.4949\n",
      "Epoch 80/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5577 - mse: 0.5498\n",
      "Epoch 00080: saving model to Regression_Model/snu398-0080.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5578 - mse: 0.5500 - val_loss: 0.4982 - val_mse: 0.4903\n",
      "Epoch 81/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5525 - mse: 0.5446 - val_loss: 0.5026 - val_mse: 0.4948\n",
      "Epoch 82/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5600 - mse: 0.5522 - val_loss: 0.5042 - val_mse: 0.4963\n",
      "Epoch 83/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5547 - mse: 0.5469 - val_loss: 0.5106 - val_mse: 0.5028\n",
      "Epoch 84/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5574 - mse: 0.5495 - val_loss: 0.4905 - val_mse: 0.4827\n",
      "Epoch 85/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5566 - mse: 0.5487 - val_loss: 0.5004 - val_mse: 0.4926\n",
      "Epoch 86/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5513 - mse: 0.5435 - val_loss: 0.5090 - val_mse: 0.5012\n",
      "Epoch 87/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5596 - mse: 0.5518 - val_loss: 0.4894 - val_mse: 0.4817\n",
      "Epoch 88/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5547 - mse: 0.5469 - val_loss: 0.5055 - val_mse: 0.4977\n",
      "Epoch 89/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5571 - mse: 0.5493 - val_loss: 0.5037 - val_mse: 0.4960\n",
      "Epoch 90/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5541 - mse: 0.5463\n",
      "Epoch 00090: saving model to Regression_Model/snu398-0090.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5539 - mse: 0.5461 - val_loss: 0.5005 - val_mse: 0.4927\n",
      "Epoch 91/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5531 - mse: 0.5453 - val_loss: 0.4886 - val_mse: 0.4809\n",
      "Epoch 92/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5506 - mse: 0.5428 - val_loss: 0.4966 - val_mse: 0.4888\n",
      "Epoch 93/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5484 - mse: 0.5406 - val_loss: 0.4894 - val_mse: 0.4816\n",
      "Epoch 94/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5540 - mse: 0.5463 - val_loss: 0.4928 - val_mse: 0.4851\n",
      "Epoch 95/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5573 - mse: 0.5495 - val_loss: 0.4867 - val_mse: 0.4789\n",
      "Epoch 96/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5545 - mse: 0.5468 - val_loss: 0.4958 - val_mse: 0.4881\n",
      "Epoch 97/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5582 - mse: 0.5505 - val_loss: 0.4900 - val_mse: 0.4823\n",
      "Epoch 98/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5577 - mse: 0.5500 - val_loss: 0.4894 - val_mse: 0.4817\n",
      "Epoch 99/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5566 - mse: 0.5489 - val_loss: 0.4916 - val_mse: 0.4839\n",
      "Epoch 100/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.5585 - mse: 0.5508\n",
      "Epoch 00100: saving model to Regression_Model/snu398-0100.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5586 - mse: 0.5510 - val_loss: 0.5002 - val_mse: 0.4925\n",
      "Epoch 101/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5529 - mse: 0.5452 - val_loss: 0.5025 - val_mse: 0.4948\n",
      "Epoch 102/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5595 - mse: 0.5518 - val_loss: 0.5000 - val_mse: 0.4923\n",
      "Epoch 103/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5533 - mse: 0.5456 - val_loss: 0.5056 - val_mse: 0.4979\n",
      "Epoch 104/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5513 - mse: 0.5437 - val_loss: 0.5203 - val_mse: 0.5126\n",
      "Epoch 105/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5574 - mse: 0.5498 - val_loss: 0.4840 - val_mse: 0.4764\n",
      "Epoch 106/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5537 - mse: 0.5461 - val_loss: 0.5117 - val_mse: 0.5041\n",
      "Epoch 107/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5584 - mse: 0.5508 - val_loss: 0.4829 - val_mse: 0.4752\n",
      "Epoch 108/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5519 - mse: 0.5443 - val_loss: 0.5098 - val_mse: 0.5021\n",
      "Epoch 109/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5599 - mse: 0.5522 - val_loss: 0.5057 - val_mse: 0.4981\n",
      "Epoch 110/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.5538 - mse: 0.5462\n",
      "Epoch 00110: saving model to Regression_Model/snu398-0110.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5548 - mse: 0.5472 - val_loss: 0.5072 - val_mse: 0.4996\n",
      "Epoch 111/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5575 - mse: 0.5499 - val_loss: 0.5056 - val_mse: 0.4979\n",
      "Epoch 112/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5542 - mse: 0.5466 - val_loss: 0.4958 - val_mse: 0.4881\n",
      "Epoch 113/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5515 - mse: 0.5439 - val_loss: 0.4924 - val_mse: 0.4848\n",
      "Epoch 114/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5503 - mse: 0.5427 - val_loss: 0.4934 - val_mse: 0.4858\n",
      "Epoch 115/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5508 - mse: 0.5432 - val_loss: 0.5027 - val_mse: 0.4951\n",
      "Epoch 116/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5535 - mse: 0.5459 - val_loss: 0.5027 - val_mse: 0.4951\n",
      "Epoch 117/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5518 - mse: 0.5442 - val_loss: 0.4887 - val_mse: 0.4812\n",
      "Epoch 118/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5533 - mse: 0.5458 - val_loss: 0.4988 - val_mse: 0.4913\n",
      "Epoch 119/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5539 - mse: 0.5463 - val_loss: 0.4886 - val_mse: 0.4810\n",
      "Epoch 120/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5473 - mse: 0.5397\n",
      "Epoch 00120: saving model to Regression_Model/snu398-0120.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5469 - mse: 0.5393 - val_loss: 0.4971 - val_mse: 0.4896\n",
      "Epoch 121/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5520 - mse: 0.5444 - val_loss: 0.4871 - val_mse: 0.4795\n",
      "Epoch 122/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5511 - mse: 0.5436 - val_loss: 0.5011 - val_mse: 0.4936\n",
      "Epoch 123/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5535 - mse: 0.5460 - val_loss: 0.4954 - val_mse: 0.4878\n",
      "Epoch 124/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5514 - mse: 0.5439 - val_loss: 0.4937 - val_mse: 0.4862\n",
      "Epoch 125/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5476 - mse: 0.5401 - val_loss: 0.4971 - val_mse: 0.4896\n",
      "Epoch 126/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5559 - mse: 0.5484 - val_loss: 0.4992 - val_mse: 0.4917\n",
      "Epoch 127/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5510 - mse: 0.5435 - val_loss: 0.4843 - val_mse: 0.4768\n",
      "Epoch 128/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5511 - mse: 0.5436 - val_loss: 0.4942 - val_mse: 0.4867\n",
      "Epoch 129/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5511 - mse: 0.5436 - val_loss: 0.4879 - val_mse: 0.4804\n",
      "Epoch 130/1000\n",
      "516/524 [============================>.] - ETA: 0s - loss: 0.5526 - mse: 0.5451\n",
      "Epoch 00130: saving model to Regression_Model/snu398-0130.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5529 - mse: 0.5454 - val_loss: 0.4943 - val_mse: 0.4868\n",
      "Epoch 131/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5532 - mse: 0.5457 - val_loss: 0.4973 - val_mse: 0.4898\n",
      "Epoch 132/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5529 - mse: 0.5454 - val_loss: 0.4892 - val_mse: 0.4818\n",
      "Epoch 133/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5533 - mse: 0.5458 - val_loss: 0.4889 - val_mse: 0.4815\n",
      "Epoch 134/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5495 - mse: 0.5420 - val_loss: 0.4826 - val_mse: 0.4751\n",
      "Epoch 135/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5500 - mse: 0.5426 - val_loss: 0.4901 - val_mse: 0.4826\n",
      "Epoch 136/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5492 - mse: 0.5417 - val_loss: 0.4911 - val_mse: 0.4836\n",
      "Epoch 137/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5480 - mse: 0.5406 - val_loss: 0.4894 - val_mse: 0.4820\n",
      "Epoch 138/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5515 - mse: 0.5441 - val_loss: 0.5030 - val_mse: 0.4956\n",
      "Epoch 139/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5437 - mse: 0.5363 - val_loss: 0.4994 - val_mse: 0.4920\n",
      "Epoch 140/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5551 - mse: 0.5476\n",
      "Epoch 00140: saving model to Regression_Model/snu398-0140.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5552 - mse: 0.5478 - val_loss: 0.5037 - val_mse: 0.4962\n",
      "Epoch 141/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5442 - mse: 0.5368 - val_loss: 0.4905 - val_mse: 0.4831\n",
      "Epoch 142/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5496 - mse: 0.5422 - val_loss: 0.4920 - val_mse: 0.4846\n",
      "Epoch 143/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5507 - mse: 0.5433 - val_loss: 0.4855 - val_mse: 0.4782\n",
      "Epoch 144/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5478 - mse: 0.5404 - val_loss: 0.4863 - val_mse: 0.4789\n",
      "Epoch 145/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5469 - mse: 0.5396 - val_loss: 0.4976 - val_mse: 0.4902\n",
      "Epoch 146/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5477 - mse: 0.5403 - val_loss: 0.4935 - val_mse: 0.4862\n",
      "Epoch 147/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5495 - mse: 0.5421 - val_loss: 0.4898 - val_mse: 0.4825\n",
      "Epoch 148/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5496 - mse: 0.5422 - val_loss: 0.4891 - val_mse: 0.4818\n",
      "Epoch 149/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5466 - mse: 0.5392 - val_loss: 0.4856 - val_mse: 0.4782\n",
      "Epoch 150/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5500 - mse: 0.5426\n",
      "Epoch 00150: saving model to Regression_Model/snu398-0150.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5491 - mse: 0.5417 - val_loss: 0.4950 - val_mse: 0.4877\n",
      "Epoch 151/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5473 - mse: 0.5399 - val_loss: 0.4898 - val_mse: 0.4825\n",
      "Epoch 152/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5536 - mse: 0.5463 - val_loss: 0.4960 - val_mse: 0.4887\n",
      "Epoch 153/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5437 - mse: 0.5364 - val_loss: 0.4946 - val_mse: 0.4873\n",
      "Epoch 154/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5520 - mse: 0.5447 - val_loss: 0.4918 - val_mse: 0.4845\n",
      "Epoch 155/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5535 - mse: 0.5462 - val_loss: 0.4860 - val_mse: 0.4787\n",
      "Epoch 156/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5475 - mse: 0.5402 - val_loss: 0.4835 - val_mse: 0.4762\n",
      "Epoch 157/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5447 - mse: 0.5374 - val_loss: 0.4842 - val_mse: 0.4769\n",
      "Epoch 158/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5488 - mse: 0.5415 - val_loss: 0.4910 - val_mse: 0.4837\n",
      "Epoch 159/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5409 - mse: 0.5336 - val_loss: 0.4917 - val_mse: 0.4844\n",
      "Epoch 160/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.5481 - mse: 0.5408\n",
      "Epoch 00160: saving model to Regression_Model/snu398-0160.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5483 - mse: 0.5410 - val_loss: 0.4923 - val_mse: 0.4850\n",
      "Epoch 161/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5499 - mse: 0.5426 - val_loss: 0.4838 - val_mse: 0.4765\n",
      "Epoch 162/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5476 - mse: 0.5403 - val_loss: 0.4834 - val_mse: 0.4762\n",
      "Epoch 163/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5462 - mse: 0.5389 - val_loss: 0.4845 - val_mse: 0.4772\n",
      "Epoch 164/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5438 - mse: 0.5365 - val_loss: 0.4885 - val_mse: 0.4813\n",
      "Epoch 165/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5455 - mse: 0.5382 - val_loss: 0.4890 - val_mse: 0.4817\n",
      "Epoch 166/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5441 - mse: 0.5369 - val_loss: 0.4894 - val_mse: 0.4821\n",
      "Epoch 167/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5457 - mse: 0.5385 - val_loss: 0.4840 - val_mse: 0.4767\n",
      "Epoch 168/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5470 - mse: 0.5398 - val_loss: 0.4883 - val_mse: 0.4811\n",
      "Epoch 169/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5417 - mse: 0.5344 - val_loss: 0.4809 - val_mse: 0.4737\n",
      "Epoch 170/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5473 - mse: 0.5400\n",
      "Epoch 00170: saving model to Regression_Model/snu398-0170.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5463 - mse: 0.5391 - val_loss: 0.4911 - val_mse: 0.4839\n",
      "Epoch 171/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5433 - mse: 0.5360 - val_loss: 0.4883 - val_mse: 0.4810\n",
      "Epoch 172/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5369 - mse: 0.5297 - val_loss: 0.4844 - val_mse: 0.4772\n",
      "Epoch 173/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5468 - mse: 0.5396 - val_loss: 0.4975 - val_mse: 0.4903\n",
      "Epoch 174/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5506 - mse: 0.5434 - val_loss: 0.4875 - val_mse: 0.4803\n",
      "Epoch 175/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5458 - mse: 0.5386 - val_loss: 0.4827 - val_mse: 0.4755\n",
      "Epoch 176/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5459 - mse: 0.5387 - val_loss: 0.4807 - val_mse: 0.4735\n",
      "Epoch 177/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5457 - mse: 0.5385 - val_loss: 0.4958 - val_mse: 0.4886\n",
      "Epoch 178/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5444 - mse: 0.5372 - val_loss: 0.4833 - val_mse: 0.4761\n",
      "Epoch 179/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5434 - mse: 0.5362 - val_loss: 0.4808 - val_mse: 0.4736\n",
      "Epoch 180/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.5508 - mse: 0.5437\n",
      "Epoch 00180: saving model to Regression_Model/snu398-0180.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5501 - mse: 0.5429 - val_loss: 0.4919 - val_mse: 0.4847\n",
      "Epoch 181/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5445 - mse: 0.5374 - val_loss: 0.4959 - val_mse: 0.4887\n",
      "Epoch 182/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5466 - mse: 0.5395 - val_loss: 0.4864 - val_mse: 0.4793\n",
      "Epoch 183/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5405 - mse: 0.5333 - val_loss: 0.4810 - val_mse: 0.4738\n",
      "Epoch 184/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5430 - mse: 0.5359 - val_loss: 0.4825 - val_mse: 0.4753\n",
      "Epoch 185/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5425 - mse: 0.5354 - val_loss: 0.4922 - val_mse: 0.4850\n",
      "Epoch 186/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5472 - mse: 0.5400 - val_loss: 0.4855 - val_mse: 0.4783\n",
      "Epoch 187/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5408 - mse: 0.5336 - val_loss: 0.4812 - val_mse: 0.4741\n",
      "Epoch 188/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5428 - mse: 0.5356 - val_loss: 0.4786 - val_mse: 0.4714\n",
      "Epoch 189/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5459 - mse: 0.5387 - val_loss: 0.4832 - val_mse: 0.4761\n",
      "Epoch 190/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5374 - mse: 0.5303\n",
      "Epoch 00190: saving model to Regression_Model/snu398-0190.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5376 - mse: 0.5305 - val_loss: 0.4813 - val_mse: 0.4742\n",
      "Epoch 191/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5465 - mse: 0.5394 - val_loss: 0.4945 - val_mse: 0.4874\n",
      "Epoch 192/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5406 - mse: 0.5335 - val_loss: 0.4794 - val_mse: 0.4723\n",
      "Epoch 193/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5435 - mse: 0.5364 - val_loss: 0.4838 - val_mse: 0.4767\n",
      "Epoch 194/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5452 - mse: 0.5382 - val_loss: 0.4833 - val_mse: 0.4762\n",
      "Epoch 195/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5421 - mse: 0.5350 - val_loss: 0.4834 - val_mse: 0.4764\n",
      "Epoch 196/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5403 - mse: 0.5332 - val_loss: 0.4880 - val_mse: 0.4809\n",
      "Epoch 197/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5481 - mse: 0.5410 - val_loss: 0.4865 - val_mse: 0.4794\n",
      "Epoch 198/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5414 - mse: 0.5343 - val_loss: 0.4982 - val_mse: 0.4911\n",
      "Epoch 199/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5448 - mse: 0.5378 - val_loss: 0.4797 - val_mse: 0.4727\n",
      "Epoch 200/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5441 - mse: 0.5371\n",
      "Epoch 00200: saving model to Regression_Model/snu398-0200.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5444 - mse: 0.5374 - val_loss: 0.4960 - val_mse: 0.4889\n",
      "Epoch 201/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5475 - mse: 0.5405 - val_loss: 0.4937 - val_mse: 0.4866\n",
      "Epoch 202/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5399 - mse: 0.5328 - val_loss: 0.4760 - val_mse: 0.4690\n",
      "Epoch 203/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5433 - mse: 0.5362 - val_loss: 0.4875 - val_mse: 0.4805\n",
      "Epoch 204/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5431 - mse: 0.5361 - val_loss: 0.4830 - val_mse: 0.4760\n",
      "Epoch 205/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5423 - mse: 0.5353 - val_loss: 0.4789 - val_mse: 0.4719\n",
      "Epoch 206/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5402 - mse: 0.5332 - val_loss: 0.4862 - val_mse: 0.4792\n",
      "Epoch 207/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5392 - mse: 0.5321 - val_loss: 0.4808 - val_mse: 0.4738\n",
      "Epoch 208/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5414 - mse: 0.5344 - val_loss: 0.4806 - val_mse: 0.4736\n",
      "Epoch 209/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5390 - mse: 0.5320 - val_loss: 0.4830 - val_mse: 0.4759\n",
      "Epoch 210/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5424 - mse: 0.5354\n",
      "Epoch 00210: saving model to Regression_Model/snu398-0210.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5412 - mse: 0.5342 - val_loss: 0.4817 - val_mse: 0.4747\n",
      "Epoch 211/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5414 - mse: 0.5344 - val_loss: 0.4794 - val_mse: 0.4724\n",
      "Epoch 212/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5387 - mse: 0.5317 - val_loss: 0.4797 - val_mse: 0.4727\n",
      "Epoch 213/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5449 - mse: 0.5380 - val_loss: 0.4980 - val_mse: 0.4910\n",
      "Epoch 214/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5405 - mse: 0.5335 - val_loss: 0.4830 - val_mse: 0.4760\n",
      "Epoch 215/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5423 - mse: 0.5353 - val_loss: 0.4865 - val_mse: 0.4795\n",
      "Epoch 216/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5452 - mse: 0.5382 - val_loss: 0.4872 - val_mse: 0.4802\n",
      "Epoch 217/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5423 - mse: 0.5353 - val_loss: 0.4845 - val_mse: 0.4775\n",
      "Epoch 218/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5390 - mse: 0.5320 - val_loss: 0.4919 - val_mse: 0.4850\n",
      "Epoch 219/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5415 - mse: 0.5345 - val_loss: 0.4822 - val_mse: 0.4752\n",
      "Epoch 220/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5393 - mse: 0.5324\n",
      "Epoch 00220: saving model to Regression_Model/snu398-0220.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5389 - mse: 0.5319 - val_loss: 0.4796 - val_mse: 0.4727\n",
      "Epoch 221/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5437 - mse: 0.5367 - val_loss: 0.4918 - val_mse: 0.4849\n",
      "Epoch 222/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5380 - mse: 0.5311 - val_loss: 0.4846 - val_mse: 0.4777\n",
      "Epoch 223/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5395 - mse: 0.5325 - val_loss: 0.4797 - val_mse: 0.4727\n",
      "Epoch 224/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5336 - mse: 0.5267 - val_loss: 0.4826 - val_mse: 0.4756\n",
      "Epoch 225/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5396 - mse: 0.5327 - val_loss: 0.4922 - val_mse: 0.4853\n",
      "Epoch 226/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5412 - mse: 0.5342 - val_loss: 0.4790 - val_mse: 0.4721\n",
      "Epoch 227/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5403 - mse: 0.5334 - val_loss: 0.4906 - val_mse: 0.4837\n",
      "Epoch 228/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5464 - mse: 0.5394 - val_loss: 0.4885 - val_mse: 0.4816\n",
      "Epoch 229/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5381 - mse: 0.5311 - val_loss: 0.4828 - val_mse: 0.4759\n",
      "Epoch 230/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5423 - mse: 0.5353\n",
      "Epoch 00230: saving model to Regression_Model/snu398-0230.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5424 - mse: 0.5354 - val_loss: 0.4921 - val_mse: 0.4852\n",
      "Epoch 231/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5382 - mse: 0.5313 - val_loss: 0.4777 - val_mse: 0.4707\n",
      "Epoch 232/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5398 - mse: 0.5329 - val_loss: 0.4748 - val_mse: 0.4679\n",
      "Epoch 233/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5406 - mse: 0.5337 - val_loss: 0.4877 - val_mse: 0.4808\n",
      "Epoch 234/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5412 - mse: 0.5342 - val_loss: 0.4793 - val_mse: 0.4724\n",
      "Epoch 235/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5369 - mse: 0.5300 - val_loss: 0.4809 - val_mse: 0.4740\n",
      "Epoch 236/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5387 - mse: 0.5318 - val_loss: 0.4844 - val_mse: 0.4775\n",
      "Epoch 237/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5386 - mse: 0.5318 - val_loss: 0.4871 - val_mse: 0.4803\n",
      "Epoch 238/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5371 - mse: 0.5302 - val_loss: 0.4751 - val_mse: 0.4682\n",
      "Epoch 239/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5372 - mse: 0.5303 - val_loss: 0.4832 - val_mse: 0.4763\n",
      "Epoch 240/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5465 - mse: 0.5397\n",
      "Epoch 00240: saving model to Regression_Model/snu398-0240.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5474 - mse: 0.5406 - val_loss: 0.4787 - val_mse: 0.4719\n",
      "Epoch 241/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5374 - mse: 0.5305 - val_loss: 0.4934 - val_mse: 0.4866\n",
      "Epoch 242/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5408 - mse: 0.5339 - val_loss: 0.4830 - val_mse: 0.4761\n",
      "Epoch 243/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5344 - mse: 0.5275 - val_loss: 0.4825 - val_mse: 0.4756\n",
      "Epoch 244/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5390 - mse: 0.5321 - val_loss: 0.4832 - val_mse: 0.4763\n",
      "Epoch 245/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5374 - mse: 0.5306 - val_loss: 0.4803 - val_mse: 0.4735\n",
      "Epoch 246/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5357 - mse: 0.5289 - val_loss: 0.4805 - val_mse: 0.4737\n",
      "Epoch 247/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5381 - mse: 0.5312 - val_loss: 0.4809 - val_mse: 0.4740\n",
      "Epoch 248/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5353 - mse: 0.5285 - val_loss: 0.4805 - val_mse: 0.4737\n",
      "Epoch 249/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5378 - mse: 0.5310 - val_loss: 0.4901 - val_mse: 0.4833\n",
      "Epoch 250/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5308 - mse: 0.5240\n",
      "Epoch 00250: saving model to Regression_Model/snu398-0250.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5314 - mse: 0.5246 - val_loss: 0.4820 - val_mse: 0.4751\n",
      "Epoch 251/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5356 - mse: 0.5288 - val_loss: 0.4824 - val_mse: 0.4756\n",
      "Epoch 252/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5357 - mse: 0.5289 - val_loss: 0.4866 - val_mse: 0.4798\n",
      "Epoch 253/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5417 - mse: 0.5349 - val_loss: 0.4821 - val_mse: 0.4753\n",
      "Epoch 254/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5341 - mse: 0.5273 - val_loss: 0.4894 - val_mse: 0.4826\n",
      "Epoch 255/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5288 - mse: 0.5220 - val_loss: 0.4759 - val_mse: 0.4691\n",
      "Epoch 256/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5378 - mse: 0.5310 - val_loss: 0.4790 - val_mse: 0.4722\n",
      "Epoch 257/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5379 - mse: 0.5311 - val_loss: 0.4856 - val_mse: 0.4788\n",
      "Epoch 258/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5403 - mse: 0.5335 - val_loss: 0.4811 - val_mse: 0.4743\n",
      "Epoch 259/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5358 - mse: 0.5290 - val_loss: 0.4759 - val_mse: 0.4691\n",
      "Epoch 260/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5380 - mse: 0.5312\n",
      "Epoch 00260: saving model to Regression_Model/snu398-0260.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5382 - mse: 0.5314 - val_loss: 0.4813 - val_mse: 0.4746\n",
      "Epoch 261/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5363 - mse: 0.5295 - val_loss: 0.4828 - val_mse: 0.4760\n",
      "Epoch 262/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5412 - mse: 0.5344 - val_loss: 0.4868 - val_mse: 0.4801\n",
      "Epoch 263/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5345 - mse: 0.5277 - val_loss: 0.4802 - val_mse: 0.4734\n",
      "Epoch 264/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5342 - mse: 0.5274 - val_loss: 0.4820 - val_mse: 0.4752\n",
      "Epoch 265/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5347 - mse: 0.5280 - val_loss: 0.4848 - val_mse: 0.4781\n",
      "Epoch 266/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5344 - mse: 0.5277 - val_loss: 0.4810 - val_mse: 0.4742\n",
      "Epoch 267/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5349 - mse: 0.5282 - val_loss: 0.4808 - val_mse: 0.4741\n",
      "Epoch 268/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5354 - mse: 0.5286 - val_loss: 0.4832 - val_mse: 0.4764\n",
      "Epoch 269/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5319 - mse: 0.5251 - val_loss: 0.4923 - val_mse: 0.4856\n",
      "Epoch 270/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5343 - mse: 0.5275\n",
      "Epoch 00270: saving model to Regression_Model/snu398-0270.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5339 - mse: 0.5272 - val_loss: 0.4791 - val_mse: 0.4723\n",
      "Epoch 271/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5361 - mse: 0.5293 - val_loss: 0.4779 - val_mse: 0.4712\n",
      "Epoch 272/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5393 - mse: 0.5325 - val_loss: 0.4935 - val_mse: 0.4868\n",
      "Epoch 273/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5332 - mse: 0.5265 - val_loss: 0.4790 - val_mse: 0.4723\n",
      "Epoch 274/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5362 - mse: 0.5295 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 275/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5373 - mse: 0.5306 - val_loss: 0.4849 - val_mse: 0.4782\n",
      "Epoch 276/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5311 - mse: 0.5244 - val_loss: 0.4787 - val_mse: 0.4719\n",
      "Epoch 277/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5408 - mse: 0.5341 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 278/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5388 - mse: 0.5321 - val_loss: 0.4955 - val_mse: 0.4888\n",
      "Epoch 279/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5387 - mse: 0.5319 - val_loss: 0.4950 - val_mse: 0.4883\n",
      "Epoch 280/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5378 - mse: 0.5311\n",
      "Epoch 00280: saving model to Regression_Model/snu398-0280.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5392 - mse: 0.5325 - val_loss: 0.4843 - val_mse: 0.4776\n",
      "Epoch 281/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5372 - mse: 0.5305 - val_loss: 0.4790 - val_mse: 0.4723\n",
      "Epoch 282/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5329 - mse: 0.5262 - val_loss: 0.4819 - val_mse: 0.4752\n",
      "Epoch 283/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5389 - mse: 0.5322 - val_loss: 0.4847 - val_mse: 0.4780\n",
      "Epoch 284/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5366 - mse: 0.5299 - val_loss: 0.4809 - val_mse: 0.4743\n",
      "Epoch 285/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5342 - mse: 0.5275 - val_loss: 0.4941 - val_mse: 0.4874\n",
      "Epoch 286/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5330 - mse: 0.5263 - val_loss: 0.4772 - val_mse: 0.4705\n",
      "Epoch 287/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5404 - mse: 0.5338 - val_loss: 0.4774 - val_mse: 0.4707\n",
      "Epoch 288/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5354 - mse: 0.5287 - val_loss: 0.4800 - val_mse: 0.4733\n",
      "Epoch 289/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5364 - mse: 0.5298 - val_loss: 0.4854 - val_mse: 0.4787\n",
      "Epoch 290/1000\n",
      "515/524 [============================>.] - ETA: 0s - loss: 0.5346 - mse: 0.5279\n",
      "Epoch 00290: saving model to Regression_Model/snu398-0290.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5341 - mse: 0.5275 - val_loss: 0.4790 - val_mse: 0.4723\n",
      "Epoch 291/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5348 - mse: 0.5282 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 292/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5340 - mse: 0.5273 - val_loss: 0.4877 - val_mse: 0.4811\n",
      "Epoch 293/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5319 - mse: 0.5252 - val_loss: 0.4844 - val_mse: 0.4777\n",
      "Epoch 294/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5334 - mse: 0.5267 - val_loss: 0.4822 - val_mse: 0.4756\n",
      "Epoch 295/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5364 - mse: 0.5298 - val_loss: 0.4773 - val_mse: 0.4707\n",
      "Epoch 296/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5360 - mse: 0.5294 - val_loss: 0.4811 - val_mse: 0.4745\n",
      "Epoch 297/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5377 - mse: 0.5310 - val_loss: 0.4804 - val_mse: 0.4738\n",
      "Epoch 298/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5342 - mse: 0.5276 - val_loss: 0.4761 - val_mse: 0.4695\n",
      "Epoch 299/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5330 - mse: 0.5264 - val_loss: 0.4787 - val_mse: 0.4721\n",
      "Epoch 300/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5362 - mse: 0.5296\n",
      "Epoch 00300: saving model to Regression_Model/snu398-0300.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5365 - mse: 0.5299 - val_loss: 0.4911 - val_mse: 0.4845\n",
      "Epoch 301/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5338 - mse: 0.5272 - val_loss: 0.4781 - val_mse: 0.4714\n",
      "Epoch 302/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5337 - mse: 0.5271 - val_loss: 0.4773 - val_mse: 0.4707\n",
      "Epoch 303/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5298 - mse: 0.5232 - val_loss: 0.4883 - val_mse: 0.4817\n",
      "Epoch 304/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5340 - mse: 0.5274 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 305/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5275 - mse: 0.5209 - val_loss: 0.4787 - val_mse: 0.4721\n",
      "Epoch 306/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5352 - mse: 0.5286 - val_loss: 0.4858 - val_mse: 0.4792\n",
      "Epoch 307/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5324 - mse: 0.5258 - val_loss: 0.4781 - val_mse: 0.4715\n",
      "Epoch 308/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5321 - mse: 0.5255 - val_loss: 0.4821 - val_mse: 0.4756\n",
      "Epoch 309/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5351 - mse: 0.5285 - val_loss: 0.4813 - val_mse: 0.4747\n",
      "Epoch 310/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5276 - mse: 0.5211\n",
      "Epoch 00310: saving model to Regression_Model/snu398-0310.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5288 - mse: 0.5223 - val_loss: 0.4798 - val_mse: 0.4732\n",
      "Epoch 311/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5379 - mse: 0.5313 - val_loss: 0.4803 - val_mse: 0.4737\n",
      "Epoch 312/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5320 - mse: 0.5254 - val_loss: 0.4808 - val_mse: 0.4743\n",
      "Epoch 313/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5308 - mse: 0.5242 - val_loss: 0.4801 - val_mse: 0.4735\n",
      "Epoch 314/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5262 - mse: 0.5196 - val_loss: 0.4801 - val_mse: 0.4736\n",
      "Epoch 315/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5318 - mse: 0.5252 - val_loss: 0.4757 - val_mse: 0.4692\n",
      "Epoch 316/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5292 - mse: 0.5226 - val_loss: 0.4746 - val_mse: 0.4680\n",
      "Epoch 317/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5279 - mse: 0.5213 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 318/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5347 - mse: 0.5282 - val_loss: 0.4837 - val_mse: 0.4771\n",
      "Epoch 319/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5329 - mse: 0.5263 - val_loss: 0.4781 - val_mse: 0.4716\n",
      "Epoch 320/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.5339 - mse: 0.5274\n",
      "Epoch 00320: saving model to Regression_Model/snu398-0320.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5341 - mse: 0.5275 - val_loss: 0.4772 - val_mse: 0.4707\n",
      "Epoch 321/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5328 - mse: 0.5263 - val_loss: 0.4778 - val_mse: 0.4712\n",
      "Epoch 322/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5345 - mse: 0.5279 - val_loss: 0.4803 - val_mse: 0.4737\n",
      "Epoch 323/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5369 - mse: 0.5304 - val_loss: 0.4754 - val_mse: 0.4689\n",
      "Epoch 324/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5372 - mse: 0.5307 - val_loss: 0.4768 - val_mse: 0.4703\n",
      "Epoch 325/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5300 - mse: 0.5235 - val_loss: 0.4875 - val_mse: 0.4810\n",
      "Epoch 326/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5287 - mse: 0.5221 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 327/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5355 - mse: 0.5289 - val_loss: 0.4786 - val_mse: 0.4721\n",
      "Epoch 328/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5305 - mse: 0.5239 - val_loss: 0.4756 - val_mse: 0.4691\n",
      "Epoch 329/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5354 - mse: 0.5289 - val_loss: 0.4790 - val_mse: 0.4724\n",
      "Epoch 330/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.5357 - mse: 0.5292\n",
      "Epoch 00330: saving model to Regression_Model/snu398-0330.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5351 - mse: 0.5285 - val_loss: 0.4813 - val_mse: 0.4748\n",
      "Epoch 331/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5328 - mse: 0.5263 - val_loss: 0.4803 - val_mse: 0.4738\n",
      "Epoch 332/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5328 - mse: 0.5263 - val_loss: 0.4798 - val_mse: 0.4733\n",
      "Epoch 333/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5272 - mse: 0.5207 - val_loss: 0.4783 - val_mse: 0.4718\n",
      "Epoch 334/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5296 - mse: 0.5231 - val_loss: 0.4819 - val_mse: 0.4754\n",
      "Epoch 335/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5283 - mse: 0.5218 - val_loss: 0.4761 - val_mse: 0.4697\n",
      "Epoch 336/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5288 - mse: 0.5223 - val_loss: 0.4805 - val_mse: 0.4740\n",
      "Epoch 337/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5307 - mse: 0.5242 - val_loss: 0.4773 - val_mse: 0.4709\n",
      "Epoch 338/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5351 - mse: 0.5286 - val_loss: 0.4805 - val_mse: 0.4740\n",
      "Epoch 339/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5303 - mse: 0.5238 - val_loss: 0.4777 - val_mse: 0.4712\n",
      "Epoch 340/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5266 - mse: 0.5201\n",
      "Epoch 00340: saving model to Regression_Model/snu398-0340.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5265 - mse: 0.5200 - val_loss: 0.4819 - val_mse: 0.4754\n",
      "Epoch 341/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5338 - mse: 0.5273 - val_loss: 0.4793 - val_mse: 0.4729\n",
      "Epoch 342/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5322 - mse: 0.5257 - val_loss: 0.4837 - val_mse: 0.4773\n",
      "Epoch 343/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5270 - mse: 0.5205 - val_loss: 0.4749 - val_mse: 0.4684\n",
      "Epoch 344/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5374 - mse: 0.5309 - val_loss: 0.4778 - val_mse: 0.4714\n",
      "Epoch 345/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5348 - mse: 0.5283 - val_loss: 0.4918 - val_mse: 0.4854\n",
      "Epoch 346/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5313 - mse: 0.5249 - val_loss: 0.4757 - val_mse: 0.4692\n",
      "Epoch 347/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5316 - mse: 0.5251 - val_loss: 0.4817 - val_mse: 0.4752\n",
      "Epoch 348/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5310 - mse: 0.5246 - val_loss: 0.4747 - val_mse: 0.4682\n",
      "Epoch 349/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5263 - mse: 0.5199 - val_loss: 0.4823 - val_mse: 0.4758\n",
      "Epoch 350/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5346 - mse: 0.5281\n",
      "Epoch 00350: saving model to Regression_Model/snu398-0350.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5344 - mse: 0.5280 - val_loss: 0.4797 - val_mse: 0.4733\n",
      "Epoch 351/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5363 - mse: 0.5299 - val_loss: 0.4776 - val_mse: 0.4711\n",
      "Epoch 352/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5287 - mse: 0.5223 - val_loss: 0.4778 - val_mse: 0.4713\n",
      "Epoch 353/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5297 - mse: 0.5233 - val_loss: 0.4818 - val_mse: 0.4753\n",
      "Epoch 354/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5305 - mse: 0.5241 - val_loss: 0.4783 - val_mse: 0.4719\n",
      "Epoch 355/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5353 - mse: 0.5289 - val_loss: 0.4777 - val_mse: 0.4712\n",
      "Epoch 356/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5288 - mse: 0.5223 - val_loss: 0.4841 - val_mse: 0.4777\n",
      "Epoch 357/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5316 - mse: 0.5252 - val_loss: 0.4855 - val_mse: 0.4791\n",
      "Epoch 358/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5346 - mse: 0.5281 - val_loss: 0.4815 - val_mse: 0.4751\n",
      "Epoch 359/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5336 - mse: 0.5271 - val_loss: 0.4790 - val_mse: 0.4726\n",
      "Epoch 360/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5286 - mse: 0.5222\n",
      "Epoch 00360: saving model to Regression_Model/snu398-0360.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5284 - mse: 0.5220 - val_loss: 0.4826 - val_mse: 0.4762\n",
      "Epoch 361/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5316 - mse: 0.5252 - val_loss: 0.4829 - val_mse: 0.4765\n",
      "Epoch 362/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5247 - mse: 0.5183 - val_loss: 0.4836 - val_mse: 0.4772\n",
      "Epoch 363/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5312 - mse: 0.5248 - val_loss: 0.4784 - val_mse: 0.4720\n",
      "Epoch 364/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5316 - mse: 0.5252 - val_loss: 0.4844 - val_mse: 0.4781\n",
      "Epoch 365/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5351 - mse: 0.5287 - val_loss: 0.4822 - val_mse: 0.4759\n",
      "Epoch 366/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5337 - mse: 0.5273 - val_loss: 0.4820 - val_mse: 0.4757\n",
      "Epoch 367/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5309 - mse: 0.5245 - val_loss: 0.4739 - val_mse: 0.4675\n",
      "Epoch 368/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5296 - mse: 0.5233 - val_loss: 0.4754 - val_mse: 0.4690\n",
      "Epoch 369/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5270 - mse: 0.5206 - val_loss: 0.4771 - val_mse: 0.4707\n",
      "Epoch 370/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5278 - mse: 0.5214\n",
      "Epoch 00370: saving model to Regression_Model/snu398-0370.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5278 - mse: 0.5214 - val_loss: 0.4790 - val_mse: 0.4726\n",
      "Epoch 371/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5303 - mse: 0.5239 - val_loss: 0.4793 - val_mse: 0.4730\n",
      "Epoch 372/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5394 - mse: 0.5330 - val_loss: 0.4764 - val_mse: 0.4701\n",
      "Epoch 373/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5289 - mse: 0.5225 - val_loss: 0.4772 - val_mse: 0.4708\n",
      "Epoch 374/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5348 - mse: 0.5285 - val_loss: 0.4815 - val_mse: 0.4751\n",
      "Epoch 375/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5332 - mse: 0.5268 - val_loss: 0.4762 - val_mse: 0.4699\n",
      "Epoch 376/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5259 - mse: 0.5196 - val_loss: 0.4843 - val_mse: 0.4780\n",
      "Epoch 377/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5314 - mse: 0.5250 - val_loss: 0.4774 - val_mse: 0.4710\n",
      "Epoch 378/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5331 - mse: 0.5267 - val_loss: 0.4787 - val_mse: 0.4724\n",
      "Epoch 379/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5325 - mse: 0.5261 - val_loss: 0.4782 - val_mse: 0.4719\n",
      "Epoch 380/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5309 - mse: 0.5245\n",
      "Epoch 00380: saving model to Regression_Model/snu398-0380.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5301 - mse: 0.5237 - val_loss: 0.4786 - val_mse: 0.4723\n",
      "Epoch 381/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5352 - mse: 0.5289 - val_loss: 0.4820 - val_mse: 0.4757\n",
      "Epoch 382/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5304 - mse: 0.5241 - val_loss: 0.4788 - val_mse: 0.4725\n",
      "Epoch 383/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5335 - mse: 0.5272 - val_loss: 0.4768 - val_mse: 0.4704\n",
      "Epoch 384/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5322 - mse: 0.5259 - val_loss: 0.4838 - val_mse: 0.4774\n",
      "Epoch 385/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5335 - mse: 0.5272 - val_loss: 0.4750 - val_mse: 0.4687\n",
      "Epoch 386/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5312 - mse: 0.5249 - val_loss: 0.4797 - val_mse: 0.4733\n",
      "Epoch 387/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5315 - mse: 0.5252 - val_loss: 0.4750 - val_mse: 0.4686\n",
      "Epoch 388/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5382 - mse: 0.5318 - val_loss: 0.4790 - val_mse: 0.4726\n",
      "Epoch 389/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5307 - mse: 0.5244 - val_loss: 0.4794 - val_mse: 0.4731\n",
      "Epoch 390/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5361 - mse: 0.5298\n",
      "Epoch 00390: saving model to Regression_Model/snu398-0390.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5358 - mse: 0.5295 - val_loss: 0.4781 - val_mse: 0.4718\n",
      "Epoch 391/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5356 - mse: 0.5292 - val_loss: 0.4893 - val_mse: 0.4830\n",
      "Epoch 392/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5335 - mse: 0.5272 - val_loss: 0.4774 - val_mse: 0.4711\n",
      "Epoch 393/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5289 - mse: 0.5226 - val_loss: 0.4765 - val_mse: 0.4702\n",
      "Epoch 394/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5346 - mse: 0.5283 - val_loss: 0.4790 - val_mse: 0.4728\n",
      "Epoch 395/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5294 - mse: 0.5231 - val_loss: 0.4852 - val_mse: 0.4789\n",
      "Epoch 396/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5268 - mse: 0.5205 - val_loss: 0.4840 - val_mse: 0.4777\n",
      "Epoch 397/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5322 - mse: 0.5260 - val_loss: 0.4820 - val_mse: 0.4757\n",
      "Epoch 398/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5286 - mse: 0.5223 - val_loss: 0.4818 - val_mse: 0.4755\n",
      "Epoch 399/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5367 - mse: 0.5304 - val_loss: 0.4763 - val_mse: 0.4700\n",
      "Epoch 400/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5320 - mse: 0.5258\n",
      "Epoch 00400: saving model to Regression_Model/snu398-0400.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5327 - mse: 0.5264 - val_loss: 0.4827 - val_mse: 0.4764\n",
      "Epoch 401/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5347 - mse: 0.5284 - val_loss: 0.4750 - val_mse: 0.4687\n",
      "Epoch 402/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5335 - mse: 0.5272 - val_loss: 0.4790 - val_mse: 0.4728\n",
      "Epoch 403/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5291 - mse: 0.5228 - val_loss: 0.4774 - val_mse: 0.4712\n",
      "Epoch 404/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5285 - mse: 0.5222 - val_loss: 0.4765 - val_mse: 0.4702\n",
      "Epoch 405/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5304 - mse: 0.5241 - val_loss: 0.4821 - val_mse: 0.4758\n",
      "Epoch 406/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5274 - mse: 0.5211 - val_loss: 0.4781 - val_mse: 0.4719\n",
      "Epoch 407/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5319 - mse: 0.5256 - val_loss: 0.4766 - val_mse: 0.4703\n",
      "Epoch 408/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5310 - mse: 0.5248 - val_loss: 0.4782 - val_mse: 0.4720\n",
      "Epoch 409/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5283 - mse: 0.5221 - val_loss: 0.4812 - val_mse: 0.4750\n",
      "Epoch 410/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5314 - mse: 0.5252\n",
      "Epoch 00410: saving model to Regression_Model/snu398-0410.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5315 - mse: 0.5253 - val_loss: 0.4781 - val_mse: 0.4718\n",
      "Epoch 411/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5304 - mse: 0.5242 - val_loss: 0.4785 - val_mse: 0.4723\n",
      "Epoch 412/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5326 - mse: 0.5264 - val_loss: 0.4797 - val_mse: 0.4735\n",
      "Epoch 413/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5234 - mse: 0.5171 - val_loss: 0.4781 - val_mse: 0.4718\n",
      "Epoch 414/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5331 - mse: 0.5268 - val_loss: 0.4737 - val_mse: 0.4675\n",
      "Epoch 415/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5305 - mse: 0.5242 - val_loss: 0.4792 - val_mse: 0.4729\n",
      "Epoch 416/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5330 - mse: 0.5268 - val_loss: 0.4793 - val_mse: 0.4731\n",
      "Epoch 417/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5323 - mse: 0.5261 - val_loss: 0.4771 - val_mse: 0.4709\n",
      "Epoch 418/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5286 - mse: 0.5224 - val_loss: 0.4768 - val_mse: 0.4706\n",
      "Epoch 419/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5286 - mse: 0.5223 - val_loss: 0.4762 - val_mse: 0.4700\n",
      "Epoch 420/1000\n",
      "516/524 [============================>.] - ETA: 0s - loss: 0.5297 - mse: 0.5235\n",
      "Epoch 00420: saving model to Regression_Model/snu398-0420.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5301 - mse: 0.5239 - val_loss: 0.4762 - val_mse: 0.4700\n",
      "Epoch 421/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5286 - mse: 0.5224 - val_loss: 0.4866 - val_mse: 0.4804\n",
      "Epoch 422/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5271 - mse: 0.5208 - val_loss: 0.4758 - val_mse: 0.4696\n",
      "Epoch 423/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5302 - mse: 0.5240 - val_loss: 0.4795 - val_mse: 0.4732\n",
      "Epoch 424/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5234 - mse: 0.5172 - val_loss: 0.4755 - val_mse: 0.4693\n",
      "Epoch 425/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5289 - mse: 0.5227 - val_loss: 0.4752 - val_mse: 0.4690\n",
      "Epoch 426/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5283 - mse: 0.5221 - val_loss: 0.4802 - val_mse: 0.4740\n",
      "Epoch 427/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5278 - mse: 0.5216 - val_loss: 0.4784 - val_mse: 0.4722\n",
      "Epoch 428/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5240 - mse: 0.5178 - val_loss: 0.4773 - val_mse: 0.4711\n",
      "Epoch 429/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5251 - mse: 0.5189 - val_loss: 0.4775 - val_mse: 0.4713\n",
      "Epoch 430/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5300 - mse: 0.5238\n",
      "Epoch 00430: saving model to Regression_Model/snu398-0430.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5293 - mse: 0.5231 - val_loss: 0.4765 - val_mse: 0.4703\n",
      "Epoch 431/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5280 - mse: 0.5218 - val_loss: 0.4791 - val_mse: 0.4729\n",
      "Epoch 432/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5279 - mse: 0.5217 - val_loss: 0.4780 - val_mse: 0.4718\n",
      "Epoch 433/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5256 - mse: 0.5194 - val_loss: 0.4808 - val_mse: 0.4746\n",
      "Epoch 434/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5284 - mse: 0.5222 - val_loss: 0.4794 - val_mse: 0.4733\n",
      "Epoch 435/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5268 - mse: 0.5206 - val_loss: 0.4775 - val_mse: 0.4713\n",
      "Epoch 436/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5280 - mse: 0.5218 - val_loss: 0.4865 - val_mse: 0.4803\n",
      "Epoch 437/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5264 - mse: 0.5202 - val_loss: 0.4768 - val_mse: 0.4706\n",
      "Epoch 438/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5335 - mse: 0.5274 - val_loss: 0.4790 - val_mse: 0.4728\n",
      "Epoch 439/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5321 - mse: 0.5259 - val_loss: 0.4825 - val_mse: 0.4764\n",
      "Epoch 440/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5248 - mse: 0.5187\n",
      "Epoch 00440: saving model to Regression_Model/snu398-0440.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5251 - mse: 0.5190 - val_loss: 0.4773 - val_mse: 0.4711\n",
      "Epoch 441/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5336 - mse: 0.5274 - val_loss: 0.4781 - val_mse: 0.4720\n",
      "Epoch 442/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5253 - mse: 0.5191 - val_loss: 0.4795 - val_mse: 0.4733\n",
      "Epoch 443/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5302 - mse: 0.5240 - val_loss: 0.4757 - val_mse: 0.4695\n",
      "Epoch 444/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5233 - mse: 0.5171 - val_loss: 0.4748 - val_mse: 0.4686\n",
      "Epoch 445/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5321 - mse: 0.5259 - val_loss: 0.4794 - val_mse: 0.4733\n",
      "Epoch 446/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5311 - mse: 0.5249 - val_loss: 0.4768 - val_mse: 0.4706\n",
      "Epoch 447/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5334 - mse: 0.5273 - val_loss: 0.4771 - val_mse: 0.4710\n",
      "Epoch 448/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5285 - mse: 0.5223 - val_loss: 0.4793 - val_mse: 0.4732\n",
      "Epoch 449/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5286 - mse: 0.5224 - val_loss: 0.4747 - val_mse: 0.4686\n",
      "Epoch 450/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5316 - mse: 0.5255\n",
      "Epoch 00450: saving model to Regression_Model/snu398-0450.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5311 - mse: 0.5249 - val_loss: 0.4757 - val_mse: 0.4695\n",
      "Epoch 451/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5275 - mse: 0.5213 - val_loss: 0.4800 - val_mse: 0.4739\n",
      "Epoch 452/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5277 - mse: 0.5215 - val_loss: 0.4764 - val_mse: 0.4702\n",
      "Epoch 453/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5303 - mse: 0.5242 - val_loss: 0.4760 - val_mse: 0.4699\n",
      "Epoch 454/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5292 - mse: 0.5230 - val_loss: 0.4780 - val_mse: 0.4718\n",
      "Epoch 455/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5270 - mse: 0.5208 - val_loss: 0.4774 - val_mse: 0.4713\n",
      "Epoch 456/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5316 - mse: 0.5255 - val_loss: 0.4770 - val_mse: 0.4708\n",
      "Epoch 457/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5297 - mse: 0.5235 - val_loss: 0.4788 - val_mse: 0.4727\n",
      "Epoch 458/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5226 - mse: 0.5165 - val_loss: 0.4778 - val_mse: 0.4716\n",
      "Epoch 459/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5275 - mse: 0.5213 - val_loss: 0.4774 - val_mse: 0.4713\n",
      "Epoch 460/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5255 - mse: 0.5194\n",
      "Epoch 00460: saving model to Regression_Model/snu398-0460.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5248 - mse: 0.5187 - val_loss: 0.4795 - val_mse: 0.4734\n",
      "Epoch 461/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5316 - mse: 0.5254 - val_loss: 0.4795 - val_mse: 0.4733\n",
      "Epoch 462/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5309 - mse: 0.5248 - val_loss: 0.4733 - val_mse: 0.4672\n",
      "Epoch 463/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5306 - mse: 0.5245 - val_loss: 0.4804 - val_mse: 0.4743\n",
      "Epoch 464/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5284 - mse: 0.5223 - val_loss: 0.4800 - val_mse: 0.4739\n",
      "Epoch 465/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5268 - mse: 0.5207 - val_loss: 0.4792 - val_mse: 0.4731\n",
      "Epoch 466/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5319 - mse: 0.5258 - val_loss: 0.4758 - val_mse: 0.4697\n",
      "Epoch 467/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5320 - mse: 0.5259 - val_loss: 0.4774 - val_mse: 0.4713\n",
      "Epoch 468/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5278 - mse: 0.5217 - val_loss: 0.4806 - val_mse: 0.4745\n",
      "Epoch 469/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5269 - mse: 0.5208 - val_loss: 0.4831 - val_mse: 0.4770\n",
      "Epoch 470/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5220 - mse: 0.5159\n",
      "Epoch 00470: saving model to Regression_Model/snu398-0470.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5227 - mse: 0.5166 - val_loss: 0.4760 - val_mse: 0.4699\n",
      "Epoch 471/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5252 - mse: 0.5191 - val_loss: 0.4786 - val_mse: 0.4725\n",
      "Epoch 472/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5246 - mse: 0.5185 - val_loss: 0.4803 - val_mse: 0.4743\n",
      "Epoch 473/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5303 - mse: 0.5242 - val_loss: 0.4749 - val_mse: 0.4688\n",
      "Epoch 474/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5253 - mse: 0.5192 - val_loss: 0.4762 - val_mse: 0.4701\n",
      "Epoch 475/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5289 - mse: 0.5228 - val_loss: 0.4732 - val_mse: 0.4671\n",
      "Epoch 476/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5286 - mse: 0.5225 - val_loss: 0.4768 - val_mse: 0.4707\n",
      "Epoch 477/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5278 - mse: 0.5217 - val_loss: 0.4754 - val_mse: 0.4693\n",
      "Epoch 478/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5294 - mse: 0.5233 - val_loss: 0.4757 - val_mse: 0.4697\n",
      "Epoch 479/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5301 - mse: 0.5241 - val_loss: 0.4788 - val_mse: 0.4727\n",
      "Epoch 480/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5279 - mse: 0.5218\n",
      "Epoch 00480: saving model to Regression_Model/snu398-0480.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5285 - mse: 0.5224 - val_loss: 0.4768 - val_mse: 0.4707\n",
      "Epoch 481/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5300 - mse: 0.5240 - val_loss: 0.4827 - val_mse: 0.4767\n",
      "Epoch 482/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5274 - mse: 0.5213 - val_loss: 0.4766 - val_mse: 0.4706\n",
      "Epoch 483/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5302 - mse: 0.5242 - val_loss: 0.4770 - val_mse: 0.4710\n",
      "Epoch 484/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5313 - mse: 0.5252 - val_loss: 0.4800 - val_mse: 0.4739\n",
      "Epoch 485/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5266 - mse: 0.5205 - val_loss: 0.4794 - val_mse: 0.4733\n",
      "Epoch 486/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5277 - mse: 0.5216 - val_loss: 0.4786 - val_mse: 0.4726\n",
      "Epoch 487/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5276 - mse: 0.5216 - val_loss: 0.4772 - val_mse: 0.4711\n",
      "Epoch 488/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5302 - mse: 0.5241 - val_loss: 0.4780 - val_mse: 0.4719\n",
      "Epoch 489/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5299 - mse: 0.5239 - val_loss: 0.4761 - val_mse: 0.4700\n",
      "Epoch 490/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5235 - mse: 0.5174\n",
      "Epoch 00490: saving model to Regression_Model/snu398-0490.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5230 - mse: 0.5170 - val_loss: 0.4795 - val_mse: 0.4735\n",
      "Epoch 491/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5325 - mse: 0.5265 - val_loss: 0.4819 - val_mse: 0.4758\n",
      "Epoch 492/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5263 - mse: 0.5202 - val_loss: 0.4780 - val_mse: 0.4719\n",
      "Epoch 493/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5256 - mse: 0.5195 - val_loss: 0.4799 - val_mse: 0.4738\n",
      "Epoch 494/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5292 - mse: 0.5231 - val_loss: 0.4751 - val_mse: 0.4691\n",
      "Epoch 495/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5266 - mse: 0.5206 - val_loss: 0.4795 - val_mse: 0.4734\n",
      "Epoch 496/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5284 - mse: 0.5223 - val_loss: 0.4773 - val_mse: 0.4713\n",
      "Epoch 497/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5296 - mse: 0.5235 - val_loss: 0.4805 - val_mse: 0.4745\n",
      "Epoch 498/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5230 - mse: 0.5170 - val_loss: 0.4772 - val_mse: 0.4712\n",
      "Epoch 499/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5276 - mse: 0.5215 - val_loss: 0.4787 - val_mse: 0.4727\n",
      "Epoch 500/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5214 - mse: 0.5153\n",
      "Epoch 00500: saving model to Regression_Model/snu398-0500.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5213 - mse: 0.5153 - val_loss: 0.4782 - val_mse: 0.4721\n",
      "Epoch 501/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5249 - mse: 0.5188 - val_loss: 0.4768 - val_mse: 0.4708\n",
      "Epoch 502/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5275 - mse: 0.5214 - val_loss: 0.4778 - val_mse: 0.4717\n",
      "Epoch 503/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5261 - mse: 0.5201 - val_loss: 0.4758 - val_mse: 0.4698\n",
      "Epoch 504/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5277 - mse: 0.5216 - val_loss: 0.4786 - val_mse: 0.4726\n",
      "Epoch 505/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5265 - mse: 0.5205 - val_loss: 0.4760 - val_mse: 0.4699\n",
      "Epoch 506/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5295 - mse: 0.5235 - val_loss: 0.4810 - val_mse: 0.4750\n",
      "Epoch 507/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5288 - mse: 0.5228 - val_loss: 0.4779 - val_mse: 0.4719\n",
      "Epoch 508/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5354 - mse: 0.5294 - val_loss: 0.4757 - val_mse: 0.4697\n",
      "Epoch 509/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5262 - mse: 0.5202 - val_loss: 0.4797 - val_mse: 0.4737\n",
      "Epoch 510/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5216 - mse: 0.5156\n",
      "Epoch 00510: saving model to Regression_Model/snu398-0510.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5222 - mse: 0.5162 - val_loss: 0.4771 - val_mse: 0.4711\n",
      "Epoch 511/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5307 - mse: 0.5247 - val_loss: 0.4803 - val_mse: 0.4742\n",
      "Epoch 512/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5258 - mse: 0.5198 - val_loss: 0.4769 - val_mse: 0.4709\n",
      "Epoch 513/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5280 - mse: 0.5220 - val_loss: 0.4801 - val_mse: 0.4741\n",
      "Epoch 514/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5284 - mse: 0.5224 - val_loss: 0.4808 - val_mse: 0.4748\n",
      "Epoch 515/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5285 - mse: 0.5225 - val_loss: 0.4754 - val_mse: 0.4694\n",
      "Epoch 516/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5258 - mse: 0.5198 - val_loss: 0.4779 - val_mse: 0.4719\n",
      "Epoch 517/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5267 - mse: 0.5208 - val_loss: 0.4779 - val_mse: 0.4719\n",
      "Epoch 518/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5272 - mse: 0.5212 - val_loss: 0.4829 - val_mse: 0.4769\n",
      "Epoch 519/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5301 - mse: 0.5241 - val_loss: 0.4754 - val_mse: 0.4694\n",
      "Epoch 520/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5278 - mse: 0.5219\n",
      "Epoch 00520: saving model to Regression_Model/snu398-0520.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5274 - mse: 0.5215 - val_loss: 0.4785 - val_mse: 0.4725\n",
      "Epoch 521/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5264 - mse: 0.5204 - val_loss: 0.4750 - val_mse: 0.4690\n",
      "Epoch 522/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5252 - mse: 0.5192 - val_loss: 0.4773 - val_mse: 0.4713\n",
      "Epoch 523/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5301 - mse: 0.5241 - val_loss: 0.4760 - val_mse: 0.4700\n",
      "Epoch 524/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5308 - mse: 0.5248 - val_loss: 0.4756 - val_mse: 0.4696\n",
      "Epoch 525/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5338 - mse: 0.5278 - val_loss: 0.4787 - val_mse: 0.4727\n",
      "Epoch 526/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5232 - mse: 0.5172 - val_loss: 0.4753 - val_mse: 0.4693\n",
      "Epoch 527/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5262 - mse: 0.5202 - val_loss: 0.4768 - val_mse: 0.4708\n",
      "Epoch 528/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5296 - mse: 0.5237 - val_loss: 0.4767 - val_mse: 0.4707\n",
      "Epoch 529/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5268 - mse: 0.5208 - val_loss: 0.4768 - val_mse: 0.4708\n",
      "Epoch 530/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5308 - mse: 0.5248\n",
      "Epoch 00530: saving model to Regression_Model/snu398-0530.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5316 - mse: 0.5256 - val_loss: 0.4769 - val_mse: 0.4709\n",
      "Epoch 531/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5254 - mse: 0.5195 - val_loss: 0.4771 - val_mse: 0.4712\n",
      "Epoch 532/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5239 - mse: 0.5179 - val_loss: 0.4757 - val_mse: 0.4697\n",
      "Epoch 533/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5260 - mse: 0.5200 - val_loss: 0.4754 - val_mse: 0.4695\n",
      "Epoch 534/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5255 - mse: 0.5195 - val_loss: 0.4729 - val_mse: 0.4670\n",
      "Epoch 535/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5269 - mse: 0.5209 - val_loss: 0.4755 - val_mse: 0.4695\n",
      "Epoch 536/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5307 - mse: 0.5247 - val_loss: 0.4774 - val_mse: 0.4714\n",
      "Epoch 537/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5320 - mse: 0.5261 - val_loss: 0.4784 - val_mse: 0.4724\n",
      "Epoch 538/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5197 - mse: 0.5137 - val_loss: 0.4763 - val_mse: 0.4703\n",
      "Epoch 539/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5252 - mse: 0.5192 - val_loss: 0.4773 - val_mse: 0.4713\n",
      "Epoch 540/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.5247 - mse: 0.5188\n",
      "Epoch 00540: saving model to Regression_Model/snu398-0540.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5267 - mse: 0.5207 - val_loss: 0.4773 - val_mse: 0.4713\n",
      "Epoch 541/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5219 - mse: 0.5160 - val_loss: 0.4770 - val_mse: 0.4711\n",
      "Epoch 542/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5264 - mse: 0.5205 - val_loss: 0.4771 - val_mse: 0.4712\n",
      "Epoch 543/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5284 - mse: 0.5224 - val_loss: 0.4789 - val_mse: 0.4730\n",
      "Epoch 544/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5287 - mse: 0.5227 - val_loss: 0.4751 - val_mse: 0.4692\n",
      "Epoch 545/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5302 - mse: 0.5242 - val_loss: 0.4772 - val_mse: 0.4712\n",
      "Epoch 546/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5253 - mse: 0.5194 - val_loss: 0.4759 - val_mse: 0.4700\n",
      "Epoch 547/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5257 - mse: 0.5198 - val_loss: 0.4754 - val_mse: 0.4695\n",
      "Epoch 548/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5319 - mse: 0.5260 - val_loss: 0.4786 - val_mse: 0.4727\n",
      "Epoch 549/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5262 - mse: 0.5203 - val_loss: 0.4761 - val_mse: 0.4702\n",
      "Epoch 550/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5243 - mse: 0.5183\n",
      "Epoch 00550: saving model to Regression_Model/snu398-0550.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5245 - mse: 0.5186 - val_loss: 0.4762 - val_mse: 0.4703\n",
      "Epoch 551/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5308 - mse: 0.5249 - val_loss: 0.4774 - val_mse: 0.4715\n",
      "Epoch 552/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5227 - mse: 0.5168 - val_loss: 0.4743 - val_mse: 0.4684\n",
      "Epoch 553/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5292 - mse: 0.5233 - val_loss: 0.4791 - val_mse: 0.4731\n",
      "Epoch 554/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5254 - mse: 0.5195 - val_loss: 0.4745 - val_mse: 0.4686\n",
      "Epoch 555/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5300 - mse: 0.5241 - val_loss: 0.4754 - val_mse: 0.4695\n",
      "Epoch 556/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5279 - mse: 0.5220 - val_loss: 0.4771 - val_mse: 0.4712\n",
      "Epoch 557/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5250 - mse: 0.5191 - val_loss: 0.4758 - val_mse: 0.4698\n",
      "Epoch 558/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5280 - mse: 0.5221 - val_loss: 0.4773 - val_mse: 0.4714\n",
      "Epoch 559/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5253 - mse: 0.5193 - val_loss: 0.4777 - val_mse: 0.4718\n",
      "Epoch 560/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5248 - mse: 0.5189\n",
      "Epoch 00560: saving model to Regression_Model/snu398-0560.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5255 - mse: 0.5196 - val_loss: 0.4784 - val_mse: 0.4725\n",
      "Epoch 561/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5261 - mse: 0.5202 - val_loss: 0.4775 - val_mse: 0.4716\n",
      "Epoch 562/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5230 - mse: 0.5171 - val_loss: 0.4783 - val_mse: 0.4724\n",
      "Epoch 563/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5247 - mse: 0.5188 - val_loss: 0.4764 - val_mse: 0.4705\n",
      "Epoch 564/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5259 - mse: 0.5200 - val_loss: 0.4764 - val_mse: 0.4705\n",
      "Epoch 565/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5211 - mse: 0.5152 - val_loss: 0.4793 - val_mse: 0.4734\n",
      "Epoch 566/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5281 - mse: 0.5222 - val_loss: 0.4822 - val_mse: 0.4763\n",
      "Epoch 567/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5180 - mse: 0.5121 - val_loss: 0.4730 - val_mse: 0.4671\n",
      "Epoch 568/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5241 - mse: 0.5182 - val_loss: 0.4765 - val_mse: 0.4706\n",
      "Epoch 569/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5258 - mse: 0.5199 - val_loss: 0.4752 - val_mse: 0.4693\n",
      "Epoch 570/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5216 - mse: 0.5157\n",
      "Epoch 00570: saving model to Regression_Model/snu398-0570.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5214 - mse: 0.5155 - val_loss: 0.4782 - val_mse: 0.4723\n",
      "Epoch 571/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5259 - mse: 0.5200 - val_loss: 0.4781 - val_mse: 0.4722\n",
      "Epoch 572/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5250 - mse: 0.5191 - val_loss: 0.4749 - val_mse: 0.4690\n",
      "Epoch 573/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5180 - mse: 0.5121 - val_loss: 0.4736 - val_mse: 0.4678\n",
      "Epoch 574/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5225 - mse: 0.5166 - val_loss: 0.4778 - val_mse: 0.4720\n",
      "Epoch 575/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5245 - mse: 0.5187 - val_loss: 0.4771 - val_mse: 0.4712\n",
      "Epoch 576/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5250 - mse: 0.5191 - val_loss: 0.4780 - val_mse: 0.4721\n",
      "Epoch 577/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5290 - mse: 0.5231 - val_loss: 0.4783 - val_mse: 0.4724\n",
      "Epoch 578/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5273 - mse: 0.5214 - val_loss: 0.4792 - val_mse: 0.4734\n",
      "Epoch 579/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5189 - mse: 0.5130 - val_loss: 0.4773 - val_mse: 0.4714\n",
      "Epoch 580/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5246 - mse: 0.5187\n",
      "Epoch 00580: saving model to Regression_Model/snu398-0580.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5242 - mse: 0.5184 - val_loss: 0.4749 - val_mse: 0.4691\n",
      "Epoch 581/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5278 - mse: 0.5219 - val_loss: 0.4773 - val_mse: 0.4714\n",
      "Epoch 582/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5186 - mse: 0.5128 - val_loss: 0.4740 - val_mse: 0.4681\n",
      "Epoch 583/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5226 - mse: 0.5167 - val_loss: 0.4741 - val_mse: 0.4683\n",
      "Epoch 584/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5302 - mse: 0.5243 - val_loss: 0.4738 - val_mse: 0.4679\n",
      "Epoch 585/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5230 - mse: 0.5171 - val_loss: 0.4760 - val_mse: 0.4701\n",
      "Epoch 586/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5267 - mse: 0.5209 - val_loss: 0.4766 - val_mse: 0.4707\n",
      "Epoch 587/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5246 - mse: 0.5188 - val_loss: 0.4779 - val_mse: 0.4720\n",
      "Epoch 588/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5259 - mse: 0.5200 - val_loss: 0.4759 - val_mse: 0.4700\n",
      "Epoch 589/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5270 - mse: 0.5211 - val_loss: 0.4766 - val_mse: 0.4708\n",
      "Epoch 590/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5253 - mse: 0.5194\n",
      "Epoch 00590: saving model to Regression_Model/snu398-0590.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5244 - mse: 0.5186 - val_loss: 0.4749 - val_mse: 0.4691\n",
      "Epoch 591/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5255 - mse: 0.5197 - val_loss: 0.4786 - val_mse: 0.4728\n",
      "Epoch 592/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5245 - mse: 0.5187 - val_loss: 0.4779 - val_mse: 0.4721\n",
      "Epoch 593/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5247 - mse: 0.5188 - val_loss: 0.4764 - val_mse: 0.4705\n",
      "Epoch 594/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5227 - mse: 0.5169 - val_loss: 0.4768 - val_mse: 0.4710\n",
      "Epoch 595/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5262 - mse: 0.5203 - val_loss: 0.4790 - val_mse: 0.4732\n",
      "Epoch 596/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5266 - mse: 0.5207 - val_loss: 0.4737 - val_mse: 0.4678\n",
      "Epoch 597/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5267 - mse: 0.5209 - val_loss: 0.4745 - val_mse: 0.4686\n",
      "Epoch 598/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5256 - mse: 0.5198 - val_loss: 0.4739 - val_mse: 0.4680\n",
      "Epoch 599/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5278 - mse: 0.5220 - val_loss: 0.4741 - val_mse: 0.4682\n",
      "Epoch 600/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5224 - mse: 0.5165\n",
      "Epoch 00600: saving model to Regression_Model/snu398-0600.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5219 - mse: 0.5160 - val_loss: 0.4768 - val_mse: 0.4710\n",
      "Epoch 601/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5223 - mse: 0.5165 - val_loss: 0.4776 - val_mse: 0.4718\n",
      "Epoch 602/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5312 - mse: 0.5253 - val_loss: 0.4808 - val_mse: 0.4750\n",
      "Epoch 603/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5234 - mse: 0.5176 - val_loss: 0.4753 - val_mse: 0.4695\n",
      "Epoch 604/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5293 - mse: 0.5235 - val_loss: 0.4788 - val_mse: 0.4730\n",
      "Epoch 605/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5224 - mse: 0.5166 - val_loss: 0.4725 - val_mse: 0.4667\n",
      "Epoch 606/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5247 - mse: 0.5189 - val_loss: 0.4759 - val_mse: 0.4701\n",
      "Epoch 607/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5246 - mse: 0.5188 - val_loss: 0.4768 - val_mse: 0.4710\n",
      "Epoch 608/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5140 - mse: 0.5082 - val_loss: 0.4752 - val_mse: 0.4694\n",
      "Epoch 609/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5195 - mse: 0.5137 - val_loss: 0.4792 - val_mse: 0.4734\n",
      "Epoch 610/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5235 - mse: 0.5177\n",
      "Epoch 00610: saving model to Regression_Model/snu398-0610.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5237 - mse: 0.5179 - val_loss: 0.4769 - val_mse: 0.4711\n",
      "Epoch 611/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5246 - mse: 0.5188 - val_loss: 0.4750 - val_mse: 0.4692\n",
      "Epoch 612/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5251 - mse: 0.5193 - val_loss: 0.4755 - val_mse: 0.4696\n",
      "Epoch 613/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5233 - mse: 0.5175 - val_loss: 0.4766 - val_mse: 0.4708\n",
      "Epoch 614/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5245 - mse: 0.5187 - val_loss: 0.4768 - val_mse: 0.4710\n",
      "Epoch 615/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5250 - mse: 0.5192 - val_loss: 0.4768 - val_mse: 0.4709\n",
      "Epoch 616/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5233 - mse: 0.5175 - val_loss: 0.4737 - val_mse: 0.4679\n",
      "Epoch 617/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5270 - mse: 0.5212 - val_loss: 0.4814 - val_mse: 0.4756\n",
      "Epoch 618/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5206 - mse: 0.5148 - val_loss: 0.4749 - val_mse: 0.4691\n",
      "Epoch 619/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5258 - mse: 0.5200 - val_loss: 0.4739 - val_mse: 0.4681\n",
      "Epoch 620/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5262 - mse: 0.5204\n",
      "Epoch 00620: saving model to Regression_Model/snu398-0620.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5263 - mse: 0.5205 - val_loss: 0.4757 - val_mse: 0.4699\n",
      "Epoch 621/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5229 - mse: 0.5171 - val_loss: 0.4753 - val_mse: 0.4695\n",
      "Epoch 622/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5207 - mse: 0.5149 - val_loss: 0.4766 - val_mse: 0.4708\n",
      "Epoch 623/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5223 - mse: 0.5164 - val_loss: 0.4750 - val_mse: 0.4692\n",
      "Epoch 624/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5238 - mse: 0.5180 - val_loss: 0.4754 - val_mse: 0.4696\n",
      "Epoch 625/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5251 - mse: 0.5193 - val_loss: 0.4762 - val_mse: 0.4704\n",
      "Epoch 626/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5204 - mse: 0.5146 - val_loss: 0.4748 - val_mse: 0.4690\n",
      "Epoch 627/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5226 - mse: 0.5168 - val_loss: 0.4751 - val_mse: 0.4693\n",
      "Epoch 628/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5243 - mse: 0.5185 - val_loss: 0.4749 - val_mse: 0.4691\n",
      "Epoch 629/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5183 - mse: 0.5125 - val_loss: 0.4734 - val_mse: 0.4676\n",
      "Epoch 630/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5224 - mse: 0.5166\n",
      "Epoch 00630: saving model to Regression_Model/snu398-0630.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5222 - mse: 0.5164 - val_loss: 0.4750 - val_mse: 0.4692\n",
      "Epoch 631/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5263 - mse: 0.5205 - val_loss: 0.4753 - val_mse: 0.4695\n",
      "Epoch 632/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5237 - mse: 0.5179 - val_loss: 0.4745 - val_mse: 0.4687\n",
      "Epoch 633/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5258 - mse: 0.5201 - val_loss: 0.4791 - val_mse: 0.4733\n",
      "Epoch 634/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5236 - mse: 0.5178 - val_loss: 0.4738 - val_mse: 0.4680\n",
      "Epoch 635/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5269 - mse: 0.5211 - val_loss: 0.4754 - val_mse: 0.4696\n",
      "Epoch 636/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5249 - mse: 0.5191 - val_loss: 0.4756 - val_mse: 0.4698\n",
      "Epoch 637/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5237 - mse: 0.5179 - val_loss: 0.4777 - val_mse: 0.4720\n",
      "Epoch 638/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5217 - mse: 0.5159 - val_loss: 0.4767 - val_mse: 0.4709\n",
      "Epoch 639/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5252 - mse: 0.5194 - val_loss: 0.4773 - val_mse: 0.4715\n",
      "Epoch 640/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5274 - mse: 0.5216\n",
      "Epoch 00640: saving model to Regression_Model/snu398-0640.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5267 - mse: 0.5209 - val_loss: 0.4762 - val_mse: 0.4704\n",
      "Epoch 641/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5248 - mse: 0.5190 - val_loss: 0.4749 - val_mse: 0.4691\n",
      "Epoch 642/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5203 - mse: 0.5145 - val_loss: 0.4759 - val_mse: 0.4702\n",
      "Epoch 643/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5262 - mse: 0.5204 - val_loss: 0.4789 - val_mse: 0.4731\n",
      "Epoch 644/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5273 - mse: 0.5215 - val_loss: 0.4744 - val_mse: 0.4686\n",
      "Epoch 645/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5164 - mse: 0.5106 - val_loss: 0.4781 - val_mse: 0.4723\n",
      "Epoch 646/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5264 - mse: 0.5206 - val_loss: 0.4772 - val_mse: 0.4715\n",
      "Epoch 647/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5201 - mse: 0.5143 - val_loss: 0.4744 - val_mse: 0.4686\n",
      "Epoch 648/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5277 - mse: 0.5219 - val_loss: 0.4751 - val_mse: 0.4693\n",
      "Epoch 649/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5243 - mse: 0.5186 - val_loss: 0.4779 - val_mse: 0.4721\n",
      "Epoch 650/1000\n",
      "517/524 [============================>.] - ETA: 0s - loss: 0.5213 - mse: 0.5156\n",
      "Epoch 00650: saving model to Regression_Model/snu398-0650.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5216 - mse: 0.5158 - val_loss: 0.4776 - val_mse: 0.4718\n",
      "Epoch 651/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5263 - mse: 0.5205 - val_loss: 0.4744 - val_mse: 0.4686\n",
      "Epoch 652/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5228 - mse: 0.5171 - val_loss: 0.4745 - val_mse: 0.4687\n",
      "Epoch 653/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5245 - mse: 0.5187 - val_loss: 0.4753 - val_mse: 0.4695\n",
      "Epoch 654/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5245 - mse: 0.5187 - val_loss: 0.4755 - val_mse: 0.4697\n",
      "Epoch 655/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5247 - mse: 0.5190 - val_loss: 0.4761 - val_mse: 0.4704\n",
      "Epoch 656/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5222 - mse: 0.5164 - val_loss: 0.4768 - val_mse: 0.4711\n",
      "Epoch 657/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5239 - mse: 0.5181 - val_loss: 0.4782 - val_mse: 0.4725\n",
      "Epoch 658/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5224 - mse: 0.5166 - val_loss: 0.4753 - val_mse: 0.4695\n",
      "Epoch 659/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5220 - mse: 0.5163 - val_loss: 0.4752 - val_mse: 0.4695\n",
      "Epoch 660/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5248 - mse: 0.5191\n",
      "Epoch 00660: saving model to Regression_Model/snu398-0660.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5241 - mse: 0.5183 - val_loss: 0.4778 - val_mse: 0.4721\n",
      "Epoch 661/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5221 - mse: 0.5163 - val_loss: 0.4831 - val_mse: 0.4773\n",
      "Epoch 662/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5242 - mse: 0.5185 - val_loss: 0.4748 - val_mse: 0.4690\n",
      "Epoch 663/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5266 - mse: 0.5208 - val_loss: 0.4762 - val_mse: 0.4705\n",
      "Epoch 664/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5255 - mse: 0.5198 - val_loss: 0.4742 - val_mse: 0.4684\n",
      "Epoch 665/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5207 - mse: 0.5149 - val_loss: 0.4727 - val_mse: 0.4669\n",
      "Epoch 666/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5245 - mse: 0.5188 - val_loss: 0.4752 - val_mse: 0.4695\n",
      "Epoch 667/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5247 - mse: 0.5190 - val_loss: 0.4776 - val_mse: 0.4719\n",
      "Epoch 668/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5226 - mse: 0.5168 - val_loss: 0.4744 - val_mse: 0.4686\n",
      "Epoch 669/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5239 - mse: 0.5182 - val_loss: 0.4765 - val_mse: 0.4707\n",
      "Epoch 670/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5229 - mse: 0.5171\n",
      "Epoch 00670: saving model to Regression_Model/snu398-0670.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5227 - mse: 0.5169 - val_loss: 0.4742 - val_mse: 0.4685\n",
      "Epoch 671/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5249 - mse: 0.5191 - val_loss: 0.4769 - val_mse: 0.4711\n",
      "Epoch 672/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5241 - mse: 0.5184 - val_loss: 0.4749 - val_mse: 0.4692\n",
      "Epoch 673/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5189 - mse: 0.5132 - val_loss: 0.4773 - val_mse: 0.4716\n",
      "Epoch 674/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5241 - mse: 0.5184 - val_loss: 0.4726 - val_mse: 0.4668\n",
      "Epoch 675/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5287 - mse: 0.5230 - val_loss: 0.4752 - val_mse: 0.4695\n",
      "Epoch 676/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5218 - mse: 0.5161 - val_loss: 0.4754 - val_mse: 0.4697\n",
      "Epoch 677/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5244 - mse: 0.5187 - val_loss: 0.4787 - val_mse: 0.4730\n",
      "Epoch 678/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5285 - mse: 0.5228 - val_loss: 0.4782 - val_mse: 0.4724\n",
      "Epoch 679/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5183 - mse: 0.5126 - val_loss: 0.4791 - val_mse: 0.4734\n",
      "Epoch 680/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5199 - mse: 0.5141\n",
      "Epoch 00680: saving model to Regression_Model/snu398-0680.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5200 - mse: 0.5143 - val_loss: 0.4747 - val_mse: 0.4689\n",
      "Epoch 681/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5237 - mse: 0.5180 - val_loss: 0.4783 - val_mse: 0.4725\n",
      "Epoch 682/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5225 - mse: 0.5168 - val_loss: 0.4766 - val_mse: 0.4708\n",
      "Epoch 683/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5235 - mse: 0.5177 - val_loss: 0.4799 - val_mse: 0.4741\n",
      "Epoch 684/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5240 - mse: 0.5183 - val_loss: 0.4762 - val_mse: 0.4705\n",
      "Epoch 685/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5217 - mse: 0.5159 - val_loss: 0.4769 - val_mse: 0.4712\n",
      "Epoch 686/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5251 - mse: 0.5193 - val_loss: 0.4724 - val_mse: 0.4667\n",
      "Epoch 687/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5270 - mse: 0.5212 - val_loss: 0.4792 - val_mse: 0.4735\n",
      "Epoch 688/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5237 - mse: 0.5179 - val_loss: 0.4759 - val_mse: 0.4701\n",
      "Epoch 689/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5269 - mse: 0.5212 - val_loss: 0.4726 - val_mse: 0.4668\n",
      "Epoch 690/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5262 - mse: 0.5204\n",
      "Epoch 00690: saving model to Regression_Model/snu398-0690.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5268 - mse: 0.5211 - val_loss: 0.4767 - val_mse: 0.4710\n",
      "Epoch 691/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5286 - mse: 0.5229 - val_loss: 0.4776 - val_mse: 0.4719\n",
      "Epoch 692/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5202 - mse: 0.5144 - val_loss: 0.4744 - val_mse: 0.4687\n",
      "Epoch 693/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5235 - mse: 0.5178 - val_loss: 0.4779 - val_mse: 0.4722\n",
      "Epoch 694/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5250 - mse: 0.5193 - val_loss: 0.4747 - val_mse: 0.4690\n",
      "Epoch 695/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5217 - mse: 0.5160 - val_loss: 0.4747 - val_mse: 0.4690\n",
      "Epoch 696/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5208 - mse: 0.5151 - val_loss: 0.4753 - val_mse: 0.4696\n",
      "Epoch 697/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5312 - mse: 0.5255 - val_loss: 0.4770 - val_mse: 0.4713\n",
      "Epoch 698/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5192 - mse: 0.5135 - val_loss: 0.4759 - val_mse: 0.4702\n",
      "Epoch 699/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5211 - mse: 0.5154 - val_loss: 0.4781 - val_mse: 0.4724\n",
      "Epoch 700/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5250 - mse: 0.5193\n",
      "Epoch 00700: saving model to Regression_Model/snu398-0700.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5255 - mse: 0.5198 - val_loss: 0.4808 - val_mse: 0.4751\n",
      "Epoch 701/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5240 - mse: 0.5183 - val_loss: 0.4763 - val_mse: 0.4706\n",
      "Epoch 702/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5256 - mse: 0.5199 - val_loss: 0.4759 - val_mse: 0.4702\n",
      "Epoch 703/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5266 - mse: 0.5209 - val_loss: 0.4755 - val_mse: 0.4698\n",
      "Epoch 704/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5228 - mse: 0.5171 - val_loss: 0.4772 - val_mse: 0.4715\n",
      "Epoch 705/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5200 - mse: 0.5142 - val_loss: 0.4749 - val_mse: 0.4692\n",
      "Epoch 706/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5230 - mse: 0.5173 - val_loss: 0.4747 - val_mse: 0.4690\n",
      "Epoch 707/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5231 - mse: 0.5174 - val_loss: 0.4763 - val_mse: 0.4706\n",
      "Epoch 708/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5222 - mse: 0.5165 - val_loss: 0.4755 - val_mse: 0.4698\n",
      "Epoch 709/1000\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5235 - mse: 0.5178 - val_loss: 0.4759 - val_mse: 0.4702\n",
      "Epoch 710/1000\n",
      "518/524 [============================>.] - ETA: 0s - loss: 0.5211 - mse: 0.5154\n",
      "Epoch 00710: saving model to Regression_Model/snu398-0710.ckpt\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.5213 - mse: 0.5156 - val_loss: 0.4765 - val_mse: 0.4708\n",
      "Epoch 711/1000\n",
      "353/524 [===================>..........] - ETA: 0s - loss: 0.5121 - mse: 0.5064"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-84a410e59eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=1000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,MODEL_PATH,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    \n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_rpm\\tpolyA_rpm\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train_data,train_labels,data_mean,data_std,label_mean,label_std):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    return train_data,train_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 20991\n"
     ]
    }
   ],
   "source": [
    "LENGTH = 1001\n",
    "model = Regression_CNN(LENGTH)\n",
    "trainid='snu398_'+str(LENGTH)\n",
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = \\\n",
    "prep_data('coverage_data/snu398.gt.gt.txt',5,7.8)\n",
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = \\\n",
    "normalization(train_data,train_labels,valid_data,valid_labels)\n",
    "#evaluate(train_x,train_y,train_id,MODEL_PATH,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate(valid_x,valid_y,valid_id,MODEL_PATH,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 20991\n",
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "bestEpoch = '0600'\n",
    "MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "#MODEL_PATH = '../APAIQ2/model/snu398_regression.ckpt'\n",
    "train_data1,train_labels1,train_pasid1,valid_data1,valid_labels1,valid_pasid1 = \\\n",
    "prep_data('coverage_data/snu398.gt.gt.txt',5,7.8)\n",
    "#prep_data('coverage_data/K562.predicted.txt',5,33.3)\n",
    "\n",
    "x=np.concatenate((train_data1, valid_data1), axis=0)\n",
    "y=np.concatenate((train_labels1, valid_labels1), axis=0)\n",
    "pasid=np.concatenate((train_pasid1, valid_pasid1), axis=0)\n",
    "#data_mean=-1.511\n",
    "#data_std=1.437\n",
    "#label_mean=2.473\n",
    "#label_std=1.518\n",
    "x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)\n",
    "evaluate(x,y,pasid,MODEL_PATH,'test'+str(LENGTH),label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/thle2_control.pAs.usage.txt',5)\n",
    "train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/Finetune.snu398_control.usage.txt',5)\n",
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='thle2.mle.linear'\n",
    "bestEpoch = '0980'\n",
    "evaluate(train_x,train_y,train_pasid,testid,'train',label_mean,label_std,bestEpoch)\n",
    "evaluate(valid_x,valid_y,valid_pasid,testid,'valid',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1(x,y,pasid,trainid,dataset,label_mean,label_std,bestEpoch=2000):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)-1\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)-1\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prep_data() missing 1 required positional argument: 'depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-258c38ac16ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_pasid1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_data1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_labels1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_pasid1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coverage_data/all.snu398_control.usage.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpasid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pasid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_pasid1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: prep_data() missing 1 required positional argument: 'depth'"
     ]
    }
   ],
   "source": [
    "train_data1,train_labels1,train_pasid1,valid_data1,valid_labels1,valid_pasid1 = prep_data('coverage_data/all.snu398_control.usage.txt',5)\n",
    "x=np.concatenate((train_data1, valid_data1), axis=0)\n",
    "y=np.concatenate((train_labels1, valid_labels1), axis=0)\n",
    "pasid=np.concatenate((train_pasid1, valid_pasid1), axis=0)\n",
    "x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='Regression.f_snu398.shift16.1001'\n",
    "bestEpoch = '2000'\n",
    "evaluate1(x,y,pasid,testid,'all',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((train_pasid1, valid_pasid1), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[3,4,5,6]\n",
    "a.remove(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(a == None):\n",
    "    print('fafa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'chromosme,start,end,score,id,strand\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,c,d = a.split(',')[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
