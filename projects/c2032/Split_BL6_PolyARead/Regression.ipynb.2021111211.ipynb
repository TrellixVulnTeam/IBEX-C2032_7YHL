{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.23.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = MaxPooling1D(pool_size = 12)(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "group_normalization (GroupNo (None, 990, 16)           32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,289\n",
      "Trainable params: 42,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 10921\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('coverage_data/K562_Chen.usage.txt',5,33.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data2,train_labels2,train_id2,valid_data2,valid_labels2,valid_id2 = prep_data('coverage_data/SNU398_Control.usage.txt',5,7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=np.concatenate((train_data1, train_data2), axis=0)\n",
    "#train_labels=np.concatenate((train_labels1, train_labels2), axis=0)\n",
    "#valid_data=np.concatenate((valid_data1, valid_data2), axis=0)\n",
    "#valid_labels=np.concatenate((valid_labels1, valid_labels2), axis=0)\n",
    "#train_id =np.concatenate((train_id1, train_id2), axis=0)\n",
    "#valid_id =np.concatenate((valid_id1, valid_id2), axis=0)\n",
    "#x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015015015"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+0.05)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    #train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    #valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0916221 1.7920761\n",
      "2.391116 1.6476064\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7fbab82588>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(train_x.shape[1]),train_x[5,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.37542865"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,train_id,16,LENGTH)\n",
    "validation_generator = DataGenerator(valid_x,valid_y,valid_id,0,LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(LENGTH),a[9])\n",
    "plt.xticks(np.arange(0, LENGTH, 100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='thle2.mse.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 273 steps, validate for 68 steps\n",
      "Epoch 1/1000\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 1.0075 - mse: 0.9996 - val_loss: 0.7471 - val_mse: 0.7387\n",
      "Epoch 2/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.8341 - mse: 0.8257 - val_loss: 0.7287 - val_mse: 0.7202\n",
      "Epoch 3/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.7717 - mse: 0.7632 - val_loss: 0.6411 - val_mse: 0.6326\n",
      "Epoch 4/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.7371 - mse: 0.7286 - val_loss: 0.6289 - val_mse: 0.6204\n",
      "Epoch 5/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.6989 - mse: 0.6904 - val_loss: 0.5816 - val_mse: 0.5731\n",
      "Epoch 6/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.6779 - mse: 0.6694 - val_loss: 0.6003 - val_mse: 0.5918\n",
      "Epoch 7/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.6699 - mse: 0.6614 - val_loss: 0.5599 - val_mse: 0.5514\n",
      "Epoch 8/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.6565 - mse: 0.6480 - val_loss: 0.5730 - val_mse: 0.5645\n",
      "Epoch 9/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.6337 - mse: 0.6252 - val_loss: 0.5500 - val_mse: 0.5415\n",
      "Epoch 10/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.6330 - mse: 0.6245\n",
      "Epoch 00010: saving model to Regression_Model/thle2.mse.linear-0010.ckpt\n",
      "273/273 [==============================] - 4s 13ms/step - loss: 0.6328 - mse: 0.6243 - val_loss: 0.5575 - val_mse: 0.5489\n",
      "Epoch 11/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6225 - mse: 0.6140 - val_loss: 0.5494 - val_mse: 0.5409\n",
      "Epoch 12/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6118 - mse: 0.6032 - val_loss: 0.5306 - val_mse: 0.5221\n",
      "Epoch 13/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6183 - mse: 0.6097 - val_loss: 0.5191 - val_mse: 0.5106\n",
      "Epoch 14/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.6148 - mse: 0.6062 - val_loss: 0.5606 - val_mse: 0.5521\n",
      "Epoch 15/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.6120 - mse: 0.6034 - val_loss: 0.5528 - val_mse: 0.5442\n",
      "Epoch 16/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.6014 - mse: 0.5928 - val_loss: 0.5219 - val_mse: 0.5133\n",
      "Epoch 17/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.6065 - mse: 0.5979 - val_loss: 0.5543 - val_mse: 0.5457\n",
      "Epoch 18/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5889 - mse: 0.5803 - val_loss: 0.5239 - val_mse: 0.5153\n",
      "Epoch 19/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5906 - mse: 0.5820 - val_loss: 0.5249 - val_mse: 0.5163\n",
      "Epoch 20/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.6011 - mse: 0.5925\n",
      "Epoch 00020: saving model to Regression_Model/thle2.mse.linear-0020.ckpt\n",
      "273/273 [==============================] - 9s 32ms/step - loss: 0.5992 - mse: 0.5906 - val_loss: 0.5369 - val_mse: 0.5282\n",
      "Epoch 21/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5937 - mse: 0.5851 - val_loss: 0.5293 - val_mse: 0.5206\n",
      "Epoch 22/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5993 - mse: 0.5906 - val_loss: 0.5269 - val_mse: 0.5183\n",
      "Epoch 23/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5920 - mse: 0.5834 - val_loss: 0.5170 - val_mse: 0.5084\n",
      "Epoch 24/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5864 - mse: 0.5777 - val_loss: 0.5363 - val_mse: 0.5277\n",
      "Epoch 25/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5921 - mse: 0.5835 - val_loss: 0.5485 - val_mse: 0.5399\n",
      "Epoch 26/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5919 - mse: 0.5833 - val_loss: 0.5423 - val_mse: 0.5337\n",
      "Epoch 27/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5828 - mse: 0.5741 - val_loss: 0.5245 - val_mse: 0.5159\n",
      "Epoch 28/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5798 - mse: 0.5711 - val_loss: 0.5363 - val_mse: 0.5276\n",
      "Epoch 29/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5834 - mse: 0.5748 - val_loss: 0.5173 - val_mse: 0.5087\n",
      "Epoch 30/1000\n",
      "257/273 [===========================>..] - ETA: 0s - loss: 0.5906 - mse: 0.5819\n",
      "Epoch 00030: saving model to Regression_Model/thle2.mse.linear-0030.ckpt\n",
      "273/273 [==============================] - 8s 28ms/step - loss: 0.5901 - mse: 0.5815 - val_loss: 0.5155 - val_mse: 0.5069\n",
      "Epoch 31/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5880 - mse: 0.5794 - val_loss: 0.5376 - val_mse: 0.5289\n",
      "Epoch 32/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5786 - mse: 0.5700 - val_loss: 0.5097 - val_mse: 0.5011\n",
      "Epoch 33/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5789 - mse: 0.5702 - val_loss: 0.5241 - val_mse: 0.5155\n",
      "Epoch 34/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5721 - mse: 0.5634 - val_loss: 0.5174 - val_mse: 0.5087\n",
      "Epoch 35/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5863 - mse: 0.5777 - val_loss: 0.5130 - val_mse: 0.5044\n",
      "Epoch 36/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5793 - mse: 0.5706 - val_loss: 0.5582 - val_mse: 0.5496\n",
      "Epoch 37/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5878 - mse: 0.5792 - val_loss: 0.5218 - val_mse: 0.5131\n",
      "Epoch 38/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5709 - mse: 0.5623 - val_loss: 0.5060 - val_mse: 0.4974\n",
      "Epoch 39/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5814 - mse: 0.5728 - val_loss: 0.5137 - val_mse: 0.5051\n",
      "Epoch 40/1000\n",
      "259/273 [===========================>..] - ETA: 0s - loss: 0.5794 - mse: 0.5707\n",
      "Epoch 00040: saving model to Regression_Model/thle2.mse.linear-0040.ckpt\n",
      "273/273 [==============================] - 5s 18ms/step - loss: 0.5804 - mse: 0.5718 - val_loss: 0.5093 - val_mse: 0.5007\n",
      "Epoch 41/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5765 - mse: 0.5678 - val_loss: 0.5229 - val_mse: 0.5143\n",
      "Epoch 42/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5732 - mse: 0.5646 - val_loss: 0.5091 - val_mse: 0.5005\n",
      "Epoch 43/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5598 - mse: 0.5511 - val_loss: 0.5162 - val_mse: 0.5076\n",
      "Epoch 44/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5634 - mse: 0.5547 - val_loss: 0.5139 - val_mse: 0.5052\n",
      "Epoch 45/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5663 - mse: 0.5576 - val_loss: 0.5158 - val_mse: 0.5072\n",
      "Epoch 46/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5663 - mse: 0.5577 - val_loss: 0.5135 - val_mse: 0.5048\n",
      "Epoch 47/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5635 - mse: 0.5549 - val_loss: 0.5134 - val_mse: 0.5047\n",
      "Epoch 48/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5664 - mse: 0.5577 - val_loss: 0.5014 - val_mse: 0.4927\n",
      "Epoch 49/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5672 - mse: 0.5585 - val_loss: 0.5026 - val_mse: 0.4939\n",
      "Epoch 50/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5653 - mse: 0.5566\n",
      "Epoch 00050: saving model to Regression_Model/thle2.mse.linear-0050.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.5680 - mse: 0.5593 - val_loss: 0.5155 - val_mse: 0.5068\n",
      "Epoch 51/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5730 - mse: 0.5644 - val_loss: 0.5124 - val_mse: 0.5037\n",
      "Epoch 52/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5600 - mse: 0.5514 - val_loss: 0.5238 - val_mse: 0.5151\n",
      "Epoch 53/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5676 - mse: 0.5589 - val_loss: 0.5250 - val_mse: 0.5163\n",
      "Epoch 54/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5605 - mse: 0.5518 - val_loss: 0.4980 - val_mse: 0.4893\n",
      "Epoch 55/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5622 - mse: 0.5535 - val_loss: 0.5001 - val_mse: 0.4914\n",
      "Epoch 56/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5697 - mse: 0.5610 - val_loss: 0.5137 - val_mse: 0.5050\n",
      "Epoch 57/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5647 - mse: 0.5560 - val_loss: 0.4922 - val_mse: 0.4835\n",
      "Epoch 58/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5610 - mse: 0.5523 - val_loss: 0.5195 - val_mse: 0.5108\n",
      "Epoch 59/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5583 - mse: 0.5496 - val_loss: 0.5162 - val_mse: 0.5075\n",
      "Epoch 60/1000\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.5610 - mse: 0.5524\n",
      "Epoch 00060: saving model to Regression_Model/thle2.mse.linear-0060.ckpt\n",
      "273/273 [==============================] - 6s 22ms/step - loss: 0.5604 - mse: 0.5517 - val_loss: 0.5046 - val_mse: 0.4959\n",
      "Epoch 61/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5540 - mse: 0.5454 - val_loss: 0.5241 - val_mse: 0.5154\n",
      "Epoch 62/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5497 - mse: 0.5411 - val_loss: 0.5105 - val_mse: 0.5019\n",
      "Epoch 63/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5588 - mse: 0.5501 - val_loss: 0.5187 - val_mse: 0.5101\n",
      "Epoch 64/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5602 - mse: 0.5515 - val_loss: 0.5103 - val_mse: 0.5017\n",
      "Epoch 65/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5586 - mse: 0.5499 - val_loss: 0.5150 - val_mse: 0.5064\n",
      "Epoch 66/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5615 - mse: 0.5528 - val_loss: 0.4975 - val_mse: 0.4888\n",
      "Epoch 67/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5533 - mse: 0.5446 - val_loss: 0.5009 - val_mse: 0.4923\n",
      "Epoch 68/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5585 - mse: 0.5498 - val_loss: 0.4975 - val_mse: 0.4888\n",
      "Epoch 69/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5562 - mse: 0.5475 - val_loss: 0.5299 - val_mse: 0.5212\n",
      "Epoch 70/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5551 - mse: 0.5464\n",
      "Epoch 00070: saving model to Regression_Model/thle2.mse.linear-0070.ckpt\n",
      "273/273 [==============================] - 5s 18ms/step - loss: 0.5558 - mse: 0.5471 - val_loss: 0.5094 - val_mse: 0.5008\n",
      "Epoch 71/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5572 - mse: 0.5485 - val_loss: 0.4965 - val_mse: 0.4878\n",
      "Epoch 72/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5458 - mse: 0.5372 - val_loss: 0.4876 - val_mse: 0.4790\n",
      "Epoch 73/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5533 - mse: 0.5447 - val_loss: 0.4979 - val_mse: 0.4892\n",
      "Epoch 74/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5672 - mse: 0.5586 - val_loss: 0.5214 - val_mse: 0.5127\n",
      "Epoch 75/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5503 - mse: 0.5416 - val_loss: 0.5034 - val_mse: 0.4947\n",
      "Epoch 76/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5665 - mse: 0.5578 - val_loss: 0.5188 - val_mse: 0.5102\n",
      "Epoch 77/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5529 - mse: 0.5443 - val_loss: 0.4888 - val_mse: 0.4802\n",
      "Epoch 78/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5514 - mse: 0.5428 - val_loss: 0.5016 - val_mse: 0.4929\n",
      "Epoch 79/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5548 - mse: 0.5461 - val_loss: 0.4967 - val_mse: 0.4881\n",
      "Epoch 80/1000\n",
      "259/273 [===========================>..] - ETA: 0s - loss: 0.5527 - mse: 0.5441\n",
      "Epoch 00080: saving model to Regression_Model/thle2.mse.linear-0080.ckpt\n",
      "273/273 [==============================] - 7s 27ms/step - loss: 0.5490 - mse: 0.5404 - val_loss: 0.4993 - val_mse: 0.4907\n",
      "Epoch 81/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5509 - mse: 0.5423 - val_loss: 0.4973 - val_mse: 0.4887\n",
      "Epoch 82/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5554 - mse: 0.5467 - val_loss: 0.4959 - val_mse: 0.4872\n",
      "Epoch 83/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5537 - mse: 0.5451 - val_loss: 0.4985 - val_mse: 0.4899\n",
      "Epoch 84/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5462 - mse: 0.5376 - val_loss: 0.4937 - val_mse: 0.4850\n",
      "Epoch 85/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5459 - mse: 0.5372 - val_loss: 0.4930 - val_mse: 0.4844\n",
      "Epoch 86/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5477 - mse: 0.5391 - val_loss: 0.5032 - val_mse: 0.4945\n",
      "Epoch 87/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5510 - mse: 0.5424 - val_loss: 0.5197 - val_mse: 0.5111\n",
      "Epoch 88/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5454 - mse: 0.5368 - val_loss: 0.4944 - val_mse: 0.4857\n",
      "Epoch 89/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5464 - mse: 0.5378 - val_loss: 0.5014 - val_mse: 0.4927\n",
      "Epoch 90/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5529 - mse: 0.5443\n",
      "Epoch 00090: saving model to Regression_Model/thle2.mse.linear-0090.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5530 - mse: 0.5444 - val_loss: 0.4957 - val_mse: 0.4870\n",
      "Epoch 91/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5392 - mse: 0.5305 - val_loss: 0.4986 - val_mse: 0.4900\n",
      "Epoch 92/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5449 - mse: 0.5363 - val_loss: 0.4901 - val_mse: 0.4814\n",
      "Epoch 93/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5488 - mse: 0.5402 - val_loss: 0.4848 - val_mse: 0.4761\n",
      "Epoch 94/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5464 - mse: 0.5377 - val_loss: 0.4959 - val_mse: 0.4873\n",
      "Epoch 95/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5557 - mse: 0.5471 - val_loss: 0.5093 - val_mse: 0.5007\n",
      "Epoch 96/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5498 - mse: 0.5412 - val_loss: 0.5007 - val_mse: 0.4921\n",
      "Epoch 97/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5421 - mse: 0.5335 - val_loss: 0.4999 - val_mse: 0.4913\n",
      "Epoch 98/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5448 - mse: 0.5361 - val_loss: 0.5012 - val_mse: 0.4926\n",
      "Epoch 99/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5436 - mse: 0.5349 - val_loss: 0.4946 - val_mse: 0.4859\n",
      "Epoch 100/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5520 - mse: 0.5433\n",
      "Epoch 00100: saving model to Regression_Model/thle2.mse.linear-0100.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.5531 - mse: 0.5444 - val_loss: 0.4805 - val_mse: 0.4719\n",
      "Epoch 101/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5525 - mse: 0.5439 - val_loss: 0.4909 - val_mse: 0.4823\n",
      "Epoch 102/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5355 - mse: 0.5269 - val_loss: 0.4873 - val_mse: 0.4786\n",
      "Epoch 103/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5336 - mse: 0.5250 - val_loss: 0.4859 - val_mse: 0.4772\n",
      "Epoch 104/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5445 - mse: 0.5359 - val_loss: 0.4875 - val_mse: 0.4789\n",
      "Epoch 105/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5373 - mse: 0.5286 - val_loss: 0.4954 - val_mse: 0.4868\n",
      "Epoch 106/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5455 - mse: 0.5369 - val_loss: 0.4915 - val_mse: 0.4829\n",
      "Epoch 107/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5410 - mse: 0.5324 - val_loss: 0.4944 - val_mse: 0.4858\n",
      "Epoch 108/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5537 - mse: 0.5451 - val_loss: 0.4940 - val_mse: 0.4854\n",
      "Epoch 109/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5407 - mse: 0.5321 - val_loss: 0.4951 - val_mse: 0.4865\n",
      "Epoch 110/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5433 - mse: 0.5347\n",
      "Epoch 00110: saving model to Regression_Model/thle2.mse.linear-0110.ckpt\n",
      "273/273 [==============================] - 6s 21ms/step - loss: 0.5426 - mse: 0.5340 - val_loss: 0.4852 - val_mse: 0.4766\n",
      "Epoch 111/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5444 - mse: 0.5358 - val_loss: 0.5039 - val_mse: 0.4953\n",
      "Epoch 112/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5361 - mse: 0.5275 - val_loss: 0.4865 - val_mse: 0.4779\n",
      "Epoch 113/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5345 - mse: 0.5259 - val_loss: 0.4860 - val_mse: 0.4774\n",
      "Epoch 114/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5468 - mse: 0.5383 - val_loss: 0.4855 - val_mse: 0.4769\n",
      "Epoch 115/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5383 - mse: 0.5297 - val_loss: 0.5067 - val_mse: 0.4981\n",
      "Epoch 116/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5434 - mse: 0.5348 - val_loss: 0.4952 - val_mse: 0.4866\n",
      "Epoch 117/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5367 - mse: 0.5281 - val_loss: 0.4786 - val_mse: 0.4700\n",
      "Epoch 118/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5371 - mse: 0.5285 - val_loss: 0.5056 - val_mse: 0.4970\n",
      "Epoch 119/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5352 - mse: 0.5266 - val_loss: 0.4875 - val_mse: 0.4790\n",
      "Epoch 120/1000\n",
      "265/273 [============================>.] - ETA: 0s - loss: 0.5370 - mse: 0.5284\n",
      "Epoch 00120: saving model to Regression_Model/thle2.mse.linear-0120.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5395 - mse: 0.5310 - val_loss: 0.4886 - val_mse: 0.4801\n",
      "Epoch 121/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5362 - mse: 0.5277 - val_loss: 0.4994 - val_mse: 0.4908\n",
      "Epoch 122/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5364 - mse: 0.5278 - val_loss: 0.4913 - val_mse: 0.4827\n",
      "Epoch 123/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5400 - mse: 0.5314 - val_loss: 0.4976 - val_mse: 0.4891\n",
      "Epoch 124/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5343 - mse: 0.5257 - val_loss: 0.4961 - val_mse: 0.4875\n",
      "Epoch 125/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5386 - mse: 0.5301 - val_loss: 0.5089 - val_mse: 0.5003\n",
      "Epoch 126/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5513 - mse: 0.5427 - val_loss: 0.4903 - val_mse: 0.4817\n",
      "Epoch 127/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5486 - mse: 0.5400 - val_loss: 0.4929 - val_mse: 0.4844\n",
      "Epoch 128/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5353 - mse: 0.5267 - val_loss: 0.4918 - val_mse: 0.4832\n",
      "Epoch 129/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5414 - mse: 0.5328 - val_loss: 0.4934 - val_mse: 0.4848\n",
      "Epoch 130/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.5340 - mse: 0.5254\n",
      "Epoch 00130: saving model to Regression_Model/thle2.mse.linear-0130.ckpt\n",
      "273/273 [==============================] - 5s 20ms/step - loss: 0.5361 - mse: 0.5275 - val_loss: 0.4973 - val_mse: 0.4888\n",
      "Epoch 131/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5362 - mse: 0.5276 - val_loss: 0.4927 - val_mse: 0.4842\n",
      "Epoch 132/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5354 - mse: 0.5268 - val_loss: 0.4838 - val_mse: 0.4752\n",
      "Epoch 133/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5391 - mse: 0.5306 - val_loss: 0.5043 - val_mse: 0.4958\n",
      "Epoch 134/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5320 - mse: 0.5235 - val_loss: 0.4832 - val_mse: 0.4746\n",
      "Epoch 135/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5331 - mse: 0.5245 - val_loss: 0.4939 - val_mse: 0.4853\n",
      "Epoch 136/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5414 - mse: 0.5329 - val_loss: 0.4821 - val_mse: 0.4735\n",
      "Epoch 137/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5282 - mse: 0.5196 - val_loss: 0.4818 - val_mse: 0.4733\n",
      "Epoch 138/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5363 - mse: 0.5278 - val_loss: 0.4820 - val_mse: 0.4735\n",
      "Epoch 139/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5369 - mse: 0.5283 - val_loss: 0.4755 - val_mse: 0.4670\n",
      "Epoch 140/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5502 - mse: 0.5417\n",
      "Epoch 00140: saving model to Regression_Model/thle2.mse.linear-0140.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.5474 - mse: 0.5388 - val_loss: 0.4848 - val_mse: 0.4763\n",
      "Epoch 141/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5381 - mse: 0.5296 - val_loss: 0.5039 - val_mse: 0.4954\n",
      "Epoch 142/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5293 - mse: 0.5208 - val_loss: 0.4813 - val_mse: 0.4727\n",
      "Epoch 143/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5356 - mse: 0.5271 - val_loss: 0.4926 - val_mse: 0.4841\n",
      "Epoch 144/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5382 - mse: 0.5296 - val_loss: 0.4901 - val_mse: 0.4815\n",
      "Epoch 145/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5294 - mse: 0.5209 - val_loss: 0.4915 - val_mse: 0.4830\n",
      "Epoch 146/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5305 - mse: 0.5220 - val_loss: 0.4753 - val_mse: 0.4668\n",
      "Epoch 147/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5295 - mse: 0.5210 - val_loss: 0.4953 - val_mse: 0.4868\n",
      "Epoch 148/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5314 - mse: 0.5229 - val_loss: 0.4950 - val_mse: 0.4865\n",
      "Epoch 149/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5380 - mse: 0.5295 - val_loss: 0.4874 - val_mse: 0.4789\n",
      "Epoch 150/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5268 - mse: 0.5183\n",
      "Epoch 00150: saving model to Regression_Model/thle2.mse.linear-0150.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.5267 - mse: 0.5182 - val_loss: 0.4849 - val_mse: 0.4764\n",
      "Epoch 151/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5353 - mse: 0.5268 - val_loss: 0.4874 - val_mse: 0.4789\n",
      "Epoch 152/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5402 - mse: 0.5317 - val_loss: 0.4930 - val_mse: 0.4845\n",
      "Epoch 153/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5456 - mse: 0.5371 - val_loss: 0.4980 - val_mse: 0.4895\n",
      "Epoch 154/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5300 - mse: 0.5215 - val_loss: 0.4899 - val_mse: 0.4814\n",
      "Epoch 155/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5292 - mse: 0.5207 - val_loss: 0.4842 - val_mse: 0.4757\n",
      "Epoch 156/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5359 - mse: 0.5274 - val_loss: 0.4887 - val_mse: 0.4802\n",
      "Epoch 157/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5334 - mse: 0.5249 - val_loss: 0.4797 - val_mse: 0.4712\n",
      "Epoch 158/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5399 - mse: 0.5315 - val_loss: 0.4876 - val_mse: 0.4791\n",
      "Epoch 159/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5362 - mse: 0.5277 - val_loss: 0.4878 - val_mse: 0.4793\n",
      "Epoch 160/1000\n",
      "264/273 [============================>.] - ETA: 0s - loss: 0.5304 - mse: 0.5219\n",
      "Epoch 00160: saving model to Regression_Model/thle2.mse.linear-0160.ckpt\n",
      "273/273 [==============================] - 11s 39ms/step - loss: 0.5297 - mse: 0.5212 - val_loss: 0.4882 - val_mse: 0.4797\n",
      "Epoch 161/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5272 - mse: 0.5187 - val_loss: 0.4760 - val_mse: 0.4675\n",
      "Epoch 162/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5271 - mse: 0.5186 - val_loss: 0.4836 - val_mse: 0.4751\n",
      "Epoch 163/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5249 - mse: 0.5164 - val_loss: 0.4743 - val_mse: 0.4658\n",
      "Epoch 164/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5238 - mse: 0.5153 - val_loss: 0.4771 - val_mse: 0.4687\n",
      "Epoch 165/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5321 - mse: 0.5237 - val_loss: 0.4777 - val_mse: 0.4692\n",
      "Epoch 166/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5302 - mse: 0.5218 - val_loss: 0.4820 - val_mse: 0.4736\n",
      "Epoch 167/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5322 - mse: 0.5237 - val_loss: 0.4799 - val_mse: 0.4715\n",
      "Epoch 168/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5241 - mse: 0.5156 - val_loss: 0.4863 - val_mse: 0.4778\n",
      "Epoch 169/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5291 - mse: 0.5207 - val_loss: 0.4864 - val_mse: 0.4780\n",
      "Epoch 170/1000\n",
      "259/273 [===========================>..] - ETA: 0s - loss: 0.5335 - mse: 0.5250\n",
      "Epoch 00170: saving model to Regression_Model/thle2.mse.linear-0170.ckpt\n",
      "273/273 [==============================] - 5s 18ms/step - loss: 0.5325 - mse: 0.5241 - val_loss: 0.4802 - val_mse: 0.4717\n",
      "Epoch 171/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5249 - mse: 0.5165 - val_loss: 0.4793 - val_mse: 0.4709\n",
      "Epoch 172/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5301 - mse: 0.5217 - val_loss: 0.4791 - val_mse: 0.4707\n",
      "Epoch 173/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5282 - mse: 0.5198 - val_loss: 0.4762 - val_mse: 0.4678\n",
      "Epoch 174/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5319 - mse: 0.5235 - val_loss: 0.4894 - val_mse: 0.4809\n",
      "Epoch 175/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5282 - mse: 0.5198 - val_loss: 0.4923 - val_mse: 0.4839\n",
      "Epoch 176/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5299 - mse: 0.5215 - val_loss: 0.4851 - val_mse: 0.4767\n",
      "Epoch 177/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5212 - mse: 0.5128 - val_loss: 0.4867 - val_mse: 0.4783\n",
      "Epoch 178/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5359 - mse: 0.5275 - val_loss: 0.4808 - val_mse: 0.4724\n",
      "Epoch 179/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5271 - mse: 0.5187 - val_loss: 0.4842 - val_mse: 0.4758\n",
      "Epoch 180/1000\n",
      "265/273 [============================>.] - ETA: 0s - loss: 0.5308 - mse: 0.5224\n",
      "Epoch 00180: saving model to Regression_Model/thle2.mse.linear-0180.ckpt\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.5304 - mse: 0.5220 - val_loss: 0.4869 - val_mse: 0.4785\n",
      "Epoch 181/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5327 - mse: 0.5243 - val_loss: 0.4790 - val_mse: 0.4706\n",
      "Epoch 182/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5370 - mse: 0.5286 - val_loss: 0.4754 - val_mse: 0.4670\n",
      "Epoch 183/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5271 - mse: 0.5187 - val_loss: 0.4969 - val_mse: 0.4885\n",
      "Epoch 184/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5312 - mse: 0.5228 - val_loss: 0.4768 - val_mse: 0.4685\n",
      "Epoch 185/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5256 - mse: 0.5172 - val_loss: 0.4815 - val_mse: 0.4731\n",
      "Epoch 186/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5339 - mse: 0.5255 - val_loss: 0.4865 - val_mse: 0.4781\n",
      "Epoch 187/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5249 - mse: 0.5165 - val_loss: 0.4794 - val_mse: 0.4710\n",
      "Epoch 188/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5403 - mse: 0.5319 - val_loss: 0.4905 - val_mse: 0.4821\n",
      "Epoch 189/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5329 - mse: 0.5246 - val_loss: 0.4987 - val_mse: 0.4904\n",
      "Epoch 190/1000\n",
      "264/273 [============================>.] - ETA: 0s - loss: 0.5235 - mse: 0.5151\n",
      "Epoch 00190: saving model to Regression_Model/thle2.mse.linear-0190.ckpt\n",
      "273/273 [==============================] - 7s 24ms/step - loss: 0.5261 - mse: 0.5177 - val_loss: 0.4719 - val_mse: 0.4636\n",
      "Epoch 191/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5229 - mse: 0.5145 - val_loss: 0.4783 - val_mse: 0.4700\n",
      "Epoch 192/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5253 - mse: 0.5169 - val_loss: 0.4754 - val_mse: 0.4670\n",
      "Epoch 193/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5267 - mse: 0.5183 - val_loss: 0.4919 - val_mse: 0.4836\n",
      "Epoch 194/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5185 - mse: 0.5101 - val_loss: 0.4930 - val_mse: 0.4847\n",
      "Epoch 195/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5278 - mse: 0.5195 - val_loss: 0.4845 - val_mse: 0.4761\n",
      "Epoch 196/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5234 - mse: 0.5151 - val_loss: 0.4796 - val_mse: 0.4712\n",
      "Epoch 197/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5229 - mse: 0.5146 - val_loss: 0.4772 - val_mse: 0.4689\n",
      "Epoch 198/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5279 - mse: 0.5196 - val_loss: 0.4830 - val_mse: 0.4747\n",
      "Epoch 199/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5277 - mse: 0.5194 - val_loss: 0.4777 - val_mse: 0.4694\n",
      "Epoch 200/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.5232 - mse: 0.5149\n",
      "Epoch 00200: saving model to Regression_Model/thle2.mse.linear-0200.ckpt\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.5241 - mse: 0.5158 - val_loss: 0.4723 - val_mse: 0.4640\n",
      "Epoch 201/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5241 - mse: 0.5158 - val_loss: 0.4761 - val_mse: 0.4678\n",
      "Epoch 202/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5322 - mse: 0.5239 - val_loss: 0.4740 - val_mse: 0.4657\n",
      "Epoch 203/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5243 - mse: 0.5160 - val_loss: 0.4833 - val_mse: 0.4750\n",
      "Epoch 204/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5287 - mse: 0.5204 - val_loss: 0.4934 - val_mse: 0.4851\n",
      "Epoch 205/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5215 - mse: 0.5132 - val_loss: 0.4736 - val_mse: 0.4653\n",
      "Epoch 206/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5252 - mse: 0.5169 - val_loss: 0.4730 - val_mse: 0.4647\n",
      "Epoch 207/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5255 - mse: 0.5172 - val_loss: 0.4930 - val_mse: 0.4848\n",
      "Epoch 208/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5273 - mse: 0.5190 - val_loss: 0.4829 - val_mse: 0.4746\n",
      "Epoch 209/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5280 - mse: 0.5197 - val_loss: 0.4767 - val_mse: 0.4684\n",
      "Epoch 210/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5275 - mse: 0.5193\n",
      "Epoch 00210: saving model to Regression_Model/thle2.mse.linear-0210.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.5272 - mse: 0.5189 - val_loss: 0.4770 - val_mse: 0.4687\n",
      "Epoch 211/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5288 - mse: 0.5205 - val_loss: 0.4766 - val_mse: 0.4683\n",
      "Epoch 212/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5281 - mse: 0.5198 - val_loss: 0.4857 - val_mse: 0.4774\n",
      "Epoch 213/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5239 - mse: 0.5156 - val_loss: 0.4833 - val_mse: 0.4750\n",
      "Epoch 214/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5224 - mse: 0.5141 - val_loss: 0.4817 - val_mse: 0.4734\n",
      "Epoch 215/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5374 - mse: 0.5291 - val_loss: 0.4889 - val_mse: 0.4806\n",
      "Epoch 216/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5245 - mse: 0.5162 - val_loss: 0.4737 - val_mse: 0.4654\n",
      "Epoch 217/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5181 - mse: 0.5099 - val_loss: 0.4783 - val_mse: 0.4701\n",
      "Epoch 218/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5209 - mse: 0.5126 - val_loss: 0.4840 - val_mse: 0.4758\n",
      "Epoch 219/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5147 - mse: 0.5064 - val_loss: 0.4789 - val_mse: 0.4707\n",
      "Epoch 220/1000\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.5293 - mse: 0.5211\n",
      "Epoch 00220: saving model to Regression_Model/thle2.mse.linear-0220.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5315 - mse: 0.5233 - val_loss: 0.4785 - val_mse: 0.4702\n",
      "Epoch 221/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5245 - mse: 0.5163 - val_loss: 0.4803 - val_mse: 0.4720\n",
      "Epoch 222/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5262 - mse: 0.5180 - val_loss: 0.4818 - val_mse: 0.4736\n",
      "Epoch 223/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5206 - mse: 0.5124 - val_loss: 0.4800 - val_mse: 0.4717\n",
      "Epoch 224/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5183 - mse: 0.5100 - val_loss: 0.4733 - val_mse: 0.4651\n",
      "Epoch 225/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5280 - mse: 0.5198 - val_loss: 0.4773 - val_mse: 0.4691\n",
      "Epoch 226/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5250 - mse: 0.5168 - val_loss: 0.4817 - val_mse: 0.4735\n",
      "Epoch 227/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5246 - mse: 0.5164 - val_loss: 0.4799 - val_mse: 0.4717\n",
      "Epoch 228/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5252 - mse: 0.5169 - val_loss: 0.4892 - val_mse: 0.4809\n",
      "Epoch 229/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5232 - mse: 0.5150 - val_loss: 0.4935 - val_mse: 0.4853\n",
      "Epoch 230/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5237 - mse: 0.5154\n",
      "Epoch 00230: saving model to Regression_Model/thle2.mse.linear-0230.ckpt\n",
      "273/273 [==============================] - 5s 17ms/step - loss: 0.5224 - mse: 0.5142 - val_loss: 0.4729 - val_mse: 0.4647\n",
      "Epoch 231/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5298 - mse: 0.5215 - val_loss: 0.4751 - val_mse: 0.4669\n",
      "Epoch 232/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5207 - mse: 0.5125 - val_loss: 0.4839 - val_mse: 0.4757\n",
      "Epoch 233/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5252 - mse: 0.5170 - val_loss: 0.4783 - val_mse: 0.4701\n",
      "Epoch 234/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5248 - mse: 0.5166 - val_loss: 0.4804 - val_mse: 0.4722\n",
      "Epoch 235/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5201 - mse: 0.5120 - val_loss: 0.4773 - val_mse: 0.4691\n",
      "Epoch 236/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5190 - mse: 0.5108 - val_loss: 0.4777 - val_mse: 0.4695\n",
      "Epoch 237/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5220 - mse: 0.5138 - val_loss: 0.4831 - val_mse: 0.4749\n",
      "Epoch 238/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5302 - mse: 0.5220 - val_loss: 0.4826 - val_mse: 0.4745\n",
      "Epoch 239/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5200 - mse: 0.5118 - val_loss: 0.4812 - val_mse: 0.4730\n",
      "Epoch 240/1000\n",
      "265/273 [============================>.] - ETA: 0s - loss: 0.5189 - mse: 0.5107\n",
      "Epoch 00240: saving model to Regression_Model/thle2.mse.linear-0240.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5190 - mse: 0.5108 - val_loss: 0.4855 - val_mse: 0.4773\n",
      "Epoch 241/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5221 - mse: 0.5139 - val_loss: 0.4852 - val_mse: 0.4770\n",
      "Epoch 242/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5264 - mse: 0.5183 - val_loss: 0.4772 - val_mse: 0.4690\n",
      "Epoch 243/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5254 - mse: 0.5172 - val_loss: 0.4859 - val_mse: 0.4778\n",
      "Epoch 244/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5123 - mse: 0.5041 - val_loss: 0.4715 - val_mse: 0.4634\n",
      "Epoch 245/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5229 - mse: 0.5147 - val_loss: 0.4842 - val_mse: 0.4760\n",
      "Epoch 246/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5251 - mse: 0.5170 - val_loss: 0.4817 - val_mse: 0.4735\n",
      "Epoch 247/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5109 - mse: 0.5027 - val_loss: 0.4815 - val_mse: 0.4733\n",
      "Epoch 248/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5271 - mse: 0.5190 - val_loss: 0.4748 - val_mse: 0.4666\n",
      "Epoch 249/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5287 - mse: 0.5205 - val_loss: 0.4810 - val_mse: 0.4728\n",
      "Epoch 250/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5255 - mse: 0.5174\n",
      "Epoch 00250: saving model to Regression_Model/thle2.mse.linear-0250.ckpt\n",
      "273/273 [==============================] - 5s 20ms/step - loss: 0.5248 - mse: 0.5167 - val_loss: 0.4819 - val_mse: 0.4738\n",
      "Epoch 251/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5238 - mse: 0.5157 - val_loss: 0.4886 - val_mse: 0.4804\n",
      "Epoch 252/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5107 - mse: 0.5025 - val_loss: 0.4811 - val_mse: 0.4729\n",
      "Epoch 253/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5190 - mse: 0.5108 - val_loss: 0.4821 - val_mse: 0.4740\n",
      "Epoch 254/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5215 - mse: 0.5134 - val_loss: 0.4785 - val_mse: 0.4704\n",
      "Epoch 255/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5262 - mse: 0.5181 - val_loss: 0.4852 - val_mse: 0.4771\n",
      "Epoch 256/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5182 - mse: 0.5101 - val_loss: 0.4772 - val_mse: 0.4691\n",
      "Epoch 257/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5187 - mse: 0.5105 - val_loss: 0.4782 - val_mse: 0.4701\n",
      "Epoch 258/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5217 - mse: 0.5136 - val_loss: 0.4820 - val_mse: 0.4739\n",
      "Epoch 259/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5183 - mse: 0.5102 - val_loss: 0.4808 - val_mse: 0.4727\n",
      "Epoch 260/1000\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.5262 - mse: 0.5181\n",
      "Epoch 00260: saving model to Regression_Model/thle2.mse.linear-0260.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.5260 - mse: 0.5179 - val_loss: 0.4865 - val_mse: 0.4784\n",
      "Epoch 261/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5297 - mse: 0.5216 - val_loss: 0.4781 - val_mse: 0.4700\n",
      "Epoch 262/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5263 - mse: 0.5182 - val_loss: 0.4793 - val_mse: 0.4712\n",
      "Epoch 263/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5208 - mse: 0.5127 - val_loss: 0.4872 - val_mse: 0.4791\n",
      "Epoch 264/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5283 - mse: 0.5203 - val_loss: 0.4805 - val_mse: 0.4725\n",
      "Epoch 265/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5270 - mse: 0.5189 - val_loss: 0.4860 - val_mse: 0.4779\n",
      "Epoch 266/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5204 - mse: 0.5123 - val_loss: 0.4750 - val_mse: 0.4669\n",
      "Epoch 267/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5257 - mse: 0.5176 - val_loss: 0.4862 - val_mse: 0.4781\n",
      "Epoch 268/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5213 - mse: 0.5132 - val_loss: 0.4786 - val_mse: 0.4705\n",
      "Epoch 269/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5267 - mse: 0.5186 - val_loss: 0.4795 - val_mse: 0.4714\n",
      "Epoch 270/1000\n",
      "265/273 [============================>.] - ETA: 0s - loss: 0.5183 - mse: 0.5102\n",
      "Epoch 00270: saving model to Regression_Model/thle2.mse.linear-0270.ckpt\n",
      "273/273 [==============================] - 8s 30ms/step - loss: 0.5188 - mse: 0.5107 - val_loss: 0.4744 - val_mse: 0.4664\n",
      "Epoch 271/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5234 - mse: 0.5154 - val_loss: 0.4780 - val_mse: 0.4700\n",
      "Epoch 272/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5216 - mse: 0.5136 - val_loss: 0.4855 - val_mse: 0.4774\n",
      "Epoch 273/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5151 - mse: 0.5070 - val_loss: 0.4719 - val_mse: 0.4639\n",
      "Epoch 274/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5200 - mse: 0.5119 - val_loss: 0.4721 - val_mse: 0.4640\n",
      "Epoch 275/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5222 - mse: 0.5141 - val_loss: 0.4806 - val_mse: 0.4725\n",
      "Epoch 276/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5236 - mse: 0.5155 - val_loss: 0.4721 - val_mse: 0.4640\n",
      "Epoch 277/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5206 - mse: 0.5125 - val_loss: 0.4728 - val_mse: 0.4648\n",
      "Epoch 278/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5115 - mse: 0.5035 - val_loss: 0.4807 - val_mse: 0.4727\n",
      "Epoch 279/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5207 - mse: 0.5127 - val_loss: 0.4693 - val_mse: 0.4612\n",
      "Epoch 280/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5229 - mse: 0.5149\n",
      "Epoch 00280: saving model to Regression_Model/thle2.mse.linear-0280.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.5233 - mse: 0.5153 - val_loss: 0.4845 - val_mse: 0.4764\n",
      "Epoch 281/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5133 - mse: 0.5053 - val_loss: 0.4724 - val_mse: 0.4644\n",
      "Epoch 282/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5224 - mse: 0.5144 - val_loss: 0.4768 - val_mse: 0.4688\n",
      "Epoch 283/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5189 - mse: 0.5108 - val_loss: 0.4837 - val_mse: 0.4757\n",
      "Epoch 284/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5167 - mse: 0.5087 - val_loss: 0.4775 - val_mse: 0.4695\n",
      "Epoch 285/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5233 - mse: 0.5153 - val_loss: 0.4739 - val_mse: 0.4658\n",
      "Epoch 286/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5234 - mse: 0.5154 - val_loss: 0.4778 - val_mse: 0.4698\n",
      "Epoch 287/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5215 - mse: 0.5135 - val_loss: 0.4837 - val_mse: 0.4757\n",
      "Epoch 288/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5260 - mse: 0.5180 - val_loss: 0.4830 - val_mse: 0.4750\n",
      "Epoch 289/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5195 - mse: 0.5115 - val_loss: 0.4790 - val_mse: 0.4710\n",
      "Epoch 290/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5215 - mse: 0.5135\n",
      "Epoch 00290: saving model to Regression_Model/thle2.mse.linear-0290.ckpt\n",
      "273/273 [==============================] - 6s 22ms/step - loss: 0.5213 - mse: 0.5133 - val_loss: 0.4805 - val_mse: 0.4726\n",
      "Epoch 291/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5201 - mse: 0.5121 - val_loss: 0.4721 - val_mse: 0.4641\n",
      "Epoch 292/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5222 - mse: 0.5143 - val_loss: 0.4790 - val_mse: 0.4710\n",
      "Epoch 293/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5178 - mse: 0.5098 - val_loss: 0.4811 - val_mse: 0.4731\n",
      "Epoch 294/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5161 - mse: 0.5081 - val_loss: 0.4732 - val_mse: 0.4652\n",
      "Epoch 295/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5169 - mse: 0.5089 - val_loss: 0.4700 - val_mse: 0.4620\n",
      "Epoch 296/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5188 - mse: 0.5108 - val_loss: 0.4769 - val_mse: 0.4689\n",
      "Epoch 297/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5151 - mse: 0.5071 - val_loss: 0.4857 - val_mse: 0.4778\n",
      "Epoch 298/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5116 - mse: 0.5037 - val_loss: 0.4760 - val_mse: 0.4681\n",
      "Epoch 299/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5203 - mse: 0.5123 - val_loss: 0.4738 - val_mse: 0.4658\n",
      "Epoch 300/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5222 - mse: 0.5143\n",
      "Epoch 00300: saving model to Regression_Model/thle2.mse.linear-0300.ckpt\n",
      "273/273 [==============================] - 11s 40ms/step - loss: 0.5224 - mse: 0.5144 - val_loss: 0.4729 - val_mse: 0.4649\n",
      "Epoch 301/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5210 - mse: 0.5131 - val_loss: 0.4730 - val_mse: 0.4651\n",
      "Epoch 302/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5174 - mse: 0.5094 - val_loss: 0.4717 - val_mse: 0.4637\n",
      "Epoch 303/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5229 - mse: 0.5150 - val_loss: 0.4801 - val_mse: 0.4722\n",
      "Epoch 304/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5184 - mse: 0.5104 - val_loss: 0.4856 - val_mse: 0.4776\n",
      "Epoch 305/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5158 - mse: 0.5079 - val_loss: 0.4717 - val_mse: 0.4637\n",
      "Epoch 306/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5206 - mse: 0.5126 - val_loss: 0.4751 - val_mse: 0.4671\n",
      "Epoch 307/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5164 - mse: 0.5085 - val_loss: 0.4805 - val_mse: 0.4726\n",
      "Epoch 308/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5213 - mse: 0.5134 - val_loss: 0.4834 - val_mse: 0.4754\n",
      "Epoch 309/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5265 - mse: 0.5185 - val_loss: 0.4841 - val_mse: 0.4762\n",
      "Epoch 310/1000\n",
      "261/273 [===========================>..] - ETA: 0s - loss: 0.5179 - mse: 0.5100\n",
      "Epoch 00310: saving model to Regression_Model/thle2.mse.linear-0310.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.5156 - mse: 0.5077 - val_loss: 0.4803 - val_mse: 0.4723\n",
      "Epoch 311/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5203 - mse: 0.5124 - val_loss: 0.4851 - val_mse: 0.4772\n",
      "Epoch 312/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5227 - mse: 0.5148 - val_loss: 0.4790 - val_mse: 0.4711\n",
      "Epoch 313/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5123 - mse: 0.5044 - val_loss: 0.4962 - val_mse: 0.4883\n",
      "Epoch 314/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5156 - mse: 0.5077 - val_loss: 0.4761 - val_mse: 0.4682\n",
      "Epoch 315/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5177 - mse: 0.5098 - val_loss: 0.4729 - val_mse: 0.4650\n",
      "Epoch 316/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5258 - mse: 0.5179 - val_loss: 0.4773 - val_mse: 0.4694\n",
      "Epoch 317/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5161 - mse: 0.5082 - val_loss: 0.4833 - val_mse: 0.4754\n",
      "Epoch 318/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5216 - mse: 0.5137 - val_loss: 0.4802 - val_mse: 0.4723\n",
      "Epoch 319/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5169 - mse: 0.5090 - val_loss: 0.4740 - val_mse: 0.4661\n",
      "Epoch 320/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5207 - mse: 0.5128\n",
      "Epoch 00320: saving model to Regression_Model/thle2.mse.linear-0320.ckpt\n",
      "273/273 [==============================] - 8s 29ms/step - loss: 0.5206 - mse: 0.5127 - val_loss: 0.4769 - val_mse: 0.4690\n",
      "Epoch 321/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5201 - mse: 0.5122 - val_loss: 0.4803 - val_mse: 0.4724\n",
      "Epoch 322/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5260 - mse: 0.5181 - val_loss: 0.4767 - val_mse: 0.4688\n",
      "Epoch 323/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5225 - mse: 0.5146 - val_loss: 0.4846 - val_mse: 0.4767\n",
      "Epoch 324/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5218 - mse: 0.5139 - val_loss: 0.4700 - val_mse: 0.4621\n",
      "Epoch 325/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5184 - mse: 0.5105 - val_loss: 0.4803 - val_mse: 0.4725\n",
      "Epoch 326/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5211 - mse: 0.5132 - val_loss: 0.4809 - val_mse: 0.4730\n",
      "Epoch 327/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5131 - mse: 0.5052 - val_loss: 0.4668 - val_mse: 0.4589\n",
      "Epoch 328/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5226 - mse: 0.5147 - val_loss: 0.4736 - val_mse: 0.4657\n",
      "Epoch 329/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5181 - mse: 0.5102 - val_loss: 0.4787 - val_mse: 0.4708\n",
      "Epoch 330/1000\n",
      "265/273 [============================>.] - ETA: 0s - loss: 0.5172 - mse: 0.5093\n",
      "Epoch 00330: saving model to Regression_Model/thle2.mse.linear-0330.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5212 - mse: 0.5134 - val_loss: 0.4845 - val_mse: 0.4767\n",
      "Epoch 331/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5251 - mse: 0.5172 - val_loss: 0.4728 - val_mse: 0.4649\n",
      "Epoch 332/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5231 - mse: 0.5152 - val_loss: 0.4747 - val_mse: 0.4668\n",
      "Epoch 333/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5243 - mse: 0.5164 - val_loss: 0.4904 - val_mse: 0.4825\n",
      "Epoch 334/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5197 - mse: 0.5118 - val_loss: 0.4777 - val_mse: 0.4698\n",
      "Epoch 335/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5159 - mse: 0.5080 - val_loss: 0.4756 - val_mse: 0.4677\n",
      "Epoch 336/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5162 - mse: 0.5083 - val_loss: 0.4758 - val_mse: 0.4679\n",
      "Epoch 337/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5209 - mse: 0.5130 - val_loss: 0.4759 - val_mse: 0.4680\n",
      "Epoch 338/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5253 - mse: 0.5174 - val_loss: 0.4823 - val_mse: 0.4744\n",
      "Epoch 339/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5203 - mse: 0.5124 - val_loss: 0.4796 - val_mse: 0.4717\n",
      "Epoch 340/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5174 - mse: 0.5096\n",
      "Epoch 00340: saving model to Regression_Model/thle2.mse.linear-0340.ckpt\n",
      "273/273 [==============================] - 6s 21ms/step - loss: 0.5166 - mse: 0.5088 - val_loss: 0.4844 - val_mse: 0.4766\n",
      "Epoch 341/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5168 - mse: 0.5090 - val_loss: 0.4727 - val_mse: 0.4649\n",
      "Epoch 342/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5325 - mse: 0.5246 - val_loss: 0.4793 - val_mse: 0.4714\n",
      "Epoch 343/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5097 - mse: 0.5018 - val_loss: 0.4700 - val_mse: 0.4622\n",
      "Epoch 344/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5183 - mse: 0.5105 - val_loss: 0.4725 - val_mse: 0.4646\n",
      "Epoch 345/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5171 - mse: 0.5093 - val_loss: 0.4773 - val_mse: 0.4695\n",
      "Epoch 346/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5115 - mse: 0.5037 - val_loss: 0.4785 - val_mse: 0.4707\n",
      "Epoch 347/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5247 - mse: 0.5169 - val_loss: 0.4727 - val_mse: 0.4649\n",
      "Epoch 348/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5155 - mse: 0.5077 - val_loss: 0.4774 - val_mse: 0.4696\n",
      "Epoch 349/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5169 - mse: 0.5091 - val_loss: 0.4754 - val_mse: 0.4676\n",
      "Epoch 350/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5138 - mse: 0.5060\n",
      "Epoch 00350: saving model to Regression_Model/thle2.mse.linear-0350.ckpt\n",
      "273/273 [==============================] - 7s 24ms/step - loss: 0.5142 - mse: 0.5064 - val_loss: 0.4745 - val_mse: 0.4667\n",
      "Epoch 351/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5173 - mse: 0.5095 - val_loss: 0.4807 - val_mse: 0.4729\n",
      "Epoch 352/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5175 - mse: 0.5097 - val_loss: 0.4802 - val_mse: 0.4724\n",
      "Epoch 353/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5191 - mse: 0.5113 - val_loss: 0.4711 - val_mse: 0.4633\n",
      "Epoch 354/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5155 - mse: 0.5077 - val_loss: 0.4834 - val_mse: 0.4756\n",
      "Epoch 355/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5120 - mse: 0.5042 - val_loss: 0.4702 - val_mse: 0.4624\n",
      "Epoch 356/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5214 - mse: 0.5136 - val_loss: 0.4891 - val_mse: 0.4813\n",
      "Epoch 357/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5186 - mse: 0.5108 - val_loss: 0.4788 - val_mse: 0.4710\n",
      "Epoch 358/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5088 - mse: 0.5010 - val_loss: 0.4759 - val_mse: 0.4681\n",
      "Epoch 359/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5165 - mse: 0.5087 - val_loss: 0.4792 - val_mse: 0.4714\n",
      "Epoch 360/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.5256 - mse: 0.5179\n",
      "Epoch 00360: saving model to Regression_Model/thle2.mse.linear-0360.ckpt\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.5264 - mse: 0.5186 - val_loss: 0.4952 - val_mse: 0.4874\n",
      "Epoch 361/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5239 - mse: 0.5161 - val_loss: 0.4832 - val_mse: 0.4754\n",
      "Epoch 362/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5187 - mse: 0.5109 - val_loss: 0.4723 - val_mse: 0.4645\n",
      "Epoch 363/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5174 - mse: 0.5096 - val_loss: 0.4924 - val_mse: 0.4846\n",
      "Epoch 364/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5196 - mse: 0.5118 - val_loss: 0.4773 - val_mse: 0.4696\n",
      "Epoch 365/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5135 - mse: 0.5058 - val_loss: 0.4820 - val_mse: 0.4742\n",
      "Epoch 366/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5134 - mse: 0.5056 - val_loss: 0.4706 - val_mse: 0.4629\n",
      "Epoch 367/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5127 - mse: 0.5049 - val_loss: 0.4836 - val_mse: 0.4758\n",
      "Epoch 368/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5187 - mse: 0.5110 - val_loss: 0.4827 - val_mse: 0.4749\n",
      "Epoch 369/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5139 - mse: 0.5062 - val_loss: 0.4748 - val_mse: 0.4671\n",
      "Epoch 370/1000\n",
      "261/273 [===========================>..] - ETA: 0s - loss: 0.5149 - mse: 0.5072\n",
      "Epoch 00370: saving model to Regression_Model/thle2.mse.linear-0370.ckpt\n",
      "273/273 [==============================] - 4s 13ms/step - loss: 0.5145 - mse: 0.5067 - val_loss: 0.4762 - val_mse: 0.4684\n",
      "Epoch 371/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5195 - mse: 0.5117 - val_loss: 0.4784 - val_mse: 0.4707\n",
      "Epoch 372/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5199 - mse: 0.5121 - val_loss: 0.4706 - val_mse: 0.4629\n",
      "Epoch 373/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5155 - mse: 0.5077 - val_loss: 0.4770 - val_mse: 0.4692\n",
      "Epoch 374/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5180 - mse: 0.5103 - val_loss: 0.4930 - val_mse: 0.4853\n",
      "Epoch 375/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5131 - mse: 0.5053 - val_loss: 0.4697 - val_mse: 0.4620\n",
      "Epoch 376/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5139 - mse: 0.5062 - val_loss: 0.4692 - val_mse: 0.4615\n",
      "Epoch 377/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5171 - mse: 0.5093 - val_loss: 0.4689 - val_mse: 0.4612\n",
      "Epoch 378/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5165 - mse: 0.5088 - val_loss: 0.4749 - val_mse: 0.4672\n",
      "Epoch 379/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5125 - mse: 0.5047 - val_loss: 0.4723 - val_mse: 0.4646\n",
      "Epoch 380/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5170 - mse: 0.5093\n",
      "Epoch 00380: saving model to Regression_Model/thle2.mse.linear-0380.ckpt\n",
      "273/273 [==============================] - 5s 17ms/step - loss: 0.5166 - mse: 0.5088 - val_loss: 0.4672 - val_mse: 0.4595\n",
      "Epoch 381/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5197 - mse: 0.5119 - val_loss: 0.4756 - val_mse: 0.4678\n",
      "Epoch 382/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5156 - mse: 0.5079 - val_loss: 0.4801 - val_mse: 0.4724\n",
      "Epoch 383/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5147 - mse: 0.5070 - val_loss: 0.4860 - val_mse: 0.4783\n",
      "Epoch 384/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5175 - mse: 0.5098 - val_loss: 0.4771 - val_mse: 0.4694\n",
      "Epoch 385/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5234 - mse: 0.5156 - val_loss: 0.4763 - val_mse: 0.4686\n",
      "Epoch 386/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5069 - mse: 0.4992 - val_loss: 0.4715 - val_mse: 0.4638\n",
      "Epoch 387/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5253 - mse: 0.5176 - val_loss: 0.4750 - val_mse: 0.4673\n",
      "Epoch 388/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5135 - mse: 0.5058 - val_loss: 0.4732 - val_mse: 0.4655\n",
      "Epoch 389/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5244 - mse: 0.5167 - val_loss: 0.4735 - val_mse: 0.4658\n",
      "Epoch 390/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.5159 - mse: 0.5082\n",
      "Epoch 00390: saving model to Regression_Model/thle2.mse.linear-0390.ckpt\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5143 - mse: 0.5066 - val_loss: 0.4779 - val_mse: 0.4702\n",
      "Epoch 391/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5111 - mse: 0.5034 - val_loss: 0.4778 - val_mse: 0.4701\n",
      "Epoch 392/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5178 - mse: 0.5101 - val_loss: 0.4751 - val_mse: 0.4674\n",
      "Epoch 393/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5195 - mse: 0.5118 - val_loss: 0.4813 - val_mse: 0.4736\n",
      "Epoch 394/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5175 - mse: 0.5098 - val_loss: 0.4756 - val_mse: 0.4680\n",
      "Epoch 395/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5135 - mse: 0.5058 - val_loss: 0.4737 - val_mse: 0.4660\n",
      "Epoch 396/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5134 - mse: 0.5057 - val_loss: 0.4692 - val_mse: 0.4616\n",
      "Epoch 397/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5154 - mse: 0.5077 - val_loss: 0.4760 - val_mse: 0.4684\n",
      "Epoch 398/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5089 - mse: 0.5013 - val_loss: 0.4787 - val_mse: 0.4710\n",
      "Epoch 399/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5109 - mse: 0.5033 - val_loss: 0.4753 - val_mse: 0.4676\n",
      "Epoch 400/1000\n",
      "261/273 [===========================>..] - ETA: 0s - loss: 0.5185 - mse: 0.5108\n",
      "Epoch 00400: saving model to Regression_Model/thle2.mse.linear-0400.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5188 - mse: 0.5111 - val_loss: 0.4722 - val_mse: 0.4645\n",
      "Epoch 401/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5190 - mse: 0.5114 - val_loss: 0.4751 - val_mse: 0.4674\n",
      "Epoch 402/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5082 - mse: 0.5005 - val_loss: 0.4674 - val_mse: 0.4597\n",
      "Epoch 403/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5071 - mse: 0.4994 - val_loss: 0.4721 - val_mse: 0.4644\n",
      "Epoch 404/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5163 - mse: 0.5087 - val_loss: 0.4758 - val_mse: 0.4681\n",
      "Epoch 405/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5121 - mse: 0.5045 - val_loss: 0.4726 - val_mse: 0.4649\n",
      "Epoch 406/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5090 - mse: 0.5014 - val_loss: 0.4670 - val_mse: 0.4593\n",
      "Epoch 407/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5177 - mse: 0.5100 - val_loss: 0.4735 - val_mse: 0.4659\n",
      "Epoch 408/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5159 - mse: 0.5082 - val_loss: 0.4751 - val_mse: 0.4674\n",
      "Epoch 409/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5120 - mse: 0.5043 - val_loss: 0.4720 - val_mse: 0.4643\n",
      "Epoch 410/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5197 - mse: 0.5121\n",
      "Epoch 00410: saving model to Regression_Model/thle2.mse.linear-0410.ckpt\n",
      "273/273 [==============================] - 6s 21ms/step - loss: 0.5200 - mse: 0.5124 - val_loss: 0.4816 - val_mse: 0.4740\n",
      "Epoch 411/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5134 - mse: 0.5058 - val_loss: 0.4746 - val_mse: 0.4670\n",
      "Epoch 412/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5153 - mse: 0.5077 - val_loss: 0.4737 - val_mse: 0.4661\n",
      "Epoch 413/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5103 - mse: 0.5027 - val_loss: 0.4721 - val_mse: 0.4644\n",
      "Epoch 414/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5133 - mse: 0.5057 - val_loss: 0.4705 - val_mse: 0.4628\n",
      "Epoch 415/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5146 - mse: 0.5069 - val_loss: 0.4842 - val_mse: 0.4766\n",
      "Epoch 416/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5174 - mse: 0.5098 - val_loss: 0.4723 - val_mse: 0.4647\n",
      "Epoch 417/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5102 - mse: 0.5026 - val_loss: 0.4766 - val_mse: 0.4690\n",
      "Epoch 418/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5116 - mse: 0.5040 - val_loss: 0.4697 - val_mse: 0.4621\n",
      "Epoch 419/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5149 - mse: 0.5073 - val_loss: 0.4843 - val_mse: 0.4767\n",
      "Epoch 420/1000\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.5134 - mse: 0.5057\n",
      "Epoch 00420: saving model to Regression_Model/thle2.mse.linear-0420.ckpt\n",
      "273/273 [==============================] - 7s 26ms/step - loss: 0.5116 - mse: 0.5040 - val_loss: 0.4779 - val_mse: 0.4702\n",
      "Epoch 421/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5163 - mse: 0.5087 - val_loss: 0.4704 - val_mse: 0.4628\n",
      "Epoch 422/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5172 - mse: 0.5096 - val_loss: 0.4744 - val_mse: 0.4668\n",
      "Epoch 423/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5063 - mse: 0.4986 - val_loss: 0.4692 - val_mse: 0.4616\n",
      "Epoch 424/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5152 - mse: 0.5076 - val_loss: 0.4702 - val_mse: 0.4626\n",
      "Epoch 425/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5085 - mse: 0.5008 - val_loss: 0.4706 - val_mse: 0.4629\n",
      "Epoch 426/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5081 - mse: 0.5004 - val_loss: 0.4832 - val_mse: 0.4756\n",
      "Epoch 427/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5190 - mse: 0.5114 - val_loss: 0.4744 - val_mse: 0.4668\n",
      "Epoch 428/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5109 - mse: 0.5033 - val_loss: 0.4770 - val_mse: 0.4694\n",
      "Epoch 429/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5079 - mse: 0.5003 - val_loss: 0.4723 - val_mse: 0.4647\n",
      "Epoch 430/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5099 - mse: 0.5023\n",
      "Epoch 00430: saving model to Regression_Model/thle2.mse.linear-0430.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5093 - mse: 0.5017 - val_loss: 0.4727 - val_mse: 0.4651\n",
      "Epoch 431/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5184 - mse: 0.5108 - val_loss: 0.4767 - val_mse: 0.4691\n",
      "Epoch 432/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5138 - mse: 0.5062 - val_loss: 0.4697 - val_mse: 0.4621\n",
      "Epoch 433/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5128 - mse: 0.5052 - val_loss: 0.4751 - val_mse: 0.4675\n",
      "Epoch 434/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5191 - mse: 0.5115 - val_loss: 0.4745 - val_mse: 0.4669\n",
      "Epoch 435/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5115 - mse: 0.5039 - val_loss: 0.4749 - val_mse: 0.4674\n",
      "Epoch 436/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5135 - mse: 0.5059 - val_loss: 0.4719 - val_mse: 0.4643\n",
      "Epoch 437/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5086 - mse: 0.5010 - val_loss: 0.4867 - val_mse: 0.4791\n",
      "Epoch 438/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5077 - mse: 0.5002 - val_loss: 0.4736 - val_mse: 0.4660\n",
      "Epoch 439/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5159 - mse: 0.5083 - val_loss: 0.4783 - val_mse: 0.4708\n",
      "Epoch 440/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.5176 - mse: 0.5100\n",
      "Epoch 00440: saving model to Regression_Model/thle2.mse.linear-0440.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.5157 - mse: 0.5081 - val_loss: 0.4757 - val_mse: 0.4681\n",
      "Epoch 441/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5132 - mse: 0.5056 - val_loss: 0.4767 - val_mse: 0.4692\n",
      "Epoch 442/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5100 - mse: 0.5024 - val_loss: 0.4764 - val_mse: 0.4689\n",
      "Epoch 443/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5177 - mse: 0.5102 - val_loss: 0.4713 - val_mse: 0.4637\n",
      "Epoch 444/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5114 - mse: 0.5038 - val_loss: 0.4828 - val_mse: 0.4752\n",
      "Epoch 445/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5122 - mse: 0.5046 - val_loss: 0.4749 - val_mse: 0.4673\n",
      "Epoch 446/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5126 - mse: 0.5050 - val_loss: 0.4790 - val_mse: 0.4715\n",
      "Epoch 447/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5116 - mse: 0.5041 - val_loss: 0.4841 - val_mse: 0.4765\n",
      "Epoch 448/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5104 - mse: 0.5028 - val_loss: 0.4714 - val_mse: 0.4638\n",
      "Epoch 449/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5147 - mse: 0.5071 - val_loss: 0.4707 - val_mse: 0.4631\n",
      "Epoch 450/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5162 - mse: 0.5087\n",
      "Epoch 00450: saving model to Regression_Model/thle2.mse.linear-0450.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.5158 - mse: 0.5082 - val_loss: 0.4670 - val_mse: 0.4595\n",
      "Epoch 451/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5170 - mse: 0.5094 - val_loss: 0.4692 - val_mse: 0.4617\n",
      "Epoch 452/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5150 - mse: 0.5074 - val_loss: 0.4692 - val_mse: 0.4617\n",
      "Epoch 453/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5148 - mse: 0.5073 - val_loss: 0.4776 - val_mse: 0.4700\n",
      "Epoch 454/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5142 - mse: 0.5067 - val_loss: 0.4716 - val_mse: 0.4641\n",
      "Epoch 455/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5091 - mse: 0.5016 - val_loss: 0.4703 - val_mse: 0.4628\n",
      "Epoch 456/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5139 - mse: 0.5064 - val_loss: 0.4691 - val_mse: 0.4616\n",
      "Epoch 457/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5141 - mse: 0.5065 - val_loss: 0.4724 - val_mse: 0.4649\n",
      "Epoch 458/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5121 - mse: 0.5046 - val_loss: 0.4699 - val_mse: 0.4623\n",
      "Epoch 459/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5127 - mse: 0.5052 - val_loss: 0.4654 - val_mse: 0.4578\n",
      "Epoch 460/1000\n",
      "259/273 [===========================>..] - ETA: 0s - loss: 0.5095 - mse: 0.5019\n",
      "Epoch 00460: saving model to Regression_Model/thle2.mse.linear-0460.ckpt\n",
      "273/273 [==============================] - 6s 21ms/step - loss: 0.5109 - mse: 0.5034 - val_loss: 0.4727 - val_mse: 0.4652\n",
      "Epoch 461/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5134 - mse: 0.5058 - val_loss: 0.4710 - val_mse: 0.4634\n",
      "Epoch 462/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5101 - mse: 0.5026 - val_loss: 0.4757 - val_mse: 0.4682\n",
      "Epoch 463/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5085 - mse: 0.5010 - val_loss: 0.4698 - val_mse: 0.4622\n",
      "Epoch 464/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5141 - mse: 0.5065 - val_loss: 0.4746 - val_mse: 0.4671\n",
      "Epoch 465/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5064 - mse: 0.4989 - val_loss: 0.4847 - val_mse: 0.4772\n",
      "Epoch 466/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5106 - mse: 0.5031 - val_loss: 0.4759 - val_mse: 0.4684\n",
      "Epoch 467/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5100 - mse: 0.5025 - val_loss: 0.4718 - val_mse: 0.4643\n",
      "Epoch 468/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5141 - mse: 0.5066 - val_loss: 0.4747 - val_mse: 0.4672\n",
      "Epoch 469/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5090 - mse: 0.5015 - val_loss: 0.4736 - val_mse: 0.4661\n",
      "Epoch 470/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5168 - mse: 0.5093\n",
      "Epoch 00470: saving model to Regression_Model/thle2.mse.linear-0470.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5144 - mse: 0.5068 - val_loss: 0.4715 - val_mse: 0.4640\n",
      "Epoch 471/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5166 - mse: 0.5090 - val_loss: 0.4727 - val_mse: 0.4652\n",
      "Epoch 472/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5153 - mse: 0.5078 - val_loss: 0.4717 - val_mse: 0.4642\n",
      "Epoch 473/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5145 - mse: 0.5070 - val_loss: 0.4673 - val_mse: 0.4598\n",
      "Epoch 474/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5089 - mse: 0.5014 - val_loss: 0.4731 - val_mse: 0.4656\n",
      "Epoch 475/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5144 - mse: 0.5069 - val_loss: 0.4700 - val_mse: 0.4625\n",
      "Epoch 476/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5063 - mse: 0.4989 - val_loss: 0.4700 - val_mse: 0.4625\n",
      "Epoch 477/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5070 - mse: 0.4995 - val_loss: 0.4668 - val_mse: 0.4593\n",
      "Epoch 478/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5053 - mse: 0.4979 - val_loss: 0.4800 - val_mse: 0.4725\n",
      "Epoch 479/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5073 - mse: 0.4998 - val_loss: 0.4776 - val_mse: 0.4701\n",
      "Epoch 480/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5096 - mse: 0.5021\n",
      "Epoch 00480: saving model to Regression_Model/thle2.mse.linear-0480.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.5098 - mse: 0.5024 - val_loss: 0.4720 - val_mse: 0.4645\n",
      "Epoch 481/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5142 - mse: 0.5067 - val_loss: 0.4711 - val_mse: 0.4636\n",
      "Epoch 482/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5105 - mse: 0.5031 - val_loss: 0.4658 - val_mse: 0.4583\n",
      "Epoch 483/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5101 - mse: 0.5027 - val_loss: 0.4782 - val_mse: 0.4707\n",
      "Epoch 484/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5272 - mse: 0.5197 - val_loss: 0.4708 - val_mse: 0.4633\n",
      "Epoch 485/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5058 - mse: 0.4983 - val_loss: 0.4731 - val_mse: 0.4656\n",
      "Epoch 486/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5136 - mse: 0.5062 - val_loss: 0.4694 - val_mse: 0.4619\n",
      "Epoch 487/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5184 - mse: 0.5110 - val_loss: 0.4654 - val_mse: 0.4580\n",
      "Epoch 488/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5145 - mse: 0.5070 - val_loss: 0.4716 - val_mse: 0.4642\n",
      "Epoch 489/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5124 - mse: 0.5049 - val_loss: 0.4733 - val_mse: 0.4658\n",
      "Epoch 490/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5056 - mse: 0.4981\n",
      "Epoch 00490: saving model to Regression_Model/thle2.mse.linear-0490.ckpt\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.5066 - mse: 0.4992 - val_loss: 0.4691 - val_mse: 0.4617\n",
      "Epoch 491/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5143 - mse: 0.5069 - val_loss: 0.4700 - val_mse: 0.4625\n",
      "Epoch 492/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5107 - mse: 0.5032 - val_loss: 0.4694 - val_mse: 0.4619\n",
      "Epoch 493/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5099 - mse: 0.5024 - val_loss: 0.4740 - val_mse: 0.4665\n",
      "Epoch 494/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5140 - mse: 0.5065 - val_loss: 0.4799 - val_mse: 0.4725\n",
      "Epoch 495/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5106 - mse: 0.5032 - val_loss: 0.4676 - val_mse: 0.4602\n",
      "Epoch 496/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5205 - mse: 0.5131 - val_loss: 0.4685 - val_mse: 0.4610\n",
      "Epoch 497/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5152 - mse: 0.5078 - val_loss: 0.4701 - val_mse: 0.4627\n",
      "Epoch 498/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5079 - mse: 0.5004 - val_loss: 0.4718 - val_mse: 0.4644\n",
      "Epoch 499/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5146 - mse: 0.5071 - val_loss: 0.4707 - val_mse: 0.4633\n",
      "Epoch 500/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.5106 - mse: 0.5032\n",
      "Epoch 00500: saving model to Regression_Model/thle2.mse.linear-0500.ckpt\n",
      "273/273 [==============================] - 6s 21ms/step - loss: 0.5085 - mse: 0.5011 - val_loss: 0.4717 - val_mse: 0.4642\n",
      "Epoch 501/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5068 - mse: 0.4994 - val_loss: 0.4664 - val_mse: 0.4590\n",
      "Epoch 502/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5141 - mse: 0.5067 - val_loss: 0.4722 - val_mse: 0.4648\n",
      "Epoch 503/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5084 - mse: 0.5010 - val_loss: 0.4742 - val_mse: 0.4668\n",
      "Epoch 504/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5167 - mse: 0.5092 - val_loss: 0.4703 - val_mse: 0.4629\n",
      "Epoch 505/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5030 - mse: 0.4956 - val_loss: 0.4658 - val_mse: 0.4583\n",
      "Epoch 506/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5139 - mse: 0.5065 - val_loss: 0.4714 - val_mse: 0.4640\n",
      "Epoch 507/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5091 - mse: 0.5017 - val_loss: 0.4708 - val_mse: 0.4634\n",
      "Epoch 508/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5128 - mse: 0.5054 - val_loss: 0.4749 - val_mse: 0.4674\n",
      "Epoch 509/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5065 - mse: 0.4991 - val_loss: 0.4667 - val_mse: 0.4592\n",
      "Epoch 510/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5075 - mse: 0.5001\n",
      "Epoch 00510: saving model to Regression_Model/thle2.mse.linear-0510.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5083 - mse: 0.5009 - val_loss: 0.4725 - val_mse: 0.4650\n",
      "Epoch 511/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5075 - mse: 0.5001 - val_loss: 0.4737 - val_mse: 0.4662\n",
      "Epoch 512/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5103 - mse: 0.5029 - val_loss: 0.4678 - val_mse: 0.4604\n",
      "Epoch 513/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5071 - mse: 0.4997 - val_loss: 0.4698 - val_mse: 0.4624\n",
      "Epoch 514/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5151 - mse: 0.5077 - val_loss: 0.4690 - val_mse: 0.4616\n",
      "Epoch 515/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5143 - mse: 0.5069 - val_loss: 0.4707 - val_mse: 0.4633\n",
      "Epoch 516/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5067 - mse: 0.4993 - val_loss: 0.4739 - val_mse: 0.4665\n",
      "Epoch 517/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5102 - mse: 0.5028 - val_loss: 0.4730 - val_mse: 0.4656\n",
      "Epoch 518/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5139 - mse: 0.5065 - val_loss: 0.4697 - val_mse: 0.4623\n",
      "Epoch 519/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5061 - mse: 0.4987 - val_loss: 0.4811 - val_mse: 0.4737\n",
      "Epoch 520/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5042 - mse: 0.4968\n",
      "Epoch 00520: saving model to Regression_Model/thle2.mse.linear-0520.ckpt\n",
      "273/273 [==============================] - 6s 24ms/step - loss: 0.5046 - mse: 0.4972 - val_loss: 0.4788 - val_mse: 0.4714\n",
      "Epoch 521/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5170 - mse: 0.5096 - val_loss: 0.4691 - val_mse: 0.4617\n",
      "Epoch 522/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5062 - mse: 0.4988 - val_loss: 0.4697 - val_mse: 0.4624\n",
      "Epoch 523/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5072 - mse: 0.4998 - val_loss: 0.4693 - val_mse: 0.4619\n",
      "Epoch 524/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5070 - mse: 0.4997 - val_loss: 0.4674 - val_mse: 0.4600\n",
      "Epoch 525/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5130 - mse: 0.5056 - val_loss: 0.4746 - val_mse: 0.4672\n",
      "Epoch 526/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5077 - mse: 0.5003 - val_loss: 0.4698 - val_mse: 0.4624\n",
      "Epoch 527/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5109 - mse: 0.5036 - val_loss: 0.4746 - val_mse: 0.4672\n",
      "Epoch 528/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5018 - mse: 0.4944 - val_loss: 0.4679 - val_mse: 0.4605\n",
      "Epoch 529/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5133 - mse: 0.5059 - val_loss: 0.4712 - val_mse: 0.4638\n",
      "Epoch 530/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5072 - mse: 0.4998\n",
      "Epoch 00530: saving model to Regression_Model/thle2.mse.linear-0530.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.5073 - mse: 0.4999 - val_loss: 0.4673 - val_mse: 0.4600\n",
      "Epoch 531/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5047 - mse: 0.4974 - val_loss: 0.4727 - val_mse: 0.4654\n",
      "Epoch 532/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5065 - mse: 0.4991 - val_loss: 0.4655 - val_mse: 0.4582\n",
      "Epoch 533/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5164 - mse: 0.5090 - val_loss: 0.4679 - val_mse: 0.4605\n",
      "Epoch 534/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5184 - mse: 0.5110 - val_loss: 0.4712 - val_mse: 0.4639\n",
      "Epoch 535/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5028 - mse: 0.4954 - val_loss: 0.4734 - val_mse: 0.4660\n",
      "Epoch 536/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5193 - mse: 0.5119 - val_loss: 0.4673 - val_mse: 0.4599\n",
      "Epoch 537/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5055 - mse: 0.4981 - val_loss: 0.4674 - val_mse: 0.4601\n",
      "Epoch 538/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5088 - mse: 0.5014 - val_loss: 0.4751 - val_mse: 0.4677\n",
      "Epoch 539/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5074 - mse: 0.5000 - val_loss: 0.4736 - val_mse: 0.4663\n",
      "Epoch 540/1000\n",
      "259/273 [===========================>..] - ETA: 0s - loss: 0.5090 - mse: 0.5016\n",
      "Epoch 00540: saving model to Regression_Model/thle2.mse.linear-0540.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.5077 - mse: 0.5003 - val_loss: 0.4688 - val_mse: 0.4615\n",
      "Epoch 541/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5079 - mse: 0.5005 - val_loss: 0.4715 - val_mse: 0.4642\n",
      "Epoch 542/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5133 - mse: 0.5059 - val_loss: 0.4726 - val_mse: 0.4653\n",
      "Epoch 543/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5016 - mse: 0.4943 - val_loss: 0.4739 - val_mse: 0.4666\n",
      "Epoch 544/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5059 - mse: 0.4985 - val_loss: 0.4710 - val_mse: 0.4637\n",
      "Epoch 545/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5064 - mse: 0.4990 - val_loss: 0.4726 - val_mse: 0.4653\n",
      "Epoch 546/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5091 - mse: 0.5018 - val_loss: 0.4684 - val_mse: 0.4611\n",
      "Epoch 547/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5057 - mse: 0.4984 - val_loss: 0.4695 - val_mse: 0.4622\n",
      "Epoch 548/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5060 - mse: 0.4987 - val_loss: 0.4665 - val_mse: 0.4591\n",
      "Epoch 549/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5191 - mse: 0.5117 - val_loss: 0.4708 - val_mse: 0.4635\n",
      "Epoch 550/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5047 - mse: 0.4974\n",
      "Epoch 00550: saving model to Regression_Model/thle2.mse.linear-0550.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5047 - mse: 0.4974 - val_loss: 0.4726 - val_mse: 0.4653\n",
      "Epoch 551/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5112 - mse: 0.5039 - val_loss: 0.4686 - val_mse: 0.4613\n",
      "Epoch 552/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5067 - mse: 0.4994 - val_loss: 0.4741 - val_mse: 0.4668\n",
      "Epoch 553/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5116 - mse: 0.5043 - val_loss: 0.4799 - val_mse: 0.4725\n",
      "Epoch 554/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5155 - mse: 0.5081 - val_loss: 0.4700 - val_mse: 0.4627\n",
      "Epoch 555/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5082 - mse: 0.5008 - val_loss: 0.4712 - val_mse: 0.4638\n",
      "Epoch 556/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5083 - mse: 0.5010 - val_loss: 0.4666 - val_mse: 0.4592\n",
      "Epoch 557/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5115 - mse: 0.5042 - val_loss: 0.4770 - val_mse: 0.4697\n",
      "Epoch 558/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5097 - mse: 0.5024 - val_loss: 0.4730 - val_mse: 0.4657\n",
      "Epoch 559/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5098 - mse: 0.5025 - val_loss: 0.4773 - val_mse: 0.4700\n",
      "Epoch 560/1000\n",
      "259/273 [===========================>..] - ETA: 0s - loss: 0.5089 - mse: 0.5016\n",
      "Epoch 00560: saving model to Regression_Model/thle2.mse.linear-0560.ckpt\n",
      "273/273 [==============================] - 6s 23ms/step - loss: 0.5081 - mse: 0.5008 - val_loss: 0.4716 - val_mse: 0.4643\n",
      "Epoch 561/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5033 - mse: 0.4959 - val_loss: 0.4747 - val_mse: 0.4674\n",
      "Epoch 562/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5106 - mse: 0.5033 - val_loss: 0.4664 - val_mse: 0.4591\n",
      "Epoch 563/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5142 - mse: 0.5069 - val_loss: 0.4707 - val_mse: 0.4634\n",
      "Epoch 564/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4959 - val_loss: 0.4727 - val_mse: 0.4654\n",
      "Epoch 565/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5101 - mse: 0.5028 - val_loss: 0.4737 - val_mse: 0.4664\n",
      "Epoch 566/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5072 - mse: 0.4999 - val_loss: 0.4737 - val_mse: 0.4664\n",
      "Epoch 567/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5101 - mse: 0.5028 - val_loss: 0.4694 - val_mse: 0.4621\n",
      "Epoch 568/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5096 - mse: 0.5023 - val_loss: 0.4753 - val_mse: 0.4680\n",
      "Epoch 569/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5085 - mse: 0.5012 - val_loss: 0.4655 - val_mse: 0.4583\n",
      "Epoch 570/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5074 - mse: 0.5001\n",
      "Epoch 00570: saving model to Regression_Model/thle2.mse.linear-0570.ckpt\n",
      "273/273 [==============================] - 11s 40ms/step - loss: 0.5077 - mse: 0.5004 - val_loss: 0.4645 - val_mse: 0.4572\n",
      "Epoch 571/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5046 - mse: 0.4973 - val_loss: 0.4720 - val_mse: 0.4647\n",
      "Epoch 572/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5093 - mse: 0.5020 - val_loss: 0.4694 - val_mse: 0.4621\n",
      "Epoch 573/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5045 - mse: 0.4972 - val_loss: 0.4675 - val_mse: 0.4602\n",
      "Epoch 574/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5070 - mse: 0.4998 - val_loss: 0.4732 - val_mse: 0.4659\n",
      "Epoch 575/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5146 - mse: 0.5073 - val_loss: 0.4748 - val_mse: 0.4675\n",
      "Epoch 576/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5123 - mse: 0.5050 - val_loss: 0.4671 - val_mse: 0.4598\n",
      "Epoch 577/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5054 - mse: 0.4981 - val_loss: 0.4706 - val_mse: 0.4633\n",
      "Epoch 578/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5042 - mse: 0.4969 - val_loss: 0.4673 - val_mse: 0.4600\n",
      "Epoch 579/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5073 - mse: 0.5000 - val_loss: 0.4689 - val_mse: 0.4616\n",
      "Epoch 580/1000\n",
      "261/273 [===========================>..] - ETA: 0s - loss: 0.5115 - mse: 0.5042\n",
      "Epoch 00580: saving model to Regression_Model/thle2.mse.linear-0580.ckpt\n",
      "273/273 [==============================] - 4s 13ms/step - loss: 0.5123 - mse: 0.5051 - val_loss: 0.4718 - val_mse: 0.4645\n",
      "Epoch 581/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5046 - mse: 0.4973 - val_loss: 0.4781 - val_mse: 0.4709\n",
      "Epoch 582/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5106 - mse: 0.5034 - val_loss: 0.4663 - val_mse: 0.4590\n",
      "Epoch 583/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5035 - mse: 0.4963 - val_loss: 0.4718 - val_mse: 0.4646\n",
      "Epoch 584/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5147 - mse: 0.5074 - val_loss: 0.4754 - val_mse: 0.4681\n",
      "Epoch 585/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5157 - mse: 0.5084 - val_loss: 0.4696 - val_mse: 0.4623\n",
      "Epoch 586/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5132 - mse: 0.5059 - val_loss: 0.4694 - val_mse: 0.4621\n",
      "Epoch 587/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5065 - mse: 0.4992 - val_loss: 0.4706 - val_mse: 0.4633\n",
      "Epoch 588/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5088 - mse: 0.5016 - val_loss: 0.4699 - val_mse: 0.4627\n",
      "Epoch 589/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5089 - mse: 0.5017 - val_loss: 0.4725 - val_mse: 0.4652\n",
      "Epoch 590/1000\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.5101 - mse: 0.5028\n",
      "Epoch 00590: saving model to Regression_Model/thle2.mse.linear-0590.ckpt\n",
      "273/273 [==============================] - 3s 9ms/step - loss: 0.5099 - mse: 0.5026 - val_loss: 0.4677 - val_mse: 0.4605\n",
      "Epoch 591/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5091 - mse: 0.5019 - val_loss: 0.4729 - val_mse: 0.4657\n",
      "Epoch 592/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5081 - mse: 0.5008 - val_loss: 0.4671 - val_mse: 0.4598\n",
      "Epoch 593/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5047 - mse: 0.4975 - val_loss: 0.4766 - val_mse: 0.4693\n",
      "Epoch 594/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5036 - mse: 0.4963 - val_loss: 0.4662 - val_mse: 0.4590\n",
      "Epoch 595/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5101 - mse: 0.5028 - val_loss: 0.4684 - val_mse: 0.4612\n",
      "Epoch 596/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5072 - mse: 0.5000 - val_loss: 0.4662 - val_mse: 0.4590\n",
      "Epoch 597/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5085 - mse: 0.5013 - val_loss: 0.4724 - val_mse: 0.4652\n",
      "Epoch 598/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5077 - mse: 0.5005 - val_loss: 0.4718 - val_mse: 0.4645\n",
      "Epoch 599/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5051 - mse: 0.4979 - val_loss: 0.4712 - val_mse: 0.4640\n",
      "Epoch 600/1000\n",
      "264/273 [============================>.] - ETA: 0s - loss: 0.5150 - mse: 0.5077\n",
      "Epoch 00600: saving model to Regression_Model/thle2.mse.linear-0600.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.5159 - mse: 0.5087 - val_loss: 0.4708 - val_mse: 0.4636\n",
      "Epoch 601/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5085 - mse: 0.5012 - val_loss: 0.4737 - val_mse: 0.4665\n",
      "Epoch 602/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5066 - mse: 0.4994 - val_loss: 0.4753 - val_mse: 0.4681\n",
      "Epoch 603/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5143 - mse: 0.5071 - val_loss: 0.4730 - val_mse: 0.4658\n",
      "Epoch 604/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5112 - mse: 0.5040 - val_loss: 0.4658 - val_mse: 0.4586\n",
      "Epoch 605/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5036 - mse: 0.4963 - val_loss: 0.4722 - val_mse: 0.4650\n",
      "Epoch 606/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5102 - mse: 0.5030 - val_loss: 0.4758 - val_mse: 0.4686\n",
      "Epoch 607/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5107 - mse: 0.5035 - val_loss: 0.4675 - val_mse: 0.4603\n",
      "Epoch 608/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5068 - mse: 0.4996 - val_loss: 0.4698 - val_mse: 0.4626\n",
      "Epoch 609/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5163 - mse: 0.5091 - val_loss: 0.4686 - val_mse: 0.4614\n",
      "Epoch 610/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5090 - mse: 0.5018\n",
      "Epoch 00610: saving model to Regression_Model/thle2.mse.linear-0610.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.5084 - mse: 0.5012 - val_loss: 0.4679 - val_mse: 0.4607\n",
      "Epoch 611/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5100 - mse: 0.5028 - val_loss: 0.4712 - val_mse: 0.4640\n",
      "Epoch 612/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5055 - mse: 0.4983 - val_loss: 0.4733 - val_mse: 0.4661\n",
      "Epoch 613/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5149 - mse: 0.5077 - val_loss: 0.4708 - val_mse: 0.4636\n",
      "Epoch 614/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5078 - mse: 0.5006 - val_loss: 0.4660 - val_mse: 0.4588\n",
      "Epoch 615/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5061 - mse: 0.4989 - val_loss: 0.4723 - val_mse: 0.4651\n",
      "Epoch 616/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5049 - mse: 0.4977 - val_loss: 0.4712 - val_mse: 0.4640\n",
      "Epoch 617/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5126 - mse: 0.5054 - val_loss: 0.4658 - val_mse: 0.4586\n",
      "Epoch 618/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5032 - mse: 0.4960 - val_loss: 0.4779 - val_mse: 0.4707\n",
      "Epoch 619/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5069 - mse: 0.4997 - val_loss: 0.4709 - val_mse: 0.4637\n",
      "Epoch 620/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.5074 - mse: 0.5002\n",
      "Epoch 00620: saving model to Regression_Model/thle2.mse.linear-0620.ckpt\n",
      "273/273 [==============================] - 5s 20ms/step - loss: 0.5082 - mse: 0.5010 - val_loss: 0.4781 - val_mse: 0.4709\n",
      "Epoch 621/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5111 - mse: 0.5039 - val_loss: 0.4653 - val_mse: 0.4581\n",
      "Epoch 622/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5058 - mse: 0.4986 - val_loss: 0.4731 - val_mse: 0.4660\n",
      "Epoch 623/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5062 - mse: 0.4990 - val_loss: 0.4759 - val_mse: 0.4687\n",
      "Epoch 624/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5014 - mse: 0.4942 - val_loss: 0.4686 - val_mse: 0.4614\n",
      "Epoch 625/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5084 - mse: 0.5013 - val_loss: 0.4669 - val_mse: 0.4597\n",
      "Epoch 626/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5065 - mse: 0.4994 - val_loss: 0.4734 - val_mse: 0.4662\n",
      "Epoch 627/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5035 - mse: 0.4963 - val_loss: 0.4703 - val_mse: 0.4631\n",
      "Epoch 628/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5062 - mse: 0.4990 - val_loss: 0.4723 - val_mse: 0.4651\n",
      "Epoch 629/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5112 - mse: 0.5041 - val_loss: 0.4672 - val_mse: 0.4600\n",
      "Epoch 630/1000\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.5061 - mse: 0.4989\n",
      "Epoch 00630: saving model to Regression_Model/thle2.mse.linear-0630.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5055 - mse: 0.4983 - val_loss: 0.4676 - val_mse: 0.4605\n",
      "Epoch 631/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5079 - mse: 0.5008 - val_loss: 0.4653 - val_mse: 0.4581\n",
      "Epoch 632/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5125 - mse: 0.5054 - val_loss: 0.4723 - val_mse: 0.4651\n",
      "Epoch 633/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5067 - mse: 0.4995 - val_loss: 0.4651 - val_mse: 0.4579\n",
      "Epoch 634/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5020 - mse: 0.4948 - val_loss: 0.4643 - val_mse: 0.4571\n",
      "Epoch 635/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5077 - mse: 0.5006 - val_loss: 0.4645 - val_mse: 0.4573\n",
      "Epoch 636/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5069 - mse: 0.4998 - val_loss: 0.4663 - val_mse: 0.4592\n",
      "Epoch 637/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5135 - mse: 0.5064 - val_loss: 0.4737 - val_mse: 0.4666\n",
      "Epoch 638/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5084 - mse: 0.5012 - val_loss: 0.4681 - val_mse: 0.4609\n",
      "Epoch 639/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5122 - mse: 0.5050 - val_loss: 0.4700 - val_mse: 0.4628\n",
      "Epoch 640/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5005 - mse: 0.4933\n",
      "Epoch 00640: saving model to Regression_Model/thle2.mse.linear-0640.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.5033 - mse: 0.4961 - val_loss: 0.4734 - val_mse: 0.4663\n",
      "Epoch 641/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5038 - mse: 0.4966 - val_loss: 0.4671 - val_mse: 0.4600\n",
      "Epoch 642/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5148 - mse: 0.5077 - val_loss: 0.4642 - val_mse: 0.4570\n",
      "Epoch 643/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4977 - mse: 0.4905 - val_loss: 0.4693 - val_mse: 0.4621\n",
      "Epoch 644/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5035 - mse: 0.4963 - val_loss: 0.4658 - val_mse: 0.4587\n",
      "Epoch 645/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5081 - mse: 0.5010 - val_loss: 0.4725 - val_mse: 0.4654\n",
      "Epoch 646/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5045 - mse: 0.4973 - val_loss: 0.4699 - val_mse: 0.4628\n",
      "Epoch 647/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5054 - mse: 0.4982 - val_loss: 0.4690 - val_mse: 0.4619\n",
      "Epoch 648/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5036 - mse: 0.4964 - val_loss: 0.4690 - val_mse: 0.4619\n",
      "Epoch 649/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5083 - mse: 0.5012 - val_loss: 0.4712 - val_mse: 0.4641\n",
      "Epoch 650/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5063 - mse: 0.4991\n",
      "Epoch 00650: saving model to Regression_Model/thle2.mse.linear-0650.ckpt\n",
      "273/273 [==============================] - 4s 13ms/step - loss: 0.5101 - mse: 0.5029 - val_loss: 0.4675 - val_mse: 0.4603\n",
      "Epoch 651/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5090 - mse: 0.5019 - val_loss: 0.4661 - val_mse: 0.4589\n",
      "Epoch 652/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5058 - mse: 0.4987 - val_loss: 0.4776 - val_mse: 0.4705\n",
      "Epoch 653/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5079 - mse: 0.5008 - val_loss: 0.4737 - val_mse: 0.4666\n",
      "Epoch 654/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5136 - mse: 0.5065 - val_loss: 0.4715 - val_mse: 0.4644\n",
      "Epoch 655/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5034 - mse: 0.4963 - val_loss: 0.4702 - val_mse: 0.4631\n",
      "Epoch 656/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5187 - mse: 0.5116 - val_loss: 0.4737 - val_mse: 0.4666\n",
      "Epoch 657/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5052 - mse: 0.4981 - val_loss: 0.4699 - val_mse: 0.4627\n",
      "Epoch 658/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5070 - mse: 0.4999 - val_loss: 0.4705 - val_mse: 0.4634\n",
      "Epoch 659/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5057 - mse: 0.4986 - val_loss: 0.4715 - val_mse: 0.4644\n",
      "Epoch 660/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5102 - mse: 0.5031\n",
      "Epoch 00660: saving model to Regression_Model/thle2.mse.linear-0660.ckpt\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.5104 - mse: 0.5032 - val_loss: 0.4727 - val_mse: 0.4656\n",
      "Epoch 661/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5071 - mse: 0.5000 - val_loss: 0.4704 - val_mse: 0.4633\n",
      "Epoch 662/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5020 - mse: 0.4948 - val_loss: 0.4668 - val_mse: 0.4597\n",
      "Epoch 663/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5089 - mse: 0.5018 - val_loss: 0.4701 - val_mse: 0.4630\n",
      "Epoch 664/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5059 - mse: 0.4987 - val_loss: 0.4652 - val_mse: 0.4581\n",
      "Epoch 665/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5043 - mse: 0.4972 - val_loss: 0.4706 - val_mse: 0.4635\n",
      "Epoch 666/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5019 - mse: 0.4948 - val_loss: 0.4738 - val_mse: 0.4667\n",
      "Epoch 667/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4961 - val_loss: 0.4677 - val_mse: 0.4606\n",
      "Epoch 668/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5074 - mse: 0.5003 - val_loss: 0.4654 - val_mse: 0.4583\n",
      "Epoch 669/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5018 - mse: 0.4947 - val_loss: 0.4681 - val_mse: 0.4610\n",
      "Epoch 670/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5068 - mse: 0.4997\n",
      "Epoch 00670: saving model to Regression_Model/thle2.mse.linear-0670.ckpt\n",
      "273/273 [==============================] - 5s 17ms/step - loss: 0.5074 - mse: 0.5003 - val_loss: 0.4684 - val_mse: 0.4613\n",
      "Epoch 671/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5045 - mse: 0.4974 - val_loss: 0.4667 - val_mse: 0.4596\n",
      "Epoch 672/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5007 - mse: 0.4936 - val_loss: 0.4691 - val_mse: 0.4620\n",
      "Epoch 673/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5007 - mse: 0.4936 - val_loss: 0.4660 - val_mse: 0.4589\n",
      "Epoch 674/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5058 - mse: 0.4987 - val_loss: 0.4649 - val_mse: 0.4578\n",
      "Epoch 675/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5009 - mse: 0.4938 - val_loss: 0.4693 - val_mse: 0.4622\n",
      "Epoch 676/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5136 - mse: 0.5065 - val_loss: 0.4682 - val_mse: 0.4611\n",
      "Epoch 677/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5058 - mse: 0.4987 - val_loss: 0.4680 - val_mse: 0.4609\n",
      "Epoch 678/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5036 - mse: 0.4965 - val_loss: 0.4654 - val_mse: 0.4583\n",
      "Epoch 679/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5036 - mse: 0.4965 - val_loss: 0.4663 - val_mse: 0.4593\n",
      "Epoch 680/1000\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.5054 - mse: 0.4983\n",
      "Epoch 00680: saving model to Regression_Model/thle2.mse.linear-0680.ckpt\n",
      "273/273 [==============================] - 5s 18ms/step - loss: 0.5059 - mse: 0.4989 - val_loss: 0.4714 - val_mse: 0.4643\n",
      "Epoch 681/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4999 - mse: 0.4928 - val_loss: 0.4656 - val_mse: 0.4585\n",
      "Epoch 682/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5002 - mse: 0.4931 - val_loss: 0.4726 - val_mse: 0.4655\n",
      "Epoch 683/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5063 - mse: 0.4993 - val_loss: 0.4748 - val_mse: 0.4677\n",
      "Epoch 684/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5162 - mse: 0.5092 - val_loss: 0.4684 - val_mse: 0.4614\n",
      "Epoch 685/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5035 - mse: 0.4964 - val_loss: 0.4671 - val_mse: 0.4601\n",
      "Epoch 686/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5101 - mse: 0.5031 - val_loss: 0.4658 - val_mse: 0.4587\n",
      "Epoch 687/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5016 - mse: 0.4946 - val_loss: 0.4737 - val_mse: 0.4666\n",
      "Epoch 688/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5033 - mse: 0.4963 - val_loss: 0.4677 - val_mse: 0.4606\n",
      "Epoch 689/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4984 - mse: 0.4913 - val_loss: 0.4690 - val_mse: 0.4619\n",
      "Epoch 690/1000\n",
      "265/273 [============================>.] - ETA: 0s - loss: 0.5008 - mse: 0.4937\n",
      "Epoch 00690: saving model to Regression_Model/thle2.mse.linear-0690.ckpt\n",
      "273/273 [==============================] - 6s 23ms/step - loss: 0.5028 - mse: 0.4957 - val_loss: 0.4708 - val_mse: 0.4637\n",
      "Epoch 691/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5001 - mse: 0.4930 - val_loss: 0.4695 - val_mse: 0.4624\n",
      "Epoch 692/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4968 - mse: 0.4897 - val_loss: 0.4662 - val_mse: 0.4591\n",
      "Epoch 693/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5064 - mse: 0.4994 - val_loss: 0.4669 - val_mse: 0.4599\n",
      "Epoch 694/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5069 - mse: 0.4999 - val_loss: 0.4687 - val_mse: 0.4616\n",
      "Epoch 695/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5045 - mse: 0.4974 - val_loss: 0.4727 - val_mse: 0.4657\n",
      "Epoch 696/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5110 - mse: 0.5040 - val_loss: 0.4709 - val_mse: 0.4638\n",
      "Epoch 697/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5074 - mse: 0.5003 - val_loss: 0.4707 - val_mse: 0.4636\n",
      "Epoch 698/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5061 - mse: 0.4990 - val_loss: 0.4744 - val_mse: 0.4673\n",
      "Epoch 699/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5047 - mse: 0.4977 - val_loss: 0.4738 - val_mse: 0.4668\n",
      "Epoch 700/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5016 - mse: 0.4946\n",
      "Epoch 00700: saving model to Regression_Model/thle2.mse.linear-0700.ckpt\n",
      "273/273 [==============================] - 4s 16ms/step - loss: 0.5018 - mse: 0.4947 - val_loss: 0.4670 - val_mse: 0.4599\n",
      "Epoch 701/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5050 - mse: 0.4980 - val_loss: 0.4705 - val_mse: 0.4634\n",
      "Epoch 702/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4997 - mse: 0.4927 - val_loss: 0.4687 - val_mse: 0.4617\n",
      "Epoch 703/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5089 - mse: 0.5018 - val_loss: 0.4630 - val_mse: 0.4560\n",
      "Epoch 704/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5024 - mse: 0.4954 - val_loss: 0.4660 - val_mse: 0.4590\n",
      "Epoch 705/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5061 - mse: 0.4991 - val_loss: 0.4673 - val_mse: 0.4602\n",
      "Epoch 706/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5027 - mse: 0.4957 - val_loss: 0.4672 - val_mse: 0.4602\n",
      "Epoch 707/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5002 - mse: 0.4931 - val_loss: 0.4749 - val_mse: 0.4678\n",
      "Epoch 708/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5064 - mse: 0.4994 - val_loss: 0.4686 - val_mse: 0.4616\n",
      "Epoch 709/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4991 - mse: 0.4921 - val_loss: 0.4657 - val_mse: 0.4586\n",
      "Epoch 710/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5050 - mse: 0.4980\n",
      "Epoch 00710: saving model to Regression_Model/thle2.mse.linear-0710.ckpt\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.5045 - mse: 0.4975 - val_loss: 0.4685 - val_mse: 0.4615\n",
      "Epoch 711/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5069 - mse: 0.4998 - val_loss: 0.4666 - val_mse: 0.4595\n",
      "Epoch 712/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5036 - mse: 0.4966 - val_loss: 0.4626 - val_mse: 0.4556\n",
      "Epoch 713/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5040 - mse: 0.4970 - val_loss: 0.4703 - val_mse: 0.4633\n",
      "Epoch 714/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5041 - mse: 0.4971 - val_loss: 0.4704 - val_mse: 0.4634\n",
      "Epoch 715/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5023 - mse: 0.4953 - val_loss: 0.4690 - val_mse: 0.4620\n",
      "Epoch 716/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4993 - mse: 0.4923 - val_loss: 0.4668 - val_mse: 0.4598\n",
      "Epoch 717/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4945 - mse: 0.4875 - val_loss: 0.4643 - val_mse: 0.4573\n",
      "Epoch 718/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5045 - mse: 0.4975 - val_loss: 0.4757 - val_mse: 0.4687\n",
      "Epoch 719/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5084 - mse: 0.5014 - val_loss: 0.4666 - val_mse: 0.4596\n",
      "Epoch 720/1000\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.5091 - mse: 0.5020\n",
      "Epoch 00720: saving model to Regression_Model/thle2.mse.linear-0720.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.5091 - mse: 0.5021 - val_loss: 0.4689 - val_mse: 0.4619\n",
      "Epoch 721/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5077 - mse: 0.5007 - val_loss: 0.4688 - val_mse: 0.4618\n",
      "Epoch 722/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5069 - mse: 0.4999 - val_loss: 0.4726 - val_mse: 0.4656\n",
      "Epoch 723/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5128 - mse: 0.5058 - val_loss: 0.4701 - val_mse: 0.4631\n",
      "Epoch 724/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4981 - mse: 0.4911 - val_loss: 0.4669 - val_mse: 0.4599\n",
      "Epoch 725/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5019 - mse: 0.4949 - val_loss: 0.4716 - val_mse: 0.4646\n",
      "Epoch 726/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5045 - mse: 0.4975 - val_loss: 0.4717 - val_mse: 0.4647\n",
      "Epoch 727/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5069 - mse: 0.4999 - val_loss: 0.4681 - val_mse: 0.4611\n",
      "Epoch 728/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5058 - mse: 0.4988 - val_loss: 0.4744 - val_mse: 0.4674\n",
      "Epoch 729/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5017 - mse: 0.4947 - val_loss: 0.4684 - val_mse: 0.4614\n",
      "Epoch 730/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5114 - mse: 0.5044\n",
      "Epoch 00730: saving model to Regression_Model/thle2.mse.linear-0730.ckpt\n",
      "273/273 [==============================] - 5s 20ms/step - loss: 0.5099 - mse: 0.5029 - val_loss: 0.4701 - val_mse: 0.4631\n",
      "Epoch 731/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5042 - mse: 0.4972 - val_loss: 0.4751 - val_mse: 0.4681\n",
      "Epoch 732/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5074 - mse: 0.5004 - val_loss: 0.4719 - val_mse: 0.4649\n",
      "Epoch 733/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5039 - mse: 0.4969 - val_loss: 0.4690 - val_mse: 0.4620\n",
      "Epoch 734/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5141 - mse: 0.5071 - val_loss: 0.4708 - val_mse: 0.4639\n",
      "Epoch 735/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5057 - mse: 0.4987 - val_loss: 0.4643 - val_mse: 0.4573\n",
      "Epoch 736/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5008 - mse: 0.4938 - val_loss: 0.4690 - val_mse: 0.4620\n",
      "Epoch 737/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5015 - mse: 0.4945 - val_loss: 0.4662 - val_mse: 0.4592\n",
      "Epoch 738/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5079 - mse: 0.5009 - val_loss: 0.4696 - val_mse: 0.4626\n",
      "Epoch 739/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5030 - mse: 0.4960 - val_loss: 0.4633 - val_mse: 0.4563\n",
      "Epoch 740/1000\n",
      "265/273 [============================>.] - ETA: 0s - loss: 0.5038 - mse: 0.4968\n",
      "Epoch 00740: saving model to Regression_Model/thle2.mse.linear-0740.ckpt\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.5064 - mse: 0.4994 - val_loss: 0.4658 - val_mse: 0.4588\n",
      "Epoch 741/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5129 - mse: 0.5060 - val_loss: 0.4689 - val_mse: 0.4619\n",
      "Epoch 742/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5054 - mse: 0.4984 - val_loss: 0.4685 - val_mse: 0.4615\n",
      "Epoch 743/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4995 - mse: 0.4925 - val_loss: 0.4672 - val_mse: 0.4602\n",
      "Epoch 744/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5102 - mse: 0.5032 - val_loss: 0.4649 - val_mse: 0.4580\n",
      "Epoch 745/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5003 - mse: 0.4933 - val_loss: 0.4690 - val_mse: 0.4621\n",
      "Epoch 746/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5083 - mse: 0.5013 - val_loss: 0.4681 - val_mse: 0.4611\n",
      "Epoch 747/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5049 - mse: 0.4980 - val_loss: 0.4767 - val_mse: 0.4697\n",
      "Epoch 748/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5028 - mse: 0.4958 - val_loss: 0.4744 - val_mse: 0.4675\n",
      "Epoch 749/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5111 - mse: 0.5041 - val_loss: 0.4670 - val_mse: 0.4601\n",
      "Epoch 750/1000\n",
      "264/273 [============================>.] - ETA: 0s - loss: 0.5008 - mse: 0.4938\n",
      "Epoch 00750: saving model to Regression_Model/thle2.mse.linear-0750.ckpt\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.5006 - mse: 0.4937 - val_loss: 0.4705 - val_mse: 0.4635\n",
      "Epoch 751/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5032 - mse: 0.4962 - val_loss: 0.4674 - val_mse: 0.4605\n",
      "Epoch 752/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4970 - mse: 0.4900 - val_loss: 0.4671 - val_mse: 0.4602\n",
      "Epoch 753/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5166 - mse: 0.5096 - val_loss: 0.4713 - val_mse: 0.4644\n",
      "Epoch 754/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5014 - mse: 0.4945 - val_loss: 0.4684 - val_mse: 0.4615\n",
      "Epoch 755/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5080 - mse: 0.5011 - val_loss: 0.4722 - val_mse: 0.4652\n",
      "Epoch 756/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4968 - mse: 0.4899 - val_loss: 0.4677 - val_mse: 0.4607\n",
      "Epoch 757/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5077 - mse: 0.5007 - val_loss: 0.4654 - val_mse: 0.4584\n",
      "Epoch 758/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5019 - mse: 0.4949 - val_loss: 0.4686 - val_mse: 0.4617\n",
      "Epoch 759/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5053 - mse: 0.4983 - val_loss: 0.4672 - val_mse: 0.4603\n",
      "Epoch 760/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.4988 - mse: 0.4918\n",
      "Epoch 00760: saving model to Regression_Model/thle2.mse.linear-0760.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5002 - mse: 0.4933 - val_loss: 0.4713 - val_mse: 0.4644\n",
      "Epoch 761/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5072 - mse: 0.5003 - val_loss: 0.4763 - val_mse: 0.4694\n",
      "Epoch 762/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5094 - mse: 0.5024 - val_loss: 0.4641 - val_mse: 0.4572\n",
      "Epoch 763/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5087 - mse: 0.5017 - val_loss: 0.4641 - val_mse: 0.4572\n",
      "Epoch 764/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5055 - mse: 0.4986 - val_loss: 0.4686 - val_mse: 0.4616\n",
      "Epoch 765/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5031 - mse: 0.4961 - val_loss: 0.4682 - val_mse: 0.4612\n",
      "Epoch 766/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4992 - mse: 0.4922 - val_loss: 0.4652 - val_mse: 0.4583\n",
      "Epoch 767/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5089 - mse: 0.5019 - val_loss: 0.4652 - val_mse: 0.4582\n",
      "Epoch 768/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5067 - mse: 0.4998 - val_loss: 0.4677 - val_mse: 0.4608\n",
      "Epoch 769/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5008 - mse: 0.4938 - val_loss: 0.4685 - val_mse: 0.4616\n",
      "Epoch 770/1000\n",
      "258/273 [===========================>..] - ETA: 0s - loss: 0.5099 - mse: 0.5030\n",
      "Epoch 00770: saving model to Regression_Model/thle2.mse.linear-0770.ckpt\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.5110 - mse: 0.5041 - val_loss: 0.4690 - val_mse: 0.4621\n",
      "Epoch 771/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5025 - mse: 0.4956 - val_loss: 0.4657 - val_mse: 0.4587\n",
      "Epoch 772/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4961 - mse: 0.4892 - val_loss: 0.4698 - val_mse: 0.4629\n",
      "Epoch 773/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4993 - mse: 0.4923 - val_loss: 0.4638 - val_mse: 0.4568\n",
      "Epoch 774/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5027 - mse: 0.4958 - val_loss: 0.4695 - val_mse: 0.4625\n",
      "Epoch 775/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4995 - mse: 0.4926 - val_loss: 0.4689 - val_mse: 0.4620\n",
      "Epoch 776/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5089 - mse: 0.5020 - val_loss: 0.4672 - val_mse: 0.4603\n",
      "Epoch 777/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4950 - mse: 0.4881 - val_loss: 0.4698 - val_mse: 0.4628\n",
      "Epoch 778/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5017 - mse: 0.4948 - val_loss: 0.4681 - val_mse: 0.4612\n",
      "Epoch 779/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5089 - mse: 0.5020 - val_loss: 0.4708 - val_mse: 0.4638\n",
      "Epoch 780/1000\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.5027 - mse: 0.4958\n",
      "Epoch 00780: saving model to Regression_Model/thle2.mse.linear-0780.ckpt\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.5022 - mse: 0.4953 - val_loss: 0.4672 - val_mse: 0.4603\n",
      "Epoch 781/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5072 - mse: 0.5003 - val_loss: 0.4718 - val_mse: 0.4649\n",
      "Epoch 782/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5101 - mse: 0.5031 - val_loss: 0.4700 - val_mse: 0.4631\n",
      "Epoch 783/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5023 - mse: 0.4953 - val_loss: 0.4720 - val_mse: 0.4651\n",
      "Epoch 784/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5042 - mse: 0.4973 - val_loss: 0.4732 - val_mse: 0.4663\n",
      "Epoch 785/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5072 - mse: 0.5003 - val_loss: 0.4720 - val_mse: 0.4651\n",
      "Epoch 786/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5113 - mse: 0.5044 - val_loss: 0.4698 - val_mse: 0.4629\n",
      "Epoch 787/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5065 - mse: 0.4995 - val_loss: 0.4701 - val_mse: 0.4632\n",
      "Epoch 788/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5060 - mse: 0.4991 - val_loss: 0.4680 - val_mse: 0.4611\n",
      "Epoch 789/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4963 - mse: 0.4894 - val_loss: 0.4672 - val_mse: 0.4603\n",
      "Epoch 790/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5027 - mse: 0.4958\n",
      "Epoch 00790: saving model to Regression_Model/thle2.mse.linear-0790.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5021 - mse: 0.4952 - val_loss: 0.4680 - val_mse: 0.4611\n",
      "Epoch 791/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5103 - mse: 0.5034 - val_loss: 0.4698 - val_mse: 0.4629\n",
      "Epoch 792/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4997 - mse: 0.4928 - val_loss: 0.4707 - val_mse: 0.4638\n",
      "Epoch 793/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5090 - mse: 0.5021 - val_loss: 0.4663 - val_mse: 0.4594\n",
      "Epoch 794/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5004 - mse: 0.4935 - val_loss: 0.4650 - val_mse: 0.4581\n",
      "Epoch 795/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5047 - mse: 0.4978 - val_loss: 0.4673 - val_mse: 0.4604\n",
      "Epoch 796/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5005 - mse: 0.4936 - val_loss: 0.4662 - val_mse: 0.4593\n",
      "Epoch 797/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5056 - mse: 0.4987 - val_loss: 0.4768 - val_mse: 0.4699\n",
      "Epoch 798/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4955 - mse: 0.4886 - val_loss: 0.4669 - val_mse: 0.4600\n",
      "Epoch 799/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5006 - mse: 0.4937 - val_loss: 0.4696 - val_mse: 0.4627\n",
      "Epoch 800/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.4977 - mse: 0.4908\n",
      "Epoch 00800: saving model to Regression_Model/thle2.mse.linear-0800.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.4988 - mse: 0.4919 - val_loss: 0.4725 - val_mse: 0.4656\n",
      "Epoch 801/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5044 - mse: 0.4975 - val_loss: 0.4715 - val_mse: 0.4646\n",
      "Epoch 802/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5024 - mse: 0.4955 - val_loss: 0.4656 - val_mse: 0.4588\n",
      "Epoch 803/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5031 - mse: 0.4962 - val_loss: 0.4654 - val_mse: 0.4585\n",
      "Epoch 804/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5029 - mse: 0.4960 - val_loss: 0.4694 - val_mse: 0.4625\n",
      "Epoch 805/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5004 - mse: 0.4936 - val_loss: 0.4705 - val_mse: 0.4636\n",
      "Epoch 806/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5031 - mse: 0.4962 - val_loss: 0.4703 - val_mse: 0.4634\n",
      "Epoch 807/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4929 - mse: 0.4860 - val_loss: 0.4696 - val_mse: 0.4627\n",
      "Epoch 808/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5008 - mse: 0.4939 - val_loss: 0.4646 - val_mse: 0.4577\n",
      "Epoch 809/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5010 - mse: 0.4941 - val_loss: 0.4642 - val_mse: 0.4573\n",
      "Epoch 810/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.4951 - mse: 0.4882\n",
      "Epoch 00810: saving model to Regression_Model/thle2.mse.linear-0810.ckpt\n",
      "273/273 [==============================] - 5s 20ms/step - loss: 0.4944 - mse: 0.4875 - val_loss: 0.4662 - val_mse: 0.4594\n",
      "Epoch 811/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5035 - mse: 0.4966 - val_loss: 0.4658 - val_mse: 0.4589\n",
      "Epoch 812/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5029 - mse: 0.4960 - val_loss: 0.4696 - val_mse: 0.4628\n",
      "Epoch 813/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5024 - mse: 0.4955 - val_loss: 0.4680 - val_mse: 0.4612\n",
      "Epoch 814/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5067 - mse: 0.4998 - val_loss: 0.4713 - val_mse: 0.4644\n",
      "Epoch 815/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4965 - mse: 0.4897 - val_loss: 0.4650 - val_mse: 0.4582\n",
      "Epoch 816/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5040 - mse: 0.4972 - val_loss: 0.4671 - val_mse: 0.4602\n",
      "Epoch 817/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5039 - mse: 0.4970 - val_loss: 0.4676 - val_mse: 0.4608\n",
      "Epoch 818/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5018 - mse: 0.4949 - val_loss: 0.4656 - val_mse: 0.4587\n",
      "Epoch 819/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5000 - mse: 0.4932 - val_loss: 0.4663 - val_mse: 0.4595\n",
      "Epoch 820/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5077 - mse: 0.5008\n",
      "Epoch 00820: saving model to Regression_Model/thle2.mse.linear-0820.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5081 - mse: 0.5013 - val_loss: 0.4706 - val_mse: 0.4638\n",
      "Epoch 821/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5037 - mse: 0.4968 - val_loss: 0.4664 - val_mse: 0.4595\n",
      "Epoch 822/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4989 - mse: 0.4920 - val_loss: 0.4627 - val_mse: 0.4558\n",
      "Epoch 823/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4914 - mse: 0.4846 - val_loss: 0.4665 - val_mse: 0.4597\n",
      "Epoch 824/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5056 - mse: 0.4987 - val_loss: 0.4631 - val_mse: 0.4562\n",
      "Epoch 825/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5044 - mse: 0.4975 - val_loss: 0.4661 - val_mse: 0.4593\n",
      "Epoch 826/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5074 - mse: 0.5005 - val_loss: 0.4714 - val_mse: 0.4645\n",
      "Epoch 827/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4964 - mse: 0.4896 - val_loss: 0.4696 - val_mse: 0.4628\n",
      "Epoch 828/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5060 - mse: 0.4992 - val_loss: 0.4658 - val_mse: 0.4590\n",
      "Epoch 829/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5058 - mse: 0.4990 - val_loss: 0.4642 - val_mse: 0.4574\n",
      "Epoch 830/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5011 - mse: 0.4943\n",
      "Epoch 00830: saving model to Regression_Model/thle2.mse.linear-0830.ckpt\n",
      "273/273 [==============================] - 6s 23ms/step - loss: 0.5015 - mse: 0.4947 - val_loss: 0.4696 - val_mse: 0.4627\n",
      "Epoch 831/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4966 - mse: 0.4898 - val_loss: 0.4643 - val_mse: 0.4574\n",
      "Epoch 832/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5058 - mse: 0.4990 - val_loss: 0.4659 - val_mse: 0.4591\n",
      "Epoch 833/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4991 - mse: 0.4922 - val_loss: 0.4637 - val_mse: 0.4568\n",
      "Epoch 834/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5063 - mse: 0.4995 - val_loss: 0.4669 - val_mse: 0.4600\n",
      "Epoch 835/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5020 - mse: 0.4952 - val_loss: 0.4712 - val_mse: 0.4644\n",
      "Epoch 836/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5034 - mse: 0.4965 - val_loss: 0.4689 - val_mse: 0.4620\n",
      "Epoch 837/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5042 - mse: 0.4973 - val_loss: 0.4698 - val_mse: 0.4630\n",
      "Epoch 838/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5004 - mse: 0.4935 - val_loss: 0.4677 - val_mse: 0.4609\n",
      "Epoch 839/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5085 - mse: 0.5016 - val_loss: 0.4712 - val_mse: 0.4644\n",
      "Epoch 840/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5049 - mse: 0.4981\n",
      "Epoch 00840: saving model to Regression_Model/thle2.mse.linear-0840.ckpt\n",
      "273/273 [==============================] - 3s 9ms/step - loss: 0.5033 - mse: 0.4965 - val_loss: 0.4660 - val_mse: 0.4592\n",
      "Epoch 841/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.4966 - mse: 0.4897 - val_loss: 0.4625 - val_mse: 0.4556\n",
      "Epoch 842/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4971 - mse: 0.4903 - val_loss: 0.4695 - val_mse: 0.4626\n",
      "Epoch 843/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4971 - mse: 0.4903 - val_loss: 0.4713 - val_mse: 0.4645\n",
      "Epoch 844/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5005 - mse: 0.4937 - val_loss: 0.4683 - val_mse: 0.4614\n",
      "Epoch 845/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4958 - mse: 0.4890 - val_loss: 0.4710 - val_mse: 0.4642\n",
      "Epoch 846/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4991 - mse: 0.4923 - val_loss: 0.4721 - val_mse: 0.4653\n",
      "Epoch 847/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5069 - mse: 0.5000 - val_loss: 0.4707 - val_mse: 0.4639\n",
      "Epoch 848/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4925 - mse: 0.4857 - val_loss: 0.4683 - val_mse: 0.4615\n",
      "Epoch 849/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5017 - mse: 0.4949 - val_loss: 0.4671 - val_mse: 0.4602\n",
      "Epoch 850/1000\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.5105 - mse: 0.5037\n",
      "Epoch 00850: saving model to Regression_Model/thle2.mse.linear-0850.ckpt\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.5103 - mse: 0.5035 - val_loss: 0.4699 - val_mse: 0.4631\n",
      "Epoch 851/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4987 - mse: 0.4919 - val_loss: 0.4680 - val_mse: 0.4612\n",
      "Epoch 852/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5079 - mse: 0.5010 - val_loss: 0.4664 - val_mse: 0.4596\n",
      "Epoch 853/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4984 - mse: 0.4916 - val_loss: 0.4658 - val_mse: 0.4590\n",
      "Epoch 854/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5052 - mse: 0.4984 - val_loss: 0.4667 - val_mse: 0.4599\n",
      "Epoch 855/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4938 - mse: 0.4870 - val_loss: 0.4709 - val_mse: 0.4641\n",
      "Epoch 856/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5033 - mse: 0.4965 - val_loss: 0.4725 - val_mse: 0.4657\n",
      "Epoch 857/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5011 - mse: 0.4943 - val_loss: 0.4702 - val_mse: 0.4634\n",
      "Epoch 858/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5017 - mse: 0.4949 - val_loss: 0.4676 - val_mse: 0.4608\n",
      "Epoch 859/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5030 - mse: 0.4962 - val_loss: 0.4675 - val_mse: 0.4607\n",
      "Epoch 860/1000\n",
      "265/273 [============================>.] - ETA: 0s - loss: 0.5063 - mse: 0.4995\n",
      "Epoch 00860: saving model to Regression_Model/thle2.mse.linear-0860.ckpt\n",
      "273/273 [==============================] - 5s 17ms/step - loss: 0.5050 - mse: 0.4982 - val_loss: 0.4651 - val_mse: 0.4583\n",
      "Epoch 861/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5044 - mse: 0.4975 - val_loss: 0.4674 - val_mse: 0.4606\n",
      "Epoch 862/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5062 - mse: 0.4994 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 863/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5042 - mse: 0.4974 - val_loss: 0.4682 - val_mse: 0.4614\n",
      "Epoch 864/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5004 - mse: 0.4936 - val_loss: 0.4667 - val_mse: 0.4599\n",
      "Epoch 865/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5010 - mse: 0.4942 - val_loss: 0.4659 - val_mse: 0.4591\n",
      "Epoch 866/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5001 - mse: 0.4933 - val_loss: 0.4654 - val_mse: 0.4586\n",
      "Epoch 867/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5009 - mse: 0.4941 - val_loss: 0.4660 - val_mse: 0.4592\n",
      "Epoch 868/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5039 - mse: 0.4971 - val_loss: 0.4659 - val_mse: 0.4591\n",
      "Epoch 869/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5075 - mse: 0.5007 - val_loss: 0.4661 - val_mse: 0.4593\n",
      "Epoch 870/1000\n",
      "264/273 [============================>.] - ETA: 0s - loss: 0.5076 - mse: 0.5008\n",
      "Epoch 00870: saving model to Regression_Model/thle2.mse.linear-0870.ckpt\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.5074 - mse: 0.5006 - val_loss: 0.4643 - val_mse: 0.4575\n",
      "Epoch 871/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.4972 - mse: 0.4904 - val_loss: 0.4624 - val_mse: 0.4556\n",
      "Epoch 872/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5008 - mse: 0.4940 - val_loss: 0.4656 - val_mse: 0.4588\n",
      "Epoch 873/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4989 - mse: 0.4921 - val_loss: 0.4680 - val_mse: 0.4613\n",
      "Epoch 874/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5045 - mse: 0.4977 - val_loss: 0.4659 - val_mse: 0.4591\n",
      "Epoch 875/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4958 - mse: 0.4890 - val_loss: 0.4688 - val_mse: 0.4620\n",
      "Epoch 876/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5008 - mse: 0.4940 - val_loss: 0.4726 - val_mse: 0.4658\n",
      "Epoch 877/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5017 - mse: 0.4950 - val_loss: 0.4648 - val_mse: 0.4580\n",
      "Epoch 878/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5044 - mse: 0.4976 - val_loss: 0.4642 - val_mse: 0.4574\n",
      "Epoch 879/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4962 - mse: 0.4895 - val_loss: 0.4668 - val_mse: 0.4600\n",
      "Epoch 880/1000\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.5111 - mse: 0.5043\n",
      "Epoch 00880: saving model to Regression_Model/thle2.mse.linear-0880.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5105 - mse: 0.5037 - val_loss: 0.4686 - val_mse: 0.4619\n",
      "Epoch 881/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4985 - mse: 0.4917 - val_loss: 0.4672 - val_mse: 0.4604\n",
      "Epoch 882/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4975 - mse: 0.4907 - val_loss: 0.4681 - val_mse: 0.4614\n",
      "Epoch 883/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5059 - mse: 0.4991 - val_loss: 0.4652 - val_mse: 0.4584\n",
      "Epoch 884/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4978 - mse: 0.4910 - val_loss: 0.4712 - val_mse: 0.4644\n",
      "Epoch 885/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4992 - mse: 0.4924 - val_loss: 0.4643 - val_mse: 0.4576\n",
      "Epoch 886/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4988 - mse: 0.4921 - val_loss: 0.4647 - val_mse: 0.4579\n",
      "Epoch 887/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4965 - mse: 0.4897 - val_loss: 0.4696 - val_mse: 0.4628\n",
      "Epoch 888/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5010 - mse: 0.4942 - val_loss: 0.4683 - val_mse: 0.4615\n",
      "Epoch 889/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5044 - mse: 0.4976 - val_loss: 0.4669 - val_mse: 0.4601\n",
      "Epoch 890/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5016 - mse: 0.4948\n",
      "Epoch 00890: saving model to Regression_Model/thle2.mse.linear-0890.ckpt\n",
      "273/273 [==============================] - 6s 23ms/step - loss: 0.4998 - mse: 0.4930 - val_loss: 0.4667 - val_mse: 0.4600\n",
      "Epoch 891/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4946 - mse: 0.4878 - val_loss: 0.4703 - val_mse: 0.4636\n",
      "Epoch 892/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5009 - mse: 0.4942 - val_loss: 0.4661 - val_mse: 0.4593\n",
      "Epoch 893/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4993 - mse: 0.4925 - val_loss: 0.4659 - val_mse: 0.4592\n",
      "Epoch 894/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4976 - mse: 0.4909 - val_loss: 0.4677 - val_mse: 0.4609\n",
      "Epoch 895/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4939 - mse: 0.4871 - val_loss: 0.4647 - val_mse: 0.4580\n",
      "Epoch 896/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5015 - mse: 0.4947 - val_loss: 0.4677 - val_mse: 0.4609\n",
      "Epoch 897/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4961 - mse: 0.4893 - val_loss: 0.4671 - val_mse: 0.4604\n",
      "Epoch 898/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5037 - mse: 0.4970 - val_loss: 0.4674 - val_mse: 0.4606\n",
      "Epoch 899/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4981 - mse: 0.4913 - val_loss: 0.4689 - val_mse: 0.4621\n",
      "Epoch 900/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5026 - mse: 0.4958\n",
      "Epoch 00900: saving model to Regression_Model/thle2.mse.linear-0900.ckpt\n",
      "273/273 [==============================] - 4s 16ms/step - loss: 0.5028 - mse: 0.4960 - val_loss: 0.4644 - val_mse: 0.4576\n",
      "Epoch 901/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5045 - mse: 0.4978 - val_loss: 0.4669 - val_mse: 0.4602\n",
      "Epoch 902/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4648 - val_mse: 0.4581\n",
      "Epoch 903/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5013 - mse: 0.4945 - val_loss: 0.4679 - val_mse: 0.4612\n",
      "Epoch 904/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4990 - mse: 0.4923 - val_loss: 0.4669 - val_mse: 0.4602\n",
      "Epoch 905/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4951 - mse: 0.4884 - val_loss: 0.4700 - val_mse: 0.4633\n",
      "Epoch 906/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4937 - mse: 0.4870 - val_loss: 0.4695 - val_mse: 0.4627\n",
      "Epoch 907/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4965 - val_loss: 0.4647 - val_mse: 0.4579\n",
      "Epoch 908/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4983 - mse: 0.4915 - val_loss: 0.4683 - val_mse: 0.4615\n",
      "Epoch 909/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5039 - mse: 0.4972 - val_loss: 0.4661 - val_mse: 0.4593\n",
      "Epoch 910/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.4980 - mse: 0.4912\n",
      "Epoch 00910: saving model to Regression_Model/thle2.mse.linear-0910.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.4986 - mse: 0.4918 - val_loss: 0.4679 - val_mse: 0.4612\n",
      "Epoch 911/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4996 - mse: 0.4928 - val_loss: 0.4685 - val_mse: 0.4618\n",
      "Epoch 912/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4923 - mse: 0.4856 - val_loss: 0.4634 - val_mse: 0.4567\n",
      "Epoch 913/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5043 - mse: 0.4976 - val_loss: 0.4691 - val_mse: 0.4623\n",
      "Epoch 914/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4984 - mse: 0.4917 - val_loss: 0.4650 - val_mse: 0.4583\n",
      "Epoch 915/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5001 - mse: 0.4934 - val_loss: 0.4677 - val_mse: 0.4610\n",
      "Epoch 916/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4955 - mse: 0.4888 - val_loss: 0.4670 - val_mse: 0.4602\n",
      "Epoch 917/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4918 - mse: 0.4850 - val_loss: 0.4641 - val_mse: 0.4574\n",
      "Epoch 918/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5037 - mse: 0.4970 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 919/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5000 - mse: 0.4933 - val_loss: 0.4664 - val_mse: 0.4596\n",
      "Epoch 920/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.4992 - mse: 0.4925\n",
      "Epoch 00920: saving model to Regression_Model/thle2.mse.linear-0920.ckpt\n",
      "273/273 [==============================] - 7s 27ms/step - loss: 0.4984 - mse: 0.4917 - val_loss: 0.4690 - val_mse: 0.4623\n",
      "Epoch 921/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4989 - mse: 0.4921 - val_loss: 0.4717 - val_mse: 0.4650\n",
      "Epoch 922/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4979 - mse: 0.4912 - val_loss: 0.4640 - val_mse: 0.4573\n",
      "Epoch 923/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5000 - mse: 0.4933 - val_loss: 0.4692 - val_mse: 0.4624\n",
      "Epoch 924/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4977 - mse: 0.4910 - val_loss: 0.4679 - val_mse: 0.4612\n",
      "Epoch 925/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4998 - mse: 0.4930 - val_loss: 0.4643 - val_mse: 0.4575\n",
      "Epoch 926/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4968 - mse: 0.4901 - val_loss: 0.4645 - val_mse: 0.4578\n",
      "Epoch 927/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5011 - mse: 0.4943 - val_loss: 0.4668 - val_mse: 0.4600\n",
      "Epoch 928/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5005 - mse: 0.4937 - val_loss: 0.4669 - val_mse: 0.4602\n",
      "Epoch 929/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5022 - mse: 0.4955 - val_loss: 0.4651 - val_mse: 0.4584\n",
      "Epoch 930/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.4947 - mse: 0.4880\n",
      "Epoch 00930: saving model to Regression_Model/thle2.mse.linear-0930.ckpt\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.4962 - mse: 0.4895 - val_loss: 0.4673 - val_mse: 0.4606\n",
      "Epoch 931/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.4992 - mse: 0.4924 - val_loss: 0.4659 - val_mse: 0.4592\n",
      "Epoch 932/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4970 - mse: 0.4903 - val_loss: 0.4658 - val_mse: 0.4591\n",
      "Epoch 933/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5004 - mse: 0.4936 - val_loss: 0.4655 - val_mse: 0.4588\n",
      "Epoch 934/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5052 - mse: 0.4984 - val_loss: 0.4745 - val_mse: 0.4678\n",
      "Epoch 935/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4963 - mse: 0.4896 - val_loss: 0.4649 - val_mse: 0.4582\n",
      "Epoch 936/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4985 - mse: 0.4918 - val_loss: 0.4674 - val_mse: 0.4607\n",
      "Epoch 937/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5015 - mse: 0.4948 - val_loss: 0.4658 - val_mse: 0.4591\n",
      "Epoch 938/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4985 - mse: 0.4918 - val_loss: 0.4701 - val_mse: 0.4634\n",
      "Epoch 939/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4715 - val_mse: 0.4648\n",
      "Epoch 940/1000\n",
      "269/273 [============================>.] - ETA: 0s - loss: 0.4942 - mse: 0.4875\n",
      "Epoch 00940: saving model to Regression_Model/thle2.mse.linear-0940.ckpt\n",
      "273/273 [==============================] - 7s 25ms/step - loss: 0.4944 - mse: 0.4877 - val_loss: 0.4646 - val_mse: 0.4578\n",
      "Epoch 941/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5030 - mse: 0.4963 - val_loss: 0.4715 - val_mse: 0.4648\n",
      "Epoch 942/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4937 - mse: 0.4870 - val_loss: 0.4663 - val_mse: 0.4596\n",
      "Epoch 943/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4983 - mse: 0.4916 - val_loss: 0.4636 - val_mse: 0.4569\n",
      "Epoch 944/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4921 - mse: 0.4854 - val_loss: 0.4701 - val_mse: 0.4634\n",
      "Epoch 945/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4961 - mse: 0.4894 - val_loss: 0.4666 - val_mse: 0.4599\n",
      "Epoch 946/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4952 - mse: 0.4885 - val_loss: 0.4647 - val_mse: 0.4580\n",
      "Epoch 947/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4675 - val_mse: 0.4608\n",
      "Epoch 948/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4955 - mse: 0.4888 - val_loss: 0.4705 - val_mse: 0.4639\n",
      "Epoch 949/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5019 - mse: 0.4952 - val_loss: 0.4647 - val_mse: 0.4580\n",
      "Epoch 950/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5018 - mse: 0.4951\n",
      "Epoch 00950: saving model to Regression_Model/thle2.mse.linear-0950.ckpt\n",
      "273/273 [==============================] - 6s 23ms/step - loss: 0.4989 - mse: 0.4922 - val_loss: 0.4638 - val_mse: 0.4571\n",
      "Epoch 951/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4976 - mse: 0.4909 - val_loss: 0.4696 - val_mse: 0.4630\n",
      "Epoch 952/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4962 - mse: 0.4895 - val_loss: 0.4641 - val_mse: 0.4574\n",
      "Epoch 953/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5003 - mse: 0.4936 - val_loss: 0.4685 - val_mse: 0.4618\n",
      "Epoch 954/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4655 - val_mse: 0.4588\n",
      "Epoch 955/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4972 - mse: 0.4905 - val_loss: 0.4643 - val_mse: 0.4576\n",
      "Epoch 956/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4992 - mse: 0.4925 - val_loss: 0.4642 - val_mse: 0.4575\n",
      "Epoch 957/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4643 - val_mse: 0.4576\n",
      "Epoch 958/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5057 - mse: 0.4990 - val_loss: 0.4636 - val_mse: 0.4569\n",
      "Epoch 959/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4989 - mse: 0.4922 - val_loss: 0.4648 - val_mse: 0.4581\n",
      "Epoch 960/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.4952 - mse: 0.4885\n",
      "Epoch 00960: saving model to Regression_Model/thle2.mse.linear-0960.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.4942 - mse: 0.4875 - val_loss: 0.4655 - val_mse: 0.4588\n",
      "Epoch 961/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5033 - mse: 0.4966 - val_loss: 0.4648 - val_mse: 0.4581\n",
      "Epoch 962/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4986 - mse: 0.4920 - val_loss: 0.4669 - val_mse: 0.4603\n",
      "Epoch 963/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5031 - mse: 0.4964 - val_loss: 0.4670 - val_mse: 0.4604\n",
      "Epoch 964/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4954 - mse: 0.4887 - val_loss: 0.4673 - val_mse: 0.4606\n",
      "Epoch 965/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4949 - mse: 0.4882 - val_loss: 0.4676 - val_mse: 0.4609\n",
      "Epoch 966/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4960 - mse: 0.4893 - val_loss: 0.4681 - val_mse: 0.4614\n",
      "Epoch 967/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4945 - mse: 0.4878 - val_loss: 0.4664 - val_mse: 0.4597\n",
      "Epoch 968/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4966 - mse: 0.4899 - val_loss: 0.4686 - val_mse: 0.4620\n",
      "Epoch 969/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4942 - mse: 0.4875 - val_loss: 0.4707 - val_mse: 0.4640\n",
      "Epoch 970/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.4955 - mse: 0.4889\n",
      "Epoch 00970: saving model to Regression_Model/thle2.mse.linear-0970.ckpt\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.4933 - mse: 0.4867 - val_loss: 0.4660 - val_mse: 0.4593\n",
      "Epoch 971/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4943 - mse: 0.4876 - val_loss: 0.4665 - val_mse: 0.4599\n",
      "Epoch 972/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4975 - mse: 0.4908 - val_loss: 0.4680 - val_mse: 0.4613\n",
      "Epoch 973/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5007 - mse: 0.4940 - val_loss: 0.4679 - val_mse: 0.4613\n",
      "Epoch 974/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.4899 - mse: 0.4833 - val_loss: 0.4680 - val_mse: 0.4613\n",
      "Epoch 975/1000\n",
      "273/273 [==============================] - ETA: 0s - loss: 0.5029 - mse: 0.496 - 1s 4ms/step - loss: 0.5025 - mse: 0.4959 - val_loss: 0.4639 - val_mse: 0.4573\n",
      "Epoch 976/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4909 - mse: 0.4842 - val_loss: 0.4650 - val_mse: 0.4584\n",
      "Epoch 977/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4969 - mse: 0.4902 - val_loss: 0.4674 - val_mse: 0.4608\n",
      "Epoch 978/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4998 - mse: 0.4932 - val_loss: 0.4694 - val_mse: 0.4627\n",
      "Epoch 979/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4985 - mse: 0.4919 - val_loss: 0.4667 - val_mse: 0.4600\n",
      "Epoch 980/1000\n",
      "259/273 [===========================>..] - ETA: 0s - loss: 0.4968 - mse: 0.4901\n",
      "Epoch 00980: saving model to Regression_Model/thle2.mse.linear-0980.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.4961 - mse: 0.4894 - val_loss: 0.4635 - val_mse: 0.4569\n",
      "Epoch 981/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5014 - mse: 0.4947 - val_loss: 0.4675 - val_mse: 0.4609\n",
      "Epoch 982/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5041 - mse: 0.4974 - val_loss: 0.4707 - val_mse: 0.4640\n",
      "Epoch 983/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4977 - mse: 0.4911 - val_loss: 0.4667 - val_mse: 0.4600\n",
      "Epoch 984/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4990 - mse: 0.4924 - val_loss: 0.4650 - val_mse: 0.4584\n",
      "Epoch 985/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5010 - mse: 0.4943 - val_loss: 0.4647 - val_mse: 0.4580\n",
      "Epoch 986/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4635 - val_mse: 0.4568\n",
      "Epoch 987/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5011 - mse: 0.4945 - val_loss: 0.4647 - val_mse: 0.4581\n",
      "Epoch 988/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5024 - mse: 0.4957 - val_loss: 0.4647 - val_mse: 0.4580\n",
      "Epoch 989/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4999 - mse: 0.4933 - val_loss: 0.4637 - val_mse: 0.4571\n",
      "Epoch 990/1000\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.5001 - mse: 0.4934\n",
      "Epoch 00990: saving model to Regression_Model/thle2.mse.linear-0990.ckpt\n",
      "273/273 [==============================] - 9s 33ms/step - loss: 0.4990 - mse: 0.4924 - val_loss: 0.4654 - val_mse: 0.4587\n",
      "Epoch 991/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.4915 - mse: 0.4849 - val_loss: 0.4682 - val_mse: 0.4616\n",
      "Epoch 992/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4970 - mse: 0.4904 - val_loss: 0.4661 - val_mse: 0.4594\n",
      "Epoch 993/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4979 - mse: 0.4913 - val_loss: 0.4649 - val_mse: 0.4583\n",
      "Epoch 994/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.4960 - mse: 0.4894 - val_loss: 0.4671 - val_mse: 0.4605\n",
      "Epoch 995/1000\n",
      "273/273 [==============================] - 2s 5ms/step - loss: 0.4959 - mse: 0.4892 - val_loss: 0.4643 - val_mse: 0.4576\n",
      "Epoch 996/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4945 - mse: 0.4879 - val_loss: 0.4627 - val_mse: 0.4561\n",
      "Epoch 997/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4961 - mse: 0.4894 - val_loss: 0.4642 - val_mse: 0.4575\n",
      "Epoch 998/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4949 - mse: 0.4883 - val_loss: 0.4643 - val_mse: 0.4577\n",
      "Epoch 999/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4959 - mse: 0.4893 - val_loss: 0.4648 - val_mse: 0.4581\n",
      "Epoch 1000/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.4944 - mse: 0.4877\n",
      "Epoch 01000: saving model to Regression_Model/thle2.mse.linear-1000.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.4949 - mse: 0.4882 - val_loss: 0.4652 - val_mse: 0.4585\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=1000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "mse\n",
      "val_loss\n",
      "val_mse\n"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7fb88806a0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std,bestEpoch=1000):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "testid=trainid\n",
    "bestEpoch = '1000'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 12488\n",
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "test_data,test_labels,test_id,test2_data,test2_labels,test2_id = prep_data('coverage_data/SNU398_Control.usage.txt',5,33.3)\n",
    "testid=trainid\n",
    "data_mean = -1.09\n",
    "data_std  = 1.79\n",
    "label_mean = 2.39\n",
    "label_std = 1.65\n",
    "test_x,test_y = standardize(train_data,train_labels,data_mean,data_std,label_mean,label_std)\n",
    "evaluate(test_x,test_y,train_id,testid,'test',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/thle2_control.pAs.usage.txt',5)\n",
    "train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/Finetune.snu398_control.usage.txt',5)\n",
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='thle2.mle.linear'\n",
    "bestEpoch = '0980'\n",
    "evaluate(train_x,train_y,train_pasid,testid,'train',label_mean,label_std,bestEpoch)\n",
    "evaluate(valid_x,valid_y,valid_pasid,testid,'valid',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train_data,train_labels,data_mean,data_std,label_mean,label_std):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    return train_data,train_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1(x,y,pasid,trainid,dataset,label_mean,label_std,bestEpoch=2000):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)-1\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)-1\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1,train_labels1,train_pasid1,valid_data1,valid_labels1,valid_pasid1 = prep_data('coverage_data/all.snu398_control.usage.txt',5)\n",
    "x=np.concatenate((train_data1, valid_data1), axis=0)\n",
    "y=np.concatenate((train_labels1, valid_labels1), axis=0)\n",
    "pasid=np.concatenate((train_pasid1, valid_pasid1), axis=0)\n",
    "x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='Regression.f_snu398.shift16.1001'\n",
    "bestEpoch = '2000'\n",
    "evaluate1(x,y,pasid,testid,'all',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((train_pasid1, valid_pasid1), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[3,4,5,6]\n",
    "a.remove(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(a == None):\n",
    "    print('fafa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'chromosme,start,end,score,id,strand\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,c,d = a.split(',')[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
