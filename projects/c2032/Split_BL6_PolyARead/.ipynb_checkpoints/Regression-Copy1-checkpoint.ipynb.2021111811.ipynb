{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.23.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = MaxPooling1D(pool_size = 12)(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "group_normalization (GroupNo (None, 990, 16)           32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,289\n",
      "Trainable params: 42,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 20991\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = \\\n",
    "prep_data('coverage_data/snu398.gt.gt.txt',5,7.8)\n",
    "trainid='thle2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data2,train_labels2,train_id2,valid_data2,valid_labels2,valid_id2 = prep_data('coverage_data/SNU398_Control.usage.txt',5,7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=np.concatenate((train_data1, train_data2), axis=0)\n",
    "#train_labels=np.concatenate((train_labels1, train_labels2), axis=0)\n",
    "#valid_data=np.concatenate((valid_data1, valid_data2), axis=0)\n",
    "#valid_labels=np.concatenate((valid_labels1, valid_labels2), axis=0)\n",
    "#train_id =np.concatenate((train_id1, train_id2), axis=0)\n",
    "#valid_id =np.concatenate((valid_id1, valid_id2), axis=0)\n",
    "#x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12820514"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+0.05)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    #train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    #valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.50459 1.3668648\n",
      "1.7837038 1.7184598\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0916221 1.7920761\n",
      "2.391116 1.6476064\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ae3eed76438>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(train_x.shape[1]),train_x[5,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.58460146"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,train_id,16,LENGTH)\n",
    "validation_generator = DataGenerator(valid_x,valid_y,valid_id,0,LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(LENGTH),a[9])\n",
    "plt.xticks(np.arange(0, LENGTH, 100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 524 steps, validate for 131 steps\n",
      "Epoch 1/1000\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.5743 - mse: 0.5665 - val_loss: 0.4936 - val_mse: 0.4858\n",
      "Epoch 2/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5581 - mse: 0.5503 - val_loss: 0.4861 - val_mse: 0.4784\n",
      "Epoch 3/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5569 - mse: 0.5491 - val_loss: 0.4979 - val_mse: 0.4901\n",
      "Epoch 4/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5610 - mse: 0.5532 - val_loss: 0.4831 - val_mse: 0.4753\n",
      "Epoch 5/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5587 - mse: 0.5509 - val_loss: 0.4924 - val_mse: 0.4846\n",
      "Epoch 6/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5522 - mse: 0.5444 - val_loss: 0.5063 - val_mse: 0.4985\n",
      "Epoch 7/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5495 - mse: 0.5416 - val_loss: 0.4856 - val_mse: 0.4778\n",
      "Epoch 8/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5547 - mse: 0.5468 - val_loss: 0.4826 - val_mse: 0.4748\n",
      "Epoch 9/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5504 - mse: 0.5426 - val_loss: 0.4797 - val_mse: 0.4719\n",
      "Epoch 10/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5520 - mse: 0.5442\n",
      "Epoch 00010: saving model to Regression_Model/thle2.mse.linear-0010.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5517 - mse: 0.5439 - val_loss: 0.4845 - val_mse: 0.4767\n",
      "Epoch 11/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5534 - mse: 0.5455 - val_loss: 0.4829 - val_mse: 0.4751\n",
      "Epoch 12/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5529 - mse: 0.5451 - val_loss: 0.4876 - val_mse: 0.4797\n",
      "Epoch 13/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5506 - mse: 0.5428 - val_loss: 0.5008 - val_mse: 0.4930\n",
      "Epoch 14/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5538 - mse: 0.5460 - val_loss: 0.4892 - val_mse: 0.4813\n",
      "Epoch 15/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5486 - mse: 0.5407 - val_loss: 0.4817 - val_mse: 0.4738\n",
      "Epoch 16/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5476 - mse: 0.5398 - val_loss: 0.4862 - val_mse: 0.4783\n",
      "Epoch 17/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5468 - mse: 0.5390 - val_loss: 0.4985 - val_mse: 0.4906\n",
      "Epoch 18/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5509 - mse: 0.5430 - val_loss: 0.4840 - val_mse: 0.4761\n",
      "Epoch 19/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5461 - mse: 0.5382 - val_loss: 0.4764 - val_mse: 0.4686\n",
      "Epoch 20/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5461 - mse: 0.5382\n",
      "Epoch 00020: saving model to Regression_Model/thle2.mse.linear-0020.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5464 - mse: 0.5385 - val_loss: 0.4829 - val_mse: 0.4750\n",
      "Epoch 21/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5440 - mse: 0.5362 - val_loss: 0.4794 - val_mse: 0.4716\n",
      "Epoch 22/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5465 - mse: 0.5386 - val_loss: 0.4947 - val_mse: 0.4868\n",
      "Epoch 23/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5483 - mse: 0.5404 - val_loss: 0.4899 - val_mse: 0.4821\n",
      "Epoch 24/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5520 - mse: 0.5442 - val_loss: 0.4868 - val_mse: 0.4790\n",
      "Epoch 25/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5442 - mse: 0.5364 - val_loss: 0.4792 - val_mse: 0.4714\n",
      "Epoch 26/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5519 - mse: 0.5440 - val_loss: 0.4975 - val_mse: 0.4897\n",
      "Epoch 27/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5470 - mse: 0.5392 - val_loss: 0.4833 - val_mse: 0.4755\n",
      "Epoch 28/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5466 - mse: 0.5388 - val_loss: 0.4948 - val_mse: 0.4870\n",
      "Epoch 29/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5446 - mse: 0.5368 - val_loss: 0.4918 - val_mse: 0.4840\n",
      "Epoch 30/1000\n",
      "515/524 [============================>.] - ETA: 0s - loss: 0.5471 - mse: 0.5393\n",
      "Epoch 00030: saving model to Regression_Model/thle2.mse.linear-0030.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5468 - mse: 0.5389 - val_loss: 0.4833 - val_mse: 0.4754\n",
      "Epoch 31/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5448 - mse: 0.5369 - val_loss: 0.5183 - val_mse: 0.5105\n",
      "Epoch 32/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5404 - mse: 0.5326 - val_loss: 0.4812 - val_mse: 0.4733\n",
      "Epoch 33/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5480 - mse: 0.5402 - val_loss: 0.4817 - val_mse: 0.4739\n",
      "Epoch 34/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5414 - mse: 0.5336 - val_loss: 0.4850 - val_mse: 0.4772\n",
      "Epoch 35/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5427 - mse: 0.5348 - val_loss: 0.5143 - val_mse: 0.5065\n",
      "Epoch 36/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5385 - mse: 0.5307 - val_loss: 0.5108 - val_mse: 0.5030\n",
      "Epoch 37/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5497 - mse: 0.5419 - val_loss: 0.4957 - val_mse: 0.4879\n",
      "Epoch 38/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5418 - mse: 0.5340 - val_loss: 0.4856 - val_mse: 0.4777\n",
      "Epoch 39/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5407 - mse: 0.5328 - val_loss: 0.4936 - val_mse: 0.4857\n",
      "Epoch 40/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5402 - mse: 0.5323\n",
      "Epoch 00040: saving model to Regression_Model/thle2.mse.linear-0040.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5402 - mse: 0.5324 - val_loss: 0.4763 - val_mse: 0.4685\n",
      "Epoch 41/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5439 - mse: 0.5361 - val_loss: 0.4770 - val_mse: 0.4692\n",
      "Epoch 42/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5391 - mse: 0.5312 - val_loss: 0.4753 - val_mse: 0.4675\n",
      "Epoch 43/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5389 - mse: 0.5310 - val_loss: 0.4796 - val_mse: 0.4718\n",
      "Epoch 44/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5436 - mse: 0.5358 - val_loss: 0.4777 - val_mse: 0.4699\n",
      "Epoch 45/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5423 - mse: 0.5345 - val_loss: 0.4818 - val_mse: 0.4740\n",
      "Epoch 46/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5378 - mse: 0.5300 - val_loss: 0.4985 - val_mse: 0.4906\n",
      "Epoch 47/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5423 - mse: 0.5345 - val_loss: 0.4826 - val_mse: 0.4748\n",
      "Epoch 48/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5416 - mse: 0.5338 - val_loss: 0.4905 - val_mse: 0.4827\n",
      "Epoch 49/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5397 - mse: 0.5319 - val_loss: 0.4819 - val_mse: 0.4741\n",
      "Epoch 50/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5420 - mse: 0.5342\n",
      "Epoch 00050: saving model to Regression_Model/thle2.mse.linear-0050.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5418 - mse: 0.5340 - val_loss: 0.4874 - val_mse: 0.4796\n",
      "Epoch 51/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5371 - mse: 0.5293 - val_loss: 0.4866 - val_mse: 0.4788\n",
      "Epoch 52/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5440 - mse: 0.5362 - val_loss: 0.4866 - val_mse: 0.4788\n",
      "Epoch 53/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5450 - mse: 0.5372 - val_loss: 0.5019 - val_mse: 0.4941\n",
      "Epoch 54/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5394 - mse: 0.5316 - val_loss: 0.5108 - val_mse: 0.5030\n",
      "Epoch 55/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5404 - mse: 0.5326 - val_loss: 0.4789 - val_mse: 0.4711\n",
      "Epoch 56/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5479 - mse: 0.5401 - val_loss: 0.4868 - val_mse: 0.4790\n",
      "Epoch 57/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5375 - mse: 0.5297 - val_loss: 0.4877 - val_mse: 0.4799\n",
      "Epoch 58/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5445 - mse: 0.5367 - val_loss: 0.4850 - val_mse: 0.4772\n",
      "Epoch 59/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5416 - mse: 0.5338 - val_loss: 0.4789 - val_mse: 0.4711\n",
      "Epoch 60/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5404 - mse: 0.5326\n",
      "Epoch 00060: saving model to Regression_Model/thle2.mse.linear-0060.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5406 - mse: 0.5328 - val_loss: 0.4771 - val_mse: 0.4693\n",
      "Epoch 61/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5350 - mse: 0.5272 - val_loss: 0.4756 - val_mse: 0.4678\n",
      "Epoch 62/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5412 - mse: 0.5335 - val_loss: 0.4756 - val_mse: 0.4678\n",
      "Epoch 63/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5333 - mse: 0.5255 - val_loss: 0.4829 - val_mse: 0.4751\n",
      "Epoch 64/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5397 - mse: 0.5319 - val_loss: 0.4897 - val_mse: 0.4819\n",
      "Epoch 65/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5419 - mse: 0.5342 - val_loss: 0.4821 - val_mse: 0.4743\n",
      "Epoch 66/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5377 - mse: 0.5299 - val_loss: 0.4824 - val_mse: 0.4746\n",
      "Epoch 67/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5399 - mse: 0.5322 - val_loss: 0.4943 - val_mse: 0.4866\n",
      "Epoch 68/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5373 - mse: 0.5295 - val_loss: 0.4850 - val_mse: 0.4773\n",
      "Epoch 69/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5349 - mse: 0.5272 - val_loss: 0.4820 - val_mse: 0.4742\n",
      "Epoch 70/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5373 - mse: 0.5295\n",
      "Epoch 00070: saving model to Regression_Model/thle2.mse.linear-0070.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5378 - mse: 0.5301 - val_loss: 0.4771 - val_mse: 0.4693\n",
      "Epoch 71/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5352 - mse: 0.5275 - val_loss: 0.4846 - val_mse: 0.4768\n",
      "Epoch 72/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5359 - mse: 0.5282 - val_loss: 0.4830 - val_mse: 0.4752\n",
      "Epoch 73/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5399 - mse: 0.5322 - val_loss: 0.4781 - val_mse: 0.4703\n",
      "Epoch 74/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5353 - mse: 0.5275 - val_loss: 0.4867 - val_mse: 0.4789\n",
      "Epoch 75/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5419 - mse: 0.5342 - val_loss: 0.4963 - val_mse: 0.4885\n",
      "Epoch 76/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5387 - mse: 0.5310 - val_loss: 0.4852 - val_mse: 0.4775\n",
      "Epoch 77/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5407 - mse: 0.5330 - val_loss: 0.4761 - val_mse: 0.4684\n",
      "Epoch 78/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5371 - mse: 0.5294 - val_loss: 0.4799 - val_mse: 0.4722\n",
      "Epoch 79/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5350 - mse: 0.5273 - val_loss: 0.4869 - val_mse: 0.4792\n",
      "Epoch 80/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5378 - mse: 0.5301\n",
      "Epoch 00080: saving model to Regression_Model/thle2.mse.linear-0080.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5377 - mse: 0.5299 - val_loss: 0.4826 - val_mse: 0.4749\n",
      "Epoch 81/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5374 - mse: 0.5297 - val_loss: 0.4856 - val_mse: 0.4779\n",
      "Epoch 82/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5400 - mse: 0.5323 - val_loss: 0.4841 - val_mse: 0.4764\n",
      "Epoch 83/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5339 - mse: 0.5262 - val_loss: 0.4880 - val_mse: 0.4803\n",
      "Epoch 84/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5411 - mse: 0.5334 - val_loss: 0.4858 - val_mse: 0.4781\n",
      "Epoch 85/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5367 - mse: 0.5290 - val_loss: 0.4829 - val_mse: 0.4752\n",
      "Epoch 86/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5406 - mse: 0.5329 - val_loss: 0.4791 - val_mse: 0.4714\n",
      "Epoch 87/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5370 - mse: 0.5293 - val_loss: 0.4967 - val_mse: 0.4890\n",
      "Epoch 88/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5374 - mse: 0.5297 - val_loss: 0.4937 - val_mse: 0.4860\n",
      "Epoch 89/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5368 - mse: 0.5291 - val_loss: 0.4792 - val_mse: 0.4715\n",
      "Epoch 90/1000\n",
      "521/524 [============================>.] - ETA: 0s - loss: 0.5344 - mse: 0.5267\n",
      "Epoch 00090: saving model to Regression_Model/thle2.mse.linear-0090.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5342 - mse: 0.5265 - val_loss: 0.4826 - val_mse: 0.4750\n",
      "Epoch 91/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5376 - mse: 0.5299 - val_loss: 0.4816 - val_mse: 0.4739\n",
      "Epoch 92/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5354 - mse: 0.5277 - val_loss: 0.4778 - val_mse: 0.4701\n",
      "Epoch 93/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5449 - mse: 0.5372 - val_loss: 0.4823 - val_mse: 0.4747\n",
      "Epoch 94/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5322 - mse: 0.5245 - val_loss: 0.4876 - val_mse: 0.4799\n",
      "Epoch 95/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5447 - mse: 0.5370 - val_loss: 0.4816 - val_mse: 0.4739\n",
      "Epoch 96/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5359 - mse: 0.5282 - val_loss: 0.4803 - val_mse: 0.4726\n",
      "Epoch 97/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5298 - mse: 0.5221 - val_loss: 0.4765 - val_mse: 0.4689\n",
      "Epoch 98/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5305 - mse: 0.5228 - val_loss: 0.4834 - val_mse: 0.4758\n",
      "Epoch 99/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5351 - mse: 0.5274 - val_loss: 0.4915 - val_mse: 0.4838\n",
      "Epoch 100/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5340 - mse: 0.5264\n",
      "Epoch 00100: saving model to Regression_Model/thle2.mse.linear-0100.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5340 - mse: 0.5263 - val_loss: 0.4776 - val_mse: 0.4699\n",
      "Epoch 101/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5379 - mse: 0.5302 - val_loss: 0.4842 - val_mse: 0.4766\n",
      "Epoch 102/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5404 - mse: 0.5328 - val_loss: 0.4906 - val_mse: 0.4830\n",
      "Epoch 103/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5422 - mse: 0.5346 - val_loss: 0.4822 - val_mse: 0.4745\n",
      "Epoch 104/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5389 - mse: 0.5313 - val_loss: 0.4769 - val_mse: 0.4693\n",
      "Epoch 105/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5356 - mse: 0.5280 - val_loss: 0.4926 - val_mse: 0.4850\n",
      "Epoch 106/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5309 - mse: 0.5233 - val_loss: 0.4896 - val_mse: 0.4819\n",
      "Epoch 107/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5334 - mse: 0.5258 - val_loss: 0.4819 - val_mse: 0.4743\n",
      "Epoch 108/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5402 - mse: 0.5325 - val_loss: 0.4837 - val_mse: 0.4761\n",
      "Epoch 109/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5334 - mse: 0.5257 - val_loss: 0.4829 - val_mse: 0.4753\n",
      "Epoch 110/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5359 - mse: 0.5283\n",
      "Epoch 00110: saving model to Regression_Model/thle2.mse.linear-0110.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5364 - mse: 0.5287 - val_loss: 0.4847 - val_mse: 0.4771\n",
      "Epoch 111/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5362 - mse: 0.5286 - val_loss: 0.4818 - val_mse: 0.4742\n",
      "Epoch 112/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5322 - mse: 0.5245 - val_loss: 0.4897 - val_mse: 0.4821\n",
      "Epoch 113/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5468 - mse: 0.5392 - val_loss: 0.4850 - val_mse: 0.4774\n",
      "Epoch 114/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5359 - mse: 0.5283 - val_loss: 0.4810 - val_mse: 0.4734\n",
      "Epoch 115/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5445 - mse: 0.5369 - val_loss: 0.4996 - val_mse: 0.4920\n",
      "Epoch 116/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5375 - mse: 0.5299 - val_loss: 0.4864 - val_mse: 0.4788\n",
      "Epoch 117/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5315 - mse: 0.5239 - val_loss: 0.4753 - val_mse: 0.4677\n",
      "Epoch 118/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5292 - mse: 0.5216 - val_loss: 0.4868 - val_mse: 0.4792\n",
      "Epoch 119/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5333 - mse: 0.5257 - val_loss: 0.4798 - val_mse: 0.4722\n",
      "Epoch 120/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5335 - mse: 0.5259\n",
      "Epoch 00120: saving model to Regression_Model/thle2.mse.linear-0120.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5332 - mse: 0.5256 - val_loss: 0.4826 - val_mse: 0.4751\n",
      "Epoch 121/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5343 - mse: 0.5267 - val_loss: 0.4824 - val_mse: 0.4748\n",
      "Epoch 122/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5392 - mse: 0.5317 - val_loss: 0.4855 - val_mse: 0.4779\n",
      "Epoch 123/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5367 - mse: 0.5291 - val_loss: 0.4886 - val_mse: 0.4810\n",
      "Epoch 124/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5307 - mse: 0.5231 - val_loss: 0.4749 - val_mse: 0.4673\n",
      "Epoch 125/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5387 - mse: 0.5311 - val_loss: 0.4829 - val_mse: 0.4754\n",
      "Epoch 126/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5384 - mse: 0.5308 - val_loss: 0.4798 - val_mse: 0.4723\n",
      "Epoch 127/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5335 - mse: 0.5260 - val_loss: 0.4735 - val_mse: 0.4659\n",
      "Epoch 128/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5335 - mse: 0.5260 - val_loss: 0.4824 - val_mse: 0.4749\n",
      "Epoch 129/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5276 - mse: 0.5200 - val_loss: 0.4793 - val_mse: 0.4717\n",
      "Epoch 130/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5312 - mse: 0.5237\n",
      "Epoch 00130: saving model to Regression_Model/thle2.mse.linear-0130.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5311 - mse: 0.5235 - val_loss: 0.4858 - val_mse: 0.4783\n",
      "Epoch 131/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5381 - mse: 0.5305 - val_loss: 0.4846 - val_mse: 0.4770\n",
      "Epoch 132/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5328 - mse: 0.5252 - val_loss: 0.4848 - val_mse: 0.4773\n",
      "Epoch 133/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5363 - mse: 0.5288 - val_loss: 0.4822 - val_mse: 0.4747\n",
      "Epoch 134/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5351 - mse: 0.5275 - val_loss: 0.4783 - val_mse: 0.4707\n",
      "Epoch 135/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5327 - mse: 0.5251 - val_loss: 0.4916 - val_mse: 0.4840\n",
      "Epoch 136/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5293 - mse: 0.5218 - val_loss: 0.4806 - val_mse: 0.4731\n",
      "Epoch 137/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5329 - mse: 0.5254 - val_loss: 0.4831 - val_mse: 0.4755\n",
      "Epoch 138/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5309 - mse: 0.5234 - val_loss: 0.4813 - val_mse: 0.4738\n",
      "Epoch 139/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5311 - mse: 0.5235 - val_loss: 0.4831 - val_mse: 0.4756\n",
      "Epoch 140/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5280 - mse: 0.5204\n",
      "Epoch 00140: saving model to Regression_Model/thle2.mse.linear-0140.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5280 - mse: 0.5205 - val_loss: 0.4796 - val_mse: 0.4721\n",
      "Epoch 141/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5336 - mse: 0.5261 - val_loss: 0.4879 - val_mse: 0.4804\n",
      "Epoch 142/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5278 - mse: 0.5202 - val_loss: 0.4821 - val_mse: 0.4746\n",
      "Epoch 143/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5326 - mse: 0.5251 - val_loss: 0.4749 - val_mse: 0.4674\n",
      "Epoch 144/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5299 - mse: 0.5224 - val_loss: 0.4775 - val_mse: 0.4700\n",
      "Epoch 145/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5275 - mse: 0.5200 - val_loss: 0.4763 - val_mse: 0.4688\n",
      "Epoch 146/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5343 - mse: 0.5268 - val_loss: 0.4850 - val_mse: 0.4775\n",
      "Epoch 147/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5359 - mse: 0.5284 - val_loss: 0.4908 - val_mse: 0.4833\n",
      "Epoch 148/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5384 - mse: 0.5309 - val_loss: 0.4785 - val_mse: 0.4710\n",
      "Epoch 149/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5329 - mse: 0.5254 - val_loss: 0.4866 - val_mse: 0.4791\n",
      "Epoch 150/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5316 - mse: 0.5242\n",
      "Epoch 00150: saving model to Regression_Model/thle2.mse.linear-0150.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5315 - mse: 0.5240 - val_loss: 0.4939 - val_mse: 0.4864\n",
      "Epoch 151/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5381 - mse: 0.5306 - val_loss: 0.4796 - val_mse: 0.4722\n",
      "Epoch 152/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5287 - mse: 0.5213 - val_loss: 0.4855 - val_mse: 0.4780\n",
      "Epoch 153/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5295 - mse: 0.5221 - val_loss: 0.4909 - val_mse: 0.4835\n",
      "Epoch 154/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5280 - mse: 0.5205 - val_loss: 0.4804 - val_mse: 0.4730\n",
      "Epoch 155/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5332 - mse: 0.5257 - val_loss: 0.4770 - val_mse: 0.4695\n",
      "Epoch 156/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5306 - mse: 0.5231 - val_loss: 0.4797 - val_mse: 0.4722\n",
      "Epoch 157/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5291 - mse: 0.5217 - val_loss: 0.4778 - val_mse: 0.4703\n",
      "Epoch 158/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5307 - mse: 0.5233 - val_loss: 0.4768 - val_mse: 0.4694\n",
      "Epoch 159/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5342 - mse: 0.5267 - val_loss: 0.4743 - val_mse: 0.4668\n",
      "Epoch 160/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5341 - mse: 0.5267\n",
      "Epoch 00160: saving model to Regression_Model/thle2.mse.linear-0160.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5338 - mse: 0.5264 - val_loss: 0.4786 - val_mse: 0.4711\n",
      "Epoch 161/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5305 - mse: 0.5231 - val_loss: 0.4826 - val_mse: 0.4751\n",
      "Epoch 162/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5286 - mse: 0.5212 - val_loss: 0.4794 - val_mse: 0.4720\n",
      "Epoch 163/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5327 - mse: 0.5253 - val_loss: 0.4813 - val_mse: 0.4739\n",
      "Epoch 164/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5357 - mse: 0.5282 - val_loss: 0.4736 - val_mse: 0.4662\n",
      "Epoch 165/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5263 - mse: 0.5189 - val_loss: 0.4798 - val_mse: 0.4724\n",
      "Epoch 166/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5283 - mse: 0.5209 - val_loss: 0.4785 - val_mse: 0.4711\n",
      "Epoch 167/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5319 - mse: 0.5245 - val_loss: 0.4800 - val_mse: 0.4726\n",
      "Epoch 168/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5316 - mse: 0.5242 - val_loss: 0.4809 - val_mse: 0.4735\n",
      "Epoch 169/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5318 - mse: 0.5244 - val_loss: 0.4873 - val_mse: 0.4799\n",
      "Epoch 170/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5306 - mse: 0.5232\n",
      "Epoch 00170: saving model to Regression_Model/thle2.mse.linear-0170.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5309 - mse: 0.5235 - val_loss: 0.4752 - val_mse: 0.4678\n",
      "Epoch 171/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5305 - mse: 0.5231 - val_loss: 0.4820 - val_mse: 0.4746\n",
      "Epoch 172/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5344 - mse: 0.5270 - val_loss: 0.4848 - val_mse: 0.4774\n",
      "Epoch 173/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5265 - mse: 0.5191 - val_loss: 0.4780 - val_mse: 0.4706\n",
      "Epoch 174/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5385 - mse: 0.5311 - val_loss: 0.4777 - val_mse: 0.4703\n",
      "Epoch 175/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5284 - mse: 0.5210 - val_loss: 0.4881 - val_mse: 0.4807\n",
      "Epoch 176/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5394 - mse: 0.5321 - val_loss: 0.4992 - val_mse: 0.4918\n",
      "Epoch 177/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5369 - mse: 0.5295 - val_loss: 0.4862 - val_mse: 0.4788\n",
      "Epoch 178/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5338 - mse: 0.5264 - val_loss: 0.4835 - val_mse: 0.4761\n",
      "Epoch 179/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5313 - mse: 0.5239 - val_loss: 0.4843 - val_mse: 0.4769\n",
      "Epoch 180/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5320 - mse: 0.5246\n",
      "Epoch 00180: saving model to Regression_Model/thle2.mse.linear-0180.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5323 - mse: 0.5249 - val_loss: 0.4778 - val_mse: 0.4704\n",
      "Epoch 181/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5287 - mse: 0.5213 - val_loss: 0.4900 - val_mse: 0.4826\n",
      "Epoch 182/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5271 - mse: 0.5197 - val_loss: 0.4762 - val_mse: 0.4688\n",
      "Epoch 183/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5273 - mse: 0.5200 - val_loss: 0.4864 - val_mse: 0.4790\n",
      "Epoch 184/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5289 - mse: 0.5215 - val_loss: 0.4795 - val_mse: 0.4721\n",
      "Epoch 185/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5305 - mse: 0.5232 - val_loss: 0.4785 - val_mse: 0.4711\n",
      "Epoch 186/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5362 - mse: 0.5288 - val_loss: 0.4767 - val_mse: 0.4693\n",
      "Epoch 187/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5296 - mse: 0.5223 - val_loss: 0.4885 - val_mse: 0.4812\n",
      "Epoch 188/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5370 - mse: 0.5296 - val_loss: 0.4817 - val_mse: 0.4743\n",
      "Epoch 189/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5325 - mse: 0.5252 - val_loss: 0.4776 - val_mse: 0.4703\n",
      "Epoch 190/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5291 - mse: 0.5217\n",
      "Epoch 00190: saving model to Regression_Model/thle2.mse.linear-0190.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5300 - mse: 0.5227 - val_loss: 0.4886 - val_mse: 0.4812\n",
      "Epoch 191/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5333 - mse: 0.5260 - val_loss: 0.4834 - val_mse: 0.4760\n",
      "Epoch 192/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5313 - mse: 0.5239 - val_loss: 0.4848 - val_mse: 0.4774\n",
      "Epoch 193/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5349 - mse: 0.5276 - val_loss: 0.4762 - val_mse: 0.4689\n",
      "Epoch 194/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5312 - mse: 0.5239 - val_loss: 0.4844 - val_mse: 0.4771\n",
      "Epoch 195/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5281 - mse: 0.5208 - val_loss: 0.4754 - val_mse: 0.4681\n",
      "Epoch 196/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5324 - mse: 0.5250 - val_loss: 0.4790 - val_mse: 0.4717\n",
      "Epoch 197/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5298 - mse: 0.5225 - val_loss: 0.4847 - val_mse: 0.4774\n",
      "Epoch 198/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5251 - mse: 0.5178 - val_loss: 0.4784 - val_mse: 0.4711\n",
      "Epoch 199/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5291 - mse: 0.5218 - val_loss: 0.4797 - val_mse: 0.4724\n",
      "Epoch 200/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5306 - mse: 0.5233\n",
      "Epoch 00200: saving model to Regression_Model/thle2.mse.linear-0200.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5305 - mse: 0.5232 - val_loss: 0.4790 - val_mse: 0.4717\n",
      "Epoch 201/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5265 - mse: 0.5191 - val_loss: 0.4796 - val_mse: 0.4723\n",
      "Epoch 202/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5321 - mse: 0.5248 - val_loss: 0.4771 - val_mse: 0.4698\n",
      "Epoch 203/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5367 - mse: 0.5294 - val_loss: 0.4790 - val_mse: 0.4717\n",
      "Epoch 204/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5305 - mse: 0.5232 - val_loss: 0.4822 - val_mse: 0.4749\n",
      "Epoch 205/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5280 - mse: 0.5207 - val_loss: 0.4816 - val_mse: 0.4743\n",
      "Epoch 206/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5304 - mse: 0.5231 - val_loss: 0.4828 - val_mse: 0.4755\n",
      "Epoch 207/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5288 - mse: 0.5215 - val_loss: 0.4829 - val_mse: 0.4756\n",
      "Epoch 208/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5295 - mse: 0.5222 - val_loss: 0.4778 - val_mse: 0.4706\n",
      "Epoch 209/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5285 - mse: 0.5212 - val_loss: 0.4854 - val_mse: 0.4781\n",
      "Epoch 210/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5265 - mse: 0.5193\n",
      "Epoch 00210: saving model to Regression_Model/thle2.mse.linear-0210.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5270 - mse: 0.5197 - val_loss: 0.4913 - val_mse: 0.4840\n",
      "Epoch 211/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5278 - mse: 0.5205 - val_loss: 0.4904 - val_mse: 0.4831\n",
      "Epoch 212/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5234 - mse: 0.5161 - val_loss: 0.4760 - val_mse: 0.4688\n",
      "Epoch 213/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5264 - mse: 0.5191 - val_loss: 0.4851 - val_mse: 0.4778\n",
      "Epoch 214/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5353 - mse: 0.5280 - val_loss: 0.4806 - val_mse: 0.4733\n",
      "Epoch 215/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5261 - mse: 0.5189 - val_loss: 0.4783 - val_mse: 0.4711\n",
      "Epoch 216/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5292 - mse: 0.5220 - val_loss: 0.4765 - val_mse: 0.4693\n",
      "Epoch 217/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5297 - mse: 0.5224 - val_loss: 0.4824 - val_mse: 0.4751\n",
      "Epoch 218/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5280 - mse: 0.5208 - val_loss: 0.4859 - val_mse: 0.4786\n",
      "Epoch 219/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5285 - mse: 0.5213 - val_loss: 0.4760 - val_mse: 0.4688\n",
      "Epoch 220/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5214 - mse: 0.5141\n",
      "Epoch 00220: saving model to Regression_Model/thle2.mse.linear-0220.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5212 - mse: 0.5139 - val_loss: 0.4759 - val_mse: 0.4687\n",
      "Epoch 221/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5261 - mse: 0.5189 - val_loss: 0.4765 - val_mse: 0.4692\n",
      "Epoch 222/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5280 - mse: 0.5207 - val_loss: 0.4803 - val_mse: 0.4731\n",
      "Epoch 223/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5232 - mse: 0.5160 - val_loss: 0.4817 - val_mse: 0.4745\n",
      "Epoch 224/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5323 - mse: 0.5250 - val_loss: 0.4783 - val_mse: 0.4711\n",
      "Epoch 225/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5204 - mse: 0.5131 - val_loss: 0.4821 - val_mse: 0.4749\n",
      "Epoch 226/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5252 - mse: 0.5180 - val_loss: 0.4867 - val_mse: 0.4795\n",
      "Epoch 227/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5249 - mse: 0.5177 - val_loss: 0.4924 - val_mse: 0.4852\n",
      "Epoch 228/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5262 - mse: 0.5190 - val_loss: 0.4762 - val_mse: 0.4690\n",
      "Epoch 229/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5280 - mse: 0.5208 - val_loss: 0.4754 - val_mse: 0.4682\n",
      "Epoch 230/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5288 - mse: 0.5216\n",
      "Epoch 00230: saving model to Regression_Model/thle2.mse.linear-0230.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5288 - mse: 0.5216 - val_loss: 0.4811 - val_mse: 0.4739\n",
      "Epoch 231/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5303 - mse: 0.5231 - val_loss: 0.4796 - val_mse: 0.4724\n",
      "Epoch 232/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5299 - mse: 0.5227 - val_loss: 0.4747 - val_mse: 0.4675\n",
      "Epoch 233/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5286 - mse: 0.5214 - val_loss: 0.4770 - val_mse: 0.4698\n",
      "Epoch 234/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5196 - mse: 0.5124 - val_loss: 0.4736 - val_mse: 0.4664\n",
      "Epoch 235/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5269 - mse: 0.5197 - val_loss: 0.4823 - val_mse: 0.4751\n",
      "Epoch 236/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5257 - mse: 0.5185 - val_loss: 0.4799 - val_mse: 0.4727\n",
      "Epoch 237/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5282 - mse: 0.5210 - val_loss: 0.4773 - val_mse: 0.4701\n",
      "Epoch 238/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5300 - mse: 0.5228 - val_loss: 0.4805 - val_mse: 0.4733\n",
      "Epoch 239/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5284 - mse: 0.5212 - val_loss: 0.4788 - val_mse: 0.4716\n",
      "Epoch 240/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5220 - mse: 0.5148\n",
      "Epoch 00240: saving model to Regression_Model/thle2.mse.linear-0240.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5213 - mse: 0.5141 - val_loss: 0.4820 - val_mse: 0.4748\n",
      "Epoch 241/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5311 - mse: 0.5239 - val_loss: 0.4806 - val_mse: 0.4734\n",
      "Epoch 242/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5254 - mse: 0.5182 - val_loss: 0.4743 - val_mse: 0.4671\n",
      "Epoch 243/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5269 - mse: 0.5197 - val_loss: 0.4764 - val_mse: 0.4692\n",
      "Epoch 244/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5263 - mse: 0.5192 - val_loss: 0.4805 - val_mse: 0.4734\n",
      "Epoch 245/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5278 - mse: 0.5206 - val_loss: 0.4780 - val_mse: 0.4708\n",
      "Epoch 246/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5246 - mse: 0.5174 - val_loss: 0.4790 - val_mse: 0.4719\n",
      "Epoch 247/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5240 - mse: 0.5168 - val_loss: 0.4825 - val_mse: 0.4753\n",
      "Epoch 248/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5254 - mse: 0.5182 - val_loss: 0.4807 - val_mse: 0.4736\n",
      "Epoch 249/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5274 - mse: 0.5202 - val_loss: 0.4748 - val_mse: 0.4677\n",
      "Epoch 250/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5252 - mse: 0.5181\n",
      "Epoch 00250: saving model to Regression_Model/thle2.mse.linear-0250.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5257 - mse: 0.5186 - val_loss: 0.4749 - val_mse: 0.4677\n",
      "Epoch 251/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5281 - mse: 0.5210 - val_loss: 0.4750 - val_mse: 0.4679\n",
      "Epoch 252/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5289 - mse: 0.5218 - val_loss: 0.4904 - val_mse: 0.4832\n",
      "Epoch 253/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5252 - mse: 0.5181 - val_loss: 0.4771 - val_mse: 0.4700\n",
      "Epoch 254/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5273 - mse: 0.5201 - val_loss: 0.4724 - val_mse: 0.4653\n",
      "Epoch 255/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5255 - mse: 0.5183 - val_loss: 0.4778 - val_mse: 0.4707\n",
      "Epoch 256/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5281 - mse: 0.5210 - val_loss: 0.4812 - val_mse: 0.4741\n",
      "Epoch 257/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5277 - mse: 0.5205 - val_loss: 0.4787 - val_mse: 0.4715\n",
      "Epoch 258/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5260 - mse: 0.5189 - val_loss: 0.4811 - val_mse: 0.4739\n",
      "Epoch 259/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5250 - mse: 0.5179 - val_loss: 0.4832 - val_mse: 0.4761\n",
      "Epoch 260/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5225 - mse: 0.5154\n",
      "Epoch 00260: saving model to Regression_Model/thle2.mse.linear-0260.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5225 - mse: 0.5154 - val_loss: 0.4758 - val_mse: 0.4686\n",
      "Epoch 261/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5244 - mse: 0.5173 - val_loss: 0.4777 - val_mse: 0.4706\n",
      "Epoch 262/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5245 - mse: 0.5174 - val_loss: 0.4778 - val_mse: 0.4707\n",
      "Epoch 263/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5266 - mse: 0.5195 - val_loss: 0.4769 - val_mse: 0.4698\n",
      "Epoch 264/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5248 - mse: 0.5177 - val_loss: 0.4801 - val_mse: 0.4730\n",
      "Epoch 265/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5286 - mse: 0.5215 - val_loss: 0.4788 - val_mse: 0.4717\n",
      "Epoch 266/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5302 - mse: 0.5231 - val_loss: 0.4819 - val_mse: 0.4748\n",
      "Epoch 267/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5353 - mse: 0.5282 - val_loss: 0.4769 - val_mse: 0.4698\n",
      "Epoch 268/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5269 - mse: 0.5198 - val_loss: 0.4896 - val_mse: 0.4825\n",
      "Epoch 269/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5264 - mse: 0.5193 - val_loss: 0.4753 - val_mse: 0.4682\n",
      "Epoch 270/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5218 - mse: 0.5147\n",
      "Epoch 00270: saving model to Regression_Model/thle2.mse.linear-0270.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5217 - mse: 0.5146 - val_loss: 0.4762 - val_mse: 0.4691\n",
      "Epoch 271/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5277 - mse: 0.5206 - val_loss: 0.4792 - val_mse: 0.4721\n",
      "Epoch 272/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5271 - mse: 0.5200 - val_loss: 0.4739 - val_mse: 0.4668\n",
      "Epoch 273/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5217 - mse: 0.5146 - val_loss: 0.4771 - val_mse: 0.4700\n",
      "Epoch 274/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5266 - mse: 0.5195 - val_loss: 0.4807 - val_mse: 0.4736\n",
      "Epoch 275/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5259 - mse: 0.5188 - val_loss: 0.4798 - val_mse: 0.4727\n",
      "Epoch 276/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5291 - mse: 0.5220 - val_loss: 0.4811 - val_mse: 0.4740\n",
      "Epoch 277/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5218 - mse: 0.5147 - val_loss: 0.4810 - val_mse: 0.4739\n",
      "Epoch 278/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5254 - mse: 0.5183 - val_loss: 0.4744 - val_mse: 0.4674\n",
      "Epoch 279/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5311 - mse: 0.5241 - val_loss: 0.4799 - val_mse: 0.4728\n",
      "Epoch 280/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5247 - mse: 0.5176\n",
      "Epoch 00280: saving model to Regression_Model/thle2.mse.linear-0280.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5247 - mse: 0.5177 - val_loss: 0.4737 - val_mse: 0.4667\n",
      "Epoch 281/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5265 - mse: 0.5194 - val_loss: 0.4837 - val_mse: 0.4767\n",
      "Epoch 282/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5277 - mse: 0.5207 - val_loss: 0.4753 - val_mse: 0.4683\n",
      "Epoch 283/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5167 - val_loss: 0.4770 - val_mse: 0.4699\n",
      "Epoch 284/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5232 - mse: 0.5161 - val_loss: 0.4827 - val_mse: 0.4756\n",
      "Epoch 285/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5211 - mse: 0.5140 - val_loss: 0.4753 - val_mse: 0.4683\n",
      "Epoch 286/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5247 - mse: 0.5176 - val_loss: 0.4762 - val_mse: 0.4691\n",
      "Epoch 287/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5240 - mse: 0.5169 - val_loss: 0.4823 - val_mse: 0.4752\n",
      "Epoch 288/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5231 - mse: 0.5161 - val_loss: 0.4737 - val_mse: 0.4666\n",
      "Epoch 289/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5260 - mse: 0.5189 - val_loss: 0.4787 - val_mse: 0.4717\n",
      "Epoch 290/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5277 - mse: 0.5206\n",
      "Epoch 00290: saving model to Regression_Model/thle2.mse.linear-0290.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5277 - mse: 0.5207 - val_loss: 0.4775 - val_mse: 0.4704\n",
      "Epoch 291/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5246 - mse: 0.5176 - val_loss: 0.4893 - val_mse: 0.4823\n",
      "Epoch 292/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5285 - mse: 0.5215 - val_loss: 0.4786 - val_mse: 0.4716\n",
      "Epoch 293/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5294 - mse: 0.5223 - val_loss: 0.4836 - val_mse: 0.4766\n",
      "Epoch 294/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5273 - mse: 0.5203 - val_loss: 0.4795 - val_mse: 0.4725\n",
      "Epoch 295/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5232 - mse: 0.5162 - val_loss: 0.4751 - val_mse: 0.4681\n",
      "Epoch 296/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5193 - mse: 0.5122 - val_loss: 0.4740 - val_mse: 0.4670\n",
      "Epoch 297/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5274 - mse: 0.5204 - val_loss: 0.4764 - val_mse: 0.4694\n",
      "Epoch 298/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5304 - mse: 0.5234 - val_loss: 0.4879 - val_mse: 0.4809\n",
      "Epoch 299/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5303 - mse: 0.5233 - val_loss: 0.4766 - val_mse: 0.4696\n",
      "Epoch 300/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5167 - mse: 0.5097\n",
      "Epoch 00300: saving model to Regression_Model/thle2.mse.linear-0300.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5168 - mse: 0.5098 - val_loss: 0.4767 - val_mse: 0.4697\n",
      "Epoch 301/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5292 - mse: 0.5222 - val_loss: 0.4802 - val_mse: 0.4732\n",
      "Epoch 302/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5277 - mse: 0.5208 - val_loss: 0.4780 - val_mse: 0.4710\n",
      "Epoch 303/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5168 - val_loss: 0.4799 - val_mse: 0.4729\n",
      "Epoch 304/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5243 - mse: 0.5173 - val_loss: 0.4791 - val_mse: 0.4721\n",
      "Epoch 305/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5255 - mse: 0.5185 - val_loss: 0.4853 - val_mse: 0.4783\n",
      "Epoch 306/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5218 - mse: 0.5148 - val_loss: 0.4786 - val_mse: 0.4716\n",
      "Epoch 307/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5168 - val_loss: 0.4769 - val_mse: 0.4699\n",
      "Epoch 308/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5233 - mse: 0.5163 - val_loss: 0.4814 - val_mse: 0.4744\n",
      "Epoch 309/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5270 - mse: 0.5200 - val_loss: 0.4824 - val_mse: 0.4754\n",
      "Epoch 310/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5222 - mse: 0.5152\n",
      "Epoch 00310: saving model to Regression_Model/thle2.mse.linear-0310.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5223 - mse: 0.5153 - val_loss: 0.4793 - val_mse: 0.4724\n",
      "Epoch 311/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5226 - mse: 0.5156 - val_loss: 0.4833 - val_mse: 0.4763\n",
      "Epoch 312/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5281 - mse: 0.5211 - val_loss: 0.4748 - val_mse: 0.4679\n",
      "Epoch 313/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5205 - mse: 0.5136 - val_loss: 0.4835 - val_mse: 0.4765\n",
      "Epoch 314/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5235 - mse: 0.5166 - val_loss: 0.4798 - val_mse: 0.4729\n",
      "Epoch 315/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5244 - mse: 0.5175 - val_loss: 0.4767 - val_mse: 0.4697\n",
      "Epoch 316/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5205 - mse: 0.5136 - val_loss: 0.4819 - val_mse: 0.4749\n",
      "Epoch 317/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5225 - mse: 0.5156 - val_loss: 0.4785 - val_mse: 0.4715\n",
      "Epoch 318/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5236 - mse: 0.5167 - val_loss: 0.4759 - val_mse: 0.4689\n",
      "Epoch 319/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5258 - mse: 0.5188 - val_loss: 0.4799 - val_mse: 0.4730\n",
      "Epoch 320/1000\n",
      "516/524 [============================>.] - ETA: 0s - loss: 0.5241 - mse: 0.5172\n",
      "Epoch 00320: saving model to Regression_Model/thle2.mse.linear-0320.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5242 - mse: 0.5173 - val_loss: 0.4818 - val_mse: 0.4749\n",
      "Epoch 321/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5220 - mse: 0.5151 - val_loss: 0.4835 - val_mse: 0.4765\n",
      "Epoch 322/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5261 - mse: 0.5192 - val_loss: 0.4747 - val_mse: 0.4678\n",
      "Epoch 323/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5258 - mse: 0.5189 - val_loss: 0.4886 - val_mse: 0.4816\n",
      "Epoch 324/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5201 - mse: 0.5132 - val_loss: 0.4757 - val_mse: 0.4688\n",
      "Epoch 325/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5208 - mse: 0.5139 - val_loss: 0.4740 - val_mse: 0.4671\n",
      "Epoch 326/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5261 - mse: 0.5192 - val_loss: 0.4750 - val_mse: 0.4680\n",
      "Epoch 327/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5282 - mse: 0.5213 - val_loss: 0.4785 - val_mse: 0.4716\n",
      "Epoch 328/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5184 - mse: 0.5114 - val_loss: 0.4739 - val_mse: 0.4670\n",
      "Epoch 329/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5246 - mse: 0.5177 - val_loss: 0.4753 - val_mse: 0.4684\n",
      "Epoch 330/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5245 - mse: 0.5175\n",
      "Epoch 00330: saving model to Regression_Model/thle2.mse.linear-0330.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5252 - mse: 0.5183 - val_loss: 0.4789 - val_mse: 0.4720\n",
      "Epoch 331/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5291 - mse: 0.5222 - val_loss: 0.4778 - val_mse: 0.4709\n",
      "Epoch 332/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5220 - mse: 0.5151 - val_loss: 0.4801 - val_mse: 0.4732\n",
      "Epoch 333/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5257 - mse: 0.5188 - val_loss: 0.4808 - val_mse: 0.4739\n",
      "Epoch 334/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5246 - mse: 0.5177 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 335/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5189 - mse: 0.5120 - val_loss: 0.4785 - val_mse: 0.4716\n",
      "Epoch 336/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5180 - mse: 0.5111 - val_loss: 0.4771 - val_mse: 0.4703\n",
      "Epoch 337/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5230 - mse: 0.5161 - val_loss: 0.4794 - val_mse: 0.4725\n",
      "Epoch 338/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5209 - mse: 0.5141 - val_loss: 0.4791 - val_mse: 0.4722\n",
      "Epoch 339/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5236 - mse: 0.5168 - val_loss: 0.4771 - val_mse: 0.4702\n",
      "Epoch 340/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5203 - mse: 0.5135\n",
      "Epoch 00340: saving model to Regression_Model/thle2.mse.linear-0340.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5206 - mse: 0.5137 - val_loss: 0.4763 - val_mse: 0.4695\n",
      "Epoch 341/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5208 - mse: 0.5139 - val_loss: 0.4813 - val_mse: 0.4744\n",
      "Epoch 342/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5218 - mse: 0.5149 - val_loss: 0.4715 - val_mse: 0.4646\n",
      "Epoch 343/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5211 - mse: 0.5142 - val_loss: 0.4787 - val_mse: 0.4719\n",
      "Epoch 344/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5160 - mse: 0.5092 - val_loss: 0.4795 - val_mse: 0.4726\n",
      "Epoch 345/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5223 - mse: 0.5154 - val_loss: 0.4774 - val_mse: 0.4705\n",
      "Epoch 346/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5214 - mse: 0.5146 - val_loss: 0.4762 - val_mse: 0.4693\n",
      "Epoch 347/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5251 - mse: 0.5183 - val_loss: 0.4749 - val_mse: 0.4680\n",
      "Epoch 348/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5169 - val_loss: 0.4774 - val_mse: 0.4706\n",
      "Epoch 349/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5269 - mse: 0.5201 - val_loss: 0.4811 - val_mse: 0.4742\n",
      "Epoch 350/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5265 - mse: 0.5197\n",
      "Epoch 00350: saving model to Regression_Model/thle2.mse.linear-0350.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5265 - mse: 0.5196 - val_loss: 0.4798 - val_mse: 0.4730\n",
      "Epoch 351/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5281 - mse: 0.5213 - val_loss: 0.4818 - val_mse: 0.4749\n",
      "Epoch 352/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5249 - mse: 0.5180 - val_loss: 0.4750 - val_mse: 0.4681\n",
      "Epoch 353/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5204 - mse: 0.5136 - val_loss: 0.4737 - val_mse: 0.4668\n",
      "Epoch 354/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5223 - mse: 0.5155 - val_loss: 0.4724 - val_mse: 0.4656\n",
      "Epoch 355/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5207 - mse: 0.5139 - val_loss: 0.4742 - val_mse: 0.4674\n",
      "Epoch 356/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5260 - mse: 0.5192 - val_loss: 0.4746 - val_mse: 0.4678\n",
      "Epoch 357/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5265 - mse: 0.5197 - val_loss: 0.4759 - val_mse: 0.4691\n",
      "Epoch 358/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5225 - mse: 0.5157 - val_loss: 0.4770 - val_mse: 0.4702\n",
      "Epoch 359/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5242 - mse: 0.5174 - val_loss: 0.4795 - val_mse: 0.4726\n",
      "Epoch 360/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5200 - mse: 0.5132\n",
      "Epoch 00360: saving model to Regression_Model/thle2.mse.linear-0360.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5208 - mse: 0.5140 - val_loss: 0.4757 - val_mse: 0.4689\n",
      "Epoch 361/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5201 - mse: 0.5132 - val_loss: 0.4812 - val_mse: 0.4743\n",
      "Epoch 362/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5212 - mse: 0.5144 - val_loss: 0.4893 - val_mse: 0.4825\n",
      "Epoch 363/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5237 - mse: 0.5169 - val_loss: 0.4756 - val_mse: 0.4687\n",
      "Epoch 364/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5215 - mse: 0.5147 - val_loss: 0.4810 - val_mse: 0.4742\n",
      "Epoch 365/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5237 - mse: 0.5169 - val_loss: 0.4788 - val_mse: 0.4720\n",
      "Epoch 366/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5140 - mse: 0.5072 - val_loss: 0.4781 - val_mse: 0.4713\n",
      "Epoch 367/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5232 - mse: 0.5164 - val_loss: 0.4754 - val_mse: 0.4686\n",
      "Epoch 368/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5216 - mse: 0.5148 - val_loss: 0.4816 - val_mse: 0.4748\n",
      "Epoch 369/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5185 - mse: 0.5117 - val_loss: 0.4775 - val_mse: 0.4707\n",
      "Epoch 370/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5163 - mse: 0.5095\n",
      "Epoch 00370: saving model to Regression_Model/thle2.mse.linear-0370.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5164 - mse: 0.5096 - val_loss: 0.4794 - val_mse: 0.4726\n",
      "Epoch 371/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5232 - mse: 0.5164 - val_loss: 0.4741 - val_mse: 0.4673\n",
      "Epoch 372/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5271 - mse: 0.5203 - val_loss: 0.4737 - val_mse: 0.4669\n",
      "Epoch 373/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5209 - mse: 0.5141 - val_loss: 0.4794 - val_mse: 0.4726\n",
      "Epoch 374/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5226 - mse: 0.5158 - val_loss: 0.4786 - val_mse: 0.4718\n",
      "Epoch 375/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5196 - mse: 0.5128 - val_loss: 0.4727 - val_mse: 0.4660\n",
      "Epoch 376/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5232 - mse: 0.5164 - val_loss: 0.4723 - val_mse: 0.4656\n",
      "Epoch 377/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5201 - mse: 0.5134 - val_loss: 0.4733 - val_mse: 0.4665\n",
      "Epoch 378/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5188 - mse: 0.5120 - val_loss: 0.4821 - val_mse: 0.4753\n",
      "Epoch 379/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5247 - mse: 0.5179 - val_loss: 0.4811 - val_mse: 0.4743\n",
      "Epoch 380/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5205 - mse: 0.5138\n",
      "Epoch 00380: saving model to Regression_Model/thle2.mse.linear-0380.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5203 - mse: 0.5135 - val_loss: 0.4721 - val_mse: 0.4653\n",
      "Epoch 381/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5254 - mse: 0.5186 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 382/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5198 - mse: 0.5130 - val_loss: 0.4735 - val_mse: 0.4668\n",
      "Epoch 383/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5252 - mse: 0.5184 - val_loss: 0.4812 - val_mse: 0.4744\n",
      "Epoch 384/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5248 - mse: 0.5180 - val_loss: 0.4785 - val_mse: 0.4717\n",
      "Epoch 385/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5214 - mse: 0.5146 - val_loss: 0.4821 - val_mse: 0.4753\n",
      "Epoch 386/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5175 - mse: 0.5108 - val_loss: 0.4781 - val_mse: 0.4714\n",
      "Epoch 387/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5243 - mse: 0.5176 - val_loss: 0.4771 - val_mse: 0.4704\n",
      "Epoch 388/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5203 - mse: 0.5136 - val_loss: 0.4750 - val_mse: 0.4682\n",
      "Epoch 389/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5160 - mse: 0.5092 - val_loss: 0.4806 - val_mse: 0.4739\n",
      "Epoch 390/1000\n",
      "516/524 [============================>.] - ETA: 0s - loss: 0.5208 - mse: 0.5141\n",
      "Epoch 00390: saving model to Regression_Model/thle2.mse.linear-0390.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5216 - mse: 0.5149 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 391/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5204 - mse: 0.5137 - val_loss: 0.4742 - val_mse: 0.4675\n",
      "Epoch 392/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5200 - mse: 0.5133 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 393/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5183 - mse: 0.5115 - val_loss: 0.4762 - val_mse: 0.4695\n",
      "Epoch 394/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5244 - mse: 0.5176 - val_loss: 0.4816 - val_mse: 0.4749\n",
      "Epoch 395/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5223 - mse: 0.5156 - val_loss: 0.4730 - val_mse: 0.4663\n",
      "Epoch 396/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5206 - mse: 0.5139 - val_loss: 0.4764 - val_mse: 0.4697\n",
      "Epoch 397/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5195 - mse: 0.5128 - val_loss: 0.4761 - val_mse: 0.4694\n",
      "Epoch 398/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5172 - mse: 0.5104 - val_loss: 0.4813 - val_mse: 0.4746\n",
      "Epoch 399/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5216 - mse: 0.5149 - val_loss: 0.4765 - val_mse: 0.4697\n",
      "Epoch 400/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5185 - mse: 0.5118\n",
      "Epoch 00400: saving model to Regression_Model/thle2.mse.linear-0400.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5185 - mse: 0.5118 - val_loss: 0.4768 - val_mse: 0.4701\n",
      "Epoch 401/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5220 - mse: 0.5153 - val_loss: 0.4728 - val_mse: 0.4661\n",
      "Epoch 402/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5169 - mse: 0.5102 - val_loss: 0.4778 - val_mse: 0.4711\n",
      "Epoch 403/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5167 - mse: 0.5100 - val_loss: 0.4805 - val_mse: 0.4738\n",
      "Epoch 404/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5224 - mse: 0.5157 - val_loss: 0.4801 - val_mse: 0.4734\n",
      "Epoch 405/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5216 - mse: 0.5149 - val_loss: 0.4763 - val_mse: 0.4696\n",
      "Epoch 406/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5195 - mse: 0.5128 - val_loss: 0.4797 - val_mse: 0.4730\n",
      "Epoch 407/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5214 - mse: 0.5147 - val_loss: 0.4724 - val_mse: 0.4657\n",
      "Epoch 408/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5238 - mse: 0.5172 - val_loss: 0.4767 - val_mse: 0.4700\n",
      "Epoch 409/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5221 - mse: 0.5154 - val_loss: 0.4746 - val_mse: 0.4679\n",
      "Epoch 410/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5165 - mse: 0.5098\n",
      "Epoch 00410: saving model to Regression_Model/thle2.mse.linear-0410.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5166 - mse: 0.5100 - val_loss: 0.4783 - val_mse: 0.4716\n",
      "Epoch 411/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5166 - mse: 0.5099 - val_loss: 0.4782 - val_mse: 0.4716\n",
      "Epoch 412/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5258 - mse: 0.5192 - val_loss: 0.4736 - val_mse: 0.4670\n",
      "Epoch 413/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5171 - mse: 0.5104 - val_loss: 0.4722 - val_mse: 0.4655\n",
      "Epoch 414/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5167 - mse: 0.5100 - val_loss: 0.4793 - val_mse: 0.4726\n",
      "Epoch 415/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5198 - mse: 0.5131 - val_loss: 0.4787 - val_mse: 0.4720\n",
      "Epoch 416/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5224 - mse: 0.5157 - val_loss: 0.4778 - val_mse: 0.4711\n",
      "Epoch 417/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5263 - mse: 0.5197 - val_loss: 0.4792 - val_mse: 0.4726\n",
      "Epoch 418/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5171 - val_loss: 0.4728 - val_mse: 0.4662\n",
      "Epoch 419/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5212 - mse: 0.5145 - val_loss: 0.4767 - val_mse: 0.4700\n",
      "Epoch 420/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5206 - mse: 0.5140\n",
      "Epoch 00420: saving model to Regression_Model/thle2.mse.linear-0420.ckpt\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.5210 - mse: 0.5143 - val_loss: 0.4722 - val_mse: 0.4655\n",
      "Epoch 421/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5174 - mse: 0.5107 - val_loss: 0.4748 - val_mse: 0.4681\n",
      "Epoch 422/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5249 - mse: 0.5182 - val_loss: 0.4777 - val_mse: 0.4710\n",
      "Epoch 423/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5209 - mse: 0.5142 - val_loss: 0.4781 - val_mse: 0.4714\n",
      "Epoch 424/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5159 - mse: 0.5093 - val_loss: 0.4763 - val_mse: 0.4697\n",
      "Epoch 425/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5197 - mse: 0.5131 - val_loss: 0.4733 - val_mse: 0.4666\n",
      "Epoch 426/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5237 - mse: 0.5171 - val_loss: 0.4785 - val_mse: 0.4719\n",
      "Epoch 427/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5214 - mse: 0.5148 - val_loss: 0.4742 - val_mse: 0.4675\n",
      "Epoch 428/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5198 - mse: 0.5131 - val_loss: 0.4748 - val_mse: 0.4682\n",
      "Epoch 429/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5202 - mse: 0.5136 - val_loss: 0.4768 - val_mse: 0.4701\n",
      "Epoch 430/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5195 - mse: 0.5129\n",
      "Epoch 00430: saving model to Regression_Model/thle2.mse.linear-0430.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5196 - mse: 0.5130 - val_loss: 0.4733 - val_mse: 0.4667\n",
      "Epoch 431/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5184 - mse: 0.5118 - val_loss: 0.4747 - val_mse: 0.4681\n",
      "Epoch 432/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5147 - mse: 0.5081 - val_loss: 0.4711 - val_mse: 0.4645\n",
      "Epoch 433/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5208 - mse: 0.5142 - val_loss: 0.4787 - val_mse: 0.4721\n",
      "Epoch 434/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5201 - mse: 0.5135 - val_loss: 0.4758 - val_mse: 0.4692\n",
      "Epoch 435/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5216 - mse: 0.5150 - val_loss: 0.4752 - val_mse: 0.4686\n",
      "Epoch 436/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5205 - mse: 0.5138 - val_loss: 0.4755 - val_mse: 0.4689\n",
      "Epoch 437/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5203 - mse: 0.5137 - val_loss: 0.4780 - val_mse: 0.4714\n",
      "Epoch 438/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5228 - mse: 0.5162 - val_loss: 0.4771 - val_mse: 0.4704\n",
      "Epoch 439/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5185 - mse: 0.5119 - val_loss: 0.4760 - val_mse: 0.4694\n",
      "Epoch 440/1000\n",
      "521/524 [============================>.] - ETA: 0s - loss: 0.5235 - mse: 0.5169\n",
      "Epoch 00440: saving model to Regression_Model/thle2.mse.linear-0440.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5235 - mse: 0.5169 - val_loss: 0.4783 - val_mse: 0.4717\n",
      "Epoch 441/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5188 - mse: 0.5122 - val_loss: 0.4774 - val_mse: 0.4708\n",
      "Epoch 442/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5211 - mse: 0.5144 - val_loss: 0.4736 - val_mse: 0.4670\n",
      "Epoch 443/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5185 - mse: 0.5119 - val_loss: 0.4772 - val_mse: 0.4706\n",
      "Epoch 444/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5199 - mse: 0.5133 - val_loss: 0.4753 - val_mse: 0.4687\n",
      "Epoch 445/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5220 - mse: 0.5154 - val_loss: 0.4768 - val_mse: 0.4702\n",
      "Epoch 446/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5199 - mse: 0.5133 - val_loss: 0.4805 - val_mse: 0.4739\n",
      "Epoch 447/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5275 - mse: 0.5209 - val_loss: 0.4778 - val_mse: 0.4713\n",
      "Epoch 448/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5183 - mse: 0.5117 - val_loss: 0.4779 - val_mse: 0.4713\n",
      "Epoch 449/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5160 - mse: 0.5094 - val_loss: 0.4757 - val_mse: 0.4692\n",
      "Epoch 450/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5197 - mse: 0.5131\n",
      "Epoch 00450: saving model to Regression_Model/thle2.mse.linear-0450.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5196 - mse: 0.5130 - val_loss: 0.4791 - val_mse: 0.4725\n",
      "Epoch 451/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5179 - mse: 0.5113 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 452/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5174 - mse: 0.5108 - val_loss: 0.4776 - val_mse: 0.4710\n",
      "Epoch 453/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5176 - mse: 0.5110 - val_loss: 0.4788 - val_mse: 0.4722\n",
      "Epoch 454/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5157 - mse: 0.5091 - val_loss: 0.4811 - val_mse: 0.4745\n",
      "Epoch 455/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5234 - mse: 0.5168 - val_loss: 0.4783 - val_mse: 0.4717\n",
      "Epoch 456/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5210 - mse: 0.5144 - val_loss: 0.4748 - val_mse: 0.4683\n",
      "Epoch 457/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5187 - mse: 0.5122 - val_loss: 0.4797 - val_mse: 0.4731\n",
      "Epoch 458/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5203 - mse: 0.5137 - val_loss: 0.4753 - val_mse: 0.4688\n",
      "Epoch 459/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5184 - mse: 0.5118 - val_loss: 0.4768 - val_mse: 0.4703\n",
      "Epoch 460/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5191 - mse: 0.5126\n",
      "Epoch 00460: saving model to Regression_Model/thle2.mse.linear-0460.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5195 - mse: 0.5129 - val_loss: 0.4775 - val_mse: 0.4710\n",
      "Epoch 461/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5164 - mse: 0.5098 - val_loss: 0.4774 - val_mse: 0.4709\n",
      "Epoch 462/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5210 - mse: 0.5145 - val_loss: 0.4754 - val_mse: 0.4689\n",
      "Epoch 463/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5244 - mse: 0.5179 - val_loss: 0.4736 - val_mse: 0.4671\n",
      "Epoch 464/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5173 - mse: 0.5107 - val_loss: 0.4811 - val_mse: 0.4745\n",
      "Epoch 465/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5207 - mse: 0.5142 - val_loss: 0.4720 - val_mse: 0.4655\n",
      "Epoch 466/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5185 - mse: 0.5120 - val_loss: 0.4744 - val_mse: 0.4679\n",
      "Epoch 467/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5189 - mse: 0.5123 - val_loss: 0.4773 - val_mse: 0.4707\n",
      "Epoch 468/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5113 - mse: 0.5048 - val_loss: 0.4760 - val_mse: 0.4694\n",
      "Epoch 469/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5202 - mse: 0.5137 - val_loss: 0.4752 - val_mse: 0.4687\n",
      "Epoch 470/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5179 - mse: 0.5113\n",
      "Epoch 00470: saving model to Regression_Model/thle2.mse.linear-0470.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5181 - mse: 0.5116 - val_loss: 0.4745 - val_mse: 0.4680\n",
      "Epoch 471/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5213 - mse: 0.5148 - val_loss: 0.4714 - val_mse: 0.4649\n",
      "Epoch 472/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5248 - mse: 0.5183 - val_loss: 0.4779 - val_mse: 0.4714\n",
      "Epoch 473/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5204 - mse: 0.5138 - val_loss: 0.4803 - val_mse: 0.4738\n",
      "Epoch 474/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5179 - mse: 0.5113 - val_loss: 0.4764 - val_mse: 0.4699\n",
      "Epoch 475/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5144 - mse: 0.5079 - val_loss: 0.4769 - val_mse: 0.4703\n",
      "Epoch 476/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5195 - mse: 0.5129 - val_loss: 0.4749 - val_mse: 0.4683\n",
      "Epoch 477/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5200 - mse: 0.5135 - val_loss: 0.4754 - val_mse: 0.4689\n",
      "Epoch 478/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5221 - mse: 0.5155 - val_loss: 0.4770 - val_mse: 0.4705\n",
      "Epoch 479/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5156 - mse: 0.5090 - val_loss: 0.4738 - val_mse: 0.4673\n",
      "Epoch 480/1000\n",
      "520/524 [============================>.] - ETA: 0s - loss: 0.5193 - mse: 0.5128\n",
      "Epoch 00480: saving model to Regression_Model/thle2.mse.linear-0480.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5190 - mse: 0.5125 - val_loss: 0.4767 - val_mse: 0.4702\n",
      "Epoch 481/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5110 - mse: 0.5045 - val_loss: 0.4738 - val_mse: 0.4672\n",
      "Epoch 482/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5178 - mse: 0.5113 - val_loss: 0.4757 - val_mse: 0.4692\n",
      "Epoch 483/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5197 - mse: 0.5131 - val_loss: 0.4742 - val_mse: 0.4677\n",
      "Epoch 484/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5145 - mse: 0.5079 - val_loss: 0.4727 - val_mse: 0.4662\n",
      "Epoch 485/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5169 - mse: 0.5104 - val_loss: 0.4795 - val_mse: 0.4730\n",
      "Epoch 486/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5213 - mse: 0.5148 - val_loss: 0.4760 - val_mse: 0.4695\n",
      "Epoch 487/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5180 - mse: 0.5115 - val_loss: 0.4754 - val_mse: 0.4689\n",
      "Epoch 488/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5181 - mse: 0.5116 - val_loss: 0.4797 - val_mse: 0.4732\n",
      "Epoch 489/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5182 - mse: 0.5117 - val_loss: 0.4766 - val_mse: 0.4701\n",
      "Epoch 490/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5224 - mse: 0.5159\n",
      "Epoch 00490: saving model to Regression_Model/thle2.mse.linear-0490.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5221 - mse: 0.5156 - val_loss: 0.4773 - val_mse: 0.4708\n",
      "Epoch 491/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5160 - mse: 0.5095 - val_loss: 0.4732 - val_mse: 0.4667\n",
      "Epoch 492/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5219 - mse: 0.5154 - val_loss: 0.4730 - val_mse: 0.4665\n",
      "Epoch 493/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5145 - mse: 0.5080 - val_loss: 0.4749 - val_mse: 0.4685\n",
      "Epoch 494/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5147 - mse: 0.5082 - val_loss: 0.4753 - val_mse: 0.4688\n",
      "Epoch 495/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5203 - mse: 0.5138 - val_loss: 0.4781 - val_mse: 0.4716\n",
      "Epoch 496/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5210 - mse: 0.5145 - val_loss: 0.4802 - val_mse: 0.4737\n",
      "Epoch 497/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5182 - mse: 0.5117 - val_loss: 0.4784 - val_mse: 0.4719\n",
      "Epoch 498/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5225 - mse: 0.5160 - val_loss: 0.4751 - val_mse: 0.4687\n",
      "Epoch 499/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5162 - mse: 0.5097 - val_loss: 0.4748 - val_mse: 0.4683\n",
      "Epoch 500/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5195 - mse: 0.5130\n",
      "Epoch 00500: saving model to Regression_Model/thle2.mse.linear-0500.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5195 - mse: 0.5130 - val_loss: 0.4753 - val_mse: 0.4688\n",
      "Epoch 501/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5225 - mse: 0.5160 - val_loss: 0.4789 - val_mse: 0.4724\n",
      "Epoch 502/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5201 - mse: 0.5136 - val_loss: 0.4763 - val_mse: 0.4698\n",
      "Epoch 503/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5185 - mse: 0.5120 - val_loss: 0.4783 - val_mse: 0.4718\n",
      "Epoch 504/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5178 - mse: 0.5113 - val_loss: 0.4768 - val_mse: 0.4703\n",
      "Epoch 505/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5179 - mse: 0.5114 - val_loss: 0.4730 - val_mse: 0.4665\n",
      "Epoch 506/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5135 - mse: 0.5070 - val_loss: 0.4765 - val_mse: 0.4700\n",
      "Epoch 507/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5176 - mse: 0.5112 - val_loss: 0.4758 - val_mse: 0.4693\n",
      "Epoch 508/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5197 - mse: 0.5132 - val_loss: 0.4804 - val_mse: 0.4739\n",
      "Epoch 509/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5195 - mse: 0.5130 - val_loss: 0.4796 - val_mse: 0.4731\n",
      "Epoch 510/1000\n",
      "516/524 [============================>.] - ETA: 0s - loss: 0.5188 - mse: 0.5123\n",
      "Epoch 00510: saving model to Regression_Model/thle2.mse.linear-0510.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5178 - mse: 0.5114 - val_loss: 0.4772 - val_mse: 0.4707\n",
      "Epoch 511/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5134 - mse: 0.5069 - val_loss: 0.4736 - val_mse: 0.4671\n",
      "Epoch 512/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5173 - mse: 0.5109 - val_loss: 0.4777 - val_mse: 0.4712\n",
      "Epoch 513/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5201 - mse: 0.5137 - val_loss: 0.4733 - val_mse: 0.4668\n",
      "Epoch 514/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5166 - mse: 0.5101 - val_loss: 0.4709 - val_mse: 0.4644\n",
      "Epoch 515/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5181 - mse: 0.5117 - val_loss: 0.4747 - val_mse: 0.4682\n",
      "Epoch 516/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5148 - mse: 0.5084 - val_loss: 0.4735 - val_mse: 0.4671\n",
      "Epoch 517/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5172 - mse: 0.5107 - val_loss: 0.4759 - val_mse: 0.4695\n",
      "Epoch 518/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5184 - mse: 0.5120 - val_loss: 0.4811 - val_mse: 0.4746\n",
      "Epoch 519/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5245 - mse: 0.5180 - val_loss: 0.4810 - val_mse: 0.4746\n",
      "Epoch 520/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5157 - mse: 0.5093\n",
      "Epoch 00520: saving model to Regression_Model/thle2.mse.linear-0520.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5158 - mse: 0.5093 - val_loss: 0.4756 - val_mse: 0.4692\n",
      "Epoch 521/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5135 - mse: 0.5070 - val_loss: 0.4729 - val_mse: 0.4664\n",
      "Epoch 522/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5165 - mse: 0.5100 - val_loss: 0.4742 - val_mse: 0.4678\n",
      "Epoch 523/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5160 - mse: 0.5095 - val_loss: 0.4807 - val_mse: 0.4743\n",
      "Epoch 524/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5194 - mse: 0.5129 - val_loss: 0.4783 - val_mse: 0.4719\n",
      "Epoch 525/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5157 - mse: 0.5092 - val_loss: 0.4751 - val_mse: 0.4686\n",
      "Epoch 526/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5244 - mse: 0.5179 - val_loss: 0.4760 - val_mse: 0.4696\n",
      "Epoch 527/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5199 - mse: 0.5135 - val_loss: 0.4787 - val_mse: 0.4723\n",
      "Epoch 528/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5168 - mse: 0.5104 - val_loss: 0.4738 - val_mse: 0.4674\n",
      "Epoch 529/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5150 - mse: 0.5085 - val_loss: 0.4753 - val_mse: 0.4689\n",
      "Epoch 530/1000\n",
      "520/524 [============================>.] - ETA: 0s - loss: 0.5155 - mse: 0.5091\n",
      "Epoch 00530: saving model to Regression_Model/thle2.mse.linear-0530.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5156 - mse: 0.5091 - val_loss: 0.4747 - val_mse: 0.4683\n",
      "Epoch 531/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5198 - mse: 0.5134 - val_loss: 0.4751 - val_mse: 0.4687\n",
      "Epoch 532/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5180 - mse: 0.5115 - val_loss: 0.4742 - val_mse: 0.4678\n",
      "Epoch 533/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5211 - mse: 0.5147 - val_loss: 0.4726 - val_mse: 0.4662\n",
      "Epoch 534/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5178 - mse: 0.5114 - val_loss: 0.4751 - val_mse: 0.4687\n",
      "Epoch 535/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5245 - mse: 0.5180 - val_loss: 0.4747 - val_mse: 0.4682\n",
      "Epoch 536/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5186 - mse: 0.5122 - val_loss: 0.4772 - val_mse: 0.4708\n",
      "Epoch 537/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5180 - mse: 0.5116 - val_loss: 0.4752 - val_mse: 0.4688\n",
      "Epoch 538/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5186 - mse: 0.5122 - val_loss: 0.4758 - val_mse: 0.4694\n",
      "Epoch 539/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5170 - mse: 0.5106 - val_loss: 0.4739 - val_mse: 0.4675\n",
      "Epoch 540/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5196 - mse: 0.5132\n",
      "Epoch 00540: saving model to Regression_Model/thle2.mse.linear-0540.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5196 - mse: 0.5132 - val_loss: 0.4791 - val_mse: 0.4727\n",
      "Epoch 541/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5196 - mse: 0.5131 - val_loss: 0.4773 - val_mse: 0.4709\n",
      "Epoch 542/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5148 - mse: 0.5084 - val_loss: 0.4758 - val_mse: 0.4694\n",
      "Epoch 543/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5206 - mse: 0.5142 - val_loss: 0.4767 - val_mse: 0.4703\n",
      "Epoch 544/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5138 - mse: 0.5074 - val_loss: 0.4777 - val_mse: 0.4713\n",
      "Epoch 545/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5183 - mse: 0.5119 - val_loss: 0.4776 - val_mse: 0.4712\n",
      "Epoch 546/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5200 - mse: 0.5136 - val_loss: 0.4738 - val_mse: 0.4674\n",
      "Epoch 547/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5193 - mse: 0.5129 - val_loss: 0.4748 - val_mse: 0.4684\n",
      "Epoch 548/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5179 - mse: 0.5116 - val_loss: 0.4763 - val_mse: 0.4699\n",
      "Epoch 549/1000\n",
      "361/524 [===================>..........] - ETA: 0s - loss: 0.5227 - mse: 0.5163"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-84a410e59eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=1000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "mse\n",
      "val_loss\n",
      "val_mse\n"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b8b4ffc7da0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,MODEL_PATH,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    \n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_rpm\\tpolyA_rpm\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "testid=trainid\n",
    "bestEpoch = '0540'\n",
    "MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "evaluate(train_x,train_y,train_id,MODEL_PATH,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,MODEL_PATH,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 20258\n",
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "train_data1,train_labels1,train_pasid1,valid_data1,valid_labels1,valid_pasid1 = \\\n",
    "prep_data('coverage_data/thle2.gt.gt.txt',5,6.2)\n",
    "x=np.concatenate((train_data1, valid_data1), axis=0)\n",
    "y=np.concatenate((train_labels1, valid_labels1), axis=0)\n",
    "pasid=np.concatenate((train_pasid1, valid_pasid1), axis=0)\n",
    "#data_mean=-1.511\n",
    "#data_std=1.437\n",
    "#label_mean=2.473\n",
    "#label_std=1.518\n",
    "x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)\n",
    "#MODEL_PATH = '../APAIQ2/model/snu398_regression.ckpt'\n",
    "evaluate(x,y,pasid,MODEL_PATH,'test',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/thle2_control.pAs.usage.txt',5)\n",
    "train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/Finetune.snu398_control.usage.txt',5)\n",
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='thle2.mle.linear'\n",
    "bestEpoch = '0980'\n",
    "evaluate(train_x,train_y,train_pasid,testid,'train',label_mean,label_std,bestEpoch)\n",
    "evaluate(valid_x,valid_y,valid_pasid,testid,'valid',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train_data,train_labels,data_mean,data_std,label_mean,label_std):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    return train_data,train_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1(x,y,pasid,trainid,dataset,label_mean,label_std,bestEpoch=2000):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)-1\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)-1\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prep_data() missing 1 required positional argument: 'depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-258c38ac16ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_pasid1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_data1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_labels1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_pasid1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coverage_data/all.snu398_control.usage.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpasid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pasid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_pasid1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: prep_data() missing 1 required positional argument: 'depth'"
     ]
    }
   ],
   "source": [
    "train_data1,train_labels1,train_pasid1,valid_data1,valid_labels1,valid_pasid1 = prep_data('coverage_data/all.snu398_control.usage.txt',5)\n",
    "x=np.concatenate((train_data1, valid_data1), axis=0)\n",
    "y=np.concatenate((train_labels1, valid_labels1), axis=0)\n",
    "pasid=np.concatenate((train_pasid1, valid_pasid1), axis=0)\n",
    "x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='Regression.f_snu398.shift16.1001'\n",
    "bestEpoch = '2000'\n",
    "evaluate1(x,y,pasid,testid,'all',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((train_pasid1, valid_pasid1), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[3,4,5,6]\n",
    "a.remove(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(a == None):\n",
    "    print('fafa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'chromosme,start,end,score,id,strand\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,c,d = a.split(',')[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
