{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.23.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = MaxPooling1D(pool_size = 12)(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "group_normalization (GroupNo (None, 990, 16)           32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,289\n",
      "Trainable params: 42,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 10921\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('coverage_data/K562_Chen.usage.txt',5,33.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data2,train_labels2,train_id2,valid_data2,valid_labels2,valid_id2 = prep_data('coverage_data/SNU398_Control.usage.txt',5,7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=np.concatenate((train_data1, train_data2), axis=0)\n",
    "#train_labels=np.concatenate((train_labels1, train_labels2), axis=0)\n",
    "#valid_data=np.concatenate((valid_data1, valid_data2), axis=0)\n",
    "#valid_labels=np.concatenate((valid_labels1, valid_labels2), axis=0)\n",
    "#train_id =np.concatenate((train_id1, train_id2), axis=0)\n",
    "#valid_id =np.concatenate((valid_id1, valid_id2), axis=0)\n",
    "#x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015015015"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+0.05)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    #train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    #valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0916221 1.7920761\n",
      "2.391116 1.6476064\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b8b5e9c7940>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(train_x.shape[1]),train_x[5,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.37542865"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,train_id,16,LENGTH)\n",
    "validation_generator = DataGenerator(valid_x,valid_y,valid_id,0,LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(LENGTH),a[9])\n",
    "plt.xticks(np.arange(0, LENGTH, 100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='thle2.mse.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 273 steps, validate for 68 steps\n",
      "Epoch 1/1000\n",
      "273/273 [==============================] - 11s 39ms/step - loss: 0.9807 - mse: 0.9735 - val_loss: 0.7085 - val_mse: 0.7008\n",
      "Epoch 2/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.7638 - mse: 0.7560 - val_loss: 0.6756 - val_mse: 0.6679\n",
      "Epoch 3/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.7251 - mse: 0.7173 - val_loss: 0.5796 - val_mse: 0.5718\n",
      "Epoch 4/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.7063 - mse: 0.6985 - val_loss: 0.5683 - val_mse: 0.5605\n",
      "Epoch 5/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6696 - mse: 0.6618 - val_loss: 0.6321 - val_mse: 0.6243\n",
      "Epoch 6/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6638 - mse: 0.6560 - val_loss: 0.5393 - val_mse: 0.5315\n",
      "Epoch 7/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6459 - mse: 0.6381 - val_loss: 0.5676 - val_mse: 0.5597\n",
      "Epoch 8/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6368 - mse: 0.6289 - val_loss: 0.5658 - val_mse: 0.5579\n",
      "Epoch 9/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6212 - mse: 0.6133 - val_loss: 0.5129 - val_mse: 0.5050\n",
      "Epoch 10/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.6307 - mse: 0.6228\n",
      "Epoch 00010: saving model to Regression_Model/thle2.mse.linear-0010.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.6295 - mse: 0.6216 - val_loss: 0.5455 - val_mse: 0.5376\n",
      "Epoch 11/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6067 - mse: 0.5988 - val_loss: 0.5617 - val_mse: 0.5538\n",
      "Epoch 12/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6156 - mse: 0.6077 - val_loss: 0.5323 - val_mse: 0.5244\n",
      "Epoch 13/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6293 - mse: 0.6213 - val_loss: 0.5273 - val_mse: 0.5193\n",
      "Epoch 14/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6039 - mse: 0.5960 - val_loss: 0.5159 - val_mse: 0.5079\n",
      "Epoch 15/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5898 - mse: 0.5818 - val_loss: 0.5208 - val_mse: 0.5128\n",
      "Epoch 16/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5997 - mse: 0.5917 - val_loss: 0.5271 - val_mse: 0.5190\n",
      "Epoch 17/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5911 - mse: 0.5831 - val_loss: 0.5278 - val_mse: 0.5198\n",
      "Epoch 18/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5906 - mse: 0.5825 - val_loss: 0.5154 - val_mse: 0.5074\n",
      "Epoch 19/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.6016 - mse: 0.5936 - val_loss: 0.5161 - val_mse: 0.5080\n",
      "Epoch 20/1000\n",
      "264/273 [============================>.] - ETA: 0s - loss: 0.5966 - mse: 0.5886\n",
      "Epoch 00020: saving model to Regression_Model/thle2.mse.linear-0020.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5967 - mse: 0.5886 - val_loss: 0.5261 - val_mse: 0.5181\n",
      "Epoch 21/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5710 - mse: 0.5629 - val_loss: 0.5127 - val_mse: 0.5046\n",
      "Epoch 22/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5795 - mse: 0.5714 - val_loss: 0.5288 - val_mse: 0.5208\n",
      "Epoch 23/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5796 - mse: 0.5715 - val_loss: 0.5108 - val_mse: 0.5027\n",
      "Epoch 24/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5807 - mse: 0.5726 - val_loss: 0.5052 - val_mse: 0.4971\n",
      "Epoch 25/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5802 - mse: 0.5721 - val_loss: 0.5288 - val_mse: 0.5207\n",
      "Epoch 26/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5849 - mse: 0.5768 - val_loss: 0.5037 - val_mse: 0.4956\n",
      "Epoch 27/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5806 - mse: 0.5725 - val_loss: 0.5194 - val_mse: 0.5113\n",
      "Epoch 28/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5790 - mse: 0.5709 - val_loss: 0.5385 - val_mse: 0.5304\n",
      "Epoch 29/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5750 - mse: 0.5669 - val_loss: 0.5208 - val_mse: 0.5127\n",
      "Epoch 30/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5682 - mse: 0.5601\n",
      "Epoch 00030: saving model to Regression_Model/thle2.mse.linear-0030.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5695 - mse: 0.5614 - val_loss: 0.5113 - val_mse: 0.5032\n",
      "Epoch 31/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5790 - mse: 0.5709 - val_loss: 0.5528 - val_mse: 0.5447\n",
      "Epoch 32/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5822 - mse: 0.5741 - val_loss: 0.5116 - val_mse: 0.5035\n",
      "Epoch 33/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5761 - mse: 0.5680 - val_loss: 0.5005 - val_mse: 0.4924\n",
      "Epoch 34/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5738 - mse: 0.5657 - val_loss: 0.5177 - val_mse: 0.5095\n",
      "Epoch 35/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5773 - mse: 0.5692 - val_loss: 0.5275 - val_mse: 0.5193\n",
      "Epoch 36/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5753 - mse: 0.5671 - val_loss: 0.5069 - val_mse: 0.4987\n",
      "Epoch 37/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5736 - mse: 0.5654 - val_loss: 0.5150 - val_mse: 0.5069\n",
      "Epoch 38/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5652 - mse: 0.5570 - val_loss: 0.5116 - val_mse: 0.5035\n",
      "Epoch 39/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5769 - mse: 0.5688 - val_loss: 0.5101 - val_mse: 0.5020\n",
      "Epoch 40/1000\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.5771 - mse: 0.5690\n",
      "Epoch 00040: saving model to Regression_Model/thle2.mse.linear-0040.ckpt\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.5764 - mse: 0.5682 - val_loss: 0.5202 - val_mse: 0.5121\n",
      "Epoch 41/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5636 - mse: 0.5554 - val_loss: 0.5289 - val_mse: 0.5207\n",
      "Epoch 42/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5757 - mse: 0.5676 - val_loss: 0.5038 - val_mse: 0.4956\n",
      "Epoch 43/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5682 - mse: 0.5601 - val_loss: 0.5201 - val_mse: 0.5119\n",
      "Epoch 44/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5726 - mse: 0.5645 - val_loss: 0.5233 - val_mse: 0.5151\n",
      "Epoch 45/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5600 - mse: 0.5518 - val_loss: 0.5086 - val_mse: 0.5004\n",
      "Epoch 46/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5617 - mse: 0.5535 - val_loss: 0.4989 - val_mse: 0.4907\n",
      "Epoch 47/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5539 - mse: 0.5457 - val_loss: 0.5194 - val_mse: 0.5113\n",
      "Epoch 48/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5625 - mse: 0.5544 - val_loss: 0.5154 - val_mse: 0.5073\n",
      "Epoch 49/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5688 - mse: 0.5606 - val_loss: 0.5182 - val_mse: 0.5100\n",
      "Epoch 50/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5566 - mse: 0.5484\n",
      "Epoch 00050: saving model to Regression_Model/thle2.mse.linear-0050.ckpt\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.5568 - mse: 0.5486 - val_loss: 0.4930 - val_mse: 0.4849\n",
      "Epoch 51/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5575 - mse: 0.5493 - val_loss: 0.5179 - val_mse: 0.5097\n",
      "Epoch 52/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5562 - mse: 0.5480 - val_loss: 0.4938 - val_mse: 0.4856\n",
      "Epoch 53/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5629 - mse: 0.5548 - val_loss: 0.5243 - val_mse: 0.5162\n",
      "Epoch 54/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5602 - mse: 0.5520 - val_loss: 0.5084 - val_mse: 0.5002\n",
      "Epoch 55/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5678 - mse: 0.5596 - val_loss: 0.5297 - val_mse: 0.5215\n",
      "Epoch 56/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5589 - mse: 0.5507 - val_loss: 0.5285 - val_mse: 0.5203\n",
      "Epoch 57/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5616 - mse: 0.5534 - val_loss: 0.5343 - val_mse: 0.5261\n",
      "Epoch 58/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5533 - mse: 0.5451 - val_loss: 0.5098 - val_mse: 0.5016\n",
      "Epoch 59/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5467 - mse: 0.5385 - val_loss: 0.5067 - val_mse: 0.4985\n",
      "Epoch 60/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5539 - mse: 0.5457\n",
      "Epoch 00060: saving model to Regression_Model/thle2.mse.linear-0060.ckpt\n",
      "273/273 [==============================] - 6s 21ms/step - loss: 0.5532 - mse: 0.5450 - val_loss: 0.4988 - val_mse: 0.4906\n",
      "Epoch 61/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5569 - mse: 0.5486 - val_loss: 0.4867 - val_mse: 0.4785\n",
      "Epoch 62/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5631 - mse: 0.5549 - val_loss: 0.5152 - val_mse: 0.5070\n",
      "Epoch 63/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5696 - mse: 0.5614 - val_loss: 0.5056 - val_mse: 0.4973\n",
      "Epoch 64/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5479 - mse: 0.5397 - val_loss: 0.5055 - val_mse: 0.4973\n",
      "Epoch 65/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5634 - mse: 0.5552 - val_loss: 0.5164 - val_mse: 0.5082\n",
      "Epoch 66/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5577 - mse: 0.5495 - val_loss: 0.5119 - val_mse: 0.5037\n",
      "Epoch 67/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5605 - mse: 0.5523 - val_loss: 0.5061 - val_mse: 0.4979\n",
      "Epoch 68/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5528 - mse: 0.5446 - val_loss: 0.5003 - val_mse: 0.4921\n",
      "Epoch 69/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5557 - mse: 0.5475 - val_loss: 0.4942 - val_mse: 0.4860\n",
      "Epoch 70/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5469 - mse: 0.5387\n",
      "Epoch 00070: saving model to Regression_Model/thle2.mse.linear-0070.ckpt\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.5472 - mse: 0.5390 - val_loss: 0.4897 - val_mse: 0.4815\n",
      "Epoch 71/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5490 - mse: 0.5407 - val_loss: 0.4919 - val_mse: 0.4836\n",
      "Epoch 72/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5547 - mse: 0.5465 - val_loss: 0.5054 - val_mse: 0.4972\n",
      "Epoch 73/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5504 - mse: 0.5422 - val_loss: 0.5009 - val_mse: 0.4927\n",
      "Epoch 74/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5457 - mse: 0.5374 - val_loss: 0.4935 - val_mse: 0.4853\n",
      "Epoch 75/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5507 - mse: 0.5425 - val_loss: 0.4906 - val_mse: 0.4823\n",
      "Epoch 76/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5471 - mse: 0.5389 - val_loss: 0.5152 - val_mse: 0.5069\n",
      "Epoch 77/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5492 - mse: 0.5410 - val_loss: 0.5034 - val_mse: 0.4952\n",
      "Epoch 78/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5592 - mse: 0.5509 - val_loss: 0.5242 - val_mse: 0.5159\n",
      "Epoch 79/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5486 - mse: 0.5404 - val_loss: 0.5007 - val_mse: 0.4925\n",
      "Epoch 80/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5470 - mse: 0.5387\n",
      "Epoch 00080: saving model to Regression_Model/thle2.mse.linear-0080.ckpt\n",
      "273/273 [==============================] - 8s 29ms/step - loss: 0.5469 - mse: 0.5386 - val_loss: 0.5002 - val_mse: 0.4920\n",
      "Epoch 81/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5451 - mse: 0.5369 - val_loss: 0.4977 - val_mse: 0.4895\n",
      "Epoch 82/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5523 - mse: 0.5440 - val_loss: 0.4974 - val_mse: 0.4891\n",
      "Epoch 83/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5451 - mse: 0.5368 - val_loss: 0.4891 - val_mse: 0.4809\n",
      "Epoch 84/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5565 - mse: 0.5483 - val_loss: 0.5147 - val_mse: 0.5064\n",
      "Epoch 85/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5485 - mse: 0.5403 - val_loss: 0.5184 - val_mse: 0.5101\n",
      "Epoch 86/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5465 - mse: 0.5382 - val_loss: 0.4907 - val_mse: 0.4824\n",
      "Epoch 87/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5440 - mse: 0.5357 - val_loss: 0.4888 - val_mse: 0.4806\n",
      "Epoch 88/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5463 - mse: 0.5381 - val_loss: 0.4885 - val_mse: 0.4803\n",
      "Epoch 89/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5449 - mse: 0.5367 - val_loss: 0.4873 - val_mse: 0.4791\n",
      "Epoch 90/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5483 - mse: 0.5401\n",
      "Epoch 00090: saving model to Regression_Model/thle2.mse.linear-0090.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5467 - mse: 0.5385 - val_loss: 0.4881 - val_mse: 0.4799\n",
      "Epoch 91/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5475 - mse: 0.5393 - val_loss: 0.4973 - val_mse: 0.4890\n",
      "Epoch 92/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5546 - mse: 0.5464 - val_loss: 0.4918 - val_mse: 0.4836\n",
      "Epoch 93/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5398 - mse: 0.5315 - val_loss: 0.4885 - val_mse: 0.4803\n",
      "Epoch 94/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5409 - mse: 0.5327 - val_loss: 0.4895 - val_mse: 0.4813\n",
      "Epoch 95/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5413 - mse: 0.5331 - val_loss: 0.4962 - val_mse: 0.4880\n",
      "Epoch 96/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5483 - mse: 0.5401 - val_loss: 0.4929 - val_mse: 0.4846\n",
      "Epoch 97/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5444 - mse: 0.5361 - val_loss: 0.4968 - val_mse: 0.4885\n",
      "Epoch 98/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5502 - mse: 0.5420 - val_loss: 0.5020 - val_mse: 0.4937\n",
      "Epoch 99/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5426 - mse: 0.5344 - val_loss: 0.4987 - val_mse: 0.4905\n",
      "Epoch 100/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5375 - mse: 0.5292\n",
      "Epoch 00100: saving model to Regression_Model/thle2.mse.linear-0100.ckpt\n",
      "273/273 [==============================] - 8s 30ms/step - loss: 0.5401 - mse: 0.5318 - val_loss: 0.4919 - val_mse: 0.4837\n",
      "Epoch 101/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5437 - mse: 0.5354 - val_loss: 0.4902 - val_mse: 0.4819\n",
      "Epoch 102/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5499 - mse: 0.5417 - val_loss: 0.4936 - val_mse: 0.4854\n",
      "Epoch 103/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5426 - mse: 0.5344 - val_loss: 0.4866 - val_mse: 0.4784\n",
      "Epoch 104/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5466 - mse: 0.5384 - val_loss: 0.5141 - val_mse: 0.5059\n",
      "Epoch 105/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5515 - mse: 0.5433 - val_loss: 0.4989 - val_mse: 0.4906\n",
      "Epoch 106/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5446 - mse: 0.5364 - val_loss: 0.4929 - val_mse: 0.4847\n",
      "Epoch 107/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5360 - mse: 0.5278 - val_loss: 0.4783 - val_mse: 0.4701\n",
      "Epoch 108/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5488 - mse: 0.5406 - val_loss: 0.5000 - val_mse: 0.4918\n",
      "Epoch 109/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5444 - mse: 0.5362 - val_loss: 0.4840 - val_mse: 0.4758\n",
      "Epoch 110/1000\n",
      "259/273 [===========================>..] - ETA: 0s - loss: 0.5368 - mse: 0.5285\n",
      "Epoch 00110: saving model to Regression_Model/thle2.mse.linear-0110.ckpt\n",
      "273/273 [==============================] - 6s 23ms/step - loss: 0.5358 - mse: 0.5276 - val_loss: 0.4907 - val_mse: 0.4824\n",
      "Epoch 111/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5407 - mse: 0.5324 - val_loss: 0.4839 - val_mse: 0.4756\n",
      "Epoch 112/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5404 - mse: 0.5322 - val_loss: 0.4805 - val_mse: 0.4723\n",
      "Epoch 113/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5484 - mse: 0.5401 - val_loss: 0.4850 - val_mse: 0.4768\n",
      "Epoch 114/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5366 - mse: 0.5284 - val_loss: 0.5003 - val_mse: 0.4920\n",
      "Epoch 115/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5325 - mse: 0.5243 - val_loss: 0.4886 - val_mse: 0.4804\n",
      "Epoch 116/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5329 - mse: 0.5247 - val_loss: 0.4804 - val_mse: 0.4722\n",
      "Epoch 117/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5348 - mse: 0.5266 - val_loss: 0.4797 - val_mse: 0.4714\n",
      "Epoch 118/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5320 - mse: 0.5238 - val_loss: 0.4810 - val_mse: 0.4727\n",
      "Epoch 119/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5331 - mse: 0.5249 - val_loss: 0.4832 - val_mse: 0.4750\n",
      "Epoch 120/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5412 - mse: 0.5329\n",
      "Epoch 00120: saving model to Regression_Model/thle2.mse.linear-0120.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5414 - mse: 0.5331 - val_loss: 0.5058 - val_mse: 0.4976\n",
      "Epoch 121/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5446 - mse: 0.5364 - val_loss: 0.4944 - val_mse: 0.4861\n",
      "Epoch 122/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5291 - mse: 0.5209 - val_loss: 0.4790 - val_mse: 0.4708\n",
      "Epoch 123/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5385 - mse: 0.5303 - val_loss: 0.4977 - val_mse: 0.4895\n",
      "Epoch 124/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5408 - mse: 0.5325 - val_loss: 0.4881 - val_mse: 0.4799\n",
      "Epoch 125/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5384 - mse: 0.5301 - val_loss: 0.4862 - val_mse: 0.4780\n",
      "Epoch 126/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5440 - mse: 0.5358 - val_loss: 0.4840 - val_mse: 0.4758\n",
      "Epoch 127/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5375 - mse: 0.5293 - val_loss: 0.5154 - val_mse: 0.5072\n",
      "Epoch 128/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5371 - mse: 0.5289 - val_loss: 0.4784 - val_mse: 0.4702\n",
      "Epoch 129/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5326 - mse: 0.5244 - val_loss: 0.4833 - val_mse: 0.4751\n",
      "Epoch 130/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5337 - mse: 0.5254\n",
      "Epoch 00130: saving model to Regression_Model/thle2.mse.linear-0130.ckpt\n",
      "273/273 [==============================] - 6s 21ms/step - loss: 0.5340 - mse: 0.5258 - val_loss: 0.4827 - val_mse: 0.4744\n",
      "Epoch 131/1000\n",
      "273/273 [==============================] - 2s 5ms/step - loss: 0.5391 - mse: 0.5309 - val_loss: 0.4877 - val_mse: 0.4795\n",
      "Epoch 132/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5377 - mse: 0.5295 - val_loss: 0.4890 - val_mse: 0.4808\n",
      "Epoch 133/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5434 - mse: 0.5352 - val_loss: 0.4913 - val_mse: 0.4831\n",
      "Epoch 134/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5410 - mse: 0.5328 - val_loss: 0.4880 - val_mse: 0.4797\n",
      "Epoch 135/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5402 - mse: 0.5320 - val_loss: 0.4992 - val_mse: 0.4909\n",
      "Epoch 136/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5345 - mse: 0.5263 - val_loss: 0.4801 - val_mse: 0.4718\n",
      "Epoch 137/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5476 - mse: 0.5394 - val_loss: 0.5250 - val_mse: 0.5167\n",
      "Epoch 138/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5360 - mse: 0.5277 - val_loss: 0.4751 - val_mse: 0.4669\n",
      "Epoch 139/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5312 - mse: 0.5230 - val_loss: 0.4832 - val_mse: 0.4750\n",
      "Epoch 140/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5395 - mse: 0.5313\n",
      "Epoch 00140: saving model to Regression_Model/thle2.mse.linear-0140.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5378 - mse: 0.5295 - val_loss: 0.5181 - val_mse: 0.5099\n",
      "Epoch 141/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5387 - mse: 0.5304 - val_loss: 0.4775 - val_mse: 0.4693\n",
      "Epoch 142/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5444 - mse: 0.5361 - val_loss: 0.4834 - val_mse: 0.4752\n",
      "Epoch 143/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5311 - mse: 0.5229 - val_loss: 0.4806 - val_mse: 0.4724\n",
      "Epoch 144/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5478 - mse: 0.5395 - val_loss: 0.4961 - val_mse: 0.4879\n",
      "Epoch 145/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5436 - mse: 0.5354 - val_loss: 0.4869 - val_mse: 0.4786\n",
      "Epoch 146/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5446 - mse: 0.5364 - val_loss: 0.4827 - val_mse: 0.4744\n",
      "Epoch 147/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5427 - mse: 0.5345 - val_loss: 0.4944 - val_mse: 0.4861\n",
      "Epoch 148/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5357 - mse: 0.5274 - val_loss: 0.4838 - val_mse: 0.4756\n",
      "Epoch 149/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5286 - mse: 0.5204 - val_loss: 0.4810 - val_mse: 0.4728\n",
      "Epoch 150/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5329 - mse: 0.5246\n",
      "Epoch 00150: saving model to Regression_Model/thle2.mse.linear-0150.ckpt\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.5327 - mse: 0.5245 - val_loss: 0.5006 - val_mse: 0.4924\n",
      "Epoch 151/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5315 - mse: 0.5232 - val_loss: 0.4871 - val_mse: 0.4789\n",
      "Epoch 152/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5404 - mse: 0.5322 - val_loss: 0.4847 - val_mse: 0.4765\n",
      "Epoch 153/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5323 - mse: 0.5241 - val_loss: 0.4884 - val_mse: 0.4802\n",
      "Epoch 154/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5288 - mse: 0.5206 - val_loss: 0.4852 - val_mse: 0.4770\n",
      "Epoch 155/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5336 - mse: 0.5253 - val_loss: 0.4817 - val_mse: 0.4735\n",
      "Epoch 156/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5348 - mse: 0.5265 - val_loss: 0.4764 - val_mse: 0.4682\n",
      "Epoch 157/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5319 - mse: 0.5237 - val_loss: 0.4847 - val_mse: 0.4765\n",
      "Epoch 158/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5268 - mse: 0.5186 - val_loss: 0.4724 - val_mse: 0.4642\n",
      "Epoch 159/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5295 - mse: 0.5212 - val_loss: 0.4963 - val_mse: 0.4881\n",
      "Epoch 160/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5276 - mse: 0.5194\n",
      "Epoch 00160: saving model to Regression_Model/thle2.mse.linear-0160.ckpt\n",
      "273/273 [==============================] - 4s 16ms/step - loss: 0.5249 - mse: 0.5167 - val_loss: 0.4808 - val_mse: 0.4726\n",
      "Epoch 161/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5354 - mse: 0.5272 - val_loss: 0.4877 - val_mse: 0.4794\n",
      "Epoch 162/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5395 - mse: 0.5313 - val_loss: 0.5103 - val_mse: 0.5021\n",
      "Epoch 163/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5287 - mse: 0.5205 - val_loss: 0.4851 - val_mse: 0.4769\n",
      "Epoch 164/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5307 - mse: 0.5225 - val_loss: 0.4828 - val_mse: 0.4746\n",
      "Epoch 165/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5412 - mse: 0.5330 - val_loss: 0.4785 - val_mse: 0.4703\n",
      "Epoch 166/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5423 - mse: 0.5341 - val_loss: 0.4825 - val_mse: 0.4743\n",
      "Epoch 167/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5241 - mse: 0.5159 - val_loss: 0.4763 - val_mse: 0.4681\n",
      "Epoch 168/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5289 - mse: 0.5207 - val_loss: 0.4858 - val_mse: 0.4776\n",
      "Epoch 169/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5346 - mse: 0.5264 - val_loss: 0.4901 - val_mse: 0.4819\n",
      "Epoch 170/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5351 - mse: 0.5269\n",
      "Epoch 00170: saving model to Regression_Model/thle2.mse.linear-0170.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5353 - mse: 0.5271 - val_loss: 0.4858 - val_mse: 0.4776\n",
      "Epoch 171/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5284 - mse: 0.5202 - val_loss: 0.4845 - val_mse: 0.4763\n",
      "Epoch 172/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5247 - mse: 0.5165 - val_loss: 0.4863 - val_mse: 0.4781\n",
      "Epoch 173/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5343 - mse: 0.5261 - val_loss: 0.4811 - val_mse: 0.4729\n",
      "Epoch 174/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5367 - mse: 0.5285 - val_loss: 0.4872 - val_mse: 0.4790\n",
      "Epoch 175/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5280 - mse: 0.5198 - val_loss: 0.4893 - val_mse: 0.4812\n",
      "Epoch 176/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5264 - mse: 0.5182 - val_loss: 0.4896 - val_mse: 0.4814\n",
      "Epoch 177/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5256 - mse: 0.5174 - val_loss: 0.4749 - val_mse: 0.4667\n",
      "Epoch 178/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5369 - mse: 0.5287 - val_loss: 0.4849 - val_mse: 0.4767\n",
      "Epoch 179/1000\n",
      "273/273 [==============================] - 2s 5ms/step - loss: 0.5404 - mse: 0.5323 - val_loss: 0.4757 - val_mse: 0.4675\n",
      "Epoch 180/1000\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.5265 - mse: 0.5184\n",
      "Epoch 00180: saving model to Regression_Model/thle2.mse.linear-0180.ckpt\n",
      "273/273 [==============================] - 5s 18ms/step - loss: 0.5253 - mse: 0.5172 - val_loss: 0.4844 - val_mse: 0.4762\n",
      "Epoch 181/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5308 - mse: 0.5227 - val_loss: 0.4930 - val_mse: 0.4848\n",
      "Epoch 182/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5310 - mse: 0.5228 - val_loss: 0.4815 - val_mse: 0.4734\n",
      "Epoch 183/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5242 - mse: 0.5161 - val_loss: 0.4832 - val_mse: 0.4751\n",
      "Epoch 184/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5399 - mse: 0.5317 - val_loss: 0.4870 - val_mse: 0.4789\n",
      "Epoch 185/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5300 - mse: 0.5219 - val_loss: 0.4749 - val_mse: 0.4668\n",
      "Epoch 186/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5387 - mse: 0.5305 - val_loss: 0.4722 - val_mse: 0.4640\n",
      "Epoch 187/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5247 - mse: 0.5165 - val_loss: 0.4825 - val_mse: 0.4744\n",
      "Epoch 188/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5332 - mse: 0.5251 - val_loss: 0.4869 - val_mse: 0.4788\n",
      "Epoch 189/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5265 - mse: 0.5184 - val_loss: 0.4781 - val_mse: 0.4700\n",
      "Epoch 190/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5284 - mse: 0.5203\n",
      "Epoch 00190: saving model to Regression_Model/thle2.mse.linear-0190.ckpt\n",
      "273/273 [==============================] - 9s 34ms/step - loss: 0.5256 - mse: 0.5175 - val_loss: 0.4812 - val_mse: 0.4731\n",
      "Epoch 191/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5231 - mse: 0.5150 - val_loss: 0.4726 - val_mse: 0.4644\n",
      "Epoch 192/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5309 - mse: 0.5227 - val_loss: 0.4784 - val_mse: 0.4703\n",
      "Epoch 193/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5342 - mse: 0.5260 - val_loss: 0.4839 - val_mse: 0.4758\n",
      "Epoch 194/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5235 - mse: 0.5154 - val_loss: 0.4955 - val_mse: 0.4873\n",
      "Epoch 195/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5340 - mse: 0.5259 - val_loss: 0.4849 - val_mse: 0.4768\n",
      "Epoch 196/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5254 - mse: 0.5172 - val_loss: 0.4705 - val_mse: 0.4624\n",
      "Epoch 197/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5370 - mse: 0.5288 - val_loss: 0.4846 - val_mse: 0.4764\n",
      "Epoch 198/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5235 - mse: 0.5154 - val_loss: 0.4757 - val_mse: 0.4676\n",
      "Epoch 199/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5273 - mse: 0.5191 - val_loss: 0.4781 - val_mse: 0.4699\n",
      "Epoch 200/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5388 - mse: 0.5307\n",
      "Epoch 00200: saving model to Regression_Model/thle2.mse.linear-0200.ckpt\n",
      "273/273 [==============================] - 4s 16ms/step - loss: 0.5378 - mse: 0.5297 - val_loss: 0.4810 - val_mse: 0.4729\n",
      "Epoch 201/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5301 - mse: 0.5220 - val_loss: 0.4782 - val_mse: 0.4701\n",
      "Epoch 202/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5262 - mse: 0.5181 - val_loss: 0.4796 - val_mse: 0.4714\n",
      "Epoch 203/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5337 - mse: 0.5256 - val_loss: 0.4925 - val_mse: 0.4843\n",
      "Epoch 204/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5254 - mse: 0.5172 - val_loss: 0.4773 - val_mse: 0.4691\n",
      "Epoch 205/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5290 - mse: 0.5209 - val_loss: 0.4751 - val_mse: 0.4670\n",
      "Epoch 206/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5378 - mse: 0.5297 - val_loss: 0.4782 - val_mse: 0.4700\n",
      "Epoch 207/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5334 - mse: 0.5253 - val_loss: 0.4762 - val_mse: 0.4681\n",
      "Epoch 208/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5341 - mse: 0.5259 - val_loss: 0.4908 - val_mse: 0.4826\n",
      "Epoch 209/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5248 - mse: 0.5167 - val_loss: 0.4863 - val_mse: 0.4782\n",
      "Epoch 210/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5292 - mse: 0.5211\n",
      "Epoch 00210: saving model to Regression_Model/thle2.mse.linear-0210.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5304 - mse: 0.5223 - val_loss: 0.4763 - val_mse: 0.4682\n",
      "Epoch 211/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5307 - mse: 0.5226 - val_loss: 0.4805 - val_mse: 0.4724\n",
      "Epoch 212/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5211 - mse: 0.5130 - val_loss: 0.4775 - val_mse: 0.4694\n",
      "Epoch 213/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5245 - mse: 0.5164 - val_loss: 0.4787 - val_mse: 0.4706\n",
      "Epoch 214/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5258 - mse: 0.5177 - val_loss: 0.4782 - val_mse: 0.4701\n",
      "Epoch 215/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5339 - mse: 0.5259 - val_loss: 0.4753 - val_mse: 0.4672\n",
      "Epoch 216/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5314 - mse: 0.5234 - val_loss: 0.4809 - val_mse: 0.4729\n",
      "Epoch 217/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5322 - mse: 0.5241 - val_loss: 0.4737 - val_mse: 0.4656\n",
      "Epoch 218/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5333 - mse: 0.5252 - val_loss: 0.4726 - val_mse: 0.4645\n",
      "Epoch 219/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5340 - mse: 0.5259 - val_loss: 0.4750 - val_mse: 0.4669\n",
      "Epoch 220/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.5346 - mse: 0.5265\n",
      "Epoch 00220: saving model to Regression_Model/thle2.mse.linear-0220.ckpt\n",
      "273/273 [==============================] - 5s 17ms/step - loss: 0.5341 - mse: 0.5260 - val_loss: 0.5009 - val_mse: 0.4928\n",
      "Epoch 221/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5302 - mse: 0.5222 - val_loss: 0.4869 - val_mse: 0.4789\n",
      "Epoch 222/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5282 - mse: 0.5201 - val_loss: 0.4882 - val_mse: 0.4801\n",
      "Epoch 223/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5276 - mse: 0.5195 - val_loss: 0.4814 - val_mse: 0.4733\n",
      "Epoch 224/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5331 - mse: 0.5251 - val_loss: 0.4782 - val_mse: 0.4701\n",
      "Epoch 225/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5199 - mse: 0.5118 - val_loss: 0.4718 - val_mse: 0.4638\n",
      "Epoch 226/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5290 - mse: 0.5210 - val_loss: 0.4843 - val_mse: 0.4762\n",
      "Epoch 227/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5314 - mse: 0.5233 - val_loss: 0.4781 - val_mse: 0.4700\n",
      "Epoch 228/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5353 - mse: 0.5272 - val_loss: 0.4760 - val_mse: 0.4680\n",
      "Epoch 229/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5292 - mse: 0.5212 - val_loss: 0.4849 - val_mse: 0.4768\n",
      "Epoch 230/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5259 - mse: 0.5178\n",
      "Epoch 00230: saving model to Regression_Model/thle2.mse.linear-0230.ckpt\n",
      "273/273 [==============================] - 7s 26ms/step - loss: 0.5260 - mse: 0.5180 - val_loss: 0.4822 - val_mse: 0.4741\n",
      "Epoch 231/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5319 - mse: 0.5238 - val_loss: 0.4893 - val_mse: 0.4813\n",
      "Epoch 232/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5342 - mse: 0.5261 - val_loss: 0.5086 - val_mse: 0.5005\n",
      "Epoch 233/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5278 - mse: 0.5197 - val_loss: 0.4898 - val_mse: 0.4818\n",
      "Epoch 234/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5297 - mse: 0.5216 - val_loss: 0.4810 - val_mse: 0.4730\n",
      "Epoch 235/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5289 - mse: 0.5209 - val_loss: 0.4840 - val_mse: 0.4759\n",
      "Epoch 236/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5251 - mse: 0.5170 - val_loss: 0.4739 - val_mse: 0.4659\n",
      "Epoch 237/1000\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5249 - mse: 0.5168 - val_loss: 0.4764 - val_mse: 0.4684\n",
      "Epoch 238/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5282 - mse: 0.5202 - val_loss: 0.4761 - val_mse: 0.4680\n",
      "Epoch 239/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5243 - mse: 0.5163 - val_loss: 0.4777 - val_mse: 0.4696\n",
      "Epoch 240/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5303 - mse: 0.5223\n",
      "Epoch 00240: saving model to Regression_Model/thle2.mse.linear-0240.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5296 - mse: 0.5216 - val_loss: 0.4770 - val_mse: 0.4690\n",
      "Epoch 241/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5276 - mse: 0.5196 - val_loss: 0.4794 - val_mse: 0.4714\n",
      "Epoch 242/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5263 - mse: 0.5182 - val_loss: 0.4772 - val_mse: 0.4692\n",
      "Epoch 243/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5317 - mse: 0.5236 - val_loss: 0.4754 - val_mse: 0.4674\n",
      "Epoch 244/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5387 - mse: 0.5307 - val_loss: 0.4879 - val_mse: 0.4799\n",
      "Epoch 245/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5287 - mse: 0.5206 - val_loss: 0.4805 - val_mse: 0.4725\n",
      "Epoch 246/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5358 - mse: 0.5278 - val_loss: 0.4855 - val_mse: 0.4775\n",
      "Epoch 247/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5206 - mse: 0.5126 - val_loss: 0.4823 - val_mse: 0.4742\n",
      "Epoch 248/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5342 - mse: 0.5262 - val_loss: 0.4804 - val_mse: 0.4724\n",
      "Epoch 249/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5211 - mse: 0.5131 - val_loss: 0.4756 - val_mse: 0.4675\n",
      "Epoch 250/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5199 - mse: 0.5118\n",
      "Epoch 00250: saving model to Regression_Model/thle2.mse.linear-0250.ckpt\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5184 - mse: 0.5104 - val_loss: 0.4765 - val_mse: 0.4685\n",
      "Epoch 251/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5229 - mse: 0.5149 - val_loss: 0.4817 - val_mse: 0.4736\n",
      "Epoch 252/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5283 - mse: 0.5203 - val_loss: 0.4777 - val_mse: 0.4697\n",
      "Epoch 253/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5240 - mse: 0.5159 - val_loss: 0.4749 - val_mse: 0.4669\n",
      "Epoch 254/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5207 - mse: 0.5127 - val_loss: 0.4794 - val_mse: 0.4714\n",
      "Epoch 255/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5231 - mse: 0.5151 - val_loss: 0.4739 - val_mse: 0.4659\n",
      "Epoch 256/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5266 - mse: 0.5186 - val_loss: 0.4949 - val_mse: 0.4869\n",
      "Epoch 257/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5261 - mse: 0.5181 - val_loss: 0.4753 - val_mse: 0.4673\n",
      "Epoch 258/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5293 - mse: 0.5213 - val_loss: 0.4804 - val_mse: 0.4724\n",
      "Epoch 259/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5289 - mse: 0.5209 - val_loss: 0.4731 - val_mse: 0.4651\n",
      "Epoch 260/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5203 - mse: 0.5123\n",
      "Epoch 00260: saving model to Regression_Model/thle2.mse.linear-0260.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.5205 - mse: 0.5125 - val_loss: 0.4749 - val_mse: 0.4669\n",
      "Epoch 261/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5152 - mse: 0.5072 - val_loss: 0.4757 - val_mse: 0.4677\n",
      "Epoch 262/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5213 - mse: 0.5133 - val_loss: 0.4759 - val_mse: 0.4679\n",
      "Epoch 263/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5214 - mse: 0.5134 - val_loss: 0.4826 - val_mse: 0.4747\n",
      "Epoch 264/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5196 - mse: 0.5116 - val_loss: 0.4754 - val_mse: 0.4674\n",
      "Epoch 265/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5216 - mse: 0.5136 - val_loss: 0.4762 - val_mse: 0.4682\n",
      "Epoch 266/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5274 - mse: 0.5194 - val_loss: 0.4783 - val_mse: 0.4703\n",
      "Epoch 267/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5283 - mse: 0.5204 - val_loss: 0.4716 - val_mse: 0.4636\n",
      "Epoch 268/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5206 - mse: 0.5126 - val_loss: 0.4783 - val_mse: 0.4703\n",
      "Epoch 269/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5209 - mse: 0.5129 - val_loss: 0.4854 - val_mse: 0.4774\n",
      "Epoch 270/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5271 - mse: 0.5191\n",
      "Epoch 00270: saving model to Regression_Model/thle2.mse.linear-0270.ckpt\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.5269 - mse: 0.5189 - val_loss: 0.4752 - val_mse: 0.4672\n",
      "Epoch 271/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5207 - mse: 0.5127 - val_loss: 0.4751 - val_mse: 0.4671\n",
      "Epoch 272/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5197 - mse: 0.5118 - val_loss: 0.4743 - val_mse: 0.4663\n",
      "Epoch 273/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5296 - mse: 0.5216 - val_loss: 0.4763 - val_mse: 0.4683\n",
      "Epoch 274/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5212 - mse: 0.5132 - val_loss: 0.4705 - val_mse: 0.4626\n",
      "Epoch 275/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5269 - mse: 0.5189 - val_loss: 0.4823 - val_mse: 0.4744\n",
      "Epoch 276/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5244 - mse: 0.5164 - val_loss: 0.4825 - val_mse: 0.4746\n",
      "Epoch 277/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5178 - mse: 0.5098 - val_loss: 0.4766 - val_mse: 0.4686\n",
      "Epoch 278/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5214 - mse: 0.5134 - val_loss: 0.4855 - val_mse: 0.4775\n",
      "Epoch 279/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5233 - mse: 0.5153 - val_loss: 0.4783 - val_mse: 0.4703\n",
      "Epoch 280/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5164 - mse: 0.5084\n",
      "Epoch 00280: saving model to Regression_Model/thle2.mse.linear-0280.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5189 - mse: 0.5109 - val_loss: 0.4717 - val_mse: 0.4638\n",
      "Epoch 281/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5234 - mse: 0.5155 - val_loss: 0.4758 - val_mse: 0.4678\n",
      "Epoch 282/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5183 - mse: 0.5104 - val_loss: 0.4730 - val_mse: 0.4651\n",
      "Epoch 283/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5248 - mse: 0.5169 - val_loss: 0.4832 - val_mse: 0.4752\n",
      "Epoch 284/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5242 - mse: 0.5163 - val_loss: 0.4715 - val_mse: 0.4636\n",
      "Epoch 285/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5303 - mse: 0.5224 - val_loss: 0.4794 - val_mse: 0.4714\n",
      "Epoch 286/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5173 - mse: 0.5094 - val_loss: 0.4766 - val_mse: 0.4686\n",
      "Epoch 287/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5202 - mse: 0.5123 - val_loss: 0.4756 - val_mse: 0.4677\n",
      "Epoch 288/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5254 - mse: 0.5175 - val_loss: 0.4707 - val_mse: 0.4627\n",
      "Epoch 289/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5190 - mse: 0.5111 - val_loss: 0.4730 - val_mse: 0.4651\n",
      "Epoch 290/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5162 - mse: 0.5083\n",
      "Epoch 00290: saving model to Regression_Model/thle2.mse.linear-0290.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5162 - mse: 0.5083 - val_loss: 0.4770 - val_mse: 0.4691\n",
      "Epoch 291/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5227 - mse: 0.5148 - val_loss: 0.4858 - val_mse: 0.4778\n",
      "Epoch 292/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5330 - mse: 0.5251 - val_loss: 0.4793 - val_mse: 0.4714\n",
      "Epoch 293/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5246 - mse: 0.5167 - val_loss: 0.4801 - val_mse: 0.4721\n",
      "Epoch 294/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5289 - mse: 0.5210 - val_loss: 0.4743 - val_mse: 0.4664\n",
      "Epoch 295/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5229 - mse: 0.5150 - val_loss: 0.4849 - val_mse: 0.4770\n",
      "Epoch 296/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5232 - mse: 0.5153 - val_loss: 0.4877 - val_mse: 0.4798\n",
      "Epoch 297/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5240 - mse: 0.5161 - val_loss: 0.4708 - val_mse: 0.4629\n",
      "Epoch 298/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5307 - mse: 0.5228 - val_loss: 0.4756 - val_mse: 0.4677\n",
      "Epoch 299/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5228 - mse: 0.5148 - val_loss: 0.4920 - val_mse: 0.4841\n",
      "Epoch 300/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5238 - mse: 0.5159\n",
      "Epoch 00300: saving model to Regression_Model/thle2.mse.linear-0300.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5197 - mse: 0.5118 - val_loss: 0.4702 - val_mse: 0.4623\n",
      "Epoch 301/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5192 - mse: 0.5113 - val_loss: 0.4687 - val_mse: 0.4608\n",
      "Epoch 302/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5230 - mse: 0.5150 - val_loss: 0.4814 - val_mse: 0.4735\n",
      "Epoch 303/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5303 - mse: 0.5224 - val_loss: 0.4796 - val_mse: 0.4717\n",
      "Epoch 304/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5236 - mse: 0.5157 - val_loss: 0.4776 - val_mse: 0.4697\n",
      "Epoch 305/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5240 - mse: 0.5161 - val_loss: 0.4813 - val_mse: 0.4734\n",
      "Epoch 306/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5264 - mse: 0.5185 - val_loss: 0.4723 - val_mse: 0.4644\n",
      "Epoch 307/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5205 - mse: 0.5126 - val_loss: 0.4818 - val_mse: 0.4739\n",
      "Epoch 308/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5237 - mse: 0.5158 - val_loss: 0.4828 - val_mse: 0.4749\n",
      "Epoch 309/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5107 - mse: 0.5028 - val_loss: 0.4762 - val_mse: 0.4683\n",
      "Epoch 310/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5246 - mse: 0.5167\n",
      "Epoch 00310: saving model to Regression_Model/thle2.mse.linear-0310.ckpt\n",
      "273/273 [==============================] - 5s 20ms/step - loss: 0.5250 - mse: 0.5172 - val_loss: 0.4782 - val_mse: 0.4704\n",
      "Epoch 311/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5175 - mse: 0.5096 - val_loss: 0.4759 - val_mse: 0.4681\n",
      "Epoch 312/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5182 - mse: 0.5104 - val_loss: 0.4740 - val_mse: 0.4661\n",
      "Epoch 313/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5183 - mse: 0.5104 - val_loss: 0.4737 - val_mse: 0.4658\n",
      "Epoch 314/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5241 - mse: 0.5162 - val_loss: 0.4816 - val_mse: 0.4737\n",
      "Epoch 315/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5216 - mse: 0.5137 - val_loss: 0.4716 - val_mse: 0.4637\n",
      "Epoch 316/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5134 - mse: 0.5056 - val_loss: 0.4689 - val_mse: 0.4610\n",
      "Epoch 317/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5231 - mse: 0.5152 - val_loss: 0.4722 - val_mse: 0.4643\n",
      "Epoch 318/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5181 - mse: 0.5103 - val_loss: 0.4791 - val_mse: 0.4712\n",
      "Epoch 319/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5164 - mse: 0.5085 - val_loss: 0.4759 - val_mse: 0.4680\n",
      "Epoch 320/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5110 - mse: 0.5032\n",
      "Epoch 00320: saving model to Regression_Model/thle2.mse.linear-0320.ckpt\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5161 - mse: 0.5083 - val_loss: 0.4704 - val_mse: 0.4626\n",
      "Epoch 321/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5240 - mse: 0.5162 - val_loss: 0.4699 - val_mse: 0.4621\n",
      "Epoch 322/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5133 - mse: 0.5054 - val_loss: 0.4857 - val_mse: 0.4778\n",
      "Epoch 323/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5168 - mse: 0.5089 - val_loss: 0.4774 - val_mse: 0.4695\n",
      "Epoch 324/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5213 - mse: 0.5135 - val_loss: 0.4751 - val_mse: 0.4672\n",
      "Epoch 325/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5230 - mse: 0.5152 - val_loss: 0.4757 - val_mse: 0.4679\n",
      "Epoch 326/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5198 - mse: 0.5119 - val_loss: 0.4700 - val_mse: 0.4622\n",
      "Epoch 327/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5245 - mse: 0.5167 - val_loss: 0.4785 - val_mse: 0.4706\n",
      "Epoch 328/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5160 - mse: 0.5082 - val_loss: 0.4690 - val_mse: 0.4611\n",
      "Epoch 329/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5173 - mse: 0.5095 - val_loss: 0.4798 - val_mse: 0.4719\n",
      "Epoch 330/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5173 - mse: 0.5095\n",
      "Epoch 00330: saving model to Regression_Model/thle2.mse.linear-0330.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5161 - mse: 0.5083 - val_loss: 0.4711 - val_mse: 0.4632\n",
      "Epoch 331/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5160 - mse: 0.5082 - val_loss: 0.4727 - val_mse: 0.4649\n",
      "Epoch 332/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5194 - mse: 0.5116 - val_loss: 0.4762 - val_mse: 0.4683\n",
      "Epoch 333/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5256 - mse: 0.5178 - val_loss: 0.4700 - val_mse: 0.4622\n",
      "Epoch 334/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5204 - mse: 0.5126 - val_loss: 0.4755 - val_mse: 0.4677\n",
      "Epoch 335/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5217 - mse: 0.5139 - val_loss: 0.4789 - val_mse: 0.4711\n",
      "Epoch 336/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5180 - mse: 0.5101 - val_loss: 0.4726 - val_mse: 0.4648\n",
      "Epoch 337/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5164 - mse: 0.5086 - val_loss: 0.4721 - val_mse: 0.4643\n",
      "Epoch 338/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5203 - mse: 0.5125 - val_loss: 0.4731 - val_mse: 0.4653\n",
      "Epoch 339/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5156 - mse: 0.5078 - val_loss: 0.4699 - val_mse: 0.4621\n",
      "Epoch 340/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5117 - mse: 0.5039\n",
      "Epoch 00340: saving model to Regression_Model/thle2.mse.linear-0340.ckpt\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5084 - mse: 0.5006 - val_loss: 0.4727 - val_mse: 0.4649\n",
      "Epoch 341/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5156 - mse: 0.5078 - val_loss: 0.4867 - val_mse: 0.4789\n",
      "Epoch 342/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5176 - mse: 0.5098 - val_loss: 0.4740 - val_mse: 0.4662\n",
      "Epoch 343/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5162 - mse: 0.5084 - val_loss: 0.4666 - val_mse: 0.4588\n",
      "Epoch 344/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5185 - mse: 0.5107 - val_loss: 0.4729 - val_mse: 0.4651\n",
      "Epoch 345/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5144 - mse: 0.5066 - val_loss: 0.4713 - val_mse: 0.4635\n",
      "Epoch 346/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5208 - mse: 0.5130 - val_loss: 0.4857 - val_mse: 0.4779\n",
      "Epoch 347/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5193 - mse: 0.5115 - val_loss: 0.4737 - val_mse: 0.4659\n",
      "Epoch 348/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5201 - mse: 0.5123 - val_loss: 0.4747 - val_mse: 0.4669\n",
      "Epoch 349/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5238 - mse: 0.5160 - val_loss: 0.4791 - val_mse: 0.4713\n",
      "Epoch 350/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5129 - mse: 0.5051\n",
      "Epoch 00350: saving model to Regression_Model/thle2.mse.linear-0350.ckpt\n",
      "273/273 [==============================] - 6s 20ms/step - loss: 0.5127 - mse: 0.5049 - val_loss: 0.4740 - val_mse: 0.4662\n",
      "Epoch 351/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5235 - mse: 0.5157 - val_loss: 0.4738 - val_mse: 0.4660\n",
      "Epoch 352/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5263 - mse: 0.5186 - val_loss: 0.4770 - val_mse: 0.4692\n",
      "Epoch 353/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5286 - mse: 0.5208 - val_loss: 0.4810 - val_mse: 0.4732\n",
      "Epoch 354/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5191 - mse: 0.5113 - val_loss: 0.4704 - val_mse: 0.4626\n",
      "Epoch 355/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5192 - mse: 0.5114 - val_loss: 0.4723 - val_mse: 0.4646\n",
      "Epoch 356/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5191 - mse: 0.5113 - val_loss: 0.4825 - val_mse: 0.4748\n",
      "Epoch 357/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5170 - mse: 0.5092 - val_loss: 0.4714 - val_mse: 0.4636\n",
      "Epoch 358/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5187 - mse: 0.5110 - val_loss: 0.4779 - val_mse: 0.4702\n",
      "Epoch 359/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5128 - mse: 0.5050 - val_loss: 0.4703 - val_mse: 0.4625\n",
      "Epoch 360/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5148 - mse: 0.5071\n",
      "Epoch 00360: saving model to Regression_Model/thle2.mse.linear-0360.ckpt\n",
      "273/273 [==============================] - 7s 26ms/step - loss: 0.5147 - mse: 0.5069 - val_loss: 0.4776 - val_mse: 0.4698\n",
      "Epoch 361/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5263 - mse: 0.5186 - val_loss: 0.4750 - val_mse: 0.4672\n",
      "Epoch 362/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5255 - mse: 0.5177 - val_loss: 0.4697 - val_mse: 0.4619\n",
      "Epoch 363/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5104 - mse: 0.5026 - val_loss: 0.4699 - val_mse: 0.4622\n",
      "Epoch 364/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5230 - mse: 0.5152 - val_loss: 0.4754 - val_mse: 0.4676\n",
      "Epoch 365/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5100 - mse: 0.5022 - val_loss: 0.4667 - val_mse: 0.4590\n",
      "Epoch 366/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5149 - mse: 0.5071 - val_loss: 0.4775 - val_mse: 0.4697\n",
      "Epoch 367/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5171 - mse: 0.5094 - val_loss: 0.4726 - val_mse: 0.4649\n",
      "Epoch 368/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5174 - mse: 0.5097 - val_loss: 0.4709 - val_mse: 0.4632\n",
      "Epoch 369/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5157 - mse: 0.5080 - val_loss: 0.4760 - val_mse: 0.4683\n",
      "Epoch 370/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5208 - mse: 0.5131\n",
      "Epoch 00370: saving model to Regression_Model/thle2.mse.linear-0370.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5210 - mse: 0.5133 - val_loss: 0.4679 - val_mse: 0.4601\n",
      "Epoch 371/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5185 - mse: 0.5108 - val_loss: 0.4676 - val_mse: 0.4599\n",
      "Epoch 372/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5201 - mse: 0.5124 - val_loss: 0.4776 - val_mse: 0.4699\n",
      "Epoch 373/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5192 - mse: 0.5115 - val_loss: 0.4690 - val_mse: 0.4613\n",
      "Epoch 374/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5142 - mse: 0.5065 - val_loss: 0.4657 - val_mse: 0.4580\n",
      "Epoch 375/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5162 - mse: 0.5085 - val_loss: 0.4694 - val_mse: 0.4617\n",
      "Epoch 376/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5085 - mse: 0.5008 - val_loss: 0.4725 - val_mse: 0.4648\n",
      "Epoch 377/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5228 - mse: 0.5151 - val_loss: 0.4722 - val_mse: 0.4645\n",
      "Epoch 378/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5145 - mse: 0.5068 - val_loss: 0.4729 - val_mse: 0.4651\n",
      "Epoch 379/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5167 - mse: 0.5090 - val_loss: 0.4722 - val_mse: 0.4644\n",
      "Epoch 380/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5162 - mse: 0.5085\n",
      "Epoch 00380: saving model to Regression_Model/thle2.mse.linear-0380.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.5154 - mse: 0.5077 - val_loss: 0.4687 - val_mse: 0.4609\n",
      "Epoch 381/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5140 - mse: 0.5063 - val_loss: 0.4725 - val_mse: 0.4648\n",
      "Epoch 382/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5147 - mse: 0.5070 - val_loss: 0.4911 - val_mse: 0.4833\n",
      "Epoch 383/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5186 - mse: 0.5109 - val_loss: 0.4717 - val_mse: 0.4640\n",
      "Epoch 384/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5232 - mse: 0.5155 - val_loss: 0.4795 - val_mse: 0.4717\n",
      "Epoch 385/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5205 - mse: 0.5128 - val_loss: 0.4756 - val_mse: 0.4679\n",
      "Epoch 386/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5170 - mse: 0.5093 - val_loss: 0.4665 - val_mse: 0.4588\n",
      "Epoch 387/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5139 - mse: 0.5062 - val_loss: 0.4735 - val_mse: 0.4658\n",
      "Epoch 388/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5230 - mse: 0.5153 - val_loss: 0.4770 - val_mse: 0.4693\n",
      "Epoch 389/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5127 - mse: 0.5050 - val_loss: 0.4660 - val_mse: 0.4583\n",
      "Epoch 390/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5119 - mse: 0.5042\n",
      "Epoch 00390: saving model to Regression_Model/thle2.mse.linear-0390.ckpt\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.5121 - mse: 0.5044 - val_loss: 0.4718 - val_mse: 0.4641\n",
      "Epoch 391/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5152 - mse: 0.5075 - val_loss: 0.4709 - val_mse: 0.4632\n",
      "Epoch 392/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5165 - mse: 0.5088 - val_loss: 0.4712 - val_mse: 0.4635\n",
      "Epoch 393/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5175 - mse: 0.5098 - val_loss: 0.4786 - val_mse: 0.4709\n",
      "Epoch 394/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5195 - mse: 0.5119 - val_loss: 0.4743 - val_mse: 0.4666\n",
      "Epoch 395/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5143 - mse: 0.5066 - val_loss: 0.4695 - val_mse: 0.4618\n",
      "Epoch 396/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5155 - mse: 0.5078 - val_loss: 0.4697 - val_mse: 0.4621\n",
      "Epoch 397/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5284 - mse: 0.5208 - val_loss: 0.4710 - val_mse: 0.4633\n",
      "Epoch 398/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5176 - mse: 0.5099 - val_loss: 0.4695 - val_mse: 0.4618\n",
      "Epoch 399/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5169 - mse: 0.5092 - val_loss: 0.4669 - val_mse: 0.4592\n",
      "Epoch 400/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5118 - mse: 0.5041\n",
      "Epoch 00400: saving model to Regression_Model/thle2.mse.linear-0400.ckpt\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.5119 - mse: 0.5042 - val_loss: 0.4735 - val_mse: 0.4658\n",
      "Epoch 401/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5201 - mse: 0.5124 - val_loss: 0.4791 - val_mse: 0.4714\n",
      "Epoch 402/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5176 - mse: 0.5100 - val_loss: 0.4668 - val_mse: 0.4591\n",
      "Epoch 403/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5176 - mse: 0.5099 - val_loss: 0.4729 - val_mse: 0.4652\n",
      "Epoch 404/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5162 - mse: 0.5085 - val_loss: 0.4698 - val_mse: 0.4621\n",
      "Epoch 405/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5180 - mse: 0.5104 - val_loss: 0.4769 - val_mse: 0.4692\n",
      "Epoch 406/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5256 - mse: 0.5179 - val_loss: 0.4778 - val_mse: 0.4701\n",
      "Epoch 407/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5248 - mse: 0.5172 - val_loss: 0.4862 - val_mse: 0.4785\n",
      "Epoch 408/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5171 - mse: 0.5094 - val_loss: 0.4756 - val_mse: 0.4679\n",
      "Epoch 409/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5084 - mse: 0.5007 - val_loss: 0.4713 - val_mse: 0.4636\n",
      "Epoch 410/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5170 - mse: 0.5094\n",
      "Epoch 00410: saving model to Regression_Model/thle2.mse.linear-0410.ckpt\n",
      "273/273 [==============================] - 5s 20ms/step - loss: 0.5189 - mse: 0.5112 - val_loss: 0.4786 - val_mse: 0.4710\n",
      "Epoch 411/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5150 - mse: 0.5073 - val_loss: 0.4674 - val_mse: 0.4597\n",
      "Epoch 412/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5173 - mse: 0.5096 - val_loss: 0.4746 - val_mse: 0.4669\n",
      "Epoch 413/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5184 - mse: 0.5107 - val_loss: 0.4675 - val_mse: 0.4598\n",
      "Epoch 414/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5219 - mse: 0.5143 - val_loss: 0.4722 - val_mse: 0.4646\n",
      "Epoch 415/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5179 - mse: 0.5103 - val_loss: 0.4698 - val_mse: 0.4622\n",
      "Epoch 416/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5111 - mse: 0.5035 - val_loss: 0.4776 - val_mse: 0.4699\n",
      "Epoch 417/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5173 - mse: 0.5097 - val_loss: 0.4711 - val_mse: 0.4635\n",
      "Epoch 418/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5058 - mse: 0.4982 - val_loss: 0.4683 - val_mse: 0.4607\n",
      "Epoch 419/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5132 - mse: 0.5056 - val_loss: 0.4806 - val_mse: 0.4730\n",
      "Epoch 420/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5137 - mse: 0.5061\n",
      "Epoch 00420: saving model to Regression_Model/thle2.mse.linear-0420.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5132 - mse: 0.5055 - val_loss: 0.4708 - val_mse: 0.4632\n",
      "Epoch 421/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5158 - mse: 0.5082 - val_loss: 0.4745 - val_mse: 0.4668\n",
      "Epoch 422/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5098 - mse: 0.5022 - val_loss: 0.4789 - val_mse: 0.4713\n",
      "Epoch 423/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5136 - mse: 0.5060 - val_loss: 0.4775 - val_mse: 0.4699\n",
      "Epoch 424/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5120 - mse: 0.5044 - val_loss: 0.4745 - val_mse: 0.4669\n",
      "Epoch 425/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5109 - mse: 0.5033 - val_loss: 0.4715 - val_mse: 0.4639\n",
      "Epoch 426/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5206 - mse: 0.5130 - val_loss: 0.4707 - val_mse: 0.4631\n",
      "Epoch 427/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5087 - mse: 0.5011 - val_loss: 0.4750 - val_mse: 0.4674\n",
      "Epoch 428/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5237 - mse: 0.5161 - val_loss: 0.4690 - val_mse: 0.4614\n",
      "Epoch 429/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5217 - mse: 0.5141 - val_loss: 0.4749 - val_mse: 0.4673\n",
      "Epoch 430/1000\n",
      "270/273 [============================>.] - ETA: 0s - loss: 0.5225 - mse: 0.5149\n",
      "Epoch 00430: saving model to Regression_Model/thle2.mse.linear-0430.ckpt\n",
      "273/273 [==============================] - 5s 18ms/step - loss: 0.5226 - mse: 0.5150 - val_loss: 0.4675 - val_mse: 0.4599\n",
      "Epoch 431/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5124 - mse: 0.5048 - val_loss: 0.4784 - val_mse: 0.4708\n",
      "Epoch 432/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5152 - mse: 0.5076 - val_loss: 0.4693 - val_mse: 0.4617\n",
      "Epoch 433/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5119 - mse: 0.5043 - val_loss: 0.4682 - val_mse: 0.4607\n",
      "Epoch 434/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5094 - mse: 0.5018 - val_loss: 0.4704 - val_mse: 0.4629\n",
      "Epoch 435/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5072 - mse: 0.4996 - val_loss: 0.4761 - val_mse: 0.4685\n",
      "Epoch 436/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5140 - mse: 0.5064 - val_loss: 0.4783 - val_mse: 0.4707\n",
      "Epoch 437/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5158 - mse: 0.5082 - val_loss: 0.4710 - val_mse: 0.4634\n",
      "Epoch 438/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5098 - mse: 0.5022 - val_loss: 0.4677 - val_mse: 0.4601\n",
      "Epoch 439/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5082 - mse: 0.5006 - val_loss: 0.4655 - val_mse: 0.4579\n",
      "Epoch 440/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5127 - mse: 0.5051\n",
      "Epoch 00440: saving model to Regression_Model/thle2.mse.linear-0440.ckpt\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.5128 - mse: 0.5052 - val_loss: 0.4730 - val_mse: 0.4654\n",
      "Epoch 441/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5210 - mse: 0.5135 - val_loss: 0.4724 - val_mse: 0.4648\n",
      "Epoch 442/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5094 - mse: 0.5019 - val_loss: 0.4690 - val_mse: 0.4614\n",
      "Epoch 443/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5077 - mse: 0.5002 - val_loss: 0.4868 - val_mse: 0.4792\n",
      "Epoch 444/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5154 - mse: 0.5079 - val_loss: 0.4696 - val_mse: 0.4620\n",
      "Epoch 445/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5201 - mse: 0.5125 - val_loss: 0.4744 - val_mse: 0.4668\n",
      "Epoch 446/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5113 - mse: 0.5037 - val_loss: 0.4675 - val_mse: 0.4599\n",
      "Epoch 447/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5140 - mse: 0.5064 - val_loss: 0.4647 - val_mse: 0.4571\n",
      "Epoch 448/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5172 - mse: 0.5097 - val_loss: 0.4724 - val_mse: 0.4649\n",
      "Epoch 449/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5092 - mse: 0.5016 - val_loss: 0.4695 - val_mse: 0.4619\n",
      "Epoch 450/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5117 - mse: 0.5042\n",
      "Epoch 00450: saving model to Regression_Model/thle2.mse.linear-0450.ckpt\n",
      "273/273 [==============================] - 3s 12ms/step - loss: 0.5109 - mse: 0.5034 - val_loss: 0.4724 - val_mse: 0.4649\n",
      "Epoch 451/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5128 - mse: 0.5053 - val_loss: 0.4774 - val_mse: 0.4699\n",
      "Epoch 452/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5083 - mse: 0.5007 - val_loss: 0.4735 - val_mse: 0.4659\n",
      "Epoch 453/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5139 - mse: 0.5063 - val_loss: 0.4698 - val_mse: 0.4622\n",
      "Epoch 454/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5114 - mse: 0.5038 - val_loss: 0.4773 - val_mse: 0.4697\n",
      "Epoch 455/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5113 - mse: 0.5038 - val_loss: 0.4730 - val_mse: 0.4654\n",
      "Epoch 456/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5114 - mse: 0.5039 - val_loss: 0.4708 - val_mse: 0.4633\n",
      "Epoch 457/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5076 - mse: 0.5001 - val_loss: 0.4749 - val_mse: 0.4674\n",
      "Epoch 458/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5119 - mse: 0.5044 - val_loss: 0.4723 - val_mse: 0.4648\n",
      "Epoch 459/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5188 - mse: 0.5112 - val_loss: 0.4771 - val_mse: 0.4695\n",
      "Epoch 460/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5119 - mse: 0.5044\n",
      "Epoch 00460: saving model to Regression_Model/thle2.mse.linear-0460.ckpt\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.5147 - mse: 0.5072 - val_loss: 0.4744 - val_mse: 0.4668\n",
      "Epoch 461/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5156 - mse: 0.5081 - val_loss: 0.4805 - val_mse: 0.4729\n",
      "Epoch 462/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5071 - mse: 0.4996 - val_loss: 0.4740 - val_mse: 0.4665\n",
      "Epoch 463/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5190 - mse: 0.5115 - val_loss: 0.4730 - val_mse: 0.4655\n",
      "Epoch 464/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5131 - mse: 0.5055 - val_loss: 0.4672 - val_mse: 0.4596\n",
      "Epoch 465/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5095 - mse: 0.5019 - val_loss: 0.4682 - val_mse: 0.4607\n",
      "Epoch 466/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5087 - mse: 0.5012 - val_loss: 0.4736 - val_mse: 0.4661\n",
      "Epoch 467/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5159 - mse: 0.5084 - val_loss: 0.4702 - val_mse: 0.4626\n",
      "Epoch 468/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5148 - mse: 0.5073 - val_loss: 0.4730 - val_mse: 0.4655\n",
      "Epoch 469/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5206 - mse: 0.5131 - val_loss: 0.4770 - val_mse: 0.4695\n",
      "Epoch 470/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5132 - mse: 0.5056\n",
      "Epoch 00470: saving model to Regression_Model/thle2.mse.linear-0470.ckpt\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.5130 - mse: 0.5054 - val_loss: 0.4686 - val_mse: 0.4611\n",
      "Epoch 471/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5155 - mse: 0.5079 - val_loss: 0.4721 - val_mse: 0.4646\n",
      "Epoch 472/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5165 - mse: 0.5090 - val_loss: 0.4700 - val_mse: 0.4625\n",
      "Epoch 473/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5144 - mse: 0.5068 - val_loss: 0.4787 - val_mse: 0.4712\n",
      "Epoch 474/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5200 - mse: 0.5125 - val_loss: 0.4713 - val_mse: 0.4638\n",
      "Epoch 475/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5143 - mse: 0.5068 - val_loss: 0.4726 - val_mse: 0.4651\n",
      "Epoch 476/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5138 - mse: 0.5063 - val_loss: 0.4778 - val_mse: 0.4703\n",
      "Epoch 477/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5116 - mse: 0.5041 - val_loss: 0.4721 - val_mse: 0.4646\n",
      "Epoch 478/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5124 - mse: 0.5049 - val_loss: 0.4874 - val_mse: 0.4799\n",
      "Epoch 479/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5187 - mse: 0.5112 - val_loss: 0.4713 - val_mse: 0.4638\n",
      "Epoch 480/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5089 - mse: 0.5014\n",
      "Epoch 00480: saving model to Regression_Model/thle2.mse.linear-0480.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.5095 - mse: 0.5020 - val_loss: 0.4724 - val_mse: 0.4649\n",
      "Epoch 481/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5088 - mse: 0.5013 - val_loss: 0.4654 - val_mse: 0.4579\n",
      "Epoch 482/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5132 - mse: 0.5058 - val_loss: 0.4729 - val_mse: 0.4654\n",
      "Epoch 483/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5052 - mse: 0.4977 - val_loss: 0.4680 - val_mse: 0.4605\n",
      "Epoch 484/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5147 - mse: 0.5072 - val_loss: 0.4813 - val_mse: 0.4738\n",
      "Epoch 485/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5138 - mse: 0.5063 - val_loss: 0.4668 - val_mse: 0.4593\n",
      "Epoch 486/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5134 - mse: 0.5059 - val_loss: 0.4674 - val_mse: 0.4599\n",
      "Epoch 487/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5070 - mse: 0.4995 - val_loss: 0.4689 - val_mse: 0.4614\n",
      "Epoch 488/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5096 - mse: 0.5022 - val_loss: 0.4699 - val_mse: 0.4624\n",
      "Epoch 489/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5137 - mse: 0.5062 - val_loss: 0.4725 - val_mse: 0.4650\n",
      "Epoch 490/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5077 - mse: 0.5002\n",
      "Epoch 00490: saving model to Regression_Model/thle2.mse.linear-0490.ckpt\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.5080 - mse: 0.5005 - val_loss: 0.4706 - val_mse: 0.4631\n",
      "Epoch 491/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5076 - mse: 0.5002 - val_loss: 0.4689 - val_mse: 0.4615\n",
      "Epoch 492/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5111 - mse: 0.5037 - val_loss: 0.4730 - val_mse: 0.4655\n",
      "Epoch 493/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5116 - mse: 0.5041 - val_loss: 0.4691 - val_mse: 0.4616\n",
      "Epoch 494/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5119 - mse: 0.5045 - val_loss: 0.4703 - val_mse: 0.4628\n",
      "Epoch 495/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5144 - mse: 0.5070 - val_loss: 0.4682 - val_mse: 0.4608\n",
      "Epoch 496/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5103 - mse: 0.5028 - val_loss: 0.4742 - val_mse: 0.4667\n",
      "Epoch 497/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5087 - mse: 0.5012 - val_loss: 0.4725 - val_mse: 0.4651\n",
      "Epoch 498/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5142 - mse: 0.5068 - val_loss: 0.4696 - val_mse: 0.4622\n",
      "Epoch 499/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5060 - mse: 0.4985 - val_loss: 0.4786 - val_mse: 0.4712\n",
      "Epoch 500/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5162 - mse: 0.5088\n",
      "Epoch 00500: saving model to Regression_Model/thle2.mse.linear-0500.ckpt\n",
      "273/273 [==============================] - 5s 18ms/step - loss: 0.5135 - mse: 0.5060 - val_loss: 0.4707 - val_mse: 0.4632\n",
      "Epoch 501/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5094 - mse: 0.5019 - val_loss: 0.4719 - val_mse: 0.4644\n",
      "Epoch 502/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5097 - mse: 0.5023 - val_loss: 0.4686 - val_mse: 0.4611\n",
      "Epoch 503/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5141 - mse: 0.5067 - val_loss: 0.4787 - val_mse: 0.4713\n",
      "Epoch 504/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5158 - mse: 0.5083 - val_loss: 0.4641 - val_mse: 0.4566\n",
      "Epoch 505/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5132 - mse: 0.5057 - val_loss: 0.4803 - val_mse: 0.4729\n",
      "Epoch 506/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5084 - mse: 0.5010 - val_loss: 0.4774 - val_mse: 0.4699\n",
      "Epoch 507/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5150 - mse: 0.5075 - val_loss: 0.4783 - val_mse: 0.4709\n",
      "Epoch 508/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5122 - mse: 0.5048 - val_loss: 0.4795 - val_mse: 0.4721\n",
      "Epoch 509/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5077 - mse: 0.5002 - val_loss: 0.4686 - val_mse: 0.4612\n",
      "Epoch 510/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5158 - mse: 0.5084\n",
      "Epoch 00510: saving model to Regression_Model/thle2.mse.linear-0510.ckpt\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5173 - mse: 0.5099 - val_loss: 0.4676 - val_mse: 0.4602\n",
      "Epoch 511/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5113 - mse: 0.5039 - val_loss: 0.4641 - val_mse: 0.4567\n",
      "Epoch 512/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5165 - mse: 0.5091 - val_loss: 0.4670 - val_mse: 0.4596\n",
      "Epoch 513/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5160 - mse: 0.5086 - val_loss: 0.4730 - val_mse: 0.4656\n",
      "Epoch 514/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5099 - mse: 0.5025 - val_loss: 0.4668 - val_mse: 0.4593\n",
      "Epoch 515/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5142 - mse: 0.5068 - val_loss: 0.4698 - val_mse: 0.4624\n",
      "Epoch 516/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5094 - mse: 0.5020 - val_loss: 0.4734 - val_mse: 0.4660\n",
      "Epoch 517/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5139 - mse: 0.5065 - val_loss: 0.4704 - val_mse: 0.4630\n",
      "Epoch 518/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5139 - mse: 0.5065 - val_loss: 0.4702 - val_mse: 0.4627\n",
      "Epoch 519/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5153 - mse: 0.5079 - val_loss: 0.4718 - val_mse: 0.4643\n",
      "Epoch 520/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5192 - mse: 0.5118\n",
      "Epoch 00520: saving model to Regression_Model/thle2.mse.linear-0520.ckpt\n",
      "273/273 [==============================] - 6s 22ms/step - loss: 0.5183 - mse: 0.5109 - val_loss: 0.4674 - val_mse: 0.4600\n",
      "Epoch 521/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5110 - mse: 0.5036 - val_loss: 0.4705 - val_mse: 0.4631\n",
      "Epoch 522/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5155 - mse: 0.5081 - val_loss: 0.4717 - val_mse: 0.4643\n",
      "Epoch 523/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5145 - mse: 0.5071 - val_loss: 0.4689 - val_mse: 0.4615\n",
      "Epoch 524/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5155 - mse: 0.5081 - val_loss: 0.4730 - val_mse: 0.4656\n",
      "Epoch 525/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5114 - mse: 0.5040 - val_loss: 0.4681 - val_mse: 0.4607\n",
      "Epoch 526/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5148 - mse: 0.5074 - val_loss: 0.4717 - val_mse: 0.4643\n",
      "Epoch 527/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5142 - mse: 0.5068 - val_loss: 0.4674 - val_mse: 0.4600\n",
      "Epoch 528/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5089 - mse: 0.5015 - val_loss: 0.4660 - val_mse: 0.4586\n",
      "Epoch 529/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5041 - mse: 0.4967 - val_loss: 0.4805 - val_mse: 0.4731\n",
      "Epoch 530/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5139 - mse: 0.5065\n",
      "Epoch 00530: saving model to Regression_Model/thle2.mse.linear-0530.ckpt\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5129 - mse: 0.5055 - val_loss: 0.4711 - val_mse: 0.4637\n",
      "Epoch 531/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5095 - mse: 0.5021 - val_loss: 0.4719 - val_mse: 0.4645\n",
      "Epoch 532/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5103 - mse: 0.5029 - val_loss: 0.4816 - val_mse: 0.4742\n",
      "Epoch 533/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5063 - mse: 0.4990 - val_loss: 0.4720 - val_mse: 0.4646\n",
      "Epoch 534/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5053 - mse: 0.4979 - val_loss: 0.4675 - val_mse: 0.4601\n",
      "Epoch 535/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5119 - mse: 0.5045 - val_loss: 0.4750 - val_mse: 0.4676\n",
      "Epoch 536/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5098 - mse: 0.5025 - val_loss: 0.4660 - val_mse: 0.4586\n",
      "Epoch 537/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5139 - mse: 0.5065 - val_loss: 0.4626 - val_mse: 0.4552\n",
      "Epoch 538/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5106 - mse: 0.5032 - val_loss: 0.4672 - val_mse: 0.4598\n",
      "Epoch 539/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5135 - mse: 0.5062 - val_loss: 0.4712 - val_mse: 0.4638\n",
      "Epoch 540/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5080 - mse: 0.5007\n",
      "Epoch 00540: saving model to Regression_Model/thle2.mse.linear-0540.ckpt\n",
      "273/273 [==============================] - 3s 13ms/step - loss: 0.5079 - mse: 0.5006 - val_loss: 0.4679 - val_mse: 0.4605\n",
      "Epoch 541/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4951 - mse: 0.4877 - val_loss: 0.4723 - val_mse: 0.4649\n",
      "Epoch 542/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5100 - mse: 0.5026 - val_loss: 0.4728 - val_mse: 0.4655\n",
      "Epoch 543/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5034 - mse: 0.4960 - val_loss: 0.4692 - val_mse: 0.4619\n",
      "Epoch 544/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5115 - mse: 0.5041 - val_loss: 0.4700 - val_mse: 0.4627\n",
      "Epoch 545/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5113 - mse: 0.5039 - val_loss: 0.4678 - val_mse: 0.4605\n",
      "Epoch 546/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5090 - mse: 0.5016 - val_loss: 0.4707 - val_mse: 0.4634\n",
      "Epoch 547/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5119 - mse: 0.5046 - val_loss: 0.4728 - val_mse: 0.4655\n",
      "Epoch 548/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5076 - mse: 0.5002 - val_loss: 0.4690 - val_mse: 0.4616\n",
      "Epoch 549/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5056 - mse: 0.4983 - val_loss: 0.4661 - val_mse: 0.4587\n",
      "Epoch 550/1000\n",
      "266/273 [============================>.] - ETA: 0s - loss: 0.5172 - mse: 0.5099\n",
      "Epoch 00550: saving model to Regression_Model/thle2.mse.linear-0550.ckpt\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5154 - mse: 0.5081 - val_loss: 0.4744 - val_mse: 0.4671\n",
      "Epoch 551/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5101 - mse: 0.5027 - val_loss: 0.4668 - val_mse: 0.4594\n",
      "Epoch 552/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5151 - mse: 0.5078 - val_loss: 0.4760 - val_mse: 0.4686\n",
      "Epoch 553/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5081 - mse: 0.5007 - val_loss: 0.4637 - val_mse: 0.4564\n",
      "Epoch 554/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5070 - mse: 0.4997 - val_loss: 0.4653 - val_mse: 0.4579\n",
      "Epoch 555/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5079 - mse: 0.5006 - val_loss: 0.4718 - val_mse: 0.4645\n",
      "Epoch 556/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5075 - mse: 0.5002 - val_loss: 0.4709 - val_mse: 0.4636\n",
      "Epoch 557/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5116 - mse: 0.5043 - val_loss: 0.4665 - val_mse: 0.4592\n",
      "Epoch 558/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5080 - mse: 0.5007 - val_loss: 0.4714 - val_mse: 0.4641\n",
      "Epoch 559/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4958 - val_loss: 0.4776 - val_mse: 0.4703\n",
      "Epoch 560/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5074 - mse: 0.5001\n",
      "Epoch 00560: saving model to Regression_Model/thle2.mse.linear-0560.ckpt\n",
      "273/273 [==============================] - 12s 43ms/step - loss: 0.5103 - mse: 0.5029 - val_loss: 0.4735 - val_mse: 0.4662\n",
      "Epoch 561/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5036 - mse: 0.4962 - val_loss: 0.4667 - val_mse: 0.4594\n",
      "Epoch 562/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5040 - mse: 0.4967 - val_loss: 0.4682 - val_mse: 0.4609\n",
      "Epoch 563/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5110 - mse: 0.5036 - val_loss: 0.4723 - val_mse: 0.4650\n",
      "Epoch 564/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5121 - mse: 0.5048 - val_loss: 0.4715 - val_mse: 0.4641\n",
      "Epoch 565/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5109 - mse: 0.5036 - val_loss: 0.4706 - val_mse: 0.4633\n",
      "Epoch 566/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5003 - mse: 0.4930 - val_loss: 0.4683 - val_mse: 0.4610\n",
      "Epoch 567/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5077 - mse: 0.5003 - val_loss: 0.4664 - val_mse: 0.4591\n",
      "Epoch 568/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5030 - mse: 0.4957 - val_loss: 0.4664 - val_mse: 0.4591\n",
      "Epoch 569/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5118 - mse: 0.5045 - val_loss: 0.4686 - val_mse: 0.4613\n",
      "Epoch 570/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5115 - mse: 0.5041\n",
      "Epoch 00570: saving model to Regression_Model/thle2.mse.linear-0570.ckpt\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5105 - mse: 0.5032 - val_loss: 0.4691 - val_mse: 0.4618\n",
      "Epoch 571/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5127 - mse: 0.5054 - val_loss: 0.4675 - val_mse: 0.4602\n",
      "Epoch 572/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4992 - mse: 0.4919 - val_loss: 0.4672 - val_mse: 0.4599\n",
      "Epoch 573/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5094 - mse: 0.5021 - val_loss: 0.4754 - val_mse: 0.4680\n",
      "Epoch 574/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5131 - mse: 0.5058 - val_loss: 0.4665 - val_mse: 0.4592\n",
      "Epoch 575/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5103 - mse: 0.5030 - val_loss: 0.4723 - val_mse: 0.4650\n",
      "Epoch 576/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5067 - mse: 0.4994 - val_loss: 0.4675 - val_mse: 0.4602\n",
      "Epoch 577/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5018 - mse: 0.4945 - val_loss: 0.4647 - val_mse: 0.4574\n",
      "Epoch 578/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5114 - mse: 0.5041 - val_loss: 0.4690 - val_mse: 0.4617\n",
      "Epoch 579/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5127 - mse: 0.5054 - val_loss: 0.4718 - val_mse: 0.4646\n",
      "Epoch 580/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5161 - mse: 0.5088\n",
      "Epoch 00580: saving model to Regression_Model/thle2.mse.linear-0580.ckpt\n",
      "273/273 [==============================] - 4s 13ms/step - loss: 0.5164 - mse: 0.5091 - val_loss: 0.4695 - val_mse: 0.4622\n",
      "Epoch 581/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5080 - mse: 0.5008 - val_loss: 0.4731 - val_mse: 0.4658\n",
      "Epoch 582/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5070 - mse: 0.4997 - val_loss: 0.4738 - val_mse: 0.4665\n",
      "Epoch 583/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5080 - mse: 0.5008 - val_loss: 0.4704 - val_mse: 0.4631\n",
      "Epoch 584/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5092 - mse: 0.5020 - val_loss: 0.4736 - val_mse: 0.4663\n",
      "Epoch 585/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5124 - mse: 0.5051 - val_loss: 0.4670 - val_mse: 0.4597\n",
      "Epoch 586/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5019 - mse: 0.4946 - val_loss: 0.4687 - val_mse: 0.4614\n",
      "Epoch 587/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5090 - mse: 0.5018 - val_loss: 0.4700 - val_mse: 0.4628\n",
      "Epoch 588/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5034 - mse: 0.4961 - val_loss: 0.4679 - val_mse: 0.4607\n",
      "Epoch 589/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5092 - mse: 0.5020 - val_loss: 0.4650 - val_mse: 0.4577\n",
      "Epoch 590/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5082 - mse: 0.5009\n",
      "Epoch 00590: saving model to Regression_Model/thle2.mse.linear-0590.ckpt\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5088 - mse: 0.5015 - val_loss: 0.4667 - val_mse: 0.4595\n",
      "Epoch 591/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5113 - mse: 0.5040 - val_loss: 0.4682 - val_mse: 0.4609\n",
      "Epoch 592/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5077 - mse: 0.5004 - val_loss: 0.4684 - val_mse: 0.4611\n",
      "Epoch 593/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5123 - mse: 0.5050 - val_loss: 0.4673 - val_mse: 0.4600\n",
      "Epoch 594/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5052 - mse: 0.4980 - val_loss: 0.4698 - val_mse: 0.4626\n",
      "Epoch 595/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5075 - mse: 0.5002 - val_loss: 0.4615 - val_mse: 0.4543\n",
      "Epoch 596/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5116 - mse: 0.5044 - val_loss: 0.4681 - val_mse: 0.4608\n",
      "Epoch 597/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5114 - mse: 0.5041 - val_loss: 0.4702 - val_mse: 0.4630\n",
      "Epoch 598/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5072 - mse: 0.5000 - val_loss: 0.4721 - val_mse: 0.4649\n",
      "Epoch 599/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5122 - mse: 0.5049 - val_loss: 0.4688 - val_mse: 0.4616\n",
      "Epoch 600/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5025 - mse: 0.4953\n",
      "Epoch 00600: saving model to Regression_Model/thle2.mse.linear-0600.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.5053 - mse: 0.4980 - val_loss: 0.4650 - val_mse: 0.4577\n",
      "Epoch 601/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5052 - mse: 0.4979 - val_loss: 0.4704 - val_mse: 0.4631\n",
      "Epoch 602/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5075 - mse: 0.5002 - val_loss: 0.4648 - val_mse: 0.4576\n",
      "Epoch 603/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5055 - mse: 0.4983 - val_loss: 0.4665 - val_mse: 0.4593\n",
      "Epoch 604/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5071 - mse: 0.4999 - val_loss: 0.4697 - val_mse: 0.4625\n",
      "Epoch 605/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5098 - mse: 0.5026 - val_loss: 0.4729 - val_mse: 0.4656\n",
      "Epoch 606/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5109 - mse: 0.5036 - val_loss: 0.4712 - val_mse: 0.4640\n",
      "Epoch 607/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5072 - mse: 0.5000 - val_loss: 0.4655 - val_mse: 0.4583\n",
      "Epoch 608/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5087 - mse: 0.5015 - val_loss: 0.4687 - val_mse: 0.4615\n",
      "Epoch 609/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5103 - mse: 0.5030 - val_loss: 0.4677 - val_mse: 0.4605\n",
      "Epoch 610/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5005 - mse: 0.4933\n",
      "Epoch 00610: saving model to Regression_Model/thle2.mse.linear-0610.ckpt\n",
      "273/273 [==============================] - 5s 20ms/step - loss: 0.5011 - mse: 0.4938 - val_loss: 0.4679 - val_mse: 0.4607\n",
      "Epoch 611/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4998 - mse: 0.4926 - val_loss: 0.4633 - val_mse: 0.4561\n",
      "Epoch 612/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5076 - mse: 0.5003 - val_loss: 0.4662 - val_mse: 0.4590\n",
      "Epoch 613/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5075 - mse: 0.5003 - val_loss: 0.4707 - val_mse: 0.4635\n",
      "Epoch 614/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5048 - mse: 0.4976 - val_loss: 0.4663 - val_mse: 0.4590\n",
      "Epoch 615/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4960 - val_loss: 0.4629 - val_mse: 0.4557\n",
      "Epoch 616/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5042 - mse: 0.4970 - val_loss: 0.4640 - val_mse: 0.4567\n",
      "Epoch 617/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5028 - mse: 0.4956 - val_loss: 0.4700 - val_mse: 0.4628\n",
      "Epoch 618/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5093 - mse: 0.5021 - val_loss: 0.4721 - val_mse: 0.4649\n",
      "Epoch 619/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5021 - mse: 0.4948 - val_loss: 0.4703 - val_mse: 0.4631\n",
      "Epoch 620/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5047 - mse: 0.4975\n",
      "Epoch 00620: saving model to Regression_Model/thle2.mse.linear-0620.ckpt\n",
      "273/273 [==============================] - 5s 17ms/step - loss: 0.5046 - mse: 0.4974 - val_loss: 0.4663 - val_mse: 0.4591\n",
      "Epoch 621/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5102 - mse: 0.5030 - val_loss: 0.4686 - val_mse: 0.4613\n",
      "Epoch 622/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5017 - mse: 0.4945 - val_loss: 0.4663 - val_mse: 0.4591\n",
      "Epoch 623/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5012 - mse: 0.4940 - val_loss: 0.4680 - val_mse: 0.4608\n",
      "Epoch 624/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5072 - mse: 0.5000 - val_loss: 0.4703 - val_mse: 0.4631\n",
      "Epoch 625/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5035 - mse: 0.4963 - val_loss: 0.4710 - val_mse: 0.4638\n",
      "Epoch 626/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5060 - mse: 0.4988 - val_loss: 0.4693 - val_mse: 0.4621\n",
      "Epoch 627/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4960 - val_loss: 0.4660 - val_mse: 0.4588\n",
      "Epoch 628/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4960 - val_loss: 0.4716 - val_mse: 0.4644\n",
      "Epoch 629/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5053 - mse: 0.4981 - val_loss: 0.4728 - val_mse: 0.4656\n",
      "Epoch 630/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5057 - mse: 0.4985\n",
      "Epoch 00630: saving model to Regression_Model/thle2.mse.linear-0630.ckpt\n",
      "273/273 [==============================] - 3s 9ms/step - loss: 0.5019 - mse: 0.4947 - val_loss: 0.4663 - val_mse: 0.4591\n",
      "Epoch 631/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5065 - mse: 0.4993 - val_loss: 0.4716 - val_mse: 0.4644\n",
      "Epoch 632/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5077 - mse: 0.5005 - val_loss: 0.4669 - val_mse: 0.4597\n",
      "Epoch 633/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4981 - mse: 0.4909 - val_loss: 0.4692 - val_mse: 0.4620\n",
      "Epoch 634/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5069 - mse: 0.4998 - val_loss: 0.4677 - val_mse: 0.4605\n",
      "Epoch 635/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5082 - mse: 0.5010 - val_loss: 0.4672 - val_mse: 0.4600\n",
      "Epoch 636/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5082 - mse: 0.5011 - val_loss: 0.4699 - val_mse: 0.4627\n",
      "Epoch 637/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5067 - mse: 0.4995 - val_loss: 0.4687 - val_mse: 0.4615\n",
      "Epoch 638/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5066 - mse: 0.4994 - val_loss: 0.4651 - val_mse: 0.4580\n",
      "Epoch 639/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5130 - mse: 0.5059 - val_loss: 0.4711 - val_mse: 0.4640\n",
      "Epoch 640/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5002 - mse: 0.4931\n",
      "Epoch 00640: saving model to Regression_Model/thle2.mse.linear-0640.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.5016 - mse: 0.4944 - val_loss: 0.4668 - val_mse: 0.4596\n",
      "Epoch 641/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5027 - mse: 0.4955 - val_loss: 0.4645 - val_mse: 0.4574\n",
      "Epoch 642/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5085 - mse: 0.5013 - val_loss: 0.4639 - val_mse: 0.4567\n",
      "Epoch 643/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5031 - mse: 0.4959 - val_loss: 0.4667 - val_mse: 0.4595\n",
      "Epoch 644/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5020 - mse: 0.4948 - val_loss: 0.4650 - val_mse: 0.4578\n",
      "Epoch 645/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5122 - mse: 0.5050 - val_loss: 0.4678 - val_mse: 0.4607\n",
      "Epoch 646/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5128 - mse: 0.5056 - val_loss: 0.4683 - val_mse: 0.4611\n",
      "Epoch 647/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5035 - mse: 0.4963 - val_loss: 0.4624 - val_mse: 0.4553\n",
      "Epoch 648/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4996 - mse: 0.4924 - val_loss: 0.4675 - val_mse: 0.4604\n",
      "Epoch 649/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5069 - mse: 0.4997 - val_loss: 0.4621 - val_mse: 0.4550\n",
      "Epoch 650/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5031 - mse: 0.4959\n",
      "Epoch 00650: saving model to Regression_Model/thle2.mse.linear-0650.ckpt\n",
      "273/273 [==============================] - 7s 26ms/step - loss: 0.5031 - mse: 0.4959 - val_loss: 0.4625 - val_mse: 0.4553\n",
      "Epoch 651/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5019 - mse: 0.4948 - val_loss: 0.4649 - val_mse: 0.4577\n",
      "Epoch 652/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5086 - mse: 0.5015 - val_loss: 0.4657 - val_mse: 0.4585\n",
      "Epoch 653/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5022 - mse: 0.4951 - val_loss: 0.4655 - val_mse: 0.4583\n",
      "Epoch 654/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5024 - mse: 0.4953 - val_loss: 0.4638 - val_mse: 0.4566\n",
      "Epoch 655/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5093 - mse: 0.5022 - val_loss: 0.4671 - val_mse: 0.4600\n",
      "Epoch 656/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5044 - mse: 0.4972 - val_loss: 0.4700 - val_mse: 0.4628\n",
      "Epoch 657/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5002 - mse: 0.4931 - val_loss: 0.4662 - val_mse: 0.4590\n",
      "Epoch 658/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5017 - mse: 0.4946 - val_loss: 0.4658 - val_mse: 0.4587\n",
      "Epoch 659/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5018 - mse: 0.4947 - val_loss: 0.4706 - val_mse: 0.4634\n",
      "Epoch 660/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5034 - mse: 0.4963\n",
      "Epoch 00660: saving model to Regression_Model/thle2.mse.linear-0660.ckpt\n",
      "273/273 [==============================] - 7s 25ms/step - loss: 0.5026 - mse: 0.4955 - val_loss: 0.4621 - val_mse: 0.4550\n",
      "Epoch 661/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5046 - mse: 0.4975 - val_loss: 0.4672 - val_mse: 0.4600\n",
      "Epoch 662/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5030 - mse: 0.4958 - val_loss: 0.4657 - val_mse: 0.4585\n",
      "Epoch 663/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5072 - mse: 0.5001 - val_loss: 0.4687 - val_mse: 0.4616\n",
      "Epoch 664/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5037 - mse: 0.4966 - val_loss: 0.4657 - val_mse: 0.4586\n",
      "Epoch 665/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5029 - mse: 0.4958 - val_loss: 0.4696 - val_mse: 0.4625\n",
      "Epoch 666/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5100 - mse: 0.5028 - val_loss: 0.4675 - val_mse: 0.4603\n",
      "Epoch 667/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5027 - mse: 0.4955 - val_loss: 0.4687 - val_mse: 0.4616\n",
      "Epoch 668/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4983 - mse: 0.4912 - val_loss: 0.4682 - val_mse: 0.4610\n",
      "Epoch 669/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5058 - mse: 0.4987 - val_loss: 0.4669 - val_mse: 0.4598\n",
      "Epoch 670/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.5010 - mse: 0.4939\n",
      "Epoch 00670: saving model to Regression_Model/thle2.mse.linear-0670.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.4990 - mse: 0.4919 - val_loss: 0.4642 - val_mse: 0.4571\n",
      "Epoch 671/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4968 - mse: 0.4896 - val_loss: 0.4670 - val_mse: 0.4599\n",
      "Epoch 672/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5054 - mse: 0.4983 - val_loss: 0.4679 - val_mse: 0.4608\n",
      "Epoch 673/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5105 - mse: 0.5034 - val_loss: 0.4683 - val_mse: 0.4612\n",
      "Epoch 674/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5024 - mse: 0.4952 - val_loss: 0.4675 - val_mse: 0.4604\n",
      "Epoch 675/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5067 - mse: 0.4996 - val_loss: 0.4670 - val_mse: 0.4599\n",
      "Epoch 676/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5077 - mse: 0.5006 - val_loss: 0.4715 - val_mse: 0.4644\n",
      "Epoch 677/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5109 - mse: 0.5038 - val_loss: 0.4708 - val_mse: 0.4637\n",
      "Epoch 678/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5001 - mse: 0.4930 - val_loss: 0.4665 - val_mse: 0.4594\n",
      "Epoch 679/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5080 - mse: 0.5009 - val_loss: 0.4676 - val_mse: 0.4605\n",
      "Epoch 680/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.5070 - mse: 0.4999\n",
      "Epoch 00680: saving model to Regression_Model/thle2.mse.linear-0680.ckpt\n",
      "273/273 [==============================] - 3s 9ms/step - loss: 0.5071 - mse: 0.5000 - val_loss: 0.4684 - val_mse: 0.4613\n",
      "Epoch 681/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5011 - mse: 0.4940 - val_loss: 0.4632 - val_mse: 0.4561\n",
      "Epoch 682/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5024 - mse: 0.4953 - val_loss: 0.4636 - val_mse: 0.4565\n",
      "Epoch 683/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5007 - mse: 0.4936 - val_loss: 0.4626 - val_mse: 0.4555\n",
      "Epoch 684/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5059 - mse: 0.4988 - val_loss: 0.4665 - val_mse: 0.4595\n",
      "Epoch 685/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5055 - mse: 0.4984 - val_loss: 0.4660 - val_mse: 0.4589\n",
      "Epoch 686/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5074 - mse: 0.5004 - val_loss: 0.4644 - val_mse: 0.4573\n",
      "Epoch 687/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5012 - mse: 0.4941 - val_loss: 0.4652 - val_mse: 0.4581\n",
      "Epoch 688/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4976 - mse: 0.4905 - val_loss: 0.4687 - val_mse: 0.4616\n",
      "Epoch 689/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5000 - mse: 0.4929 - val_loss: 0.4669 - val_mse: 0.4598\n",
      "Epoch 690/1000\n",
      "259/273 [===========================>..] - ETA: 0s - loss: 0.5100 - mse: 0.5029\n",
      "Epoch 00690: saving model to Regression_Model/thle2.mse.linear-0690.ckpt\n",
      "273/273 [==============================] - 4s 16ms/step - loss: 0.5096 - mse: 0.5025 - val_loss: 0.4641 - val_mse: 0.4571\n",
      "Epoch 691/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5114 - mse: 0.5044 - val_loss: 0.4696 - val_mse: 0.4625\n",
      "Epoch 692/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5048 - mse: 0.4978 - val_loss: 0.4724 - val_mse: 0.4653\n",
      "Epoch 693/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5037 - mse: 0.4966 - val_loss: 0.4665 - val_mse: 0.4595\n",
      "Epoch 694/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5071 - mse: 0.5000 - val_loss: 0.4631 - val_mse: 0.4560\n",
      "Epoch 695/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5113 - mse: 0.5042 - val_loss: 0.4689 - val_mse: 0.4619\n",
      "Epoch 696/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5014 - mse: 0.4943 - val_loss: 0.4640 - val_mse: 0.4569\n",
      "Epoch 697/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5019 - mse: 0.4948 - val_loss: 0.4664 - val_mse: 0.4593\n",
      "Epoch 698/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5052 - mse: 0.4981 - val_loss: 0.4676 - val_mse: 0.4606\n",
      "Epoch 699/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4955 - mse: 0.4884 - val_loss: 0.4696 - val_mse: 0.4626\n",
      "Epoch 700/1000\n",
      "264/273 [============================>.] - ETA: 0s - loss: 0.5060 - mse: 0.4989\n",
      "Epoch 00700: saving model to Regression_Model/thle2.mse.linear-0700.ckpt\n",
      "273/273 [==============================] - 6s 22ms/step - loss: 0.5068 - mse: 0.4997 - val_loss: 0.4642 - val_mse: 0.4571\n",
      "Epoch 701/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5019 - mse: 0.4949 - val_loss: 0.4620 - val_mse: 0.4550\n",
      "Epoch 702/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5023 - mse: 0.4952 - val_loss: 0.4637 - val_mse: 0.4567\n",
      "Epoch 703/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5013 - mse: 0.4942 - val_loss: 0.4657 - val_mse: 0.4586\n",
      "Epoch 704/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4984 - mse: 0.4914 - val_loss: 0.4659 - val_mse: 0.4588\n",
      "Epoch 705/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5037 - mse: 0.4967 - val_loss: 0.4660 - val_mse: 0.4590\n",
      "Epoch 706/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5042 - mse: 0.4972 - val_loss: 0.4653 - val_mse: 0.4583\n",
      "Epoch 707/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4961 - val_loss: 0.4648 - val_mse: 0.4578\n",
      "Epoch 708/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4992 - mse: 0.4922 - val_loss: 0.4663 - val_mse: 0.4593\n",
      "Epoch 709/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5109 - mse: 0.5038 - val_loss: 0.4648 - val_mse: 0.4578\n",
      "Epoch 710/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5012 - mse: 0.4941\n",
      "Epoch 00710: saving model to Regression_Model/thle2.mse.linear-0710.ckpt\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.5017 - mse: 0.4947 - val_loss: 0.4666 - val_mse: 0.4596\n",
      "Epoch 711/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5096 - mse: 0.5026 - val_loss: 0.4656 - val_mse: 0.4585\n",
      "Epoch 712/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5119 - mse: 0.5049 - val_loss: 0.4629 - val_mse: 0.4559\n",
      "Epoch 713/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5091 - mse: 0.5020 - val_loss: 0.4688 - val_mse: 0.4618\n",
      "Epoch 714/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5083 - mse: 0.5013 - val_loss: 0.4648 - val_mse: 0.4578\n",
      "Epoch 715/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5029 - mse: 0.4959 - val_loss: 0.4656 - val_mse: 0.4585\n",
      "Epoch 716/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5069 - mse: 0.4998 - val_loss: 0.4684 - val_mse: 0.4614\n",
      "Epoch 717/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5005 - mse: 0.4935 - val_loss: 0.4717 - val_mse: 0.4646\n",
      "Epoch 718/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5013 - mse: 0.4943 - val_loss: 0.4658 - val_mse: 0.4588\n",
      "Epoch 719/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5039 - mse: 0.4969 - val_loss: 0.4690 - val_mse: 0.4620\n",
      "Epoch 720/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5052 - mse: 0.4982\n",
      "Epoch 00720: saving model to Regression_Model/thle2.mse.linear-0720.ckpt\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5048 - mse: 0.4977 - val_loss: 0.4674 - val_mse: 0.4604\n",
      "Epoch 721/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4940 - mse: 0.4870 - val_loss: 0.4644 - val_mse: 0.4574\n",
      "Epoch 722/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5091 - mse: 0.5020 - val_loss: 0.4686 - val_mse: 0.4616\n",
      "Epoch 723/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4960 - mse: 0.4890 - val_loss: 0.4621 - val_mse: 0.4550\n",
      "Epoch 724/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5047 - mse: 0.4977 - val_loss: 0.4647 - val_mse: 0.4577\n",
      "Epoch 725/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4972 - mse: 0.4902 - val_loss: 0.4675 - val_mse: 0.4604\n",
      "Epoch 726/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5052 - mse: 0.4982 - val_loss: 0.4648 - val_mse: 0.4578\n",
      "Epoch 727/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5015 - mse: 0.4945 - val_loss: 0.4646 - val_mse: 0.4576\n",
      "Epoch 728/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5044 - mse: 0.4974 - val_loss: 0.4625 - val_mse: 0.4555\n",
      "Epoch 729/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4978 - mse: 0.4907 - val_loss: 0.4663 - val_mse: 0.4593\n",
      "Epoch 730/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5004 - mse: 0.4933\n",
      "Epoch 00730: saving model to Regression_Model/thle2.mse.linear-0730.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5015 - mse: 0.4945 - val_loss: 0.4664 - val_mse: 0.4594\n",
      "Epoch 731/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5073 - mse: 0.5003 - val_loss: 0.4699 - val_mse: 0.4629\n",
      "Epoch 732/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4994 - mse: 0.4924 - val_loss: 0.4655 - val_mse: 0.4585\n",
      "Epoch 733/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5055 - mse: 0.4984 - val_loss: 0.4783 - val_mse: 0.4713\n",
      "Epoch 734/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5019 - mse: 0.4948 - val_loss: 0.4642 - val_mse: 0.4572\n",
      "Epoch 735/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5027 - mse: 0.4957 - val_loss: 0.4668 - val_mse: 0.4598\n",
      "Epoch 736/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5040 - mse: 0.4970 - val_loss: 0.4703 - val_mse: 0.4633\n",
      "Epoch 737/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5060 - mse: 0.4989 - val_loss: 0.4667 - val_mse: 0.4597\n",
      "Epoch 738/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5029 - mse: 0.4959 - val_loss: 0.4634 - val_mse: 0.4564\n",
      "Epoch 739/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5030 - mse: 0.4960 - val_loss: 0.4658 - val_mse: 0.4588\n",
      "Epoch 740/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5085 - mse: 0.5015\n",
      "Epoch 00740: saving model to Regression_Model/thle2.mse.linear-0740.ckpt\n",
      "273/273 [==============================] - 5s 19ms/step - loss: 0.5042 - mse: 0.4972 - val_loss: 0.4660 - val_mse: 0.4590\n",
      "Epoch 741/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5058 - mse: 0.4988 - val_loss: 0.4703 - val_mse: 0.4633\n",
      "Epoch 742/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5038 - mse: 0.4968 - val_loss: 0.4657 - val_mse: 0.4587\n",
      "Epoch 743/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4960 - mse: 0.4890 - val_loss: 0.4640 - val_mse: 0.4570\n",
      "Epoch 744/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4994 - mse: 0.4924 - val_loss: 0.4619 - val_mse: 0.4549\n",
      "Epoch 745/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5049 - mse: 0.4979 - val_loss: 0.4714 - val_mse: 0.4644\n",
      "Epoch 746/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5028 - mse: 0.4958 - val_loss: 0.4722 - val_mse: 0.4652\n",
      "Epoch 747/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5094 - mse: 0.5024 - val_loss: 0.4676 - val_mse: 0.4606\n",
      "Epoch 748/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5022 - mse: 0.4952 - val_loss: 0.4713 - val_mse: 0.4644\n",
      "Epoch 749/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5060 - mse: 0.4990 - val_loss: 0.4676 - val_mse: 0.4607\n",
      "Epoch 750/1000\n",
      "260/273 [===========================>..] - ETA: 0s - loss: 0.5070 - mse: 0.5000\n",
      "Epoch 00750: saving model to Regression_Model/thle2.mse.linear-0750.ckpt\n",
      "273/273 [==============================] - 5s 17ms/step - loss: 0.5056 - mse: 0.4986 - val_loss: 0.4677 - val_mse: 0.4607\n",
      "Epoch 751/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4990 - mse: 0.4920 - val_loss: 0.4670 - val_mse: 0.4601\n",
      "Epoch 752/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5040 - mse: 0.4970 - val_loss: 0.4693 - val_mse: 0.4623\n",
      "Epoch 753/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4995 - mse: 0.4925 - val_loss: 0.4690 - val_mse: 0.4620\n",
      "Epoch 754/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5053 - mse: 0.4983 - val_loss: 0.4621 - val_mse: 0.4551\n",
      "Epoch 755/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4967 - mse: 0.4897 - val_loss: 0.4624 - val_mse: 0.4555\n",
      "Epoch 756/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5056 - mse: 0.4986 - val_loss: 0.4645 - val_mse: 0.4576\n",
      "Epoch 757/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5033 - mse: 0.4963 - val_loss: 0.4711 - val_mse: 0.4641\n",
      "Epoch 758/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5080 - mse: 0.5010 - val_loss: 0.4699 - val_mse: 0.4630\n",
      "Epoch 759/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5049 - mse: 0.4979 - val_loss: 0.4650 - val_mse: 0.4580\n",
      "Epoch 760/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5037 - mse: 0.4967\n",
      "Epoch 00760: saving model to Regression_Model/thle2.mse.linear-0760.ckpt\n",
      "273/273 [==============================] - 7s 26ms/step - loss: 0.5046 - mse: 0.4977 - val_loss: 0.4672 - val_mse: 0.4602\n",
      "Epoch 761/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5039 - mse: 0.4969 - val_loss: 0.4678 - val_mse: 0.4608\n",
      "Epoch 762/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5047 - mse: 0.4977 - val_loss: 0.4686 - val_mse: 0.4616\n",
      "Epoch 763/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5047 - mse: 0.4978 - val_loss: 0.4652 - val_mse: 0.4582\n",
      "Epoch 764/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5000 - mse: 0.4930 - val_loss: 0.4708 - val_mse: 0.4639\n",
      "Epoch 765/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5041 - mse: 0.4971 - val_loss: 0.4622 - val_mse: 0.4553\n",
      "Epoch 766/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5055 - mse: 0.4985 - val_loss: 0.4691 - val_mse: 0.4622\n",
      "Epoch 767/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5005 - mse: 0.4935 - val_loss: 0.4712 - val_mse: 0.4642\n",
      "Epoch 768/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5028 - mse: 0.4958 - val_loss: 0.4636 - val_mse: 0.4566\n",
      "Epoch 769/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4971 - mse: 0.4901 - val_loss: 0.4642 - val_mse: 0.4572\n",
      "Epoch 770/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.5043 - mse: 0.4973\n",
      "Epoch 00770: saving model to Regression_Model/thle2.mse.linear-0770.ckpt\n",
      "273/273 [==============================] - 3s 9ms/step - loss: 0.5010 - mse: 0.4940 - val_loss: 0.4644 - val_mse: 0.4575\n",
      "Epoch 771/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5052 - mse: 0.4982 - val_loss: 0.4662 - val_mse: 0.4593\n",
      "Epoch 772/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4994 - mse: 0.4925 - val_loss: 0.4642 - val_mse: 0.4572\n",
      "Epoch 773/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5026 - mse: 0.4956 - val_loss: 0.4652 - val_mse: 0.4583\n",
      "Epoch 774/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5053 - mse: 0.4984 - val_loss: 0.4628 - val_mse: 0.4558\n",
      "Epoch 775/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4969 - mse: 0.4900 - val_loss: 0.4627 - val_mse: 0.4558\n",
      "Epoch 776/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5054 - mse: 0.4984 - val_loss: 0.4708 - val_mse: 0.4638\n",
      "Epoch 777/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4992 - mse: 0.4922 - val_loss: 0.4661 - val_mse: 0.4592\n",
      "Epoch 778/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5027 - mse: 0.4958 - val_loss: 0.4679 - val_mse: 0.4609\n",
      "Epoch 779/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5024 - mse: 0.4954 - val_loss: 0.4667 - val_mse: 0.4597\n",
      "Epoch 780/1000\n",
      "264/273 [============================>.] - ETA: 0s - loss: 0.5058 - mse: 0.4989\n",
      "Epoch 00780: saving model to Regression_Model/thle2.mse.linear-0780.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.5038 - mse: 0.4968 - val_loss: 0.4607 - val_mse: 0.4538\n",
      "Epoch 781/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4975 - mse: 0.4905 - val_loss: 0.4629 - val_mse: 0.4560\n",
      "Epoch 782/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5015 - mse: 0.4945 - val_loss: 0.4648 - val_mse: 0.4578\n",
      "Epoch 783/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4918 - mse: 0.4849 - val_loss: 0.4633 - val_mse: 0.4563\n",
      "Epoch 784/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5097 - mse: 0.5028 - val_loss: 0.4623 - val_mse: 0.4553\n",
      "Epoch 785/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5108 - mse: 0.5039 - val_loss: 0.4667 - val_mse: 0.4598\n",
      "Epoch 786/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4954 - mse: 0.4885 - val_loss: 0.4617 - val_mse: 0.4548\n",
      "Epoch 787/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5051 - mse: 0.4982 - val_loss: 0.4659 - val_mse: 0.4589\n",
      "Epoch 788/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4941 - mse: 0.4872 - val_loss: 0.4680 - val_mse: 0.4610\n",
      "Epoch 789/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5039 - mse: 0.4970 - val_loss: 0.4706 - val_mse: 0.4637\n",
      "Epoch 790/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.4948 - mse: 0.4879\n",
      "Epoch 00790: saving model to Regression_Model/thle2.mse.linear-0790.ckpt\n",
      "273/273 [==============================] - 7s 27ms/step - loss: 0.4952 - mse: 0.4882 - val_loss: 0.4664 - val_mse: 0.4594\n",
      "Epoch 791/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5022 - mse: 0.4953 - val_loss: 0.4651 - val_mse: 0.4582\n",
      "Epoch 792/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4993 - mse: 0.4924 - val_loss: 0.4672 - val_mse: 0.4603\n",
      "Epoch 793/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5026 - mse: 0.4957 - val_loss: 0.4639 - val_mse: 0.4569\n",
      "Epoch 794/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5064 - mse: 0.4995 - val_loss: 0.4647 - val_mse: 0.4578\n",
      "Epoch 795/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4996 - mse: 0.4927 - val_loss: 0.4654 - val_mse: 0.4585\n",
      "Epoch 796/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5049 - mse: 0.4980 - val_loss: 0.4661 - val_mse: 0.4592\n",
      "Epoch 797/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5037 - mse: 0.4968 - val_loss: 0.4649 - val_mse: 0.4580\n",
      "Epoch 798/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5006 - mse: 0.4937 - val_loss: 0.4647 - val_mse: 0.4578\n",
      "Epoch 799/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4963 - val_loss: 0.4662 - val_mse: 0.4593\n",
      "Epoch 800/1000\n",
      "271/273 [============================>.] - ETA: 0s - loss: 0.5050 - mse: 0.4981\n",
      "Epoch 00800: saving model to Regression_Model/thle2.mse.linear-0800.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.5046 - mse: 0.4977 - val_loss: 0.4693 - val_mse: 0.4623\n",
      "Epoch 801/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4975 - mse: 0.4906 - val_loss: 0.4602 - val_mse: 0.4533\n",
      "Epoch 802/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5078 - mse: 0.5009 - val_loss: 0.4618 - val_mse: 0.4549\n",
      "Epoch 803/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5032 - mse: 0.4963 - val_loss: 0.4657 - val_mse: 0.4588\n",
      "Epoch 804/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5116 - mse: 0.5047 - val_loss: 0.4707 - val_mse: 0.4638\n",
      "Epoch 805/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5030 - mse: 0.4961 - val_loss: 0.4676 - val_mse: 0.4607\n",
      "Epoch 806/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4956 - mse: 0.4887 - val_loss: 0.4616 - val_mse: 0.4547\n",
      "Epoch 807/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5052 - mse: 0.4983 - val_loss: 0.4646 - val_mse: 0.4577\n",
      "Epoch 808/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5087 - mse: 0.5018 - val_loss: 0.4639 - val_mse: 0.4570\n",
      "Epoch 809/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5004 - mse: 0.4935 - val_loss: 0.4646 - val_mse: 0.4577\n",
      "Epoch 810/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5034 - mse: 0.4965\n",
      "Epoch 00810: saving model to Regression_Model/thle2.mse.linear-0810.ckpt\n",
      "273/273 [==============================] - 7s 26ms/step - loss: 0.5025 - mse: 0.4957 - val_loss: 0.4640 - val_mse: 0.4571\n",
      "Epoch 811/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5039 - mse: 0.4970 - val_loss: 0.4676 - val_mse: 0.4607\n",
      "Epoch 812/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4987 - mse: 0.4918 - val_loss: 0.4629 - val_mse: 0.4560\n",
      "Epoch 813/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5001 - mse: 0.4932 - val_loss: 0.4675 - val_mse: 0.4606\n",
      "Epoch 814/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5013 - mse: 0.4944 - val_loss: 0.4658 - val_mse: 0.4589\n",
      "Epoch 815/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5006 - mse: 0.4937 - val_loss: 0.4656 - val_mse: 0.4587\n",
      "Epoch 816/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4984 - mse: 0.4916 - val_loss: 0.4653 - val_mse: 0.4584\n",
      "Epoch 817/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4996 - mse: 0.4927 - val_loss: 0.4644 - val_mse: 0.4575\n",
      "Epoch 818/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5030 - mse: 0.4961 - val_loss: 0.4639 - val_mse: 0.4570\n",
      "Epoch 819/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5047 - mse: 0.4978 - val_loss: 0.4736 - val_mse: 0.4667\n",
      "Epoch 820/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.4975 - mse: 0.4906\n",
      "Epoch 00820: saving model to Regression_Model/thle2.mse.linear-0820.ckpt\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.4990 - mse: 0.4921 - val_loss: 0.4625 - val_mse: 0.4556\n",
      "Epoch 821/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5006 - mse: 0.4937 - val_loss: 0.4612 - val_mse: 0.4543\n",
      "Epoch 822/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5015 - mse: 0.4946 - val_loss: 0.4682 - val_mse: 0.4613\n",
      "Epoch 823/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5033 - mse: 0.4964 - val_loss: 0.4638 - val_mse: 0.4569\n",
      "Epoch 824/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4992 - mse: 0.4924 - val_loss: 0.4643 - val_mse: 0.4575\n",
      "Epoch 825/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5031 - mse: 0.4962 - val_loss: 0.4646 - val_mse: 0.4577\n",
      "Epoch 826/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5083 - mse: 0.5014 - val_loss: 0.4668 - val_mse: 0.4599\n",
      "Epoch 827/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4985 - mse: 0.4917 - val_loss: 0.4661 - val_mse: 0.4592\n",
      "Epoch 828/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5001 - mse: 0.4932 - val_loss: 0.4614 - val_mse: 0.4545\n",
      "Epoch 829/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5044 - mse: 0.4975 - val_loss: 0.4624 - val_mse: 0.4555\n",
      "Epoch 830/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5056 - mse: 0.4988\n",
      "Epoch 00830: saving model to Regression_Model/thle2.mse.linear-0830.ckpt\n",
      "273/273 [==============================] - 4s 16ms/step - loss: 0.5082 - mse: 0.5013 - val_loss: 0.4635 - val_mse: 0.4566\n",
      "Epoch 831/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5018 - mse: 0.4950 - val_loss: 0.4644 - val_mse: 0.4575\n",
      "Epoch 832/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4951 - mse: 0.4883 - val_loss: 0.4627 - val_mse: 0.4558\n",
      "Epoch 833/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4994 - mse: 0.4925 - val_loss: 0.4649 - val_mse: 0.4581\n",
      "Epoch 834/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5029 - mse: 0.4960 - val_loss: 0.4647 - val_mse: 0.4579\n",
      "Epoch 835/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5048 - mse: 0.4979 - val_loss: 0.4628 - val_mse: 0.4559\n",
      "Epoch 836/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5023 - mse: 0.4954 - val_loss: 0.4622 - val_mse: 0.4554\n",
      "Epoch 837/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4935 - mse: 0.4866 - val_loss: 0.4658 - val_mse: 0.4589\n",
      "Epoch 838/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5021 - mse: 0.4953 - val_loss: 0.4633 - val_mse: 0.4565\n",
      "Epoch 839/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5004 - mse: 0.4935 - val_loss: 0.4674 - val_mse: 0.4605\n",
      "Epoch 840/1000\n",
      "272/273 [============================>.] - ETA: 0s - loss: 0.4978 - mse: 0.4910\n",
      "Epoch 00840: saving model to Regression_Model/thle2.mse.linear-0840.ckpt\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.4985 - mse: 0.4917 - val_loss: 0.4646 - val_mse: 0.4577\n",
      "Epoch 841/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5047 - mse: 0.4978 - val_loss: 0.4669 - val_mse: 0.4600\n",
      "Epoch 842/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5027 - mse: 0.4958 - val_loss: 0.4649 - val_mse: 0.4580\n",
      "Epoch 843/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4931 - mse: 0.4862 - val_loss: 0.4646 - val_mse: 0.4577\n",
      "Epoch 844/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5050 - mse: 0.4981 - val_loss: 0.4616 - val_mse: 0.4547\n",
      "Epoch 845/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4988 - mse: 0.4919 - val_loss: 0.4647 - val_mse: 0.4579\n",
      "Epoch 846/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5023 - mse: 0.4955 - val_loss: 0.4624 - val_mse: 0.4556\n",
      "Epoch 847/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4964 - mse: 0.4895 - val_loss: 0.4638 - val_mse: 0.4569\n",
      "Epoch 848/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4952 - mse: 0.4883 - val_loss: 0.4620 - val_mse: 0.4552\n",
      "Epoch 849/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4995 - mse: 0.4927 - val_loss: 0.4658 - val_mse: 0.4590\n",
      "Epoch 850/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.4973 - mse: 0.4905\n",
      "Epoch 00850: saving model to Regression_Model/thle2.mse.linear-0850.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.4993 - mse: 0.4925 - val_loss: 0.4661 - val_mse: 0.4593\n",
      "Epoch 851/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4941 - mse: 0.4873 - val_loss: 0.4666 - val_mse: 0.4598\n",
      "Epoch 852/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5000 - mse: 0.4932 - val_loss: 0.4653 - val_mse: 0.4585\n",
      "Epoch 853/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5052 - mse: 0.4984 - val_loss: 0.4638 - val_mse: 0.4570\n",
      "Epoch 854/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5028 - mse: 0.4960 - val_loss: 0.4640 - val_mse: 0.4572\n",
      "Epoch 855/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4957 - mse: 0.4889 - val_loss: 0.4641 - val_mse: 0.4572\n",
      "Epoch 856/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4980 - mse: 0.4912 - val_loss: 0.4646 - val_mse: 0.4577\n",
      "Epoch 857/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5011 - mse: 0.4942 - val_loss: 0.4639 - val_mse: 0.4571\n",
      "Epoch 858/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5024 - mse: 0.4956 - val_loss: 0.4644 - val_mse: 0.4576\n",
      "Epoch 859/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5012 - mse: 0.4944 - val_loss: 0.4660 - val_mse: 0.4591\n",
      "Epoch 860/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5026 - mse: 0.4958\n",
      "Epoch 00860: saving model to Regression_Model/thle2.mse.linear-0860.ckpt\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.5039 - mse: 0.4971 - val_loss: 0.4644 - val_mse: 0.4575\n",
      "Epoch 861/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4986 - mse: 0.4918 - val_loss: 0.4644 - val_mse: 0.4575\n",
      "Epoch 862/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4935 - mse: 0.4867 - val_loss: 0.4701 - val_mse: 0.4633\n",
      "Epoch 863/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4997 - mse: 0.4928 - val_loss: 0.4635 - val_mse: 0.4566\n",
      "Epoch 864/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4987 - mse: 0.4919 - val_loss: 0.4666 - val_mse: 0.4598\n",
      "Epoch 865/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4978 - mse: 0.4909 - val_loss: 0.4654 - val_mse: 0.4586\n",
      "Epoch 866/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4998 - mse: 0.4930 - val_loss: 0.4652 - val_mse: 0.4584\n",
      "Epoch 867/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4981 - mse: 0.4913 - val_loss: 0.4621 - val_mse: 0.4553\n",
      "Epoch 868/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5003 - mse: 0.4935 - val_loss: 0.4649 - val_mse: 0.4581\n",
      "Epoch 869/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5049 - mse: 0.4981 - val_loss: 0.4695 - val_mse: 0.4627\n",
      "Epoch 870/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5027 - mse: 0.4959\n",
      "Epoch 00870: saving model to Regression_Model/thle2.mse.linear-0870.ckpt\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.5026 - mse: 0.4958 - val_loss: 0.4669 - val_mse: 0.4601\n",
      "Epoch 871/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5045 - mse: 0.4977 - val_loss: 0.4651 - val_mse: 0.4583\n",
      "Epoch 872/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5017 - mse: 0.4948 - val_loss: 0.4647 - val_mse: 0.4579\n",
      "Epoch 873/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5034 - mse: 0.4965 - val_loss: 0.4659 - val_mse: 0.4591\n",
      "Epoch 874/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4993 - mse: 0.4925 - val_loss: 0.4628 - val_mse: 0.4560\n",
      "Epoch 875/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5002 - mse: 0.4934 - val_loss: 0.4669 - val_mse: 0.4600\n",
      "Epoch 876/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4988 - mse: 0.4920 - val_loss: 0.4630 - val_mse: 0.4562\n",
      "Epoch 877/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5066 - mse: 0.4998 - val_loss: 0.4640 - val_mse: 0.4572\n",
      "Epoch 878/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5042 - mse: 0.4974 - val_loss: 0.4686 - val_mse: 0.4618\n",
      "Epoch 879/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5031 - mse: 0.4963 - val_loss: 0.4647 - val_mse: 0.4579\n",
      "Epoch 880/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.4944 - mse: 0.4876\n",
      "Epoch 00880: saving model to Regression_Model/thle2.mse.linear-0880.ckpt\n",
      "273/273 [==============================] - 9s 31ms/step - loss: 0.4978 - mse: 0.4910 - val_loss: 0.4613 - val_mse: 0.4545\n",
      "Epoch 881/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4973 - mse: 0.4905 - val_loss: 0.4650 - val_mse: 0.4582\n",
      "Epoch 882/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5008 - mse: 0.4940 - val_loss: 0.4639 - val_mse: 0.4571\n",
      "Epoch 883/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5031 - mse: 0.4963 - val_loss: 0.4657 - val_mse: 0.4589\n",
      "Epoch 884/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4926 - mse: 0.4858 - val_loss: 0.4614 - val_mse: 0.4546\n",
      "Epoch 885/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5041 - mse: 0.4973 - val_loss: 0.4657 - val_mse: 0.4589\n",
      "Epoch 886/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5041 - mse: 0.4973 - val_loss: 0.4646 - val_mse: 0.4579\n",
      "Epoch 887/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5085 - mse: 0.5017 - val_loss: 0.4640 - val_mse: 0.4572\n",
      "Epoch 888/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4878 - mse: 0.4810 - val_loss: 0.4641 - val_mse: 0.4573\n",
      "Epoch 889/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4907 - mse: 0.4839 - val_loss: 0.4682 - val_mse: 0.4614\n",
      "Epoch 890/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.4970 - mse: 0.4902\n",
      "Epoch 00890: saving model to Regression_Model/thle2.mse.linear-0890.ckpt\n",
      "273/273 [==============================] - 3s 9ms/step - loss: 0.4959 - mse: 0.4892 - val_loss: 0.4653 - val_mse: 0.4586\n",
      "Epoch 891/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5038 - mse: 0.4970 - val_loss: 0.4653 - val_mse: 0.4585\n",
      "Epoch 892/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5020 - mse: 0.4952 - val_loss: 0.4612 - val_mse: 0.4544\n",
      "Epoch 893/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5012 - mse: 0.4944 - val_loss: 0.4643 - val_mse: 0.4576\n",
      "Epoch 894/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5008 - mse: 0.4941 - val_loss: 0.4617 - val_mse: 0.4549\n",
      "Epoch 895/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5041 - mse: 0.4973 - val_loss: 0.4659 - val_mse: 0.4591\n",
      "Epoch 896/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4984 - mse: 0.4916 - val_loss: 0.4649 - val_mse: 0.4581\n",
      "Epoch 897/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4903 - mse: 0.4835 - val_loss: 0.4607 - val_mse: 0.4539\n",
      "Epoch 898/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4947 - mse: 0.4879 - val_loss: 0.4650 - val_mse: 0.4582\n",
      "Epoch 899/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5065 - mse: 0.4997 - val_loss: 0.4711 - val_mse: 0.4643\n",
      "Epoch 900/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.4958 - mse: 0.4890\n",
      "Epoch 00900: saving model to Regression_Model/thle2.mse.linear-0900.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.4959 - mse: 0.4891 - val_loss: 0.4642 - val_mse: 0.4574\n",
      "Epoch 901/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5003 - mse: 0.4935 - val_loss: 0.4617 - val_mse: 0.4549\n",
      "Epoch 902/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4979 - mse: 0.4912 - val_loss: 0.4659 - val_mse: 0.4591\n",
      "Epoch 903/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5001 - mse: 0.4933 - val_loss: 0.4675 - val_mse: 0.4608\n",
      "Epoch 904/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4998 - mse: 0.4930 - val_loss: 0.4632 - val_mse: 0.4565\n",
      "Epoch 905/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5006 - mse: 0.4938 - val_loss: 0.4591 - val_mse: 0.4523\n",
      "Epoch 906/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4963 - mse: 0.4895 - val_loss: 0.4634 - val_mse: 0.4566\n",
      "Epoch 907/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4956 - mse: 0.4888 - val_loss: 0.4730 - val_mse: 0.4662\n",
      "Epoch 908/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5068 - mse: 0.5001 - val_loss: 0.4654 - val_mse: 0.4586\n",
      "Epoch 909/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4977 - mse: 0.4909 - val_loss: 0.4665 - val_mse: 0.4598\n",
      "Epoch 910/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.4991 - mse: 0.4924\n",
      "Epoch 00910: saving model to Regression_Model/thle2.mse.linear-0910.ckpt\n",
      "273/273 [==============================] - 4s 16ms/step - loss: 0.4968 - mse: 0.4900 - val_loss: 0.4610 - val_mse: 0.4542\n",
      "Epoch 911/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4977 - mse: 0.4910 - val_loss: 0.4654 - val_mse: 0.4586\n",
      "Epoch 912/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4997 - mse: 0.4929 - val_loss: 0.4621 - val_mse: 0.4554\n",
      "Epoch 913/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4954 - mse: 0.4886 - val_loss: 0.4657 - val_mse: 0.4589\n",
      "Epoch 914/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5038 - mse: 0.4970 - val_loss: 0.4694 - val_mse: 0.4627\n",
      "Epoch 915/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4983 - mse: 0.4916 - val_loss: 0.4627 - val_mse: 0.4559\n",
      "Epoch 916/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4979 - mse: 0.4911 - val_loss: 0.4648 - val_mse: 0.4580\n",
      "Epoch 917/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5014 - mse: 0.4946 - val_loss: 0.4658 - val_mse: 0.4590\n",
      "Epoch 918/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5012 - mse: 0.4945 - val_loss: 0.4646 - val_mse: 0.4578\n",
      "Epoch 919/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4943 - mse: 0.4875 - val_loss: 0.4641 - val_mse: 0.4573\n",
      "Epoch 920/1000\n",
      "257/273 [===========================>..] - ETA: 0s - loss: 0.4988 - mse: 0.4920\n",
      "Epoch 00920: saving model to Regression_Model/thle2.mse.linear-0920.ckpt\n",
      "273/273 [==============================] - 4s 14ms/step - loss: 0.5014 - mse: 0.4947 - val_loss: 0.4680 - val_mse: 0.4613\n",
      "Epoch 921/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4962 - mse: 0.4894 - val_loss: 0.4629 - val_mse: 0.4562\n",
      "Epoch 922/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5008 - mse: 0.4940 - val_loss: 0.4646 - val_mse: 0.4578\n",
      "Epoch 923/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5078 - mse: 0.5011 - val_loss: 0.4688 - val_mse: 0.4621\n",
      "Epoch 924/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5013 - mse: 0.4946 - val_loss: 0.4662 - val_mse: 0.4595\n",
      "Epoch 925/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5024 - mse: 0.4956 - val_loss: 0.4665 - val_mse: 0.4598\n",
      "Epoch 926/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4943 - mse: 0.4875 - val_loss: 0.4649 - val_mse: 0.4582\n",
      "Epoch 927/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4962 - mse: 0.4894 - val_loss: 0.4631 - val_mse: 0.4563\n",
      "Epoch 928/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4970 - mse: 0.4902 - val_loss: 0.4638 - val_mse: 0.4570\n",
      "Epoch 929/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4969 - mse: 0.4902 - val_loss: 0.4639 - val_mse: 0.4572\n",
      "Epoch 930/1000\n",
      "268/273 [============================>.] - ETA: 0s - loss: 0.4982 - mse: 0.4915\n",
      "Epoch 00930: saving model to Regression_Model/thle2.mse.linear-0930.ckpt\n",
      "273/273 [==============================] - 4s 16ms/step - loss: 0.4978 - mse: 0.4910 - val_loss: 0.4625 - val_mse: 0.4557\n",
      "Epoch 931/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5037 - mse: 0.4970 - val_loss: 0.4617 - val_mse: 0.4550\n",
      "Epoch 932/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4949 - mse: 0.4882 - val_loss: 0.4634 - val_mse: 0.4566\n",
      "Epoch 933/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4876 - mse: 0.4808 - val_loss: 0.4640 - val_mse: 0.4573\n",
      "Epoch 934/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4974 - mse: 0.4907 - val_loss: 0.4629 - val_mse: 0.4561\n",
      "Epoch 935/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5017 - mse: 0.4950 - val_loss: 0.4633 - val_mse: 0.4565\n",
      "Epoch 936/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4890 - mse: 0.4823 - val_loss: 0.4642 - val_mse: 0.4575\n",
      "Epoch 937/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4993 - mse: 0.4925 - val_loss: 0.4674 - val_mse: 0.4607\n",
      "Epoch 938/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5015 - mse: 0.4948 - val_loss: 0.4653 - val_mse: 0.4586\n",
      "Epoch 939/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4963 - mse: 0.4896 - val_loss: 0.4648 - val_mse: 0.4581\n",
      "Epoch 940/1000\n",
      "262/273 [===========================>..] - ETA: 0s - loss: 0.4987 - mse: 0.4920\n",
      "Epoch 00940: saving model to Regression_Model/thle2.mse.linear-0940.ckpt\n",
      "273/273 [==============================] - 4s 13ms/step - loss: 0.4958 - mse: 0.4891 - val_loss: 0.4655 - val_mse: 0.4588\n",
      "Epoch 941/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4960 - mse: 0.4893 - val_loss: 0.4626 - val_mse: 0.4559\n",
      "Epoch 942/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4999 - mse: 0.4931 - val_loss: 0.4631 - val_mse: 0.4564\n",
      "Epoch 943/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4988 - mse: 0.4921 - val_loss: 0.4627 - val_mse: 0.4560\n",
      "Epoch 944/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4916 - mse: 0.4848 - val_loss: 0.4598 - val_mse: 0.4531\n",
      "Epoch 945/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5009 - mse: 0.4942 - val_loss: 0.4640 - val_mse: 0.4573\n",
      "Epoch 946/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4995 - mse: 0.4928 - val_loss: 0.4641 - val_mse: 0.4574\n",
      "Epoch 947/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4922 - mse: 0.4854 - val_loss: 0.4635 - val_mse: 0.4568\n",
      "Epoch 948/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4992 - mse: 0.4925 - val_loss: 0.4615 - val_mse: 0.4548\n",
      "Epoch 949/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5003 - mse: 0.4936 - val_loss: 0.4670 - val_mse: 0.4603\n",
      "Epoch 950/1000\n",
      "261/273 [===========================>..] - ETA: 0s - loss: 0.4946 - mse: 0.4879\n",
      "Epoch 00950: saving model to Regression_Model/thle2.mse.linear-0950.ckpt\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4930 - mse: 0.4863 - val_loss: 0.4640 - val_mse: 0.4573\n",
      "Epoch 951/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5041 - mse: 0.4974 - val_loss: 0.4650 - val_mse: 0.4583\n",
      "Epoch 952/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4999 - mse: 0.4932 - val_loss: 0.4631 - val_mse: 0.4564\n",
      "Epoch 953/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4983 - mse: 0.4916 - val_loss: 0.4626 - val_mse: 0.4559\n",
      "Epoch 954/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5018 - mse: 0.4951 - val_loss: 0.4645 - val_mse: 0.4578\n",
      "Epoch 955/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5044 - mse: 0.4977 - val_loss: 0.4654 - val_mse: 0.4587\n",
      "Epoch 956/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4953 - mse: 0.4886 - val_loss: 0.4670 - val_mse: 0.4603\n",
      "Epoch 957/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5002 - mse: 0.4935 - val_loss: 0.4622 - val_mse: 0.4555\n",
      "Epoch 958/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5016 - mse: 0.4949 - val_loss: 0.4652 - val_mse: 0.4585\n",
      "Epoch 959/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5056 - mse: 0.4989 - val_loss: 0.4651 - val_mse: 0.4584\n",
      "Epoch 960/1000\n",
      "263/273 [===========================>..] - ETA: 0s - loss: 0.5002 - mse: 0.4935\n",
      "Epoch 00960: saving model to Regression_Model/thle2.mse.linear-0960.ckpt\n",
      "273/273 [==============================] - 4s 15ms/step - loss: 0.5020 - mse: 0.4953 - val_loss: 0.4621 - val_mse: 0.4554\n",
      "Epoch 961/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4958 - mse: 0.4891 - val_loss: 0.4641 - val_mse: 0.4574\n",
      "Epoch 962/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4969 - mse: 0.4902 - val_loss: 0.4619 - val_mse: 0.4552\n",
      "Epoch 963/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4975 - mse: 0.4908 - val_loss: 0.4686 - val_mse: 0.4619\n",
      "Epoch 964/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4976 - mse: 0.4909 - val_loss: 0.4674 - val_mse: 0.4607\n",
      "Epoch 965/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4987 - mse: 0.4920 - val_loss: 0.4644 - val_mse: 0.4577\n",
      "Epoch 966/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4961 - mse: 0.4894 - val_loss: 0.4617 - val_mse: 0.4550\n",
      "Epoch 967/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4985 - mse: 0.4919 - val_loss: 0.4657 - val_mse: 0.4590\n",
      "Epoch 968/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5033 - mse: 0.4966 - val_loss: 0.4679 - val_mse: 0.4612\n",
      "Epoch 969/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5079 - mse: 0.5012 - val_loss: 0.4706 - val_mse: 0.4639\n",
      "Epoch 970/1000\n",
      "267/273 [============================>.] - ETA: 0s - loss: 0.4988 - mse: 0.4921\n",
      "Epoch 00970: saving model to Regression_Model/thle2.mse.linear-0970.ckpt\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.4987 - mse: 0.4920 - val_loss: 0.4646 - val_mse: 0.4579\n",
      "Epoch 971/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5028 - mse: 0.4961 - val_loss: 0.4633 - val_mse: 0.4567\n",
      "Epoch 972/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4947 - mse: 0.4880 - val_loss: 0.4657 - val_mse: 0.4590\n",
      "Epoch 973/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4939 - mse: 0.4872 - val_loss: 0.4644 - val_mse: 0.4577\n",
      "Epoch 974/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4973 - mse: 0.4906 - val_loss: 0.4641 - val_mse: 0.4574\n",
      "Epoch 975/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4946 - mse: 0.4879 - val_loss: 0.4644 - val_mse: 0.4577\n",
      "Epoch 976/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4984 - mse: 0.4918 - val_loss: 0.4632 - val_mse: 0.4566\n",
      "Epoch 977/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4956 - mse: 0.4889 - val_loss: 0.4634 - val_mse: 0.4567\n",
      "Epoch 978/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4975 - mse: 0.4909 - val_loss: 0.4635 - val_mse: 0.4569\n",
      "Epoch 979/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4924 - mse: 0.4857 - val_loss: 0.4654 - val_mse: 0.4587\n",
      "Epoch 980/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.4981 - mse: 0.4915\n",
      "Epoch 00980: saving model to Regression_Model/thle2.mse.linear-0980.ckpt\n",
      "273/273 [==============================] - 5s 17ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4651 - val_mse: 0.4584\n",
      "Epoch 981/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.4995 - mse: 0.4929 - val_loss: 0.4635 - val_mse: 0.4568\n",
      "Epoch 982/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4978 - mse: 0.4911 - val_loss: 0.4657 - val_mse: 0.4590\n",
      "Epoch 983/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5004 - mse: 0.4937 - val_loss: 0.4652 - val_mse: 0.4586\n",
      "Epoch 984/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4991 - mse: 0.4924 - val_loss: 0.4670 - val_mse: 0.4603\n",
      "Epoch 985/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4958 - mse: 0.4891 - val_loss: 0.4617 - val_mse: 0.4550\n",
      "Epoch 986/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4954 - mse: 0.4887 - val_loss: 0.4652 - val_mse: 0.4585\n",
      "Epoch 987/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5010 - mse: 0.4943 - val_loss: 0.4672 - val_mse: 0.4605\n",
      "Epoch 988/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5027 - mse: 0.4961 - val_loss: 0.4665 - val_mse: 0.4599\n",
      "Epoch 989/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5039 - mse: 0.4972 - val_loss: 0.4671 - val_mse: 0.4605\n",
      "Epoch 990/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.5038 - mse: 0.4971\n",
      "Epoch 00990: saving model to Regression_Model/thle2.mse.linear-0990.ckpt\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.5049 - mse: 0.4982 - val_loss: 0.4658 - val_mse: 0.4592\n",
      "Epoch 991/1000\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.5026 - mse: 0.4959 - val_loss: 0.4628 - val_mse: 0.4561\n",
      "Epoch 992/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4961 - mse: 0.4894 - val_loss: 0.4625 - val_mse: 0.4558\n",
      "Epoch 993/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5013 - mse: 0.4947 - val_loss: 0.4632 - val_mse: 0.4565\n",
      "Epoch 994/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4637 - val_mse: 0.4570\n",
      "Epoch 995/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5000 - mse: 0.4934 - val_loss: 0.4639 - val_mse: 0.4573\n",
      "Epoch 996/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5083 - mse: 0.5017 - val_loss: 0.4661 - val_mse: 0.4594\n",
      "Epoch 997/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5027 - mse: 0.4960 - val_loss: 0.4635 - val_mse: 0.4568\n",
      "Epoch 998/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.4944 - mse: 0.4877 - val_loss: 0.4655 - val_mse: 0.4588\n",
      "Epoch 999/1000\n",
      "273/273 [==============================] - 1s 4ms/step - loss: 0.5026 - mse: 0.4960 - val_loss: 0.4640 - val_mse: 0.4573\n",
      "Epoch 1000/1000\n",
      "256/273 [===========================>..] - ETA: 0s - loss: 0.4945 - mse: 0.4878\n",
      "Epoch 01000: saving model to Regression_Model/thle2.mse.linear-1000.ckpt\n",
      "273/273 [==============================] - 6s 20ms/step - loss: 0.4929 - mse: 0.4862 - val_loss: 0.4619 - val_mse: 0.4553\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=1000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "mse\n",
      "val_loss\n",
      "val_mse\n"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b8b4ffc7da0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,MODEL_PATH,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    \n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "testid=trainid\n",
    "bestEpoch = '1000'\n",
    "MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "evaluate(train_x,train_y,train_id,MODEL_PATH,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,MODEL_PATH,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 11851\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'standardize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e78e34443d56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#label_std = 1.65\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#MODEL_PATH = 'bestModel/thle2.mse.linear-0980.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'standardize' is not defined"
     ]
    }
   ],
   "source": [
    "test_data,test_labels,test_id,test2_data,test2_labels,test2_id = prep_data('coverage_data/THLE2_Control.usage.txt',5,33.3)\n",
    "testid=trainid\n",
    "#data_mean = -1.09\n",
    "#data_std  = 1.79\n",
    "#label_mean = 2.39\n",
    "#label_std = 1.65\n",
    "#MODEL_PATH = 'bestModel/thle2.mse.linear-0980.ckpt'\n",
    "test_x,test_y = standardize(test_data,test_labels,data_mean,data_std,label_mean,label_std)\n",
    "evaluate(test_x,test_y,test_id,MODEL_PATH,'test',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/thle2_control.pAs.usage.txt',5)\n",
    "train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/Finetune.snu398_control.usage.txt',5)\n",
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='thle2.mle.linear'\n",
    "bestEpoch = '0980'\n",
    "evaluate(train_x,train_y,train_pasid,testid,'train',label_mean,label_std,bestEpoch)\n",
    "evaluate(valid_x,valid_y,valid_pasid,testid,'valid',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train_data,train_labels,data_mean,data_std,label_mean,label_std):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    return train_data,train_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1(x,y,pasid,trainid,dataset,label_mean,label_std,bestEpoch=2000):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)-1\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)-1\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1,train_labels1,train_pasid1,valid_data1,valid_labels1,valid_pasid1 = prep_data('coverage_data/all.snu398_control.usage.txt',5)\n",
    "x=np.concatenate((train_data1, valid_data1), axis=0)\n",
    "y=np.concatenate((train_labels1, valid_labels1), axis=0)\n",
    "pasid=np.concatenate((train_pasid1, valid_pasid1), axis=0)\n",
    "x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='Regression.f_snu398.shift16.1001'\n",
    "bestEpoch = '2000'\n",
    "evaluate1(x,y,pasid,testid,'all',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((train_pasid1, valid_pasid1), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[3,4,5,6]\n",
    "a.remove(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(a == None):\n",
    "    print('fafa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'chromosme,start,end,score,id,strand\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,c,d = a.split(',')[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
