{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = MaxPooling1D(pool_size = 12)(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "group_normalization (GroupNo (None, 990, 16)           32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,289\n",
      "Trainable params: 42,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 89967\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = \\\n",
    "prep_data('coverage_data/SNU398.gt.onlyrna0.05.txt',5,7.8)\n",
    "trainid='snu398'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data2,train_labels2,train_id2,valid_data2,valid_labels2,valid_id2 = prep_data('coverage_data/SNU398_Control.usage.txt',5,7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=np.concatenate((train_data1, train_data2), axis=0)\n",
    "#train_labels=np.concatenate((train_labels1, train_labels2), axis=0)\n",
    "#valid_data=np.concatenate((valid_data1, valid_data2), axis=0)\n",
    "#valid_labels=np.concatenate((valid_labels1, valid_labels2), axis=0)\n",
    "#train_id =np.concatenate((train_id1, train_id2), axis=0)\n",
    "#valid_id =np.concatenate((valid_id1, valid_id2), axis=0)\n",
    "#x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels+0.1)\n",
    "    valid_data = np.log(valid_data+0.05)\n",
    "    valid_labels = np.log(valid_labels+0.1)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    #train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    #valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3246073 1.4337103\n",
      "-0.9327404 1.9654697\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3239406 1.4519023\n",
      "0.87234724 1.79385\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b2817dd2ef0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(train_x.shape[1]),train_x[5,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.778967"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,train_id,16,LENGTH)\n",
    "validation_generator = DataGenerator(valid_x,valid_y,valid_id,0,LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(LENGTH),a[9])\n",
    "plt.xticks(np.arange(0, LENGTH, 100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 524 steps, validate for 131 steps\n",
      "Epoch 1/1000\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.5743 - mse: 0.5665 - val_loss: 0.4936 - val_mse: 0.4858\n",
      "Epoch 2/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5581 - mse: 0.5503 - val_loss: 0.4861 - val_mse: 0.4784\n",
      "Epoch 3/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5569 - mse: 0.5491 - val_loss: 0.4979 - val_mse: 0.4901\n",
      "Epoch 4/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5610 - mse: 0.5532 - val_loss: 0.4831 - val_mse: 0.4753\n",
      "Epoch 5/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5587 - mse: 0.5509 - val_loss: 0.4924 - val_mse: 0.4846\n",
      "Epoch 6/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5522 - mse: 0.5444 - val_loss: 0.5063 - val_mse: 0.4985\n",
      "Epoch 7/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5495 - mse: 0.5416 - val_loss: 0.4856 - val_mse: 0.4778\n",
      "Epoch 8/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5547 - mse: 0.5468 - val_loss: 0.4826 - val_mse: 0.4748\n",
      "Epoch 9/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5504 - mse: 0.5426 - val_loss: 0.4797 - val_mse: 0.4719\n",
      "Epoch 10/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5520 - mse: 0.5442\n",
      "Epoch 00010: saving model to Regression_Model/thle2.mse.linear-0010.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5517 - mse: 0.5439 - val_loss: 0.4845 - val_mse: 0.4767\n",
      "Epoch 11/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5534 - mse: 0.5455 - val_loss: 0.4829 - val_mse: 0.4751\n",
      "Epoch 12/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5529 - mse: 0.5451 - val_loss: 0.4876 - val_mse: 0.4797\n",
      "Epoch 13/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5506 - mse: 0.5428 - val_loss: 0.5008 - val_mse: 0.4930\n",
      "Epoch 14/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5538 - mse: 0.5460 - val_loss: 0.4892 - val_mse: 0.4813\n",
      "Epoch 15/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5486 - mse: 0.5407 - val_loss: 0.4817 - val_mse: 0.4738\n",
      "Epoch 16/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5476 - mse: 0.5398 - val_loss: 0.4862 - val_mse: 0.4783\n",
      "Epoch 17/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5468 - mse: 0.5390 - val_loss: 0.4985 - val_mse: 0.4906\n",
      "Epoch 18/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5509 - mse: 0.5430 - val_loss: 0.4840 - val_mse: 0.4761\n",
      "Epoch 19/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5461 - mse: 0.5382 - val_loss: 0.4764 - val_mse: 0.4686\n",
      "Epoch 20/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5461 - mse: 0.5382\n",
      "Epoch 00020: saving model to Regression_Model/thle2.mse.linear-0020.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5464 - mse: 0.5385 - val_loss: 0.4829 - val_mse: 0.4750\n",
      "Epoch 21/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5440 - mse: 0.5362 - val_loss: 0.4794 - val_mse: 0.4716\n",
      "Epoch 22/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5465 - mse: 0.5386 - val_loss: 0.4947 - val_mse: 0.4868\n",
      "Epoch 23/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5483 - mse: 0.5404 - val_loss: 0.4899 - val_mse: 0.4821\n",
      "Epoch 24/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5520 - mse: 0.5442 - val_loss: 0.4868 - val_mse: 0.4790\n",
      "Epoch 25/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5442 - mse: 0.5364 - val_loss: 0.4792 - val_mse: 0.4714\n",
      "Epoch 26/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5519 - mse: 0.5440 - val_loss: 0.4975 - val_mse: 0.4897\n",
      "Epoch 27/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5470 - mse: 0.5392 - val_loss: 0.4833 - val_mse: 0.4755\n",
      "Epoch 28/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5466 - mse: 0.5388 - val_loss: 0.4948 - val_mse: 0.4870\n",
      "Epoch 29/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5446 - mse: 0.5368 - val_loss: 0.4918 - val_mse: 0.4840\n",
      "Epoch 30/1000\n",
      "515/524 [============================>.] - ETA: 0s - loss: 0.5471 - mse: 0.5393\n",
      "Epoch 00030: saving model to Regression_Model/thle2.mse.linear-0030.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5468 - mse: 0.5389 - val_loss: 0.4833 - val_mse: 0.4754\n",
      "Epoch 31/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5448 - mse: 0.5369 - val_loss: 0.5183 - val_mse: 0.5105\n",
      "Epoch 32/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5404 - mse: 0.5326 - val_loss: 0.4812 - val_mse: 0.4733\n",
      "Epoch 33/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5480 - mse: 0.5402 - val_loss: 0.4817 - val_mse: 0.4739\n",
      "Epoch 34/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5414 - mse: 0.5336 - val_loss: 0.4850 - val_mse: 0.4772\n",
      "Epoch 35/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5427 - mse: 0.5348 - val_loss: 0.5143 - val_mse: 0.5065\n",
      "Epoch 36/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5385 - mse: 0.5307 - val_loss: 0.5108 - val_mse: 0.5030\n",
      "Epoch 37/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5497 - mse: 0.5419 - val_loss: 0.4957 - val_mse: 0.4879\n",
      "Epoch 38/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5418 - mse: 0.5340 - val_loss: 0.4856 - val_mse: 0.4777\n",
      "Epoch 39/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5407 - mse: 0.5328 - val_loss: 0.4936 - val_mse: 0.4857\n",
      "Epoch 40/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5402 - mse: 0.5323\n",
      "Epoch 00040: saving model to Regression_Model/thle2.mse.linear-0040.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5402 - mse: 0.5324 - val_loss: 0.4763 - val_mse: 0.4685\n",
      "Epoch 41/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5439 - mse: 0.5361 - val_loss: 0.4770 - val_mse: 0.4692\n",
      "Epoch 42/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5391 - mse: 0.5312 - val_loss: 0.4753 - val_mse: 0.4675\n",
      "Epoch 43/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5389 - mse: 0.5310 - val_loss: 0.4796 - val_mse: 0.4718\n",
      "Epoch 44/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5436 - mse: 0.5358 - val_loss: 0.4777 - val_mse: 0.4699\n",
      "Epoch 45/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5423 - mse: 0.5345 - val_loss: 0.4818 - val_mse: 0.4740\n",
      "Epoch 46/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5378 - mse: 0.5300 - val_loss: 0.4985 - val_mse: 0.4906\n",
      "Epoch 47/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5423 - mse: 0.5345 - val_loss: 0.4826 - val_mse: 0.4748\n",
      "Epoch 48/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5416 - mse: 0.5338 - val_loss: 0.4905 - val_mse: 0.4827\n",
      "Epoch 49/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5397 - mse: 0.5319 - val_loss: 0.4819 - val_mse: 0.4741\n",
      "Epoch 50/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5420 - mse: 0.5342\n",
      "Epoch 00050: saving model to Regression_Model/thle2.mse.linear-0050.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5418 - mse: 0.5340 - val_loss: 0.4874 - val_mse: 0.4796\n",
      "Epoch 51/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5371 - mse: 0.5293 - val_loss: 0.4866 - val_mse: 0.4788\n",
      "Epoch 52/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5440 - mse: 0.5362 - val_loss: 0.4866 - val_mse: 0.4788\n",
      "Epoch 53/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5450 - mse: 0.5372 - val_loss: 0.5019 - val_mse: 0.4941\n",
      "Epoch 54/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5394 - mse: 0.5316 - val_loss: 0.5108 - val_mse: 0.5030\n",
      "Epoch 55/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5404 - mse: 0.5326 - val_loss: 0.4789 - val_mse: 0.4711\n",
      "Epoch 56/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5479 - mse: 0.5401 - val_loss: 0.4868 - val_mse: 0.4790\n",
      "Epoch 57/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5375 - mse: 0.5297 - val_loss: 0.4877 - val_mse: 0.4799\n",
      "Epoch 58/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5445 - mse: 0.5367 - val_loss: 0.4850 - val_mse: 0.4772\n",
      "Epoch 59/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5416 - mse: 0.5338 - val_loss: 0.4789 - val_mse: 0.4711\n",
      "Epoch 60/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5404 - mse: 0.5326\n",
      "Epoch 00060: saving model to Regression_Model/thle2.mse.linear-0060.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5406 - mse: 0.5328 - val_loss: 0.4771 - val_mse: 0.4693\n",
      "Epoch 61/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5350 - mse: 0.5272 - val_loss: 0.4756 - val_mse: 0.4678\n",
      "Epoch 62/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5412 - mse: 0.5335 - val_loss: 0.4756 - val_mse: 0.4678\n",
      "Epoch 63/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5333 - mse: 0.5255 - val_loss: 0.4829 - val_mse: 0.4751\n",
      "Epoch 64/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5397 - mse: 0.5319 - val_loss: 0.4897 - val_mse: 0.4819\n",
      "Epoch 65/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5419 - mse: 0.5342 - val_loss: 0.4821 - val_mse: 0.4743\n",
      "Epoch 66/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5377 - mse: 0.5299 - val_loss: 0.4824 - val_mse: 0.4746\n",
      "Epoch 67/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5399 - mse: 0.5322 - val_loss: 0.4943 - val_mse: 0.4866\n",
      "Epoch 68/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5373 - mse: 0.5295 - val_loss: 0.4850 - val_mse: 0.4773\n",
      "Epoch 69/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5349 - mse: 0.5272 - val_loss: 0.4820 - val_mse: 0.4742\n",
      "Epoch 70/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5373 - mse: 0.5295\n",
      "Epoch 00070: saving model to Regression_Model/thle2.mse.linear-0070.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5378 - mse: 0.5301 - val_loss: 0.4771 - val_mse: 0.4693\n",
      "Epoch 71/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5352 - mse: 0.5275 - val_loss: 0.4846 - val_mse: 0.4768\n",
      "Epoch 72/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5359 - mse: 0.5282 - val_loss: 0.4830 - val_mse: 0.4752\n",
      "Epoch 73/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5399 - mse: 0.5322 - val_loss: 0.4781 - val_mse: 0.4703\n",
      "Epoch 74/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5353 - mse: 0.5275 - val_loss: 0.4867 - val_mse: 0.4789\n",
      "Epoch 75/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5419 - mse: 0.5342 - val_loss: 0.4963 - val_mse: 0.4885\n",
      "Epoch 76/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5387 - mse: 0.5310 - val_loss: 0.4852 - val_mse: 0.4775\n",
      "Epoch 77/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5407 - mse: 0.5330 - val_loss: 0.4761 - val_mse: 0.4684\n",
      "Epoch 78/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5371 - mse: 0.5294 - val_loss: 0.4799 - val_mse: 0.4722\n",
      "Epoch 79/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5350 - mse: 0.5273 - val_loss: 0.4869 - val_mse: 0.4792\n",
      "Epoch 80/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5378 - mse: 0.5301\n",
      "Epoch 00080: saving model to Regression_Model/thle2.mse.linear-0080.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5377 - mse: 0.5299 - val_loss: 0.4826 - val_mse: 0.4749\n",
      "Epoch 81/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5374 - mse: 0.5297 - val_loss: 0.4856 - val_mse: 0.4779\n",
      "Epoch 82/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5400 - mse: 0.5323 - val_loss: 0.4841 - val_mse: 0.4764\n",
      "Epoch 83/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5339 - mse: 0.5262 - val_loss: 0.4880 - val_mse: 0.4803\n",
      "Epoch 84/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5411 - mse: 0.5334 - val_loss: 0.4858 - val_mse: 0.4781\n",
      "Epoch 85/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5367 - mse: 0.5290 - val_loss: 0.4829 - val_mse: 0.4752\n",
      "Epoch 86/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5406 - mse: 0.5329 - val_loss: 0.4791 - val_mse: 0.4714\n",
      "Epoch 87/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5370 - mse: 0.5293 - val_loss: 0.4967 - val_mse: 0.4890\n",
      "Epoch 88/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5374 - mse: 0.5297 - val_loss: 0.4937 - val_mse: 0.4860\n",
      "Epoch 89/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5368 - mse: 0.5291 - val_loss: 0.4792 - val_mse: 0.4715\n",
      "Epoch 90/1000\n",
      "521/524 [============================>.] - ETA: 0s - loss: 0.5344 - mse: 0.5267\n",
      "Epoch 00090: saving model to Regression_Model/thle2.mse.linear-0090.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5342 - mse: 0.5265 - val_loss: 0.4826 - val_mse: 0.4750\n",
      "Epoch 91/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5376 - mse: 0.5299 - val_loss: 0.4816 - val_mse: 0.4739\n",
      "Epoch 92/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5354 - mse: 0.5277 - val_loss: 0.4778 - val_mse: 0.4701\n",
      "Epoch 93/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5449 - mse: 0.5372 - val_loss: 0.4823 - val_mse: 0.4747\n",
      "Epoch 94/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5322 - mse: 0.5245 - val_loss: 0.4876 - val_mse: 0.4799\n",
      "Epoch 95/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5447 - mse: 0.5370 - val_loss: 0.4816 - val_mse: 0.4739\n",
      "Epoch 96/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5359 - mse: 0.5282 - val_loss: 0.4803 - val_mse: 0.4726\n",
      "Epoch 97/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5298 - mse: 0.5221 - val_loss: 0.4765 - val_mse: 0.4689\n",
      "Epoch 98/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5305 - mse: 0.5228 - val_loss: 0.4834 - val_mse: 0.4758\n",
      "Epoch 99/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5351 - mse: 0.5274 - val_loss: 0.4915 - val_mse: 0.4838\n",
      "Epoch 100/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5340 - mse: 0.5264\n",
      "Epoch 00100: saving model to Regression_Model/thle2.mse.linear-0100.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5340 - mse: 0.5263 - val_loss: 0.4776 - val_mse: 0.4699\n",
      "Epoch 101/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5379 - mse: 0.5302 - val_loss: 0.4842 - val_mse: 0.4766\n",
      "Epoch 102/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5404 - mse: 0.5328 - val_loss: 0.4906 - val_mse: 0.4830\n",
      "Epoch 103/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5422 - mse: 0.5346 - val_loss: 0.4822 - val_mse: 0.4745\n",
      "Epoch 104/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5389 - mse: 0.5313 - val_loss: 0.4769 - val_mse: 0.4693\n",
      "Epoch 105/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5356 - mse: 0.5280 - val_loss: 0.4926 - val_mse: 0.4850\n",
      "Epoch 106/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5309 - mse: 0.5233 - val_loss: 0.4896 - val_mse: 0.4819\n",
      "Epoch 107/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5334 - mse: 0.5258 - val_loss: 0.4819 - val_mse: 0.4743\n",
      "Epoch 108/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5402 - mse: 0.5325 - val_loss: 0.4837 - val_mse: 0.4761\n",
      "Epoch 109/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5334 - mse: 0.5257 - val_loss: 0.4829 - val_mse: 0.4753\n",
      "Epoch 110/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5359 - mse: 0.5283\n",
      "Epoch 00110: saving model to Regression_Model/thle2.mse.linear-0110.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5364 - mse: 0.5287 - val_loss: 0.4847 - val_mse: 0.4771\n",
      "Epoch 111/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5362 - mse: 0.5286 - val_loss: 0.4818 - val_mse: 0.4742\n",
      "Epoch 112/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5322 - mse: 0.5245 - val_loss: 0.4897 - val_mse: 0.4821\n",
      "Epoch 113/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5468 - mse: 0.5392 - val_loss: 0.4850 - val_mse: 0.4774\n",
      "Epoch 114/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5359 - mse: 0.5283 - val_loss: 0.4810 - val_mse: 0.4734\n",
      "Epoch 115/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5445 - mse: 0.5369 - val_loss: 0.4996 - val_mse: 0.4920\n",
      "Epoch 116/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5375 - mse: 0.5299 - val_loss: 0.4864 - val_mse: 0.4788\n",
      "Epoch 117/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5315 - mse: 0.5239 - val_loss: 0.4753 - val_mse: 0.4677\n",
      "Epoch 118/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5292 - mse: 0.5216 - val_loss: 0.4868 - val_mse: 0.4792\n",
      "Epoch 119/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5333 - mse: 0.5257 - val_loss: 0.4798 - val_mse: 0.4722\n",
      "Epoch 120/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5335 - mse: 0.5259\n",
      "Epoch 00120: saving model to Regression_Model/thle2.mse.linear-0120.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5332 - mse: 0.5256 - val_loss: 0.4826 - val_mse: 0.4751\n",
      "Epoch 121/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5343 - mse: 0.5267 - val_loss: 0.4824 - val_mse: 0.4748\n",
      "Epoch 122/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5392 - mse: 0.5317 - val_loss: 0.4855 - val_mse: 0.4779\n",
      "Epoch 123/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5367 - mse: 0.5291 - val_loss: 0.4886 - val_mse: 0.4810\n",
      "Epoch 124/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5307 - mse: 0.5231 - val_loss: 0.4749 - val_mse: 0.4673\n",
      "Epoch 125/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5387 - mse: 0.5311 - val_loss: 0.4829 - val_mse: 0.4754\n",
      "Epoch 126/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5384 - mse: 0.5308 - val_loss: 0.4798 - val_mse: 0.4723\n",
      "Epoch 127/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5335 - mse: 0.5260 - val_loss: 0.4735 - val_mse: 0.4659\n",
      "Epoch 128/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5335 - mse: 0.5260 - val_loss: 0.4824 - val_mse: 0.4749\n",
      "Epoch 129/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5276 - mse: 0.5200 - val_loss: 0.4793 - val_mse: 0.4717\n",
      "Epoch 130/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5312 - mse: 0.5237\n",
      "Epoch 00130: saving model to Regression_Model/thle2.mse.linear-0130.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5311 - mse: 0.5235 - val_loss: 0.4858 - val_mse: 0.4783\n",
      "Epoch 131/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5381 - mse: 0.5305 - val_loss: 0.4846 - val_mse: 0.4770\n",
      "Epoch 132/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5328 - mse: 0.5252 - val_loss: 0.4848 - val_mse: 0.4773\n",
      "Epoch 133/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5363 - mse: 0.5288 - val_loss: 0.4822 - val_mse: 0.4747\n",
      "Epoch 134/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5351 - mse: 0.5275 - val_loss: 0.4783 - val_mse: 0.4707\n",
      "Epoch 135/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5327 - mse: 0.5251 - val_loss: 0.4916 - val_mse: 0.4840\n",
      "Epoch 136/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5293 - mse: 0.5218 - val_loss: 0.4806 - val_mse: 0.4731\n",
      "Epoch 137/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5329 - mse: 0.5254 - val_loss: 0.4831 - val_mse: 0.4755\n",
      "Epoch 138/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5309 - mse: 0.5234 - val_loss: 0.4813 - val_mse: 0.4738\n",
      "Epoch 139/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5311 - mse: 0.5235 - val_loss: 0.4831 - val_mse: 0.4756\n",
      "Epoch 140/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5280 - mse: 0.5204\n",
      "Epoch 00140: saving model to Regression_Model/thle2.mse.linear-0140.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5280 - mse: 0.5205 - val_loss: 0.4796 - val_mse: 0.4721\n",
      "Epoch 141/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5336 - mse: 0.5261 - val_loss: 0.4879 - val_mse: 0.4804\n",
      "Epoch 142/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5278 - mse: 0.5202 - val_loss: 0.4821 - val_mse: 0.4746\n",
      "Epoch 143/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5326 - mse: 0.5251 - val_loss: 0.4749 - val_mse: 0.4674\n",
      "Epoch 144/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5299 - mse: 0.5224 - val_loss: 0.4775 - val_mse: 0.4700\n",
      "Epoch 145/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5275 - mse: 0.5200 - val_loss: 0.4763 - val_mse: 0.4688\n",
      "Epoch 146/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5343 - mse: 0.5268 - val_loss: 0.4850 - val_mse: 0.4775\n",
      "Epoch 147/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5359 - mse: 0.5284 - val_loss: 0.4908 - val_mse: 0.4833\n",
      "Epoch 148/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5384 - mse: 0.5309 - val_loss: 0.4785 - val_mse: 0.4710\n",
      "Epoch 149/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5329 - mse: 0.5254 - val_loss: 0.4866 - val_mse: 0.4791\n",
      "Epoch 150/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5316 - mse: 0.5242\n",
      "Epoch 00150: saving model to Regression_Model/thle2.mse.linear-0150.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5315 - mse: 0.5240 - val_loss: 0.4939 - val_mse: 0.4864\n",
      "Epoch 151/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5381 - mse: 0.5306 - val_loss: 0.4796 - val_mse: 0.4722\n",
      "Epoch 152/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5287 - mse: 0.5213 - val_loss: 0.4855 - val_mse: 0.4780\n",
      "Epoch 153/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5295 - mse: 0.5221 - val_loss: 0.4909 - val_mse: 0.4835\n",
      "Epoch 154/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5280 - mse: 0.5205 - val_loss: 0.4804 - val_mse: 0.4730\n",
      "Epoch 155/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5332 - mse: 0.5257 - val_loss: 0.4770 - val_mse: 0.4695\n",
      "Epoch 156/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5306 - mse: 0.5231 - val_loss: 0.4797 - val_mse: 0.4722\n",
      "Epoch 157/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5291 - mse: 0.5217 - val_loss: 0.4778 - val_mse: 0.4703\n",
      "Epoch 158/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5307 - mse: 0.5233 - val_loss: 0.4768 - val_mse: 0.4694\n",
      "Epoch 159/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5342 - mse: 0.5267 - val_loss: 0.4743 - val_mse: 0.4668\n",
      "Epoch 160/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5341 - mse: 0.5267\n",
      "Epoch 00160: saving model to Regression_Model/thle2.mse.linear-0160.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5338 - mse: 0.5264 - val_loss: 0.4786 - val_mse: 0.4711\n",
      "Epoch 161/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5305 - mse: 0.5231 - val_loss: 0.4826 - val_mse: 0.4751\n",
      "Epoch 162/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5286 - mse: 0.5212 - val_loss: 0.4794 - val_mse: 0.4720\n",
      "Epoch 163/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5327 - mse: 0.5253 - val_loss: 0.4813 - val_mse: 0.4739\n",
      "Epoch 164/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5357 - mse: 0.5282 - val_loss: 0.4736 - val_mse: 0.4662\n",
      "Epoch 165/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5263 - mse: 0.5189 - val_loss: 0.4798 - val_mse: 0.4724\n",
      "Epoch 166/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5283 - mse: 0.5209 - val_loss: 0.4785 - val_mse: 0.4711\n",
      "Epoch 167/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5319 - mse: 0.5245 - val_loss: 0.4800 - val_mse: 0.4726\n",
      "Epoch 168/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5316 - mse: 0.5242 - val_loss: 0.4809 - val_mse: 0.4735\n",
      "Epoch 169/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5318 - mse: 0.5244 - val_loss: 0.4873 - val_mse: 0.4799\n",
      "Epoch 170/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5306 - mse: 0.5232\n",
      "Epoch 00170: saving model to Regression_Model/thle2.mse.linear-0170.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5309 - mse: 0.5235 - val_loss: 0.4752 - val_mse: 0.4678\n",
      "Epoch 171/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5305 - mse: 0.5231 - val_loss: 0.4820 - val_mse: 0.4746\n",
      "Epoch 172/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5344 - mse: 0.5270 - val_loss: 0.4848 - val_mse: 0.4774\n",
      "Epoch 173/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5265 - mse: 0.5191 - val_loss: 0.4780 - val_mse: 0.4706\n",
      "Epoch 174/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5385 - mse: 0.5311 - val_loss: 0.4777 - val_mse: 0.4703\n",
      "Epoch 175/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5284 - mse: 0.5210 - val_loss: 0.4881 - val_mse: 0.4807\n",
      "Epoch 176/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5394 - mse: 0.5321 - val_loss: 0.4992 - val_mse: 0.4918\n",
      "Epoch 177/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5369 - mse: 0.5295 - val_loss: 0.4862 - val_mse: 0.4788\n",
      "Epoch 178/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5338 - mse: 0.5264 - val_loss: 0.4835 - val_mse: 0.4761\n",
      "Epoch 179/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5313 - mse: 0.5239 - val_loss: 0.4843 - val_mse: 0.4769\n",
      "Epoch 180/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5320 - mse: 0.5246\n",
      "Epoch 00180: saving model to Regression_Model/thle2.mse.linear-0180.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5323 - mse: 0.5249 - val_loss: 0.4778 - val_mse: 0.4704\n",
      "Epoch 181/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5287 - mse: 0.5213 - val_loss: 0.4900 - val_mse: 0.4826\n",
      "Epoch 182/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5271 - mse: 0.5197 - val_loss: 0.4762 - val_mse: 0.4688\n",
      "Epoch 183/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5273 - mse: 0.5200 - val_loss: 0.4864 - val_mse: 0.4790\n",
      "Epoch 184/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5289 - mse: 0.5215 - val_loss: 0.4795 - val_mse: 0.4721\n",
      "Epoch 185/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5305 - mse: 0.5232 - val_loss: 0.4785 - val_mse: 0.4711\n",
      "Epoch 186/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5362 - mse: 0.5288 - val_loss: 0.4767 - val_mse: 0.4693\n",
      "Epoch 187/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5296 - mse: 0.5223 - val_loss: 0.4885 - val_mse: 0.4812\n",
      "Epoch 188/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5370 - mse: 0.5296 - val_loss: 0.4817 - val_mse: 0.4743\n",
      "Epoch 189/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5325 - mse: 0.5252 - val_loss: 0.4776 - val_mse: 0.4703\n",
      "Epoch 190/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5291 - mse: 0.5217\n",
      "Epoch 00190: saving model to Regression_Model/thle2.mse.linear-0190.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5300 - mse: 0.5227 - val_loss: 0.4886 - val_mse: 0.4812\n",
      "Epoch 191/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5333 - mse: 0.5260 - val_loss: 0.4834 - val_mse: 0.4760\n",
      "Epoch 192/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5313 - mse: 0.5239 - val_loss: 0.4848 - val_mse: 0.4774\n",
      "Epoch 193/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5349 - mse: 0.5276 - val_loss: 0.4762 - val_mse: 0.4689\n",
      "Epoch 194/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5312 - mse: 0.5239 - val_loss: 0.4844 - val_mse: 0.4771\n",
      "Epoch 195/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5281 - mse: 0.5208 - val_loss: 0.4754 - val_mse: 0.4681\n",
      "Epoch 196/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5324 - mse: 0.5250 - val_loss: 0.4790 - val_mse: 0.4717\n",
      "Epoch 197/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5298 - mse: 0.5225 - val_loss: 0.4847 - val_mse: 0.4774\n",
      "Epoch 198/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5251 - mse: 0.5178 - val_loss: 0.4784 - val_mse: 0.4711\n",
      "Epoch 199/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5291 - mse: 0.5218 - val_loss: 0.4797 - val_mse: 0.4724\n",
      "Epoch 200/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5306 - mse: 0.5233\n",
      "Epoch 00200: saving model to Regression_Model/thle2.mse.linear-0200.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5305 - mse: 0.5232 - val_loss: 0.4790 - val_mse: 0.4717\n",
      "Epoch 201/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5265 - mse: 0.5191 - val_loss: 0.4796 - val_mse: 0.4723\n",
      "Epoch 202/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5321 - mse: 0.5248 - val_loss: 0.4771 - val_mse: 0.4698\n",
      "Epoch 203/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5367 - mse: 0.5294 - val_loss: 0.4790 - val_mse: 0.4717\n",
      "Epoch 204/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5305 - mse: 0.5232 - val_loss: 0.4822 - val_mse: 0.4749\n",
      "Epoch 205/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5280 - mse: 0.5207 - val_loss: 0.4816 - val_mse: 0.4743\n",
      "Epoch 206/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5304 - mse: 0.5231 - val_loss: 0.4828 - val_mse: 0.4755\n",
      "Epoch 207/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5288 - mse: 0.5215 - val_loss: 0.4829 - val_mse: 0.4756\n",
      "Epoch 208/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5295 - mse: 0.5222 - val_loss: 0.4778 - val_mse: 0.4706\n",
      "Epoch 209/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5285 - mse: 0.5212 - val_loss: 0.4854 - val_mse: 0.4781\n",
      "Epoch 210/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5265 - mse: 0.5193\n",
      "Epoch 00210: saving model to Regression_Model/thle2.mse.linear-0210.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5270 - mse: 0.5197 - val_loss: 0.4913 - val_mse: 0.4840\n",
      "Epoch 211/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5278 - mse: 0.5205 - val_loss: 0.4904 - val_mse: 0.4831\n",
      "Epoch 212/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5234 - mse: 0.5161 - val_loss: 0.4760 - val_mse: 0.4688\n",
      "Epoch 213/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5264 - mse: 0.5191 - val_loss: 0.4851 - val_mse: 0.4778\n",
      "Epoch 214/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5353 - mse: 0.5280 - val_loss: 0.4806 - val_mse: 0.4733\n",
      "Epoch 215/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5261 - mse: 0.5189 - val_loss: 0.4783 - val_mse: 0.4711\n",
      "Epoch 216/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5292 - mse: 0.5220 - val_loss: 0.4765 - val_mse: 0.4693\n",
      "Epoch 217/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5297 - mse: 0.5224 - val_loss: 0.4824 - val_mse: 0.4751\n",
      "Epoch 218/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5280 - mse: 0.5208 - val_loss: 0.4859 - val_mse: 0.4786\n",
      "Epoch 219/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5285 - mse: 0.5213 - val_loss: 0.4760 - val_mse: 0.4688\n",
      "Epoch 220/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5214 - mse: 0.5141\n",
      "Epoch 00220: saving model to Regression_Model/thle2.mse.linear-0220.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5212 - mse: 0.5139 - val_loss: 0.4759 - val_mse: 0.4687\n",
      "Epoch 221/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5261 - mse: 0.5189 - val_loss: 0.4765 - val_mse: 0.4692\n",
      "Epoch 222/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5280 - mse: 0.5207 - val_loss: 0.4803 - val_mse: 0.4731\n",
      "Epoch 223/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5232 - mse: 0.5160 - val_loss: 0.4817 - val_mse: 0.4745\n",
      "Epoch 224/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5323 - mse: 0.5250 - val_loss: 0.4783 - val_mse: 0.4711\n",
      "Epoch 225/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5204 - mse: 0.5131 - val_loss: 0.4821 - val_mse: 0.4749\n",
      "Epoch 226/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5252 - mse: 0.5180 - val_loss: 0.4867 - val_mse: 0.4795\n",
      "Epoch 227/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5249 - mse: 0.5177 - val_loss: 0.4924 - val_mse: 0.4852\n",
      "Epoch 228/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5262 - mse: 0.5190 - val_loss: 0.4762 - val_mse: 0.4690\n",
      "Epoch 229/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5280 - mse: 0.5208 - val_loss: 0.4754 - val_mse: 0.4682\n",
      "Epoch 230/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5288 - mse: 0.5216\n",
      "Epoch 00230: saving model to Regression_Model/thle2.mse.linear-0230.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5288 - mse: 0.5216 - val_loss: 0.4811 - val_mse: 0.4739\n",
      "Epoch 231/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5303 - mse: 0.5231 - val_loss: 0.4796 - val_mse: 0.4724\n",
      "Epoch 232/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5299 - mse: 0.5227 - val_loss: 0.4747 - val_mse: 0.4675\n",
      "Epoch 233/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5286 - mse: 0.5214 - val_loss: 0.4770 - val_mse: 0.4698\n",
      "Epoch 234/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5196 - mse: 0.5124 - val_loss: 0.4736 - val_mse: 0.4664\n",
      "Epoch 235/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5269 - mse: 0.5197 - val_loss: 0.4823 - val_mse: 0.4751\n",
      "Epoch 236/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5257 - mse: 0.5185 - val_loss: 0.4799 - val_mse: 0.4727\n",
      "Epoch 237/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5282 - mse: 0.5210 - val_loss: 0.4773 - val_mse: 0.4701\n",
      "Epoch 238/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5300 - mse: 0.5228 - val_loss: 0.4805 - val_mse: 0.4733\n",
      "Epoch 239/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5284 - mse: 0.5212 - val_loss: 0.4788 - val_mse: 0.4716\n",
      "Epoch 240/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5220 - mse: 0.5148\n",
      "Epoch 00240: saving model to Regression_Model/thle2.mse.linear-0240.ckpt\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5213 - mse: 0.5141 - val_loss: 0.4820 - val_mse: 0.4748\n",
      "Epoch 241/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5311 - mse: 0.5239 - val_loss: 0.4806 - val_mse: 0.4734\n",
      "Epoch 242/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5254 - mse: 0.5182 - val_loss: 0.4743 - val_mse: 0.4671\n",
      "Epoch 243/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5269 - mse: 0.5197 - val_loss: 0.4764 - val_mse: 0.4692\n",
      "Epoch 244/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5263 - mse: 0.5192 - val_loss: 0.4805 - val_mse: 0.4734\n",
      "Epoch 245/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5278 - mse: 0.5206 - val_loss: 0.4780 - val_mse: 0.4708\n",
      "Epoch 246/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5246 - mse: 0.5174 - val_loss: 0.4790 - val_mse: 0.4719\n",
      "Epoch 247/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5240 - mse: 0.5168 - val_loss: 0.4825 - val_mse: 0.4753\n",
      "Epoch 248/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5254 - mse: 0.5182 - val_loss: 0.4807 - val_mse: 0.4736\n",
      "Epoch 249/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5274 - mse: 0.5202 - val_loss: 0.4748 - val_mse: 0.4677\n",
      "Epoch 250/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5252 - mse: 0.5181\n",
      "Epoch 00250: saving model to Regression_Model/thle2.mse.linear-0250.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5257 - mse: 0.5186 - val_loss: 0.4749 - val_mse: 0.4677\n",
      "Epoch 251/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5281 - mse: 0.5210 - val_loss: 0.4750 - val_mse: 0.4679\n",
      "Epoch 252/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5289 - mse: 0.5218 - val_loss: 0.4904 - val_mse: 0.4832\n",
      "Epoch 253/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5252 - mse: 0.5181 - val_loss: 0.4771 - val_mse: 0.4700\n",
      "Epoch 254/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5273 - mse: 0.5201 - val_loss: 0.4724 - val_mse: 0.4653\n",
      "Epoch 255/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5255 - mse: 0.5183 - val_loss: 0.4778 - val_mse: 0.4707\n",
      "Epoch 256/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5281 - mse: 0.5210 - val_loss: 0.4812 - val_mse: 0.4741\n",
      "Epoch 257/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5277 - mse: 0.5205 - val_loss: 0.4787 - val_mse: 0.4715\n",
      "Epoch 258/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5260 - mse: 0.5189 - val_loss: 0.4811 - val_mse: 0.4739\n",
      "Epoch 259/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5250 - mse: 0.5179 - val_loss: 0.4832 - val_mse: 0.4761\n",
      "Epoch 260/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5225 - mse: 0.5154\n",
      "Epoch 00260: saving model to Regression_Model/thle2.mse.linear-0260.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5225 - mse: 0.5154 - val_loss: 0.4758 - val_mse: 0.4686\n",
      "Epoch 261/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5244 - mse: 0.5173 - val_loss: 0.4777 - val_mse: 0.4706\n",
      "Epoch 262/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5245 - mse: 0.5174 - val_loss: 0.4778 - val_mse: 0.4707\n",
      "Epoch 263/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5266 - mse: 0.5195 - val_loss: 0.4769 - val_mse: 0.4698\n",
      "Epoch 264/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5248 - mse: 0.5177 - val_loss: 0.4801 - val_mse: 0.4730\n",
      "Epoch 265/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5286 - mse: 0.5215 - val_loss: 0.4788 - val_mse: 0.4717\n",
      "Epoch 266/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5302 - mse: 0.5231 - val_loss: 0.4819 - val_mse: 0.4748\n",
      "Epoch 267/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5353 - mse: 0.5282 - val_loss: 0.4769 - val_mse: 0.4698\n",
      "Epoch 268/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5269 - mse: 0.5198 - val_loss: 0.4896 - val_mse: 0.4825\n",
      "Epoch 269/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5264 - mse: 0.5193 - val_loss: 0.4753 - val_mse: 0.4682\n",
      "Epoch 270/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5218 - mse: 0.5147\n",
      "Epoch 00270: saving model to Regression_Model/thle2.mse.linear-0270.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5217 - mse: 0.5146 - val_loss: 0.4762 - val_mse: 0.4691\n",
      "Epoch 271/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5277 - mse: 0.5206 - val_loss: 0.4792 - val_mse: 0.4721\n",
      "Epoch 272/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5271 - mse: 0.5200 - val_loss: 0.4739 - val_mse: 0.4668\n",
      "Epoch 273/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5217 - mse: 0.5146 - val_loss: 0.4771 - val_mse: 0.4700\n",
      "Epoch 274/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5266 - mse: 0.5195 - val_loss: 0.4807 - val_mse: 0.4736\n",
      "Epoch 275/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5259 - mse: 0.5188 - val_loss: 0.4798 - val_mse: 0.4727\n",
      "Epoch 276/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5291 - mse: 0.5220 - val_loss: 0.4811 - val_mse: 0.4740\n",
      "Epoch 277/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5218 - mse: 0.5147 - val_loss: 0.4810 - val_mse: 0.4739\n",
      "Epoch 278/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5254 - mse: 0.5183 - val_loss: 0.4744 - val_mse: 0.4674\n",
      "Epoch 279/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5311 - mse: 0.5241 - val_loss: 0.4799 - val_mse: 0.4728\n",
      "Epoch 280/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5247 - mse: 0.5176\n",
      "Epoch 00280: saving model to Regression_Model/thle2.mse.linear-0280.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5247 - mse: 0.5177 - val_loss: 0.4737 - val_mse: 0.4667\n",
      "Epoch 281/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5265 - mse: 0.5194 - val_loss: 0.4837 - val_mse: 0.4767\n",
      "Epoch 282/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5277 - mse: 0.5207 - val_loss: 0.4753 - val_mse: 0.4683\n",
      "Epoch 283/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5167 - val_loss: 0.4770 - val_mse: 0.4699\n",
      "Epoch 284/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5232 - mse: 0.5161 - val_loss: 0.4827 - val_mse: 0.4756\n",
      "Epoch 285/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5211 - mse: 0.5140 - val_loss: 0.4753 - val_mse: 0.4683\n",
      "Epoch 286/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5247 - mse: 0.5176 - val_loss: 0.4762 - val_mse: 0.4691\n",
      "Epoch 287/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5240 - mse: 0.5169 - val_loss: 0.4823 - val_mse: 0.4752\n",
      "Epoch 288/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5231 - mse: 0.5161 - val_loss: 0.4737 - val_mse: 0.4666\n",
      "Epoch 289/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5260 - mse: 0.5189 - val_loss: 0.4787 - val_mse: 0.4717\n",
      "Epoch 290/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5277 - mse: 0.5206\n",
      "Epoch 00290: saving model to Regression_Model/thle2.mse.linear-0290.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5277 - mse: 0.5207 - val_loss: 0.4775 - val_mse: 0.4704\n",
      "Epoch 291/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5246 - mse: 0.5176 - val_loss: 0.4893 - val_mse: 0.4823\n",
      "Epoch 292/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5285 - mse: 0.5215 - val_loss: 0.4786 - val_mse: 0.4716\n",
      "Epoch 293/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5294 - mse: 0.5223 - val_loss: 0.4836 - val_mse: 0.4766\n",
      "Epoch 294/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5273 - mse: 0.5203 - val_loss: 0.4795 - val_mse: 0.4725\n",
      "Epoch 295/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5232 - mse: 0.5162 - val_loss: 0.4751 - val_mse: 0.4681\n",
      "Epoch 296/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5193 - mse: 0.5122 - val_loss: 0.4740 - val_mse: 0.4670\n",
      "Epoch 297/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5274 - mse: 0.5204 - val_loss: 0.4764 - val_mse: 0.4694\n",
      "Epoch 298/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5304 - mse: 0.5234 - val_loss: 0.4879 - val_mse: 0.4809\n",
      "Epoch 299/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5303 - mse: 0.5233 - val_loss: 0.4766 - val_mse: 0.4696\n",
      "Epoch 300/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5167 - mse: 0.5097\n",
      "Epoch 00300: saving model to Regression_Model/thle2.mse.linear-0300.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5168 - mse: 0.5098 - val_loss: 0.4767 - val_mse: 0.4697\n",
      "Epoch 301/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5292 - mse: 0.5222 - val_loss: 0.4802 - val_mse: 0.4732\n",
      "Epoch 302/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5277 - mse: 0.5208 - val_loss: 0.4780 - val_mse: 0.4710\n",
      "Epoch 303/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5168 - val_loss: 0.4799 - val_mse: 0.4729\n",
      "Epoch 304/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5243 - mse: 0.5173 - val_loss: 0.4791 - val_mse: 0.4721\n",
      "Epoch 305/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5255 - mse: 0.5185 - val_loss: 0.4853 - val_mse: 0.4783\n",
      "Epoch 306/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5218 - mse: 0.5148 - val_loss: 0.4786 - val_mse: 0.4716\n",
      "Epoch 307/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5168 - val_loss: 0.4769 - val_mse: 0.4699\n",
      "Epoch 308/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5233 - mse: 0.5163 - val_loss: 0.4814 - val_mse: 0.4744\n",
      "Epoch 309/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5270 - mse: 0.5200 - val_loss: 0.4824 - val_mse: 0.4754\n",
      "Epoch 310/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5222 - mse: 0.5152\n",
      "Epoch 00310: saving model to Regression_Model/thle2.mse.linear-0310.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5223 - mse: 0.5153 - val_loss: 0.4793 - val_mse: 0.4724\n",
      "Epoch 311/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5226 - mse: 0.5156 - val_loss: 0.4833 - val_mse: 0.4763\n",
      "Epoch 312/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5281 - mse: 0.5211 - val_loss: 0.4748 - val_mse: 0.4679\n",
      "Epoch 313/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5205 - mse: 0.5136 - val_loss: 0.4835 - val_mse: 0.4765\n",
      "Epoch 314/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5235 - mse: 0.5166 - val_loss: 0.4798 - val_mse: 0.4729\n",
      "Epoch 315/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5244 - mse: 0.5175 - val_loss: 0.4767 - val_mse: 0.4697\n",
      "Epoch 316/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5205 - mse: 0.5136 - val_loss: 0.4819 - val_mse: 0.4749\n",
      "Epoch 317/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5225 - mse: 0.5156 - val_loss: 0.4785 - val_mse: 0.4715\n",
      "Epoch 318/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5236 - mse: 0.5167 - val_loss: 0.4759 - val_mse: 0.4689\n",
      "Epoch 319/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5258 - mse: 0.5188 - val_loss: 0.4799 - val_mse: 0.4730\n",
      "Epoch 320/1000\n",
      "516/524 [============================>.] - ETA: 0s - loss: 0.5241 - mse: 0.5172\n",
      "Epoch 00320: saving model to Regression_Model/thle2.mse.linear-0320.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5242 - mse: 0.5173 - val_loss: 0.4818 - val_mse: 0.4749\n",
      "Epoch 321/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5220 - mse: 0.5151 - val_loss: 0.4835 - val_mse: 0.4765\n",
      "Epoch 322/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5261 - mse: 0.5192 - val_loss: 0.4747 - val_mse: 0.4678\n",
      "Epoch 323/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5258 - mse: 0.5189 - val_loss: 0.4886 - val_mse: 0.4816\n",
      "Epoch 324/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5201 - mse: 0.5132 - val_loss: 0.4757 - val_mse: 0.4688\n",
      "Epoch 325/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5208 - mse: 0.5139 - val_loss: 0.4740 - val_mse: 0.4671\n",
      "Epoch 326/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5261 - mse: 0.5192 - val_loss: 0.4750 - val_mse: 0.4680\n",
      "Epoch 327/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5282 - mse: 0.5213 - val_loss: 0.4785 - val_mse: 0.4716\n",
      "Epoch 328/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5184 - mse: 0.5114 - val_loss: 0.4739 - val_mse: 0.4670\n",
      "Epoch 329/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5246 - mse: 0.5177 - val_loss: 0.4753 - val_mse: 0.4684\n",
      "Epoch 330/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5245 - mse: 0.5175\n",
      "Epoch 00330: saving model to Regression_Model/thle2.mse.linear-0330.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5252 - mse: 0.5183 - val_loss: 0.4789 - val_mse: 0.4720\n",
      "Epoch 331/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5291 - mse: 0.5222 - val_loss: 0.4778 - val_mse: 0.4709\n",
      "Epoch 332/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5220 - mse: 0.5151 - val_loss: 0.4801 - val_mse: 0.4732\n",
      "Epoch 333/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5257 - mse: 0.5188 - val_loss: 0.4808 - val_mse: 0.4739\n",
      "Epoch 334/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5246 - mse: 0.5177 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 335/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5189 - mse: 0.5120 - val_loss: 0.4785 - val_mse: 0.4716\n",
      "Epoch 336/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5180 - mse: 0.5111 - val_loss: 0.4771 - val_mse: 0.4703\n",
      "Epoch 337/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5230 - mse: 0.5161 - val_loss: 0.4794 - val_mse: 0.4725\n",
      "Epoch 338/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5209 - mse: 0.5141 - val_loss: 0.4791 - val_mse: 0.4722\n",
      "Epoch 339/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5236 - mse: 0.5168 - val_loss: 0.4771 - val_mse: 0.4702\n",
      "Epoch 340/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5203 - mse: 0.5135\n",
      "Epoch 00340: saving model to Regression_Model/thle2.mse.linear-0340.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5206 - mse: 0.5137 - val_loss: 0.4763 - val_mse: 0.4695\n",
      "Epoch 341/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5208 - mse: 0.5139 - val_loss: 0.4813 - val_mse: 0.4744\n",
      "Epoch 342/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5218 - mse: 0.5149 - val_loss: 0.4715 - val_mse: 0.4646\n",
      "Epoch 343/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5211 - mse: 0.5142 - val_loss: 0.4787 - val_mse: 0.4719\n",
      "Epoch 344/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5160 - mse: 0.5092 - val_loss: 0.4795 - val_mse: 0.4726\n",
      "Epoch 345/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5223 - mse: 0.5154 - val_loss: 0.4774 - val_mse: 0.4705\n",
      "Epoch 346/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5214 - mse: 0.5146 - val_loss: 0.4762 - val_mse: 0.4693\n",
      "Epoch 347/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5251 - mse: 0.5183 - val_loss: 0.4749 - val_mse: 0.4680\n",
      "Epoch 348/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5169 - val_loss: 0.4774 - val_mse: 0.4706\n",
      "Epoch 349/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5269 - mse: 0.5201 - val_loss: 0.4811 - val_mse: 0.4742\n",
      "Epoch 350/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5265 - mse: 0.5197\n",
      "Epoch 00350: saving model to Regression_Model/thle2.mse.linear-0350.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5265 - mse: 0.5196 - val_loss: 0.4798 - val_mse: 0.4730\n",
      "Epoch 351/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5281 - mse: 0.5213 - val_loss: 0.4818 - val_mse: 0.4749\n",
      "Epoch 352/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5249 - mse: 0.5180 - val_loss: 0.4750 - val_mse: 0.4681\n",
      "Epoch 353/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5204 - mse: 0.5136 - val_loss: 0.4737 - val_mse: 0.4668\n",
      "Epoch 354/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5223 - mse: 0.5155 - val_loss: 0.4724 - val_mse: 0.4656\n",
      "Epoch 355/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5207 - mse: 0.5139 - val_loss: 0.4742 - val_mse: 0.4674\n",
      "Epoch 356/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5260 - mse: 0.5192 - val_loss: 0.4746 - val_mse: 0.4678\n",
      "Epoch 357/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5265 - mse: 0.5197 - val_loss: 0.4759 - val_mse: 0.4691\n",
      "Epoch 358/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5225 - mse: 0.5157 - val_loss: 0.4770 - val_mse: 0.4702\n",
      "Epoch 359/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5242 - mse: 0.5174 - val_loss: 0.4795 - val_mse: 0.4726\n",
      "Epoch 360/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5200 - mse: 0.5132\n",
      "Epoch 00360: saving model to Regression_Model/thle2.mse.linear-0360.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5208 - mse: 0.5140 - val_loss: 0.4757 - val_mse: 0.4689\n",
      "Epoch 361/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5201 - mse: 0.5132 - val_loss: 0.4812 - val_mse: 0.4743\n",
      "Epoch 362/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5212 - mse: 0.5144 - val_loss: 0.4893 - val_mse: 0.4825\n",
      "Epoch 363/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5237 - mse: 0.5169 - val_loss: 0.4756 - val_mse: 0.4687\n",
      "Epoch 364/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5215 - mse: 0.5147 - val_loss: 0.4810 - val_mse: 0.4742\n",
      "Epoch 365/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5237 - mse: 0.5169 - val_loss: 0.4788 - val_mse: 0.4720\n",
      "Epoch 366/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5140 - mse: 0.5072 - val_loss: 0.4781 - val_mse: 0.4713\n",
      "Epoch 367/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5232 - mse: 0.5164 - val_loss: 0.4754 - val_mse: 0.4686\n",
      "Epoch 368/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5216 - mse: 0.5148 - val_loss: 0.4816 - val_mse: 0.4748\n",
      "Epoch 369/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5185 - mse: 0.5117 - val_loss: 0.4775 - val_mse: 0.4707\n",
      "Epoch 370/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5163 - mse: 0.5095\n",
      "Epoch 00370: saving model to Regression_Model/thle2.mse.linear-0370.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5164 - mse: 0.5096 - val_loss: 0.4794 - val_mse: 0.4726\n",
      "Epoch 371/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5232 - mse: 0.5164 - val_loss: 0.4741 - val_mse: 0.4673\n",
      "Epoch 372/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5271 - mse: 0.5203 - val_loss: 0.4737 - val_mse: 0.4669\n",
      "Epoch 373/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5209 - mse: 0.5141 - val_loss: 0.4794 - val_mse: 0.4726\n",
      "Epoch 374/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5226 - mse: 0.5158 - val_loss: 0.4786 - val_mse: 0.4718\n",
      "Epoch 375/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5196 - mse: 0.5128 - val_loss: 0.4727 - val_mse: 0.4660\n",
      "Epoch 376/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5232 - mse: 0.5164 - val_loss: 0.4723 - val_mse: 0.4656\n",
      "Epoch 377/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5201 - mse: 0.5134 - val_loss: 0.4733 - val_mse: 0.4665\n",
      "Epoch 378/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5188 - mse: 0.5120 - val_loss: 0.4821 - val_mse: 0.4753\n",
      "Epoch 379/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5247 - mse: 0.5179 - val_loss: 0.4811 - val_mse: 0.4743\n",
      "Epoch 380/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5205 - mse: 0.5138\n",
      "Epoch 00380: saving model to Regression_Model/thle2.mse.linear-0380.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5203 - mse: 0.5135 - val_loss: 0.4721 - val_mse: 0.4653\n",
      "Epoch 381/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5254 - mse: 0.5186 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 382/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5198 - mse: 0.5130 - val_loss: 0.4735 - val_mse: 0.4668\n",
      "Epoch 383/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5252 - mse: 0.5184 - val_loss: 0.4812 - val_mse: 0.4744\n",
      "Epoch 384/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5248 - mse: 0.5180 - val_loss: 0.4785 - val_mse: 0.4717\n",
      "Epoch 385/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5214 - mse: 0.5146 - val_loss: 0.4821 - val_mse: 0.4753\n",
      "Epoch 386/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5175 - mse: 0.5108 - val_loss: 0.4781 - val_mse: 0.4714\n",
      "Epoch 387/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5243 - mse: 0.5176 - val_loss: 0.4771 - val_mse: 0.4704\n",
      "Epoch 388/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5203 - mse: 0.5136 - val_loss: 0.4750 - val_mse: 0.4682\n",
      "Epoch 389/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5160 - mse: 0.5092 - val_loss: 0.4806 - val_mse: 0.4739\n",
      "Epoch 390/1000\n",
      "516/524 [============================>.] - ETA: 0s - loss: 0.5208 - mse: 0.5141\n",
      "Epoch 00390: saving model to Regression_Model/thle2.mse.linear-0390.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5216 - mse: 0.5149 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 391/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5204 - mse: 0.5137 - val_loss: 0.4742 - val_mse: 0.4675\n",
      "Epoch 392/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5200 - mse: 0.5133 - val_loss: 0.4760 - val_mse: 0.4692\n",
      "Epoch 393/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5183 - mse: 0.5115 - val_loss: 0.4762 - val_mse: 0.4695\n",
      "Epoch 394/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5244 - mse: 0.5176 - val_loss: 0.4816 - val_mse: 0.4749\n",
      "Epoch 395/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5223 - mse: 0.5156 - val_loss: 0.4730 - val_mse: 0.4663\n",
      "Epoch 396/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5206 - mse: 0.5139 - val_loss: 0.4764 - val_mse: 0.4697\n",
      "Epoch 397/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5195 - mse: 0.5128 - val_loss: 0.4761 - val_mse: 0.4694\n",
      "Epoch 398/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5172 - mse: 0.5104 - val_loss: 0.4813 - val_mse: 0.4746\n",
      "Epoch 399/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5216 - mse: 0.5149 - val_loss: 0.4765 - val_mse: 0.4697\n",
      "Epoch 400/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5185 - mse: 0.5118\n",
      "Epoch 00400: saving model to Regression_Model/thle2.mse.linear-0400.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5185 - mse: 0.5118 - val_loss: 0.4768 - val_mse: 0.4701\n",
      "Epoch 401/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5220 - mse: 0.5153 - val_loss: 0.4728 - val_mse: 0.4661\n",
      "Epoch 402/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5169 - mse: 0.5102 - val_loss: 0.4778 - val_mse: 0.4711\n",
      "Epoch 403/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5167 - mse: 0.5100 - val_loss: 0.4805 - val_mse: 0.4738\n",
      "Epoch 404/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5224 - mse: 0.5157 - val_loss: 0.4801 - val_mse: 0.4734\n",
      "Epoch 405/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5216 - mse: 0.5149 - val_loss: 0.4763 - val_mse: 0.4696\n",
      "Epoch 406/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5195 - mse: 0.5128 - val_loss: 0.4797 - val_mse: 0.4730\n",
      "Epoch 407/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5214 - mse: 0.5147 - val_loss: 0.4724 - val_mse: 0.4657\n",
      "Epoch 408/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5238 - mse: 0.5172 - val_loss: 0.4767 - val_mse: 0.4700\n",
      "Epoch 409/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5221 - mse: 0.5154 - val_loss: 0.4746 - val_mse: 0.4679\n",
      "Epoch 410/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5165 - mse: 0.5098\n",
      "Epoch 00410: saving model to Regression_Model/thle2.mse.linear-0410.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5166 - mse: 0.5100 - val_loss: 0.4783 - val_mse: 0.4716\n",
      "Epoch 411/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5166 - mse: 0.5099 - val_loss: 0.4782 - val_mse: 0.4716\n",
      "Epoch 412/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5258 - mse: 0.5192 - val_loss: 0.4736 - val_mse: 0.4670\n",
      "Epoch 413/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5171 - mse: 0.5104 - val_loss: 0.4722 - val_mse: 0.4655\n",
      "Epoch 414/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5167 - mse: 0.5100 - val_loss: 0.4793 - val_mse: 0.4726\n",
      "Epoch 415/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5198 - mse: 0.5131 - val_loss: 0.4787 - val_mse: 0.4720\n",
      "Epoch 416/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5224 - mse: 0.5157 - val_loss: 0.4778 - val_mse: 0.4711\n",
      "Epoch 417/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5263 - mse: 0.5197 - val_loss: 0.4792 - val_mse: 0.4726\n",
      "Epoch 418/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5238 - mse: 0.5171 - val_loss: 0.4728 - val_mse: 0.4662\n",
      "Epoch 419/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5212 - mse: 0.5145 - val_loss: 0.4767 - val_mse: 0.4700\n",
      "Epoch 420/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5206 - mse: 0.5140\n",
      "Epoch 00420: saving model to Regression_Model/thle2.mse.linear-0420.ckpt\n",
      "524/524 [==============================] - 4s 8ms/step - loss: 0.5210 - mse: 0.5143 - val_loss: 0.4722 - val_mse: 0.4655\n",
      "Epoch 421/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5174 - mse: 0.5107 - val_loss: 0.4748 - val_mse: 0.4681\n",
      "Epoch 422/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5249 - mse: 0.5182 - val_loss: 0.4777 - val_mse: 0.4710\n",
      "Epoch 423/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5209 - mse: 0.5142 - val_loss: 0.4781 - val_mse: 0.4714\n",
      "Epoch 424/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5159 - mse: 0.5093 - val_loss: 0.4763 - val_mse: 0.4697\n",
      "Epoch 425/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5197 - mse: 0.5131 - val_loss: 0.4733 - val_mse: 0.4666\n",
      "Epoch 426/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5237 - mse: 0.5171 - val_loss: 0.4785 - val_mse: 0.4719\n",
      "Epoch 427/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5214 - mse: 0.5148 - val_loss: 0.4742 - val_mse: 0.4675\n",
      "Epoch 428/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5198 - mse: 0.5131 - val_loss: 0.4748 - val_mse: 0.4682\n",
      "Epoch 429/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5202 - mse: 0.5136 - val_loss: 0.4768 - val_mse: 0.4701\n",
      "Epoch 430/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5195 - mse: 0.5129\n",
      "Epoch 00430: saving model to Regression_Model/thle2.mse.linear-0430.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5196 - mse: 0.5130 - val_loss: 0.4733 - val_mse: 0.4667\n",
      "Epoch 431/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5184 - mse: 0.5118 - val_loss: 0.4747 - val_mse: 0.4681\n",
      "Epoch 432/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5147 - mse: 0.5081 - val_loss: 0.4711 - val_mse: 0.4645\n",
      "Epoch 433/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5208 - mse: 0.5142 - val_loss: 0.4787 - val_mse: 0.4721\n",
      "Epoch 434/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5201 - mse: 0.5135 - val_loss: 0.4758 - val_mse: 0.4692\n",
      "Epoch 435/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5216 - mse: 0.5150 - val_loss: 0.4752 - val_mse: 0.4686\n",
      "Epoch 436/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5205 - mse: 0.5138 - val_loss: 0.4755 - val_mse: 0.4689\n",
      "Epoch 437/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5203 - mse: 0.5137 - val_loss: 0.4780 - val_mse: 0.4714\n",
      "Epoch 438/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5228 - mse: 0.5162 - val_loss: 0.4771 - val_mse: 0.4704\n",
      "Epoch 439/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5185 - mse: 0.5119 - val_loss: 0.4760 - val_mse: 0.4694\n",
      "Epoch 440/1000\n",
      "521/524 [============================>.] - ETA: 0s - loss: 0.5235 - mse: 0.5169\n",
      "Epoch 00440: saving model to Regression_Model/thle2.mse.linear-0440.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5235 - mse: 0.5169 - val_loss: 0.4783 - val_mse: 0.4717\n",
      "Epoch 441/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5188 - mse: 0.5122 - val_loss: 0.4774 - val_mse: 0.4708\n",
      "Epoch 442/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5211 - mse: 0.5144 - val_loss: 0.4736 - val_mse: 0.4670\n",
      "Epoch 443/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5185 - mse: 0.5119 - val_loss: 0.4772 - val_mse: 0.4706\n",
      "Epoch 444/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5199 - mse: 0.5133 - val_loss: 0.4753 - val_mse: 0.4687\n",
      "Epoch 445/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5220 - mse: 0.5154 - val_loss: 0.4768 - val_mse: 0.4702\n",
      "Epoch 446/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5199 - mse: 0.5133 - val_loss: 0.4805 - val_mse: 0.4739\n",
      "Epoch 447/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5275 - mse: 0.5209 - val_loss: 0.4778 - val_mse: 0.4713\n",
      "Epoch 448/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5183 - mse: 0.5117 - val_loss: 0.4779 - val_mse: 0.4713\n",
      "Epoch 449/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5160 - mse: 0.5094 - val_loss: 0.4757 - val_mse: 0.4692\n",
      "Epoch 450/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5197 - mse: 0.5131\n",
      "Epoch 00450: saving model to Regression_Model/thle2.mse.linear-0450.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5196 - mse: 0.5130 - val_loss: 0.4791 - val_mse: 0.4725\n",
      "Epoch 451/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5179 - mse: 0.5113 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 452/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5174 - mse: 0.5108 - val_loss: 0.4776 - val_mse: 0.4710\n",
      "Epoch 453/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5176 - mse: 0.5110 - val_loss: 0.4788 - val_mse: 0.4722\n",
      "Epoch 454/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5157 - mse: 0.5091 - val_loss: 0.4811 - val_mse: 0.4745\n",
      "Epoch 455/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5234 - mse: 0.5168 - val_loss: 0.4783 - val_mse: 0.4717\n",
      "Epoch 456/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5210 - mse: 0.5144 - val_loss: 0.4748 - val_mse: 0.4683\n",
      "Epoch 457/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5187 - mse: 0.5122 - val_loss: 0.4797 - val_mse: 0.4731\n",
      "Epoch 458/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5203 - mse: 0.5137 - val_loss: 0.4753 - val_mse: 0.4688\n",
      "Epoch 459/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5184 - mse: 0.5118 - val_loss: 0.4768 - val_mse: 0.4703\n",
      "Epoch 460/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5191 - mse: 0.5126\n",
      "Epoch 00460: saving model to Regression_Model/thle2.mse.linear-0460.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5195 - mse: 0.5129 - val_loss: 0.4775 - val_mse: 0.4710\n",
      "Epoch 461/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5164 - mse: 0.5098 - val_loss: 0.4774 - val_mse: 0.4709\n",
      "Epoch 462/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5210 - mse: 0.5145 - val_loss: 0.4754 - val_mse: 0.4689\n",
      "Epoch 463/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5244 - mse: 0.5179 - val_loss: 0.4736 - val_mse: 0.4671\n",
      "Epoch 464/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5173 - mse: 0.5107 - val_loss: 0.4811 - val_mse: 0.4745\n",
      "Epoch 465/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5207 - mse: 0.5142 - val_loss: 0.4720 - val_mse: 0.4655\n",
      "Epoch 466/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5185 - mse: 0.5120 - val_loss: 0.4744 - val_mse: 0.4679\n",
      "Epoch 467/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5189 - mse: 0.5123 - val_loss: 0.4773 - val_mse: 0.4707\n",
      "Epoch 468/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5113 - mse: 0.5048 - val_loss: 0.4760 - val_mse: 0.4694\n",
      "Epoch 469/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5202 - mse: 0.5137 - val_loss: 0.4752 - val_mse: 0.4687\n",
      "Epoch 470/1000\n",
      "519/524 [============================>.] - ETA: 0s - loss: 0.5179 - mse: 0.5113\n",
      "Epoch 00470: saving model to Regression_Model/thle2.mse.linear-0470.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5181 - mse: 0.5116 - val_loss: 0.4745 - val_mse: 0.4680\n",
      "Epoch 471/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5213 - mse: 0.5148 - val_loss: 0.4714 - val_mse: 0.4649\n",
      "Epoch 472/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5248 - mse: 0.5183 - val_loss: 0.4779 - val_mse: 0.4714\n",
      "Epoch 473/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5204 - mse: 0.5138 - val_loss: 0.4803 - val_mse: 0.4738\n",
      "Epoch 474/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5179 - mse: 0.5113 - val_loss: 0.4764 - val_mse: 0.4699\n",
      "Epoch 475/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5144 - mse: 0.5079 - val_loss: 0.4769 - val_mse: 0.4703\n",
      "Epoch 476/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5195 - mse: 0.5129 - val_loss: 0.4749 - val_mse: 0.4683\n",
      "Epoch 477/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5200 - mse: 0.5135 - val_loss: 0.4754 - val_mse: 0.4689\n",
      "Epoch 478/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5221 - mse: 0.5155 - val_loss: 0.4770 - val_mse: 0.4705\n",
      "Epoch 479/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5156 - mse: 0.5090 - val_loss: 0.4738 - val_mse: 0.4673\n",
      "Epoch 480/1000\n",
      "520/524 [============================>.] - ETA: 0s - loss: 0.5193 - mse: 0.5128\n",
      "Epoch 00480: saving model to Regression_Model/thle2.mse.linear-0480.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5190 - mse: 0.5125 - val_loss: 0.4767 - val_mse: 0.4702\n",
      "Epoch 481/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5110 - mse: 0.5045 - val_loss: 0.4738 - val_mse: 0.4672\n",
      "Epoch 482/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5178 - mse: 0.5113 - val_loss: 0.4757 - val_mse: 0.4692\n",
      "Epoch 483/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5197 - mse: 0.5131 - val_loss: 0.4742 - val_mse: 0.4677\n",
      "Epoch 484/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5145 - mse: 0.5079 - val_loss: 0.4727 - val_mse: 0.4662\n",
      "Epoch 485/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5169 - mse: 0.5104 - val_loss: 0.4795 - val_mse: 0.4730\n",
      "Epoch 486/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5213 - mse: 0.5148 - val_loss: 0.4760 - val_mse: 0.4695\n",
      "Epoch 487/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5180 - mse: 0.5115 - val_loss: 0.4754 - val_mse: 0.4689\n",
      "Epoch 488/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5181 - mse: 0.5116 - val_loss: 0.4797 - val_mse: 0.4732\n",
      "Epoch 489/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5182 - mse: 0.5117 - val_loss: 0.4766 - val_mse: 0.4701\n",
      "Epoch 490/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5224 - mse: 0.5159\n",
      "Epoch 00490: saving model to Regression_Model/thle2.mse.linear-0490.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5221 - mse: 0.5156 - val_loss: 0.4773 - val_mse: 0.4708\n",
      "Epoch 491/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5160 - mse: 0.5095 - val_loss: 0.4732 - val_mse: 0.4667\n",
      "Epoch 492/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5219 - mse: 0.5154 - val_loss: 0.4730 - val_mse: 0.4665\n",
      "Epoch 493/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5145 - mse: 0.5080 - val_loss: 0.4749 - val_mse: 0.4685\n",
      "Epoch 494/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5147 - mse: 0.5082 - val_loss: 0.4753 - val_mse: 0.4688\n",
      "Epoch 495/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5203 - mse: 0.5138 - val_loss: 0.4781 - val_mse: 0.4716\n",
      "Epoch 496/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5210 - mse: 0.5145 - val_loss: 0.4802 - val_mse: 0.4737\n",
      "Epoch 497/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5182 - mse: 0.5117 - val_loss: 0.4784 - val_mse: 0.4719\n",
      "Epoch 498/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5225 - mse: 0.5160 - val_loss: 0.4751 - val_mse: 0.4687\n",
      "Epoch 499/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5162 - mse: 0.5097 - val_loss: 0.4748 - val_mse: 0.4683\n",
      "Epoch 500/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5195 - mse: 0.5130\n",
      "Epoch 00500: saving model to Regression_Model/thle2.mse.linear-0500.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5195 - mse: 0.5130 - val_loss: 0.4753 - val_mse: 0.4688\n",
      "Epoch 501/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5225 - mse: 0.5160 - val_loss: 0.4789 - val_mse: 0.4724\n",
      "Epoch 502/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5201 - mse: 0.5136 - val_loss: 0.4763 - val_mse: 0.4698\n",
      "Epoch 503/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5185 - mse: 0.5120 - val_loss: 0.4783 - val_mse: 0.4718\n",
      "Epoch 504/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5178 - mse: 0.5113 - val_loss: 0.4768 - val_mse: 0.4703\n",
      "Epoch 505/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5179 - mse: 0.5114 - val_loss: 0.4730 - val_mse: 0.4665\n",
      "Epoch 506/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5135 - mse: 0.5070 - val_loss: 0.4765 - val_mse: 0.4700\n",
      "Epoch 507/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5176 - mse: 0.5112 - val_loss: 0.4758 - val_mse: 0.4693\n",
      "Epoch 508/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5197 - mse: 0.5132 - val_loss: 0.4804 - val_mse: 0.4739\n",
      "Epoch 509/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5195 - mse: 0.5130 - val_loss: 0.4796 - val_mse: 0.4731\n",
      "Epoch 510/1000\n",
      "516/524 [============================>.] - ETA: 0s - loss: 0.5188 - mse: 0.5123\n",
      "Epoch 00510: saving model to Regression_Model/thle2.mse.linear-0510.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5178 - mse: 0.5114 - val_loss: 0.4772 - val_mse: 0.4707\n",
      "Epoch 511/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5134 - mse: 0.5069 - val_loss: 0.4736 - val_mse: 0.4671\n",
      "Epoch 512/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5173 - mse: 0.5109 - val_loss: 0.4777 - val_mse: 0.4712\n",
      "Epoch 513/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5201 - mse: 0.5137 - val_loss: 0.4733 - val_mse: 0.4668\n",
      "Epoch 514/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5166 - mse: 0.5101 - val_loss: 0.4709 - val_mse: 0.4644\n",
      "Epoch 515/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5181 - mse: 0.5117 - val_loss: 0.4747 - val_mse: 0.4682\n",
      "Epoch 516/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5148 - mse: 0.5084 - val_loss: 0.4735 - val_mse: 0.4671\n",
      "Epoch 517/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5172 - mse: 0.5107 - val_loss: 0.4759 - val_mse: 0.4695\n",
      "Epoch 518/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5184 - mse: 0.5120 - val_loss: 0.4811 - val_mse: 0.4746\n",
      "Epoch 519/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5245 - mse: 0.5180 - val_loss: 0.4810 - val_mse: 0.4746\n",
      "Epoch 520/1000\n",
      "523/524 [============================>.] - ETA: 0s - loss: 0.5157 - mse: 0.5093\n",
      "Epoch 00520: saving model to Regression_Model/thle2.mse.linear-0520.ckpt\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5158 - mse: 0.5093 - val_loss: 0.4756 - val_mse: 0.4692\n",
      "Epoch 521/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5135 - mse: 0.5070 - val_loss: 0.4729 - val_mse: 0.4664\n",
      "Epoch 522/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5165 - mse: 0.5100 - val_loss: 0.4742 - val_mse: 0.4678\n",
      "Epoch 523/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5160 - mse: 0.5095 - val_loss: 0.4807 - val_mse: 0.4743\n",
      "Epoch 524/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5194 - mse: 0.5129 - val_loss: 0.4783 - val_mse: 0.4719\n",
      "Epoch 525/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5157 - mse: 0.5092 - val_loss: 0.4751 - val_mse: 0.4686\n",
      "Epoch 526/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5244 - mse: 0.5179 - val_loss: 0.4760 - val_mse: 0.4696\n",
      "Epoch 527/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5199 - mse: 0.5135 - val_loss: 0.4787 - val_mse: 0.4723\n",
      "Epoch 528/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5168 - mse: 0.5104 - val_loss: 0.4738 - val_mse: 0.4674\n",
      "Epoch 529/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5150 - mse: 0.5085 - val_loss: 0.4753 - val_mse: 0.4689\n",
      "Epoch 530/1000\n",
      "520/524 [============================>.] - ETA: 0s - loss: 0.5155 - mse: 0.5091\n",
      "Epoch 00530: saving model to Regression_Model/thle2.mse.linear-0530.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5156 - mse: 0.5091 - val_loss: 0.4747 - val_mse: 0.4683\n",
      "Epoch 531/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5198 - mse: 0.5134 - val_loss: 0.4751 - val_mse: 0.4687\n",
      "Epoch 532/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5180 - mse: 0.5115 - val_loss: 0.4742 - val_mse: 0.4678\n",
      "Epoch 533/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5211 - mse: 0.5147 - val_loss: 0.4726 - val_mse: 0.4662\n",
      "Epoch 534/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5178 - mse: 0.5114 - val_loss: 0.4751 - val_mse: 0.4687\n",
      "Epoch 535/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5245 - mse: 0.5180 - val_loss: 0.4747 - val_mse: 0.4682\n",
      "Epoch 536/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5186 - mse: 0.5122 - val_loss: 0.4772 - val_mse: 0.4708\n",
      "Epoch 537/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5180 - mse: 0.5116 - val_loss: 0.4752 - val_mse: 0.4688\n",
      "Epoch 538/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5186 - mse: 0.5122 - val_loss: 0.4758 - val_mse: 0.4694\n",
      "Epoch 539/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5170 - mse: 0.5106 - val_loss: 0.4739 - val_mse: 0.4675\n",
      "Epoch 540/1000\n",
      "522/524 [============================>.] - ETA: 0s - loss: 0.5196 - mse: 0.5132\n",
      "Epoch 00540: saving model to Regression_Model/thle2.mse.linear-0540.ckpt\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5196 - mse: 0.5132 - val_loss: 0.4791 - val_mse: 0.4727\n",
      "Epoch 541/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5196 - mse: 0.5131 - val_loss: 0.4773 - val_mse: 0.4709\n",
      "Epoch 542/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5148 - mse: 0.5084 - val_loss: 0.4758 - val_mse: 0.4694\n",
      "Epoch 543/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5206 - mse: 0.5142 - val_loss: 0.4767 - val_mse: 0.4703\n",
      "Epoch 544/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5138 - mse: 0.5074 - val_loss: 0.4777 - val_mse: 0.4713\n",
      "Epoch 545/1000\n",
      "524/524 [==============================] - 3s 7ms/step - loss: 0.5183 - mse: 0.5119 - val_loss: 0.4776 - val_mse: 0.4712\n",
      "Epoch 546/1000\n",
      "524/524 [==============================] - 4s 7ms/step - loss: 0.5200 - mse: 0.5136 - val_loss: 0.4738 - val_mse: 0.4674\n",
      "Epoch 547/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5193 - mse: 0.5129 - val_loss: 0.4748 - val_mse: 0.4684\n",
      "Epoch 548/1000\n",
      "524/524 [==============================] - 3s 6ms/step - loss: 0.5179 - mse: 0.5116 - val_loss: 0.4763 - val_mse: 0.4699\n",
      "Epoch 549/1000\n",
      "361/524 [===================>..........] - ETA: 0s - loss: 0.5227 - mse: 0.5163"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-84a410e59eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=1000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0f2ccce95ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b8b4ffc7da0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,MODEL_PATH,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    \n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_rpm\\tpolyA_rpm\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "trainid='snu398_onlyrna0.05'\n",
    "bestEpoch = '0600'\n",
    "MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "evaluate(train_x,train_y,train_id,MODEL_PATH,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,MODEL_PATH,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train_data,train_labels,data_mean,data_std,label_mean,label_std):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    return train_data,train_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 20258\n",
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "bestEpoch = '0590'\n",
    "trainid='k562'\n",
    "MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "#MODEL_PATH = '../APAIQ2/model/thle2.mse.linear-0540.ckpt'\n",
    "train_data1,train_labels1,train_pasid1,valid_data1,valid_labels1,valid_pasid1 = \\\n",
    "prep_data('coverage_data/thle2.gt.gt.txt',5,8.9)\n",
    "#prep_data('coverage_data/K562.predicted.txt',5,33.3)\n",
    "\n",
    "x=np.concatenate((train_data1, valid_data1), axis=0)\n",
    "y=np.concatenate((train_labels1, valid_labels1), axis=0)\n",
    "pasid=np.concatenate((train_pasid1, valid_pasid1), axis=0)\n",
    "#data_mean=-1.511\n",
    "#data_std=1.437\n",
    "#label_mean=2.473\n",
    "#label_std=1.518\n",
    "x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)\n",
    "evaluate(x,y,pasid,MODEL_PATH,'test',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/thle2_control.pAs.usage.txt',5)\n",
    "train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/Finetune.snu398_control.usage.txt',5)\n",
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='thle2.mle.linear'\n",
    "bestEpoch = '0980'\n",
    "evaluate(train_x,train_y,train_pasid,testid,'train',label_mean,label_std,bestEpoch)\n",
    "evaluate(valid_x,valid_y,valid_pasid,testid,'valid',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1(x,y,pasid,trainid,dataset,label_mean,label_std,bestEpoch=2000):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)-1\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)-1\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prep_data() missing 1 required positional argument: 'depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-258c38ac16ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_pasid1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_data1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_labels1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_pasid1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coverage_data/all.snu398_control.usage.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpasid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pasid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_pasid1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: prep_data() missing 1 required positional argument: 'depth'"
     ]
    }
   ],
   "source": [
    "train_data1,train_labels1,train_pasid1,valid_data1,valid_labels1,valid_pasid1 = prep_data('coverage_data/all.snu398_control.usage.txt',5)\n",
    "x=np.concatenate((train_data1, valid_data1), axis=0)\n",
    "y=np.concatenate((train_labels1, valid_labels1), axis=0)\n",
    "pasid=np.concatenate((train_pasid1, valid_pasid1), axis=0)\n",
    "x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='Regression.f_snu398.shift16.1001'\n",
    "bestEpoch = '2000'\n",
    "evaluate1(x,y,pasid,testid,'all',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((train_pasid1, valid_pasid1), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[3,4,5,6]\n",
    "a.remove(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(a == None):\n",
    "    print('fafa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'chromosme,start,end,score,id,strand\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,c,d = a.split(',')[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
