{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.23.2 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = MaxPooling1D(pool_size = 12)(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "group_normalization (GroupNo (None, 990, 16)           32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,289\n",
      "Trainable params: 42,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 12488\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('coverage_data/SNU398_Control.usage.txt',5,7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data2,train_labels2,train_id2,valid_data2,valid_labels2,valid_id2 = prep_data('coverage_data/SNU398_Control.usage.txt',5,7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=np.concatenate((train_data1, train_data2), axis=0)\n",
    "#train_labels=np.concatenate((train_labels1, train_labels2), axis=0)\n",
    "#valid_data=np.concatenate((valid_data1, valid_data2), axis=0)\n",
    "#valid_labels=np.concatenate((valid_labels1, valid_labels2), axis=0)\n",
    "#train_id =np.concatenate((train_id1, train_id2), axis=0)\n",
    "#valid_id =np.concatenate((valid_id1, valid_id2), axis=0)\n",
    "#x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12820514"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+0.05)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    #train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    #valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5108502 1.4369208\n",
      "2.4731958 1.5182152\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7071e42630>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(train_x.shape[1]),train_x[5,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5522538"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,train_id,16,LENGTH)\n",
    "validation_generator = DataGenerator(valid_x,valid_y,valid_id,0,LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(LENGTH),a[9])\n",
    "plt.xticks(np.arange(0, LENGTH, 100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='thle2.mse.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 312 steps, validate for 78 steps\n",
      "Epoch 1/1000\n",
      "312/312 [==============================] - 3s 10ms/step - loss: 0.9243 - mse: 0.9173 - val_loss: 0.8045 - val_mse: 0.7973\n",
      "Epoch 2/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.7780 - mse: 0.7708 - val_loss: 0.6485 - val_mse: 0.6413\n",
      "Epoch 3/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.7338 - mse: 0.7266 - val_loss: 0.5970 - val_mse: 0.5897\n",
      "Epoch 4/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.7011 - mse: 0.6939 - val_loss: 0.5785 - val_mse: 0.5713\n",
      "Epoch 5/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6836 - mse: 0.6763 - val_loss: 0.5666 - val_mse: 0.5594\n",
      "Epoch 6/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6873 - mse: 0.6800 - val_loss: 0.5737 - val_mse: 0.5664\n",
      "Epoch 7/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.6718 - mse: 0.6645 - val_loss: 0.5752 - val_mse: 0.5679\n",
      "Epoch 8/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6763 - mse: 0.6690 - val_loss: 0.5622 - val_mse: 0.5549\n",
      "Epoch 9/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6685 - mse: 0.6612 - val_loss: 0.5835 - val_mse: 0.5762\n",
      "Epoch 10/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.6488 - mse: 0.6415\n",
      "Epoch 00010: saving model to Regression_Model/thle2.mse.linear-0010.ckpt\n",
      "312/312 [==============================] - 3s 11ms/step - loss: 0.6488 - mse: 0.6415 - val_loss: 0.5443 - val_mse: 0.5369\n",
      "Epoch 11/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6571 - mse: 0.6498 - val_loss: 0.5457 - val_mse: 0.5383\n",
      "Epoch 12/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6696 - mse: 0.6622 - val_loss: 0.5564 - val_mse: 0.5490\n",
      "Epoch 13/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6555 - mse: 0.6482 - val_loss: 0.5520 - val_mse: 0.5446\n",
      "Epoch 14/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6467 - mse: 0.6393 - val_loss: 0.5729 - val_mse: 0.5655\n",
      "Epoch 15/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6397 - mse: 0.6323 - val_loss: 0.5526 - val_mse: 0.5452\n",
      "Epoch 16/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6401 - mse: 0.6327 - val_loss: 0.5654 - val_mse: 0.5580\n",
      "Epoch 17/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6463 - mse: 0.6389 - val_loss: 0.5419 - val_mse: 0.5345\n",
      "Epoch 18/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6302 - mse: 0.6228 - val_loss: 0.5584 - val_mse: 0.5510\n",
      "Epoch 19/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6243 - mse: 0.6169 - val_loss: 0.5301 - val_mse: 0.5227\n",
      "Epoch 20/1000\n",
      "305/312 [============================>.] - ETA: 0s - loss: 0.6216 - mse: 0.6142\n",
      "Epoch 00020: saving model to Regression_Model/thle2.mse.linear-0020.ckpt\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.6241 - mse: 0.6167 - val_loss: 0.5419 - val_mse: 0.5344\n",
      "Epoch 21/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.6267 - mse: 0.6192 - val_loss: 0.5296 - val_mse: 0.5221\n",
      "Epoch 22/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6149 - mse: 0.6074 - val_loss: 0.5788 - val_mse: 0.5713\n",
      "Epoch 23/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6057 - mse: 0.5982 - val_loss: 0.5444 - val_mse: 0.5369\n",
      "Epoch 24/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6102 - mse: 0.6027 - val_loss: 0.5207 - val_mse: 0.5132\n",
      "Epoch 25/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6137 - mse: 0.6062 - val_loss: 0.5407 - val_mse: 0.5332\n",
      "Epoch 26/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6040 - mse: 0.5965 - val_loss: 0.5351 - val_mse: 0.5276\n",
      "Epoch 27/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6137 - mse: 0.6061 - val_loss: 0.5211 - val_mse: 0.5136\n",
      "Epoch 28/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5979 - mse: 0.5904 - val_loss: 0.5630 - val_mse: 0.5555\n",
      "Epoch 29/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.6058 - mse: 0.5983 - val_loss: 0.5544 - val_mse: 0.5469\n",
      "Epoch 30/1000\n",
      "310/312 [============================>.] - ETA: 0s - loss: 0.5948 - mse: 0.5873\n",
      "Epoch 00030: saving model to Regression_Model/thle2.mse.linear-0030.ckpt\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 0.5953 - mse: 0.5877 - val_loss: 0.5227 - val_mse: 0.5152\n",
      "Epoch 31/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5935 - mse: 0.5860 - val_loss: 0.5412 - val_mse: 0.5337\n",
      "Epoch 32/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5965 - mse: 0.5889 - val_loss: 0.5227 - val_mse: 0.5152\n",
      "Epoch 33/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5988 - mse: 0.5913 - val_loss: 0.5341 - val_mse: 0.5265\n",
      "Epoch 34/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5961 - mse: 0.5886 - val_loss: 0.5386 - val_mse: 0.5310\n",
      "Epoch 35/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5938 - mse: 0.5863 - val_loss: 0.5309 - val_mse: 0.5234\n",
      "Epoch 36/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5880 - mse: 0.5805 - val_loss: 0.5343 - val_mse: 0.5268\n",
      "Epoch 37/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5889 - mse: 0.5814 - val_loss: 0.5478 - val_mse: 0.5403\n",
      "Epoch 38/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5954 - mse: 0.5879 - val_loss: 0.5334 - val_mse: 0.5259\n",
      "Epoch 39/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5953 - mse: 0.5878 - val_loss: 0.5231 - val_mse: 0.5156\n",
      "Epoch 40/1000\n",
      "310/312 [============================>.] - ETA: 0s - loss: 0.5911 - mse: 0.5836\n",
      "Epoch 00040: saving model to Regression_Model/thle2.mse.linear-0040.ckpt\n",
      "312/312 [==============================] - 3s 10ms/step - loss: 0.5916 - mse: 0.5841 - val_loss: 0.5264 - val_mse: 0.5188\n",
      "Epoch 41/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5993 - mse: 0.5917 - val_loss: 0.5223 - val_mse: 0.5148\n",
      "Epoch 42/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5805 - mse: 0.5730 - val_loss: 0.5283 - val_mse: 0.5207\n",
      "Epoch 43/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5918 - mse: 0.5843 - val_loss: 0.5186 - val_mse: 0.5111\n",
      "Epoch 44/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5917 - mse: 0.5842 - val_loss: 0.5294 - val_mse: 0.5219\n",
      "Epoch 45/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5946 - mse: 0.5871 - val_loss: 0.5290 - val_mse: 0.5215\n",
      "Epoch 46/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5948 - mse: 0.5873 - val_loss: 0.5326 - val_mse: 0.5250\n",
      "Epoch 47/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5971 - mse: 0.5896 - val_loss: 0.5226 - val_mse: 0.5151\n",
      "Epoch 48/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5947 - mse: 0.5871 - val_loss: 0.5200 - val_mse: 0.5125\n",
      "Epoch 49/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5806 - mse: 0.5730 - val_loss: 0.5261 - val_mse: 0.5185\n",
      "Epoch 50/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5925 - mse: 0.5849\n",
      "Epoch 00050: saving model to Regression_Model/thle2.mse.linear-0050.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5949 - mse: 0.5874 - val_loss: 0.5284 - val_mse: 0.5208\n",
      "Epoch 51/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5939 - mse: 0.5864 - val_loss: 0.5428 - val_mse: 0.5353\n",
      "Epoch 52/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5801 - mse: 0.5725 - val_loss: 0.5144 - val_mse: 0.5068\n",
      "Epoch 53/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5855 - mse: 0.5779 - val_loss: 0.5572 - val_mse: 0.5497\n",
      "Epoch 54/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5991 - mse: 0.5916 - val_loss: 0.5286 - val_mse: 0.5211\n",
      "Epoch 55/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5781 - mse: 0.5706 - val_loss: 0.5218 - val_mse: 0.5143\n",
      "Epoch 56/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5894 - mse: 0.5819 - val_loss: 0.5351 - val_mse: 0.5276\n",
      "Epoch 57/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5787 - mse: 0.5712 - val_loss: 0.5392 - val_mse: 0.5316\n",
      "Epoch 58/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5890 - mse: 0.5815 - val_loss: 0.5253 - val_mse: 0.5178\n",
      "Epoch 59/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5867 - mse: 0.5792 - val_loss: 0.5416 - val_mse: 0.5341\n",
      "Epoch 60/1000\n",
      "308/312 [============================>.] - ETA: 0s - loss: 0.5917 - mse: 0.5842\n",
      "Epoch 00060: saving model to Regression_Model/thle2.mse.linear-0060.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5925 - mse: 0.5850 - val_loss: 0.5211 - val_mse: 0.5136\n",
      "Epoch 61/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5847 - mse: 0.5772 - val_loss: 0.5266 - val_mse: 0.5191\n",
      "Epoch 62/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5867 - mse: 0.5791 - val_loss: 0.5340 - val_mse: 0.5264\n",
      "Epoch 63/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5840 - mse: 0.5765 - val_loss: 0.5255 - val_mse: 0.5180\n",
      "Epoch 64/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5798 - mse: 0.5723 - val_loss: 0.5329 - val_mse: 0.5254\n",
      "Epoch 65/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5885 - mse: 0.5810 - val_loss: 0.5314 - val_mse: 0.5239\n",
      "Epoch 66/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5868 - mse: 0.5793 - val_loss: 0.5154 - val_mse: 0.5080\n",
      "Epoch 67/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5820 - mse: 0.5745 - val_loss: 0.5290 - val_mse: 0.5215\n",
      "Epoch 68/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5818 - mse: 0.5743 - val_loss: 0.5304 - val_mse: 0.5229\n",
      "Epoch 69/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5866 - mse: 0.5791 - val_loss: 0.5284 - val_mse: 0.5209\n",
      "Epoch 70/1000\n",
      "310/312 [============================>.] - ETA: 0s - loss: 0.5826 - mse: 0.5751\n",
      "Epoch 00070: saving model to Regression_Model/thle2.mse.linear-0070.ckpt\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5821 - mse: 0.5746 - val_loss: 0.5210 - val_mse: 0.5135\n",
      "Epoch 71/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5837 - mse: 0.5762 - val_loss: 0.5418 - val_mse: 0.5343\n",
      "Epoch 72/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5855 - mse: 0.5780 - val_loss: 0.5297 - val_mse: 0.5222\n",
      "Epoch 73/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5807 - mse: 0.5733 - val_loss: 0.5259 - val_mse: 0.5185\n",
      "Epoch 74/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5889 - mse: 0.5814 - val_loss: 0.5170 - val_mse: 0.5096\n",
      "Epoch 75/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5827 - mse: 0.5752 - val_loss: 0.5387 - val_mse: 0.5313\n",
      "Epoch 76/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5779 - mse: 0.5705 - val_loss: 0.5192 - val_mse: 0.5118\n",
      "Epoch 77/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5867 - mse: 0.5793 - val_loss: 0.5232 - val_mse: 0.5157\n",
      "Epoch 78/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5851 - mse: 0.5776 - val_loss: 0.5293 - val_mse: 0.5219\n",
      "Epoch 79/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5827 - mse: 0.5753 - val_loss: 0.5348 - val_mse: 0.5274\n",
      "Epoch 80/1000\n",
      "301/312 [===========================>..] - ETA: 0s - loss: 0.5787 - mse: 0.5712\n",
      "Epoch 00080: saving model to Regression_Model/thle2.mse.linear-0080.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5758 - mse: 0.5684 - val_loss: 0.5129 - val_mse: 0.5055\n",
      "Epoch 81/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5936 - mse: 0.5862 - val_loss: 0.5112 - val_mse: 0.5038\n",
      "Epoch 82/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5935 - mse: 0.5861 - val_loss: 0.5180 - val_mse: 0.5106\n",
      "Epoch 83/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5814 - mse: 0.5740 - val_loss: 0.5234 - val_mse: 0.5160\n",
      "Epoch 84/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5851 - mse: 0.5777 - val_loss: 0.5342 - val_mse: 0.5268\n",
      "Epoch 85/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5845 - mse: 0.5771 - val_loss: 0.5284 - val_mse: 0.5210\n",
      "Epoch 86/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5796 - mse: 0.5722 - val_loss: 0.5283 - val_mse: 0.5209\n",
      "Epoch 87/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5922 - mse: 0.5848 - val_loss: 0.5319 - val_mse: 0.5245\n",
      "Epoch 88/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5808 - mse: 0.5734 - val_loss: 0.5299 - val_mse: 0.5225\n",
      "Epoch 89/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5776 - mse: 0.5702 - val_loss: 0.5238 - val_mse: 0.5164\n",
      "Epoch 90/1000\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.5804 - mse: 0.5730\n",
      "Epoch 00090: saving model to Regression_Model/thle2.mse.linear-0090.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5801 - mse: 0.5727 - val_loss: 0.5269 - val_mse: 0.5195\n",
      "Epoch 91/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5776 - mse: 0.5703 - val_loss: 0.5196 - val_mse: 0.5122\n",
      "Epoch 92/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5788 - mse: 0.5714 - val_loss: 0.5211 - val_mse: 0.5137\n",
      "Epoch 93/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5828 - mse: 0.5755 - val_loss: 0.5386 - val_mse: 0.5313\n",
      "Epoch 94/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5825 - mse: 0.5751 - val_loss: 0.5267 - val_mse: 0.5193\n",
      "Epoch 95/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5829 - mse: 0.5756 - val_loss: 0.5444 - val_mse: 0.5371\n",
      "Epoch 96/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5852 - mse: 0.5778 - val_loss: 0.5236 - val_mse: 0.5162\n",
      "Epoch 97/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5695 - mse: 0.5621 - val_loss: 0.5098 - val_mse: 0.5024\n",
      "Epoch 98/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5781 - mse: 0.5708 - val_loss: 0.5144 - val_mse: 0.5070\n",
      "Epoch 99/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5815 - mse: 0.5741 - val_loss: 0.5234 - val_mse: 0.5161\n",
      "Epoch 100/1000\n",
      "303/312 [============================>.] - ETA: 0s - loss: 0.5839 - mse: 0.5765\n",
      "Epoch 00100: saving model to Regression_Model/thle2.mse.linear-0100.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5839 - mse: 0.5765 - val_loss: 0.5109 - val_mse: 0.5036\n",
      "Epoch 101/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5803 - mse: 0.5729 - val_loss: 0.5222 - val_mse: 0.5149\n",
      "Epoch 102/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5897 - mse: 0.5823 - val_loss: 0.5175 - val_mse: 0.5102\n",
      "Epoch 103/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5849 - mse: 0.5775 - val_loss: 0.5107 - val_mse: 0.5034\n",
      "Epoch 104/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5808 - mse: 0.5734 - val_loss: 0.5239 - val_mse: 0.5166\n",
      "Epoch 105/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5793 - mse: 0.5720 - val_loss: 0.5208 - val_mse: 0.5135\n",
      "Epoch 106/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5822 - mse: 0.5749 - val_loss: 0.5152 - val_mse: 0.5079\n",
      "Epoch 107/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5792 - mse: 0.5719 - val_loss: 0.5161 - val_mse: 0.5088\n",
      "Epoch 108/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5702 - mse: 0.5629 - val_loss: 0.5206 - val_mse: 0.5133\n",
      "Epoch 109/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5819 - mse: 0.5746 - val_loss: 0.5228 - val_mse: 0.5155\n",
      "Epoch 110/1000\n",
      "305/312 [============================>.] - ETA: 0s - loss: 0.5817 - mse: 0.5744\n",
      "Epoch 00110: saving model to Regression_Model/thle2.mse.linear-0110.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5824 - mse: 0.5751 - val_loss: 0.5223 - val_mse: 0.5150\n",
      "Epoch 111/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5814 - mse: 0.5741 - val_loss: 0.5176 - val_mse: 0.5103\n",
      "Epoch 112/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5789 - mse: 0.5716 - val_loss: 0.5405 - val_mse: 0.5332\n",
      "Epoch 113/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5808 - mse: 0.5735 - val_loss: 0.5142 - val_mse: 0.5069\n",
      "Epoch 114/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5828 - mse: 0.5755 - val_loss: 0.5120 - val_mse: 0.5047\n",
      "Epoch 115/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5820 - mse: 0.5747 - val_loss: 0.5167 - val_mse: 0.5094\n",
      "Epoch 116/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5834 - mse: 0.5761 - val_loss: 0.5236 - val_mse: 0.5163\n",
      "Epoch 117/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5825 - mse: 0.5752 - val_loss: 0.5227 - val_mse: 0.5154\n",
      "Epoch 118/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5829 - mse: 0.5756 - val_loss: 0.5143 - val_mse: 0.5070\n",
      "Epoch 119/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5753 - mse: 0.5680 - val_loss: 0.5118 - val_mse: 0.5045\n",
      "Epoch 120/1000\n",
      "302/312 [============================>.] - ETA: 0s - loss: 0.5742 - mse: 0.5669\n",
      "Epoch 00120: saving model to Regression_Model/thle2.mse.linear-0120.ckpt\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.5762 - mse: 0.5689 - val_loss: 0.5377 - val_mse: 0.5304\n",
      "Epoch 121/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5807 - mse: 0.5734 - val_loss: 0.5201 - val_mse: 0.5128\n",
      "Epoch 122/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5815 - mse: 0.5742 - val_loss: 0.5333 - val_mse: 0.5260\n",
      "Epoch 123/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5808 - mse: 0.5735 - val_loss: 0.5320 - val_mse: 0.5247\n",
      "Epoch 124/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5745 - mse: 0.5672 - val_loss: 0.5181 - val_mse: 0.5109\n",
      "Epoch 125/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5738 - mse: 0.5665 - val_loss: 0.5229 - val_mse: 0.5157\n",
      "Epoch 126/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5769 - mse: 0.5697 - val_loss: 0.5134 - val_mse: 0.5062\n",
      "Epoch 127/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5838 - mse: 0.5765 - val_loss: 0.5298 - val_mse: 0.5225\n",
      "Epoch 128/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5797 - mse: 0.5724 - val_loss: 0.5237 - val_mse: 0.5165\n",
      "Epoch 129/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5780 - mse: 0.5707 - val_loss: 0.5265 - val_mse: 0.5192\n",
      "Epoch 130/1000\n",
      "299/312 [===========================>..] - ETA: 0s - loss: 0.5825 - mse: 0.5752\n",
      "Epoch 00130: saving model to Regression_Model/thle2.mse.linear-0130.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5806 - mse: 0.5733 - val_loss: 0.5192 - val_mse: 0.5120\n",
      "Epoch 131/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5744 - mse: 0.5671 - val_loss: 0.5180 - val_mse: 0.5108\n",
      "Epoch 132/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5730 - mse: 0.5657 - val_loss: 0.5223 - val_mse: 0.5151\n",
      "Epoch 133/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5824 - mse: 0.5752 - val_loss: 0.5246 - val_mse: 0.5173\n",
      "Epoch 134/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5753 - mse: 0.5681 - val_loss: 0.5189 - val_mse: 0.5117\n",
      "Epoch 135/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5744 - mse: 0.5672 - val_loss: 0.5256 - val_mse: 0.5184\n",
      "Epoch 136/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5768 - mse: 0.5696 - val_loss: 0.5243 - val_mse: 0.5171\n",
      "Epoch 137/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5742 - mse: 0.5670 - val_loss: 0.5198 - val_mse: 0.5125\n",
      "Epoch 138/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5787 - mse: 0.5715 - val_loss: 0.5372 - val_mse: 0.5300\n",
      "Epoch 139/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5755 - mse: 0.5683 - val_loss: 0.5140 - val_mse: 0.5068\n",
      "Epoch 140/1000\n",
      "296/312 [===========================>..] - ETA: 0s - loss: 0.5846 - mse: 0.5774\n",
      "Epoch 00140: saving model to Regression_Model/thle2.mse.linear-0140.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5812 - mse: 0.5740 - val_loss: 0.5182 - val_mse: 0.5110\n",
      "Epoch 141/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5788 - mse: 0.5716 - val_loss: 0.5374 - val_mse: 0.5302\n",
      "Epoch 142/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5810 - mse: 0.5738 - val_loss: 0.5324 - val_mse: 0.5252\n",
      "Epoch 143/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5761 - mse: 0.5689 - val_loss: 0.5114 - val_mse: 0.5042\n",
      "Epoch 144/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5804 - mse: 0.5732 - val_loss: 0.5337 - val_mse: 0.5265\n",
      "Epoch 145/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5784 - mse: 0.5712 - val_loss: 0.5263 - val_mse: 0.5191\n",
      "Epoch 146/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5724 - mse: 0.5652 - val_loss: 0.5220 - val_mse: 0.5148\n",
      "Epoch 147/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5727 - mse: 0.5655 - val_loss: 0.5197 - val_mse: 0.5126\n",
      "Epoch 148/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5736 - mse: 0.5664 - val_loss: 0.5086 - val_mse: 0.5015\n",
      "Epoch 149/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5862 - mse: 0.5790 - val_loss: 0.5278 - val_mse: 0.5207\n",
      "Epoch 150/1000\n",
      "309/312 [============================>.] - ETA: 0s - loss: 0.5755 - mse: 0.5684\n",
      "Epoch 00150: saving model to Regression_Model/thle2.mse.linear-0150.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5749 - mse: 0.5678 - val_loss: 0.5231 - val_mse: 0.5159\n",
      "Epoch 151/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5720 - mse: 0.5648 - val_loss: 0.5146 - val_mse: 0.5075\n",
      "Epoch 152/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5720 - mse: 0.5649 - val_loss: 0.5190 - val_mse: 0.5119\n",
      "Epoch 153/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5734 - mse: 0.5663 - val_loss: 0.5275 - val_mse: 0.5204\n",
      "Epoch 154/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5783 - mse: 0.5712 - val_loss: 0.5224 - val_mse: 0.5152\n",
      "Epoch 155/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5776 - mse: 0.5705 - val_loss: 0.5291 - val_mse: 0.5219\n",
      "Epoch 156/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5772 - mse: 0.5700 - val_loss: 0.5123 - val_mse: 0.5051\n",
      "Epoch 157/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5735 - mse: 0.5664 - val_loss: 0.5122 - val_mse: 0.5050\n",
      "Epoch 158/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5794 - mse: 0.5723 - val_loss: 0.5149 - val_mse: 0.5077\n",
      "Epoch 159/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5778 - mse: 0.5707 - val_loss: 0.5241 - val_mse: 0.5169\n",
      "Epoch 160/1000\n",
      "302/312 [============================>.] - ETA: 0s - loss: 0.5769 - mse: 0.5698\n",
      "Epoch 00160: saving model to Regression_Model/thle2.mse.linear-0160.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5767 - mse: 0.5696 - val_loss: 0.5173 - val_mse: 0.5102\n",
      "Epoch 161/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5756 - mse: 0.5685 - val_loss: 0.5290 - val_mse: 0.5219\n",
      "Epoch 162/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5651 - mse: 0.5580 - val_loss: 0.5274 - val_mse: 0.5202\n",
      "Epoch 163/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5724 - mse: 0.5653 - val_loss: 0.5185 - val_mse: 0.5113\n",
      "Epoch 164/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5805 - mse: 0.5734 - val_loss: 0.5333 - val_mse: 0.5262\n",
      "Epoch 165/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5756 - mse: 0.5685 - val_loss: 0.5231 - val_mse: 0.5160\n",
      "Epoch 166/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5792 - mse: 0.5721 - val_loss: 0.5219 - val_mse: 0.5148\n",
      "Epoch 167/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5746 - mse: 0.5675 - val_loss: 0.5271 - val_mse: 0.5200\n",
      "Epoch 168/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5724 - mse: 0.5653 - val_loss: 0.5198 - val_mse: 0.5127\n",
      "Epoch 169/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5754 - mse: 0.5683 - val_loss: 0.5182 - val_mse: 0.5111\n",
      "Epoch 170/1000\n",
      "307/312 [============================>.] - ETA: 0s - loss: 0.5767 - mse: 0.5696\n",
      "Epoch 00170: saving model to Regression_Model/thle2.mse.linear-0170.ckpt\n",
      "312/312 [==============================] - 3s 11ms/step - loss: 0.5761 - mse: 0.5690 - val_loss: 0.5156 - val_mse: 0.5085\n",
      "Epoch 171/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5764 - mse: 0.5693 - val_loss: 0.5176 - val_mse: 0.5105\n",
      "Epoch 172/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5752 - mse: 0.5681 - val_loss: 0.5173 - val_mse: 0.5102\n",
      "Epoch 173/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5739 - mse: 0.5668 - val_loss: 0.5173 - val_mse: 0.5102\n",
      "Epoch 174/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5785 - mse: 0.5715 - val_loss: 0.5207 - val_mse: 0.5136\n",
      "Epoch 175/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5804 - mse: 0.5733 - val_loss: 0.5106 - val_mse: 0.5035\n",
      "Epoch 176/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5758 - mse: 0.5688 - val_loss: 0.5190 - val_mse: 0.5120\n",
      "Epoch 177/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5738 - mse: 0.5667 - val_loss: 0.5199 - val_mse: 0.5129\n",
      "Epoch 178/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5822 - mse: 0.5751 - val_loss: 0.5352 - val_mse: 0.5281\n",
      "Epoch 179/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5717 - mse: 0.5646 - val_loss: 0.5231 - val_mse: 0.5160\n",
      "Epoch 180/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5695 - mse: 0.5624\n",
      "Epoch 00180: saving model to Regression_Model/thle2.mse.linear-0180.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5744 - mse: 0.5674 - val_loss: 0.5187 - val_mse: 0.5116\n",
      "Epoch 181/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5717 - mse: 0.5646 - val_loss: 0.5181 - val_mse: 0.5111\n",
      "Epoch 182/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5739 - mse: 0.5669 - val_loss: 0.5207 - val_mse: 0.5136\n",
      "Epoch 183/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5783 - mse: 0.5712 - val_loss: 0.5378 - val_mse: 0.5308\n",
      "Epoch 184/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5789 - mse: 0.5719 - val_loss: 0.5258 - val_mse: 0.5187\n",
      "Epoch 185/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5737 - mse: 0.5666 - val_loss: 0.5242 - val_mse: 0.5172\n",
      "Epoch 186/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5772 - mse: 0.5702 - val_loss: 0.5293 - val_mse: 0.5223\n",
      "Epoch 187/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5725 - mse: 0.5655 - val_loss: 0.5115 - val_mse: 0.5045\n",
      "Epoch 188/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5719 - mse: 0.5648 - val_loss: 0.5225 - val_mse: 0.5155\n",
      "Epoch 189/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5727 - mse: 0.5657 - val_loss: 0.5212 - val_mse: 0.5142\n",
      "Epoch 190/1000\n",
      "299/312 [===========================>..] - ETA: 0s - loss: 0.5731 - mse: 0.5660\n",
      "Epoch 00190: saving model to Regression_Model/thle2.mse.linear-0190.ckpt\n",
      "312/312 [==============================] - 3s 10ms/step - loss: 0.5725 - mse: 0.5655 - val_loss: 0.5288 - val_mse: 0.5218\n",
      "Epoch 191/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5767 - mse: 0.5697 - val_loss: 0.5147 - val_mse: 0.5077\n",
      "Epoch 192/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5613 - mse: 0.5543 - val_loss: 0.5111 - val_mse: 0.5041\n",
      "Epoch 193/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5735 - mse: 0.5665 - val_loss: 0.5346 - val_mse: 0.5276\n",
      "Epoch 194/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5649 - mse: 0.5580 - val_loss: 0.5126 - val_mse: 0.5056\n",
      "Epoch 195/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5687 - mse: 0.5617 - val_loss: 0.5116 - val_mse: 0.5046\n",
      "Epoch 196/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5703 - mse: 0.5633 - val_loss: 0.5270 - val_mse: 0.5201\n",
      "Epoch 197/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5758 - mse: 0.5689 - val_loss: 0.5201 - val_mse: 0.5131\n",
      "Epoch 198/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5647 - mse: 0.5577 - val_loss: 0.5191 - val_mse: 0.5121\n",
      "Epoch 199/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5791 - mse: 0.5721 - val_loss: 0.5237 - val_mse: 0.5168\n",
      "Epoch 200/1000\n",
      "301/312 [===========================>..] - ETA: 0s - loss: 0.5673 - mse: 0.5603\n",
      "Epoch 00200: saving model to Regression_Model/thle2.mse.linear-0200.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5692 - mse: 0.5622 - val_loss: 0.5233 - val_mse: 0.5163\n",
      "Epoch 201/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5654 - mse: 0.5585 - val_loss: 0.5111 - val_mse: 0.5041\n",
      "Epoch 202/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5697 - mse: 0.5627 - val_loss: 0.5208 - val_mse: 0.5139\n",
      "Epoch 203/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5718 - mse: 0.5649 - val_loss: 0.5197 - val_mse: 0.5128\n",
      "Epoch 204/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5733 - mse: 0.5664 - val_loss: 0.5176 - val_mse: 0.5106\n",
      "Epoch 205/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5677 - mse: 0.5608 - val_loss: 0.5187 - val_mse: 0.5118\n",
      "Epoch 206/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5719 - mse: 0.5650 - val_loss: 0.5207 - val_mse: 0.5137\n",
      "Epoch 207/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5668 - mse: 0.5598 - val_loss: 0.5263 - val_mse: 0.5194\n",
      "Epoch 208/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5692 - mse: 0.5623 - val_loss: 0.5252 - val_mse: 0.5182\n",
      "Epoch 209/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5698 - mse: 0.5628 - val_loss: 0.5187 - val_mse: 0.5118\n",
      "Epoch 210/1000\n",
      "301/312 [===========================>..] - ETA: 0s - loss: 0.5722 - mse: 0.5652\n",
      "Epoch 00210: saving model to Regression_Model/thle2.mse.linear-0210.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5755 - mse: 0.5686 - val_loss: 0.5192 - val_mse: 0.5123\n",
      "Epoch 211/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5716 - mse: 0.5647 - val_loss: 0.5164 - val_mse: 0.5095\n",
      "Epoch 212/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5733 - mse: 0.5664 - val_loss: 0.5191 - val_mse: 0.5121\n",
      "Epoch 213/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5737 - mse: 0.5668 - val_loss: 0.5141 - val_mse: 0.5071\n",
      "Epoch 214/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5702 - mse: 0.5633 - val_loss: 0.5227 - val_mse: 0.5158\n",
      "Epoch 215/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5820 - mse: 0.5751 - val_loss: 0.5280 - val_mse: 0.5211\n",
      "Epoch 216/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5715 - mse: 0.5646 - val_loss: 0.5368 - val_mse: 0.5299\n",
      "Epoch 217/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5783 - mse: 0.5714 - val_loss: 0.5206 - val_mse: 0.5137\n",
      "Epoch 218/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5710 - mse: 0.5641 - val_loss: 0.5265 - val_mse: 0.5196\n",
      "Epoch 219/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5668 - mse: 0.5599 - val_loss: 0.5360 - val_mse: 0.5291\n",
      "Epoch 220/1000\n",
      "304/312 [============================>.] - ETA: 0s - loss: 0.5758 - mse: 0.5689\n",
      "Epoch 00220: saving model to Regression_Model/thle2.mse.linear-0220.ckpt\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.5779 - mse: 0.5710 - val_loss: 0.5259 - val_mse: 0.5190\n",
      "Epoch 221/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5648 - mse: 0.5579 - val_loss: 0.5137 - val_mse: 0.5068\n",
      "Epoch 222/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5709 - mse: 0.5640 - val_loss: 0.5232 - val_mse: 0.5163\n",
      "Epoch 223/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5710 - mse: 0.5641 - val_loss: 0.5214 - val_mse: 0.5145\n",
      "Epoch 224/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5714 - mse: 0.5645 - val_loss: 0.5151 - val_mse: 0.5082\n",
      "Epoch 225/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5736 - mse: 0.5667 - val_loss: 0.5345 - val_mse: 0.5276\n",
      "Epoch 226/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5659 - mse: 0.5590 - val_loss: 0.5112 - val_mse: 0.5043\n",
      "Epoch 227/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5716 - mse: 0.5647 - val_loss: 0.5279 - val_mse: 0.5210\n",
      "Epoch 228/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5746 - mse: 0.5677 - val_loss: 0.5154 - val_mse: 0.5085\n",
      "Epoch 229/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5670 - mse: 0.5601 - val_loss: 0.5162 - val_mse: 0.5093\n",
      "Epoch 230/1000\n",
      "296/312 [===========================>..] - ETA: 0s - loss: 0.5731 - mse: 0.5662\n",
      "Epoch 00230: saving model to Regression_Model/thle2.mse.linear-0230.ckpt\n",
      "312/312 [==============================] - 4s 13ms/step - loss: 0.5735 - mse: 0.5666 - val_loss: 0.5227 - val_mse: 0.5158\n",
      "Epoch 231/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5681 - mse: 0.5613 - val_loss: 0.5198 - val_mse: 0.5130\n",
      "Epoch 232/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5746 - mse: 0.5677 - val_loss: 0.5155 - val_mse: 0.5087\n",
      "Epoch 233/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5754 - mse: 0.5686 - val_loss: 0.5204 - val_mse: 0.5135\n",
      "Epoch 234/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5677 - mse: 0.5608 - val_loss: 0.5263 - val_mse: 0.5195\n",
      "Epoch 235/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5697 - mse: 0.5628 - val_loss: 0.5265 - val_mse: 0.5197\n",
      "Epoch 236/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5642 - mse: 0.5573 - val_loss: 0.5237 - val_mse: 0.5168\n",
      "Epoch 237/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5733 - mse: 0.5665 - val_loss: 0.5160 - val_mse: 0.5091\n",
      "Epoch 238/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5674 - mse: 0.5605 - val_loss: 0.5159 - val_mse: 0.5091\n",
      "Epoch 239/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5692 - mse: 0.5624 - val_loss: 0.5092 - val_mse: 0.5024\n",
      "Epoch 240/1000\n",
      "299/312 [===========================>..] - ETA: 0s - loss: 0.5760 - mse: 0.5692\n",
      "Epoch 00240: saving model to Regression_Model/thle2.mse.linear-0240.ckpt\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.5746 - mse: 0.5678 - val_loss: 0.5149 - val_mse: 0.5081\n",
      "Epoch 241/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5665 - mse: 0.5596 - val_loss: 0.5208 - val_mse: 0.5140\n",
      "Epoch 242/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5621 - mse: 0.5553 - val_loss: 0.5154 - val_mse: 0.5086\n",
      "Epoch 243/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5700 - mse: 0.5631 - val_loss: 0.5221 - val_mse: 0.5153\n",
      "Epoch 244/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5676 - mse: 0.5607 - val_loss: 0.5204 - val_mse: 0.5136\n",
      "Epoch 245/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5714 - mse: 0.5646 - val_loss: 0.5136 - val_mse: 0.5068\n",
      "Epoch 246/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5694 - mse: 0.5626 - val_loss: 0.5276 - val_mse: 0.5208\n",
      "Epoch 247/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5697 - mse: 0.5629 - val_loss: 0.5321 - val_mse: 0.5253\n",
      "Epoch 248/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5769 - mse: 0.5701 - val_loss: 0.5145 - val_mse: 0.5077\n",
      "Epoch 249/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5732 - mse: 0.5664 - val_loss: 0.5211 - val_mse: 0.5143\n",
      "Epoch 250/1000\n",
      "300/312 [===========================>..] - ETA: 0s - loss: 0.5669 - mse: 0.5601\n",
      "Epoch 00250: saving model to Regression_Model/thle2.mse.linear-0250.ckpt\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.5681 - mse: 0.5613 - val_loss: 0.5130 - val_mse: 0.5062\n",
      "Epoch 251/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5740 - mse: 0.5672 - val_loss: 0.5274 - val_mse: 0.5206\n",
      "Epoch 252/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5701 - mse: 0.5633 - val_loss: 0.5353 - val_mse: 0.5285\n",
      "Epoch 253/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5688 - mse: 0.5620 - val_loss: 0.5290 - val_mse: 0.5222\n",
      "Epoch 254/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5747 - mse: 0.5679 - val_loss: 0.5155 - val_mse: 0.5087\n",
      "Epoch 255/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5718 - mse: 0.5650 - val_loss: 0.5133 - val_mse: 0.5065\n",
      "Epoch 256/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5592 - mse: 0.5524 - val_loss: 0.5152 - val_mse: 0.5084\n",
      "Epoch 257/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5631 - mse: 0.5563 - val_loss: 0.5079 - val_mse: 0.5012\n",
      "Epoch 258/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5753 - mse: 0.5685 - val_loss: 0.5275 - val_mse: 0.5207\n",
      "Epoch 259/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5643 - mse: 0.5575 - val_loss: 0.5257 - val_mse: 0.5189\n",
      "Epoch 260/1000\n",
      "302/312 [============================>.] - ETA: 0s - loss: 0.5696 - mse: 0.5628\n",
      "Epoch 00260: saving model to Regression_Model/thle2.mse.linear-0260.ckpt\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5720 - mse: 0.5652 - val_loss: 0.5149 - val_mse: 0.5081\n",
      "Epoch 261/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5666 - mse: 0.5598 - val_loss: 0.5247 - val_mse: 0.5179\n",
      "Epoch 262/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5658 - mse: 0.5590 - val_loss: 0.5182 - val_mse: 0.5114\n",
      "Epoch 263/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5733 - mse: 0.5666 - val_loss: 0.5092 - val_mse: 0.5024\n",
      "Epoch 264/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5668 - mse: 0.5600 - val_loss: 0.5167 - val_mse: 0.5099\n",
      "Epoch 265/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5657 - mse: 0.5590 - val_loss: 0.5156 - val_mse: 0.5088\n",
      "Epoch 266/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5684 - mse: 0.5617 - val_loss: 0.5218 - val_mse: 0.5150\n",
      "Epoch 267/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5786 - mse: 0.5719 - val_loss: 0.5150 - val_mse: 0.5083\n",
      "Epoch 268/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5716 - mse: 0.5649 - val_loss: 0.5128 - val_mse: 0.5060\n",
      "Epoch 269/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5725 - mse: 0.5658 - val_loss: 0.5215 - val_mse: 0.5147\n",
      "Epoch 270/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5700 - mse: 0.5633\n",
      "Epoch 00270: saving model to Regression_Model/thle2.mse.linear-0270.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5682 - mse: 0.5615 - val_loss: 0.5177 - val_mse: 0.5109\n",
      "Epoch 271/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5687 - mse: 0.5620 - val_loss: 0.5173 - val_mse: 0.5105\n",
      "Epoch 272/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5708 - mse: 0.5641 - val_loss: 0.5177 - val_mse: 0.5110\n",
      "Epoch 273/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5670 - mse: 0.5603 - val_loss: 0.5131 - val_mse: 0.5063\n",
      "Epoch 274/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5641 - mse: 0.5573 - val_loss: 0.5220 - val_mse: 0.5152\n",
      "Epoch 275/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5664 - mse: 0.5597 - val_loss: 0.5171 - val_mse: 0.5104\n",
      "Epoch 276/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5682 - mse: 0.5615 - val_loss: 0.5228 - val_mse: 0.5161\n",
      "Epoch 277/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5666 - mse: 0.5599 - val_loss: 0.5296 - val_mse: 0.5229\n",
      "Epoch 278/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5754 - mse: 0.5687 - val_loss: 0.5191 - val_mse: 0.5124\n",
      "Epoch 279/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5680 - mse: 0.5613 - val_loss: 0.5159 - val_mse: 0.5092\n",
      "Epoch 280/1000\n",
      "308/312 [============================>.] - ETA: 0s - loss: 0.5680 - mse: 0.5613\n",
      "Epoch 00280: saving model to Regression_Model/thle2.mse.linear-0280.ckpt\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5686 - mse: 0.5619 - val_loss: 0.5168 - val_mse: 0.5101\n",
      "Epoch 281/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5724 - mse: 0.5657 - val_loss: 0.5140 - val_mse: 0.5073\n",
      "Epoch 282/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5626 - mse: 0.5559 - val_loss: 0.5254 - val_mse: 0.5187\n",
      "Epoch 283/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5694 - mse: 0.5627 - val_loss: 0.5150 - val_mse: 0.5083\n",
      "Epoch 284/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5673 - mse: 0.5606 - val_loss: 0.5097 - val_mse: 0.5030\n",
      "Epoch 285/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5677 - mse: 0.5610 - val_loss: 0.5317 - val_mse: 0.5250\n",
      "Epoch 286/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5597 - mse: 0.5531 - val_loss: 0.5132 - val_mse: 0.5065\n",
      "Epoch 287/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5712 - mse: 0.5645 - val_loss: 0.5135 - val_mse: 0.5068\n",
      "Epoch 288/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5673 - mse: 0.5607 - val_loss: 0.5168 - val_mse: 0.5101\n",
      "Epoch 289/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5670 - mse: 0.5603 - val_loss: 0.5186 - val_mse: 0.5119\n",
      "Epoch 290/1000\n",
      "311/312 [============================>.] - ETA: 0s - loss: 0.5736 - mse: 0.5669\n",
      "Epoch 00290: saving model to Regression_Model/thle2.mse.linear-0290.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5752 - mse: 0.5685 - val_loss: 0.5328 - val_mse: 0.5261\n",
      "Epoch 291/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5667 - mse: 0.5600 - val_loss: 0.5150 - val_mse: 0.5083\n",
      "Epoch 292/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5676 - mse: 0.5610 - val_loss: 0.5169 - val_mse: 0.5102\n",
      "Epoch 293/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5668 - mse: 0.5602 - val_loss: 0.5114 - val_mse: 0.5048\n",
      "Epoch 294/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5704 - mse: 0.5638 - val_loss: 0.5283 - val_mse: 0.5217\n",
      "Epoch 295/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5727 - mse: 0.5661 - val_loss: 0.5206 - val_mse: 0.5139\n",
      "Epoch 296/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5674 - mse: 0.5607 - val_loss: 0.5231 - val_mse: 0.5165\n",
      "Epoch 297/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5704 - mse: 0.5638 - val_loss: 0.5232 - val_mse: 0.5166\n",
      "Epoch 298/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5662 - mse: 0.5595 - val_loss: 0.5229 - val_mse: 0.5163\n",
      "Epoch 299/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5687 - mse: 0.5620 - val_loss: 0.5237 - val_mse: 0.5171\n",
      "Epoch 300/1000\n",
      "305/312 [============================>.] - ETA: 0s - loss: 0.5627 - mse: 0.5560\n",
      "Epoch 00300: saving model to Regression_Model/thle2.mse.linear-0300.ckpt\n",
      "312/312 [==============================] - 4s 12ms/step - loss: 0.5632 - mse: 0.5565 - val_loss: 0.5368 - val_mse: 0.5301\n",
      "Epoch 301/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5712 - mse: 0.5646 - val_loss: 0.5269 - val_mse: 0.5202\n",
      "Epoch 302/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5706 - mse: 0.5639 - val_loss: 0.5076 - val_mse: 0.5010\n",
      "Epoch 303/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5807 - mse: 0.5741 - val_loss: 0.5244 - val_mse: 0.5178\n",
      "Epoch 304/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5678 - mse: 0.5611 - val_loss: 0.5222 - val_mse: 0.5156\n",
      "Epoch 305/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5684 - mse: 0.5618 - val_loss: 0.5206 - val_mse: 0.5140\n",
      "Epoch 306/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5675 - mse: 0.5609 - val_loss: 0.5154 - val_mse: 0.5088\n",
      "Epoch 307/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5689 - mse: 0.5623 - val_loss: 0.5170 - val_mse: 0.5103\n",
      "Epoch 308/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5624 - mse: 0.5557 - val_loss: 0.5158 - val_mse: 0.5092\n",
      "Epoch 309/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5592 - mse: 0.5526 - val_loss: 0.5149 - val_mse: 0.5083\n",
      "Epoch 310/1000\n",
      "307/312 [============================>.] - ETA: 0s - loss: 0.5694 - mse: 0.5628\n",
      "Epoch 00310: saving model to Regression_Model/thle2.mse.linear-0310.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5721 - mse: 0.5654 - val_loss: 0.5171 - val_mse: 0.5104\n",
      "Epoch 311/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5659 - mse: 0.5593 - val_loss: 0.5204 - val_mse: 0.5137\n",
      "Epoch 312/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5743 - mse: 0.5677 - val_loss: 0.5194 - val_mse: 0.5127\n",
      "Epoch 313/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5682 - mse: 0.5616 - val_loss: 0.5131 - val_mse: 0.5065\n",
      "Epoch 314/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5661 - mse: 0.5594 - val_loss: 0.5168 - val_mse: 0.5101\n",
      "Epoch 315/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5622 - mse: 0.5556 - val_loss: 0.5126 - val_mse: 0.5059\n",
      "Epoch 316/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5680 - mse: 0.5614 - val_loss: 0.5142 - val_mse: 0.5076\n",
      "Epoch 317/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5715 - mse: 0.5649 - val_loss: 0.5067 - val_mse: 0.5000\n",
      "Epoch 318/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5680 - mse: 0.5614 - val_loss: 0.5209 - val_mse: 0.5143\n",
      "Epoch 319/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5655 - mse: 0.5589 - val_loss: 0.5209 - val_mse: 0.5143\n",
      "Epoch 320/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5614 - mse: 0.5548\n",
      "Epoch 00320: saving model to Regression_Model/thle2.mse.linear-0320.ckpt\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.5613 - mse: 0.5547 - val_loss: 0.5211 - val_mse: 0.5145\n",
      "Epoch 321/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5718 - mse: 0.5652 - val_loss: 0.5169 - val_mse: 0.5103\n",
      "Epoch 322/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5624 - mse: 0.5559 - val_loss: 0.5150 - val_mse: 0.5084\n",
      "Epoch 323/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5652 - mse: 0.5586 - val_loss: 0.5267 - val_mse: 0.5201\n",
      "Epoch 324/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5624 - mse: 0.5558 - val_loss: 0.5165 - val_mse: 0.5099\n",
      "Epoch 325/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5641 - mse: 0.5576 - val_loss: 0.5121 - val_mse: 0.5055\n",
      "Epoch 326/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5563 - mse: 0.5497 - val_loss: 0.5229 - val_mse: 0.5163\n",
      "Epoch 327/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5630 - mse: 0.5565 - val_loss: 0.5241 - val_mse: 0.5176\n",
      "Epoch 328/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5671 - mse: 0.5605 - val_loss: 0.5189 - val_mse: 0.5123\n",
      "Epoch 329/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5670 - mse: 0.5604 - val_loss: 0.5217 - val_mse: 0.5152\n",
      "Epoch 330/1000\n",
      "301/312 [===========================>..] - ETA: 0s - loss: 0.5713 - mse: 0.5647\n",
      "Epoch 00330: saving model to Regression_Model/thle2.mse.linear-0330.ckpt\n",
      "312/312 [==============================] - 3s 10ms/step - loss: 0.5687 - mse: 0.5622 - val_loss: 0.5190 - val_mse: 0.5125\n",
      "Epoch 331/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5637 - mse: 0.5571 - val_loss: 0.5279 - val_mse: 0.5214\n",
      "Epoch 332/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5683 - mse: 0.5617 - val_loss: 0.5228 - val_mse: 0.5163\n",
      "Epoch 333/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5609 - mse: 0.5543 - val_loss: 0.5227 - val_mse: 0.5161\n",
      "Epoch 334/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5648 - mse: 0.5582 - val_loss: 0.5151 - val_mse: 0.5086\n",
      "Epoch 335/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5660 - mse: 0.5594 - val_loss: 0.5221 - val_mse: 0.5155\n",
      "Epoch 336/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5616 - mse: 0.5551 - val_loss: 0.5218 - val_mse: 0.5153\n",
      "Epoch 337/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5620 - mse: 0.5554 - val_loss: 0.5086 - val_mse: 0.5021\n",
      "Epoch 338/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5646 - mse: 0.5581 - val_loss: 0.5162 - val_mse: 0.5096\n",
      "Epoch 339/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5609 - mse: 0.5543 - val_loss: 0.5336 - val_mse: 0.5271\n",
      "Epoch 340/1000\n",
      "296/312 [===========================>..] - ETA: 0s - loss: 0.5655 - mse: 0.5589\n",
      "Epoch 00340: saving model to Regression_Model/thle2.mse.linear-0340.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5636 - mse: 0.5571 - val_loss: 0.5088 - val_mse: 0.5023\n",
      "Epoch 341/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5639 - mse: 0.5574 - val_loss: 0.5150 - val_mse: 0.5084\n",
      "Epoch 342/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5634 - mse: 0.5569 - val_loss: 0.5117 - val_mse: 0.5051\n",
      "Epoch 343/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5598 - mse: 0.5533 - val_loss: 0.5057 - val_mse: 0.4992\n",
      "Epoch 344/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5647 - mse: 0.5581 - val_loss: 0.5209 - val_mse: 0.5144\n",
      "Epoch 345/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5667 - mse: 0.5601 - val_loss: 0.5127 - val_mse: 0.5062\n",
      "Epoch 346/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5602 - mse: 0.5537 - val_loss: 0.5192 - val_mse: 0.5126\n",
      "Epoch 347/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5616 - mse: 0.5551 - val_loss: 0.5150 - val_mse: 0.5085\n",
      "Epoch 348/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5627 - mse: 0.5562 - val_loss: 0.5259 - val_mse: 0.5193\n",
      "Epoch 349/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5670 - mse: 0.5605 - val_loss: 0.5081 - val_mse: 0.5016\n",
      "Epoch 350/1000\n",
      "297/312 [===========================>..] - ETA: 0s - loss: 0.5609 - mse: 0.5544\n",
      "Epoch 00350: saving model to Regression_Model/thle2.mse.linear-0350.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5612 - mse: 0.5547 - val_loss: 0.5106 - val_mse: 0.5041\n",
      "Epoch 351/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5644 - mse: 0.5578 - val_loss: 0.5228 - val_mse: 0.5163\n",
      "Epoch 352/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5565 - mse: 0.5499 - val_loss: 0.5156 - val_mse: 0.5091\n",
      "Epoch 353/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5647 - mse: 0.5582 - val_loss: 0.5164 - val_mse: 0.5099\n",
      "Epoch 354/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5696 - mse: 0.5630 - val_loss: 0.5224 - val_mse: 0.5158\n",
      "Epoch 355/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5666 - mse: 0.5601 - val_loss: 0.5133 - val_mse: 0.5068\n",
      "Epoch 356/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5571 - mse: 0.5506 - val_loss: 0.5142 - val_mse: 0.5077\n",
      "Epoch 357/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5688 - mse: 0.5624 - val_loss: 0.5171 - val_mse: 0.5106\n",
      "Epoch 358/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5603 - mse: 0.5538 - val_loss: 0.5125 - val_mse: 0.5060\n",
      "Epoch 359/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5567 - mse: 0.5502 - val_loss: 0.5172 - val_mse: 0.5107\n",
      "Epoch 360/1000\n",
      "301/312 [===========================>..] - ETA: 0s - loss: 0.5607 - mse: 0.5542\n",
      "Epoch 00360: saving model to Regression_Model/thle2.mse.linear-0360.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5590 - mse: 0.5525 - val_loss: 0.5092 - val_mse: 0.5027\n",
      "Epoch 361/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5578 - mse: 0.5513 - val_loss: 0.5136 - val_mse: 0.5072\n",
      "Epoch 362/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5675 - mse: 0.5610 - val_loss: 0.5337 - val_mse: 0.5272\n",
      "Epoch 363/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5593 - mse: 0.5528 - val_loss: 0.5102 - val_mse: 0.5037\n",
      "Epoch 364/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5637 - mse: 0.5572 - val_loss: 0.5218 - val_mse: 0.5153\n",
      "Epoch 365/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5573 - mse: 0.5509 - val_loss: 0.5243 - val_mse: 0.5178\n",
      "Epoch 366/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5646 - mse: 0.5581 - val_loss: 0.5152 - val_mse: 0.5087\n",
      "Epoch 367/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5614 - mse: 0.5550 - val_loss: 0.5179 - val_mse: 0.5114\n",
      "Epoch 368/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5587 - mse: 0.5523 - val_loss: 0.5097 - val_mse: 0.5032\n",
      "Epoch 369/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5603 - mse: 0.5538 - val_loss: 0.5092 - val_mse: 0.5028\n",
      "Epoch 370/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5643 - mse: 0.5578\n",
      "Epoch 00370: saving model to Regression_Model/thle2.mse.linear-0370.ckpt\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.5622 - mse: 0.5557 - val_loss: 0.5115 - val_mse: 0.5050\n",
      "Epoch 371/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5691 - mse: 0.5626 - val_loss: 0.5192 - val_mse: 0.5128\n",
      "Epoch 372/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5656 - mse: 0.5592 - val_loss: 0.5155 - val_mse: 0.5090\n",
      "Epoch 373/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5721 - mse: 0.5657 - val_loss: 0.5086 - val_mse: 0.5021\n",
      "Epoch 374/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5587 - mse: 0.5522 - val_loss: 0.5115 - val_mse: 0.5050\n",
      "Epoch 375/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5628 - mse: 0.5563 - val_loss: 0.5124 - val_mse: 0.5059\n",
      "Epoch 376/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5591 - mse: 0.5527 - val_loss: 0.5162 - val_mse: 0.5097\n",
      "Epoch 377/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5605 - mse: 0.5541 - val_loss: 0.5272 - val_mse: 0.5208\n",
      "Epoch 378/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5568 - mse: 0.5503 - val_loss: 0.5158 - val_mse: 0.5094\n",
      "Epoch 379/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5551 - mse: 0.5487 - val_loss: 0.5069 - val_mse: 0.5005\n",
      "Epoch 380/1000\n",
      "300/312 [===========================>..] - ETA: 0s - loss: 0.5631 - mse: 0.5566\n",
      "Epoch 00380: saving model to Regression_Model/thle2.mse.linear-0380.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5610 - mse: 0.5545 - val_loss: 0.5295 - val_mse: 0.5231\n",
      "Epoch 381/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5572 - mse: 0.5507 - val_loss: 0.5252 - val_mse: 0.5187\n",
      "Epoch 382/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5621 - mse: 0.5557 - val_loss: 0.5169 - val_mse: 0.5105\n",
      "Epoch 383/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5589 - mse: 0.5524 - val_loss: 0.5141 - val_mse: 0.5077\n",
      "Epoch 384/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5663 - mse: 0.5599 - val_loss: 0.5126 - val_mse: 0.5062\n",
      "Epoch 385/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5623 - mse: 0.5559 - val_loss: 0.5222 - val_mse: 0.5158\n",
      "Epoch 386/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5706 - mse: 0.5642 - val_loss: 0.5153 - val_mse: 0.5089\n",
      "Epoch 387/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5558 - mse: 0.5494 - val_loss: 0.5112 - val_mse: 0.5048\n",
      "Epoch 388/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5559 - mse: 0.5495 - val_loss: 0.5103 - val_mse: 0.5038\n",
      "Epoch 389/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5655 - mse: 0.5591 - val_loss: 0.5168 - val_mse: 0.5104\n",
      "Epoch 390/1000\n",
      "301/312 [===========================>..] - ETA: 0s - loss: 0.5625 - mse: 0.5561\n",
      "Epoch 00390: saving model to Regression_Model/thle2.mse.linear-0390.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5647 - mse: 0.5583 - val_loss: 0.5091 - val_mse: 0.5026\n",
      "Epoch 391/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5628 - mse: 0.5563 - val_loss: 0.5123 - val_mse: 0.5059\n",
      "Epoch 392/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5597 - mse: 0.5533 - val_loss: 0.5270 - val_mse: 0.5206\n",
      "Epoch 393/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5604 - mse: 0.5540 - val_loss: 0.5197 - val_mse: 0.5133\n",
      "Epoch 394/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5595 - mse: 0.5531 - val_loss: 0.5103 - val_mse: 0.5038\n",
      "Epoch 395/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5592 - mse: 0.5528 - val_loss: 0.5080 - val_mse: 0.5015\n",
      "Epoch 396/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5593 - mse: 0.5529 - val_loss: 0.5168 - val_mse: 0.5104\n",
      "Epoch 397/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5612 - mse: 0.5548 - val_loss: 0.5183 - val_mse: 0.5119\n",
      "Epoch 398/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5528 - mse: 0.5464 - val_loss: 0.5045 - val_mse: 0.4981\n",
      "Epoch 399/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5660 - mse: 0.5596 - val_loss: 0.5256 - val_mse: 0.5192\n",
      "Epoch 400/1000\n",
      "301/312 [===========================>..] - ETA: 0s - loss: 0.5596 - mse: 0.5532\n",
      "Epoch 00400: saving model to Regression_Model/thle2.mse.linear-0400.ckpt\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5596 - mse: 0.5532 - val_loss: 0.5119 - val_mse: 0.5055\n",
      "Epoch 401/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5612 - mse: 0.5548 - val_loss: 0.5197 - val_mse: 0.5133\n",
      "Epoch 402/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5610 - mse: 0.5546 - val_loss: 0.5096 - val_mse: 0.5032\n",
      "Epoch 403/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5585 - mse: 0.5522 - val_loss: 0.5125 - val_mse: 0.5061\n",
      "Epoch 404/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5559 - mse: 0.5495 - val_loss: 0.5143 - val_mse: 0.5079\n",
      "Epoch 405/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5562 - mse: 0.5498 - val_loss: 0.5105 - val_mse: 0.5041\n",
      "Epoch 406/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5604 - mse: 0.5540 - val_loss: 0.5083 - val_mse: 0.5019\n",
      "Epoch 407/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5626 - mse: 0.5562 - val_loss: 0.5142 - val_mse: 0.5079\n",
      "Epoch 408/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5683 - mse: 0.5620 - val_loss: 0.5225 - val_mse: 0.5161\n",
      "Epoch 409/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5587 - mse: 0.5524 - val_loss: 0.5269 - val_mse: 0.5205\n",
      "Epoch 410/1000\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.5619 - mse: 0.5556\n",
      "Epoch 00410: saving model to Regression_Model/thle2.mse.linear-0410.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5630 - mse: 0.5566 - val_loss: 0.5160 - val_mse: 0.5096\n",
      "Epoch 411/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5626 - mse: 0.5563 - val_loss: 0.5142 - val_mse: 0.5078\n",
      "Epoch 412/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5617 - mse: 0.5553 - val_loss: 0.5172 - val_mse: 0.5108\n",
      "Epoch 413/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5524 - mse: 0.5460 - val_loss: 0.5116 - val_mse: 0.5052\n",
      "Epoch 414/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5533 - mse: 0.5470 - val_loss: 0.5105 - val_mse: 0.5042\n",
      "Epoch 415/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5567 - mse: 0.5503 - val_loss: 0.5086 - val_mse: 0.5023\n",
      "Epoch 416/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5589 - mse: 0.5525 - val_loss: 0.5146 - val_mse: 0.5083\n",
      "Epoch 417/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5648 - mse: 0.5585 - val_loss: 0.5274 - val_mse: 0.5211\n",
      "Epoch 418/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5543 - mse: 0.5479 - val_loss: 0.5130 - val_mse: 0.5067\n",
      "Epoch 419/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5567 - mse: 0.5504 - val_loss: 0.5173 - val_mse: 0.5110\n",
      "Epoch 420/1000\n",
      "308/312 [============================>.] - ETA: 0s - loss: 0.5556 - mse: 0.5492\n",
      "Epoch 00420: saving model to Regression_Model/thle2.mse.linear-0420.ckpt\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.5559 - mse: 0.5496 - val_loss: 0.5117 - val_mse: 0.5054\n",
      "Epoch 421/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5558 - mse: 0.5495 - val_loss: 0.5074 - val_mse: 0.5010\n",
      "Epoch 422/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5585 - mse: 0.5522 - val_loss: 0.5202 - val_mse: 0.5138\n",
      "Epoch 423/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5582 - mse: 0.5519 - val_loss: 0.5118 - val_mse: 0.5054\n",
      "Epoch 424/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5614 - mse: 0.5550 - val_loss: 0.5046 - val_mse: 0.4983\n",
      "Epoch 425/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5614 - mse: 0.5551 - val_loss: 0.5211 - val_mse: 0.5148\n",
      "Epoch 426/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5555 - mse: 0.5491 - val_loss: 0.5048 - val_mse: 0.4985\n",
      "Epoch 427/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5621 - mse: 0.5557 - val_loss: 0.5121 - val_mse: 0.5058\n",
      "Epoch 428/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5564 - mse: 0.5500 - val_loss: 0.5155 - val_mse: 0.5091\n",
      "Epoch 429/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5542 - mse: 0.5479 - val_loss: 0.5115 - val_mse: 0.5052\n",
      "Epoch 430/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5570 - mse: 0.5506\n",
      "Epoch 00430: saving model to Regression_Model/thle2.mse.linear-0430.ckpt\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5561 - mse: 0.5498 - val_loss: 0.5141 - val_mse: 0.5078\n",
      "Epoch 431/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5584 - mse: 0.5520 - val_loss: 0.5138 - val_mse: 0.5074\n",
      "Epoch 432/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5592 - mse: 0.5528 - val_loss: 0.5152 - val_mse: 0.5089\n",
      "Epoch 433/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5534 - mse: 0.5471 - val_loss: 0.5127 - val_mse: 0.5063\n",
      "Epoch 434/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5639 - mse: 0.5576 - val_loss: 0.5162 - val_mse: 0.5099\n",
      "Epoch 435/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5634 - mse: 0.5571 - val_loss: 0.5217 - val_mse: 0.5154\n",
      "Epoch 436/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5563 - mse: 0.5500 - val_loss: 0.5162 - val_mse: 0.5099\n",
      "Epoch 437/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5661 - mse: 0.5598 - val_loss: 0.5212 - val_mse: 0.5149\n",
      "Epoch 438/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5589 - mse: 0.5526 - val_loss: 0.5190 - val_mse: 0.5127\n",
      "Epoch 439/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5609 - mse: 0.5546 - val_loss: 0.5103 - val_mse: 0.5040\n",
      "Epoch 440/1000\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.5533 - mse: 0.5470\n",
      "Epoch 00440: saving model to Regression_Model/thle2.mse.linear-0440.ckpt\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.5557 - mse: 0.5494 - val_loss: 0.5197 - val_mse: 0.5134\n",
      "Epoch 441/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5610 - mse: 0.5546 - val_loss: 0.5184 - val_mse: 0.5121\n",
      "Epoch 442/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5593 - mse: 0.5530 - val_loss: 0.5132 - val_mse: 0.5069\n",
      "Epoch 443/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5526 - mse: 0.5463 - val_loss: 0.5252 - val_mse: 0.5189\n",
      "Epoch 444/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5580 - mse: 0.5517 - val_loss: 0.5208 - val_mse: 0.5145\n",
      "Epoch 445/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5554 - mse: 0.5491 - val_loss: 0.5177 - val_mse: 0.5114\n",
      "Epoch 446/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5521 - mse: 0.5458 - val_loss: 0.5175 - val_mse: 0.5112\n",
      "Epoch 447/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5576 - mse: 0.5513 - val_loss: 0.5136 - val_mse: 0.5073\n",
      "Epoch 448/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5585 - mse: 0.5522 - val_loss: 0.5112 - val_mse: 0.5049\n",
      "Epoch 449/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5642 - mse: 0.5579 - val_loss: 0.5113 - val_mse: 0.5050\n",
      "Epoch 450/1000\n",
      "305/312 [============================>.] - ETA: 0s - loss: 0.5606 - mse: 0.5544\n",
      "Epoch 00450: saving model to Regression_Model/thle2.mse.linear-0450.ckpt\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.5614 - mse: 0.5551 - val_loss: 0.5232 - val_mse: 0.5169\n",
      "Epoch 451/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5573 - mse: 0.5510 - val_loss: 0.5075 - val_mse: 0.5012\n",
      "Epoch 452/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5579 - mse: 0.5516 - val_loss: 0.5116 - val_mse: 0.5053\n",
      "Epoch 453/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5504 - mse: 0.5442 - val_loss: 0.5085 - val_mse: 0.5022\n",
      "Epoch 454/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5611 - mse: 0.5548 - val_loss: 0.5102 - val_mse: 0.5040\n",
      "Epoch 455/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5596 - mse: 0.5533 - val_loss: 0.5160 - val_mse: 0.5097\n",
      "Epoch 456/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5604 - mse: 0.5542 - val_loss: 0.5148 - val_mse: 0.5085\n",
      "Epoch 457/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5607 - mse: 0.5544 - val_loss: 0.5212 - val_mse: 0.5149\n",
      "Epoch 458/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5553 - mse: 0.5491 - val_loss: 0.5295 - val_mse: 0.5232\n",
      "Epoch 459/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5625 - mse: 0.5562 - val_loss: 0.5104 - val_mse: 0.5042\n",
      "Epoch 460/1000\n",
      "307/312 [============================>.] - ETA: 0s - loss: 0.5565 - mse: 0.5502\n",
      "Epoch 00460: saving model to Regression_Model/thle2.mse.linear-0460.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5573 - mse: 0.5510 - val_loss: 0.5069 - val_mse: 0.5006\n",
      "Epoch 461/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5577 - mse: 0.5515 - val_loss: 0.5141 - val_mse: 0.5078\n",
      "Epoch 462/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5539 - mse: 0.5477 - val_loss: 0.5104 - val_mse: 0.5042\n",
      "Epoch 463/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5536 - mse: 0.5473 - val_loss: 0.5051 - val_mse: 0.4988\n",
      "Epoch 464/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5582 - mse: 0.5520 - val_loss: 0.5148 - val_mse: 0.5085\n",
      "Epoch 465/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5580 - mse: 0.5518 - val_loss: 0.5114 - val_mse: 0.5052\n",
      "Epoch 466/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5571 - mse: 0.5509 - val_loss: 0.5150 - val_mse: 0.5087\n",
      "Epoch 467/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5573 - mse: 0.5510 - val_loss: 0.5295 - val_mse: 0.5232\n",
      "Epoch 468/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5566 - mse: 0.5504 - val_loss: 0.5183 - val_mse: 0.5121\n",
      "Epoch 469/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5576 - mse: 0.5514 - val_loss: 0.5100 - val_mse: 0.5038\n",
      "Epoch 470/1000\n",
      "304/312 [============================>.] - ETA: 0s - loss: 0.5471 - mse: 0.5409\n",
      "Epoch 00470: saving model to Regression_Model/thle2.mse.linear-0470.ckpt\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.5489 - mse: 0.5427 - val_loss: 0.5098 - val_mse: 0.5035\n",
      "Epoch 471/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5569 - mse: 0.5507 - val_loss: 0.5194 - val_mse: 0.5131\n",
      "Epoch 472/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5543 - mse: 0.5480 - val_loss: 0.5075 - val_mse: 0.5013\n",
      "Epoch 473/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5620 - mse: 0.5557 - val_loss: 0.5174 - val_mse: 0.5112\n",
      "Epoch 474/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5578 - mse: 0.5515 - val_loss: 0.5170 - val_mse: 0.5108\n",
      "Epoch 475/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5595 - mse: 0.5532 - val_loss: 0.5086 - val_mse: 0.5024\n",
      "Epoch 476/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5522 - mse: 0.5459 - val_loss: 0.5088 - val_mse: 0.5026\n",
      "Epoch 477/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5610 - mse: 0.5547 - val_loss: 0.5100 - val_mse: 0.5038\n",
      "Epoch 478/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5551 - mse: 0.5489 - val_loss: 0.5132 - val_mse: 0.5070\n",
      "Epoch 479/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5594 - mse: 0.5532 - val_loss: 0.5175 - val_mse: 0.5113\n",
      "Epoch 480/1000\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.5605 - mse: 0.5543\n",
      "Epoch 00480: saving model to Regression_Model/thle2.mse.linear-0480.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5606 - mse: 0.5543 - val_loss: 0.5063 - val_mse: 0.5000\n",
      "Epoch 481/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5575 - mse: 0.5513 - val_loss: 0.5048 - val_mse: 0.4986\n",
      "Epoch 482/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5494 - mse: 0.5432 - val_loss: 0.5130 - val_mse: 0.5068\n",
      "Epoch 483/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5584 - mse: 0.5522 - val_loss: 0.5098 - val_mse: 0.5036\n",
      "Epoch 484/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5513 - mse: 0.5451 - val_loss: 0.5114 - val_mse: 0.5052\n",
      "Epoch 485/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5558 - mse: 0.5496 - val_loss: 0.5158 - val_mse: 0.5096\n",
      "Epoch 486/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5512 - mse: 0.5450 - val_loss: 0.5083 - val_mse: 0.5021\n",
      "Epoch 487/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5499 - mse: 0.5437 - val_loss: 0.5150 - val_mse: 0.5088\n",
      "Epoch 488/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5530 - mse: 0.5468 - val_loss: 0.5089 - val_mse: 0.5027\n",
      "Epoch 489/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5578 - mse: 0.5516 - val_loss: 0.5097 - val_mse: 0.5035\n",
      "Epoch 490/1000\n",
      "311/312 [============================>.] - ETA: 0s - loss: 0.5564 - mse: 0.5502\n",
      "Epoch 00490: saving model to Regression_Model/thle2.mse.linear-0490.ckpt\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 0.5561 - mse: 0.5499 - val_loss: 0.5042 - val_mse: 0.4980\n",
      "Epoch 491/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5562 - mse: 0.5500 - val_loss: 0.5125 - val_mse: 0.5064\n",
      "Epoch 492/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5502 - mse: 0.5440 - val_loss: 0.5067 - val_mse: 0.5005\n",
      "Epoch 493/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5495 - mse: 0.5433 - val_loss: 0.5153 - val_mse: 0.5091\n",
      "Epoch 494/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5576 - mse: 0.5514 - val_loss: 0.5073 - val_mse: 0.5011\n",
      "Epoch 495/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5573 - mse: 0.5511 - val_loss: 0.5142 - val_mse: 0.5080\n",
      "Epoch 496/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5606 - mse: 0.5544 - val_loss: 0.5161 - val_mse: 0.5099\n",
      "Epoch 497/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5624 - mse: 0.5562 - val_loss: 0.5140 - val_mse: 0.5078\n",
      "Epoch 498/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5549 - mse: 0.5487 - val_loss: 0.5104 - val_mse: 0.5043\n",
      "Epoch 499/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5568 - mse: 0.5506 - val_loss: 0.5177 - val_mse: 0.5115\n",
      "Epoch 500/1000\n",
      "303/312 [============================>.] - ETA: 0s - loss: 0.5560 - mse: 0.5498\n",
      "Epoch 00500: saving model to Regression_Model/thle2.mse.linear-0500.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5547 - mse: 0.5486 - val_loss: 0.5167 - val_mse: 0.5105\n",
      "Epoch 501/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5522 - mse: 0.5461 - val_loss: 0.5113 - val_mse: 0.5051\n",
      "Epoch 502/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5557 - mse: 0.5496 - val_loss: 0.5112 - val_mse: 0.5051\n",
      "Epoch 503/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5517 - mse: 0.5455 - val_loss: 0.5093 - val_mse: 0.5031\n",
      "Epoch 504/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5582 - mse: 0.5521 - val_loss: 0.5117 - val_mse: 0.5055\n",
      "Epoch 505/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5520 - mse: 0.5458 - val_loss: 0.5083 - val_mse: 0.5021\n",
      "Epoch 506/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5558 - mse: 0.5496 - val_loss: 0.5082 - val_mse: 0.5020\n",
      "Epoch 507/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5555 - mse: 0.5493 - val_loss: 0.5208 - val_mse: 0.5147\n",
      "Epoch 508/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5554 - mse: 0.5492 - val_loss: 0.5096 - val_mse: 0.5035\n",
      "Epoch 509/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5484 - mse: 0.5422 - val_loss: 0.5046 - val_mse: 0.4984\n",
      "Epoch 510/1000\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.5608 - mse: 0.5547\n",
      "Epoch 00510: saving model to Regression_Model/thle2.mse.linear-0510.ckpt\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.5587 - mse: 0.5526 - val_loss: 0.5176 - val_mse: 0.5115\n",
      "Epoch 511/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5568 - mse: 0.5507 - val_loss: 0.5113 - val_mse: 0.5052\n",
      "Epoch 512/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5510 - mse: 0.5449 - val_loss: 0.5171 - val_mse: 0.5109\n",
      "Epoch 513/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5519 - mse: 0.5457 - val_loss: 0.5058 - val_mse: 0.4996\n",
      "Epoch 514/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5546 - mse: 0.5485 - val_loss: 0.5086 - val_mse: 0.5025\n",
      "Epoch 515/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5498 - mse: 0.5436 - val_loss: 0.5149 - val_mse: 0.5087\n",
      "Epoch 516/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5499 - mse: 0.5437 - val_loss: 0.5072 - val_mse: 0.5011\n",
      "Epoch 517/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5520 - mse: 0.5459 - val_loss: 0.5092 - val_mse: 0.5031\n",
      "Epoch 518/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5501 - mse: 0.5439 - val_loss: 0.5050 - val_mse: 0.4988\n",
      "Epoch 519/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5585 - mse: 0.5523 - val_loss: 0.5158 - val_mse: 0.5096\n",
      "Epoch 520/1000\n",
      "311/312 [============================>.] - ETA: 0s - loss: 0.5514 - mse: 0.5453\n",
      "Epoch 00520: saving model to Regression_Model/thle2.mse.linear-0520.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5513 - mse: 0.5452 - val_loss: 0.5091 - val_mse: 0.5029\n",
      "Epoch 521/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5581 - mse: 0.5520 - val_loss: 0.5118 - val_mse: 0.5057\n",
      "Epoch 522/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5527 - mse: 0.5466 - val_loss: 0.5100 - val_mse: 0.5039\n",
      "Epoch 523/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5532 - mse: 0.5470 - val_loss: 0.5144 - val_mse: 0.5083\n",
      "Epoch 524/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5492 - mse: 0.5430 - val_loss: 0.5041 - val_mse: 0.4980\n",
      "Epoch 525/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5525 - mse: 0.5464 - val_loss: 0.5049 - val_mse: 0.4988\n",
      "Epoch 526/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5525 - mse: 0.5464 - val_loss: 0.5222 - val_mse: 0.5161\n",
      "Epoch 527/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5544 - mse: 0.5483 - val_loss: 0.5053 - val_mse: 0.4992\n",
      "Epoch 528/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5518 - mse: 0.5457 - val_loss: 0.5063 - val_mse: 0.5002\n",
      "Epoch 529/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5529 - mse: 0.5468 - val_loss: 0.5087 - val_mse: 0.5026\n",
      "Epoch 530/1000\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.5560 - mse: 0.5499\n",
      "Epoch 00530: saving model to Regression_Model/thle2.mse.linear-0530.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5560 - mse: 0.5499 - val_loss: 0.5103 - val_mse: 0.5042\n",
      "Epoch 531/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5509 - mse: 0.5448 - val_loss: 0.5086 - val_mse: 0.5024\n",
      "Epoch 532/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5505 - mse: 0.5444 - val_loss: 0.5162 - val_mse: 0.5101\n",
      "Epoch 533/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5505 - mse: 0.5444 - val_loss: 0.5092 - val_mse: 0.5031\n",
      "Epoch 534/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5582 - mse: 0.5521 - val_loss: 0.5082 - val_mse: 0.5021\n",
      "Epoch 535/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5598 - mse: 0.5537 - val_loss: 0.5067 - val_mse: 0.5006\n",
      "Epoch 536/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5553 - mse: 0.5492 - val_loss: 0.5093 - val_mse: 0.5031\n",
      "Epoch 537/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5462 - mse: 0.5401 - val_loss: 0.5045 - val_mse: 0.4984\n",
      "Epoch 538/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5542 - mse: 0.5481 - val_loss: 0.5103 - val_mse: 0.5042\n",
      "Epoch 539/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5534 - mse: 0.5473 - val_loss: 0.5098 - val_mse: 0.5037\n",
      "Epoch 540/1000\n",
      "295/312 [===========================>..] - ETA: 0s - loss: 0.5534 - mse: 0.5473\n",
      "Epoch 00540: saving model to Regression_Model/thle2.mse.linear-0540.ckpt\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 0.5528 - mse: 0.5467 - val_loss: 0.5137 - val_mse: 0.5076\n",
      "Epoch 541/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5591 - mse: 0.5530 - val_loss: 0.5078 - val_mse: 0.5017\n",
      "Epoch 542/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5589 - mse: 0.5528 - val_loss: 0.5092 - val_mse: 0.5031\n",
      "Epoch 543/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5550 - mse: 0.5489 - val_loss: 0.5107 - val_mse: 0.5046\n",
      "Epoch 544/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5485 - mse: 0.5425 - val_loss: 0.5136 - val_mse: 0.5075\n",
      "Epoch 545/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5450 - mse: 0.5389 - val_loss: 0.5120 - val_mse: 0.5059\n",
      "Epoch 546/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5552 - mse: 0.5491 - val_loss: 0.5187 - val_mse: 0.5126\n",
      "Epoch 547/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5574 - mse: 0.5513 - val_loss: 0.5073 - val_mse: 0.5012\n",
      "Epoch 548/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5534 - mse: 0.5473 - val_loss: 0.5091 - val_mse: 0.5030\n",
      "Epoch 549/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5541 - mse: 0.5481 - val_loss: 0.5221 - val_mse: 0.5160\n",
      "Epoch 550/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5477 - mse: 0.5417\n",
      "Epoch 00550: saving model to Regression_Model/thle2.mse.linear-0550.ckpt\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.5488 - mse: 0.5427 - val_loss: 0.5059 - val_mse: 0.4998\n",
      "Epoch 551/1000\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5519 - mse: 0.5458 - val_loss: 0.5108 - val_mse: 0.5048\n",
      "Epoch 552/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5590 - mse: 0.5529 - val_loss: 0.5062 - val_mse: 0.5001\n",
      "Epoch 553/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5487 - mse: 0.5426 - val_loss: 0.5148 - val_mse: 0.5087\n",
      "Epoch 554/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5566 - mse: 0.5506 - val_loss: 0.5202 - val_mse: 0.5141\n",
      "Epoch 555/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5499 - mse: 0.5439 - val_loss: 0.5110 - val_mse: 0.5049\n",
      "Epoch 556/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5555 - mse: 0.5494 - val_loss: 0.5049 - val_mse: 0.4988\n",
      "Epoch 557/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5542 - mse: 0.5481 - val_loss: 0.5144 - val_mse: 0.5083\n",
      "Epoch 558/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5531 - mse: 0.5470 - val_loss: 0.5050 - val_mse: 0.4989\n",
      "Epoch 559/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5498 - mse: 0.5438 - val_loss: 0.5074 - val_mse: 0.5013\n",
      "Epoch 560/1000\n",
      "309/312 [============================>.] - ETA: 0s - loss: 0.5525 - mse: 0.5464\n",
      "Epoch 00560: saving model to Regression_Model/thle2.mse.linear-0560.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5510 - mse: 0.5449 - val_loss: 0.5026 - val_mse: 0.4965\n",
      "Epoch 561/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5508 - mse: 0.5448 - val_loss: 0.5088 - val_mse: 0.5028\n",
      "Epoch 562/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5465 - mse: 0.5404 - val_loss: 0.5104 - val_mse: 0.5043\n",
      "Epoch 563/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5578 - mse: 0.5517 - val_loss: 0.5107 - val_mse: 0.5047\n",
      "Epoch 564/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5495 - mse: 0.5435 - val_loss: 0.5043 - val_mse: 0.4983\n",
      "Epoch 565/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5562 - mse: 0.5502 - val_loss: 0.5074 - val_mse: 0.5014\n",
      "Epoch 566/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5501 - mse: 0.5440 - val_loss: 0.5072 - val_mse: 0.5011\n",
      "Epoch 567/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5557 - mse: 0.5496 - val_loss: 0.5074 - val_mse: 0.5014\n",
      "Epoch 568/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5536 - mse: 0.5475 - val_loss: 0.5103 - val_mse: 0.5042\n",
      "Epoch 569/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5470 - mse: 0.5410 - val_loss: 0.5207 - val_mse: 0.5147\n",
      "Epoch 570/1000\n",
      "311/312 [============================>.] - ETA: 0s - loss: 0.5531 - mse: 0.5471\n",
      "Epoch 00570: saving model to Regression_Model/thle2.mse.linear-0570.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5527 - mse: 0.5467 - val_loss: 0.5086 - val_mse: 0.5026\n",
      "Epoch 571/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5542 - mse: 0.5481 - val_loss: 0.5118 - val_mse: 0.5058\n",
      "Epoch 572/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5586 - mse: 0.5526 - val_loss: 0.5117 - val_mse: 0.5057\n",
      "Epoch 573/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5516 - mse: 0.5456 - val_loss: 0.5107 - val_mse: 0.5047\n",
      "Epoch 574/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5544 - mse: 0.5483 - val_loss: 0.5103 - val_mse: 0.5042\n",
      "Epoch 575/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5569 - mse: 0.5509 - val_loss: 0.5113 - val_mse: 0.5053\n",
      "Epoch 576/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5467 - mse: 0.5407 - val_loss: 0.5128 - val_mse: 0.5068\n",
      "Epoch 577/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5503 - mse: 0.5443 - val_loss: 0.5138 - val_mse: 0.5078\n",
      "Epoch 578/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5500 - mse: 0.5439 - val_loss: 0.5260 - val_mse: 0.5200\n",
      "Epoch 579/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5501 - mse: 0.5440 - val_loss: 0.5132 - val_mse: 0.5071\n",
      "Epoch 580/1000\n",
      "311/312 [============================>.] - ETA: 0s - loss: 0.5566 - mse: 0.5506\n",
      "Epoch 00580: saving model to Regression_Model/thle2.mse.linear-0580.ckpt\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5565 - mse: 0.5505 - val_loss: 0.5147 - val_mse: 0.5087\n",
      "Epoch 581/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5543 - mse: 0.5483 - val_loss: 0.5083 - val_mse: 0.5022\n",
      "Epoch 582/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5611 - mse: 0.5550 - val_loss: 0.5175 - val_mse: 0.5115\n",
      "Epoch 583/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5576 - mse: 0.5516 - val_loss: 0.5091 - val_mse: 0.5030\n",
      "Epoch 584/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5544 - mse: 0.5484 - val_loss: 0.5073 - val_mse: 0.5013\n",
      "Epoch 585/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5547 - mse: 0.5487 - val_loss: 0.5130 - val_mse: 0.5070\n",
      "Epoch 586/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5530 - mse: 0.5469 - val_loss: 0.5062 - val_mse: 0.5002\n",
      "Epoch 587/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5525 - mse: 0.5465 - val_loss: 0.5065 - val_mse: 0.5005\n",
      "Epoch 588/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5525 - mse: 0.5464 - val_loss: 0.5109 - val_mse: 0.5049\n",
      "Epoch 589/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5553 - mse: 0.5492 - val_loss: 0.5070 - val_mse: 0.5010\n",
      "Epoch 590/1000\n",
      "301/312 [===========================>..] - ETA: 0s - loss: 0.5580 - mse: 0.5520\n",
      "Epoch 00590: saving model to Regression_Model/thle2.mse.linear-0590.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5585 - mse: 0.5524 - val_loss: 0.5154 - val_mse: 0.5094\n",
      "Epoch 591/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5524 - mse: 0.5464 - val_loss: 0.5110 - val_mse: 0.5050\n",
      "Epoch 592/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5521 - mse: 0.5461 - val_loss: 0.5095 - val_mse: 0.5035\n",
      "Epoch 593/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5495 - mse: 0.5435 - val_loss: 0.5087 - val_mse: 0.5027\n",
      "Epoch 594/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5517 - mse: 0.5457 - val_loss: 0.5139 - val_mse: 0.5079\n",
      "Epoch 595/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5466 - mse: 0.5406 - val_loss: 0.5042 - val_mse: 0.4982\n",
      "Epoch 596/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5574 - mse: 0.5514 - val_loss: 0.5093 - val_mse: 0.5033\n",
      "Epoch 597/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5509 - mse: 0.5449 - val_loss: 0.5095 - val_mse: 0.5035\n",
      "Epoch 598/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5531 - mse: 0.5471 - val_loss: 0.5105 - val_mse: 0.5045\n",
      "Epoch 599/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5572 - mse: 0.5512 - val_loss: 0.5126 - val_mse: 0.5066\n",
      "Epoch 600/1000\n",
      "297/312 [===========================>..] - ETA: 0s - loss: 0.5512 - mse: 0.5452\n",
      "Epoch 00600: saving model to Regression_Model/thle2.mse.linear-0600.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5513 - mse: 0.5453 - val_loss: 0.5032 - val_mse: 0.4973\n",
      "Epoch 601/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5517 - mse: 0.5458 - val_loss: 0.5068 - val_mse: 0.5008\n",
      "Epoch 602/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5501 - mse: 0.5442 - val_loss: 0.5130 - val_mse: 0.5070\n",
      "Epoch 603/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5513 - mse: 0.5453 - val_loss: 0.5071 - val_mse: 0.5011\n",
      "Epoch 604/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5524 - mse: 0.5464 - val_loss: 0.5009 - val_mse: 0.4949\n",
      "Epoch 605/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5533 - mse: 0.5473 - val_loss: 0.5053 - val_mse: 0.4993\n",
      "Epoch 606/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5528 - mse: 0.5468 - val_loss: 0.5029 - val_mse: 0.4969\n",
      "Epoch 607/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5527 - mse: 0.5467 - val_loss: 0.4994 - val_mse: 0.4934\n",
      "Epoch 608/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5532 - mse: 0.5472 - val_loss: 0.5047 - val_mse: 0.4987\n",
      "Epoch 609/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5441 - mse: 0.5381 - val_loss: 0.5228 - val_mse: 0.5168\n",
      "Epoch 610/1000\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.5474 - mse: 0.5414\n",
      "Epoch 00610: saving model to Regression_Model/thle2.mse.linear-0610.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5476 - mse: 0.5416 - val_loss: 0.5047 - val_mse: 0.4988\n",
      "Epoch 611/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5455 - mse: 0.5395 - val_loss: 0.5061 - val_mse: 0.5001\n",
      "Epoch 612/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5598 - mse: 0.5538 - val_loss: 0.5090 - val_mse: 0.5030\n",
      "Epoch 613/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5510 - mse: 0.5451 - val_loss: 0.5093 - val_mse: 0.5033\n",
      "Epoch 614/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5498 - mse: 0.5438 - val_loss: 0.5067 - val_mse: 0.5007\n",
      "Epoch 615/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5509 - mse: 0.5450 - val_loss: 0.5160 - val_mse: 0.5101\n",
      "Epoch 616/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5564 - mse: 0.5505 - val_loss: 0.5129 - val_mse: 0.5069\n",
      "Epoch 617/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5571 - mse: 0.5511 - val_loss: 0.5176 - val_mse: 0.5116\n",
      "Epoch 618/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5528 - mse: 0.5468 - val_loss: 0.5084 - val_mse: 0.5024\n",
      "Epoch 619/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5463 - mse: 0.5403 - val_loss: 0.5026 - val_mse: 0.4966\n",
      "Epoch 620/1000\n",
      "302/312 [============================>.] - ETA: 0s - loss: 0.5481 - mse: 0.5421\n",
      "Epoch 00620: saving model to Regression_Model/thle2.mse.linear-0620.ckpt\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 0.5491 - mse: 0.5431 - val_loss: 0.5151 - val_mse: 0.5091\n",
      "Epoch 621/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5527 - mse: 0.5467 - val_loss: 0.5080 - val_mse: 0.5020\n",
      "Epoch 622/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5508 - mse: 0.5449 - val_loss: 0.5065 - val_mse: 0.5005\n",
      "Epoch 623/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5483 - mse: 0.5424 - val_loss: 0.5110 - val_mse: 0.5051\n",
      "Epoch 624/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5497 - mse: 0.5438 - val_loss: 0.5078 - val_mse: 0.5019\n",
      "Epoch 625/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5509 - mse: 0.5449 - val_loss: 0.5103 - val_mse: 0.5043\n",
      "Epoch 626/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5460 - mse: 0.5400 - val_loss: 0.5120 - val_mse: 0.5061\n",
      "Epoch 627/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5551 - mse: 0.5492 - val_loss: 0.5069 - val_mse: 0.5009\n",
      "Epoch 628/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5513 - mse: 0.5453 - val_loss: 0.5088 - val_mse: 0.5028\n",
      "Epoch 629/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5524 - mse: 0.5465 - val_loss: 0.5076 - val_mse: 0.5017\n",
      "Epoch 630/1000\n",
      "304/312 [============================>.] - ETA: 0s - loss: 0.5472 - mse: 0.5412\n",
      "Epoch 00630: saving model to Regression_Model/thle2.mse.linear-0630.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5436 - mse: 0.5377 - val_loss: 0.5083 - val_mse: 0.5023\n",
      "Epoch 631/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5504 - mse: 0.5445 - val_loss: 0.5127 - val_mse: 0.5068\n",
      "Epoch 632/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5465 - mse: 0.5406 - val_loss: 0.5120 - val_mse: 0.5060\n",
      "Epoch 633/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5518 - mse: 0.5459 - val_loss: 0.5060 - val_mse: 0.5001\n",
      "Epoch 634/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5528 - mse: 0.5468 - val_loss: 0.5114 - val_mse: 0.5054\n",
      "Epoch 635/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5529 - mse: 0.5470 - val_loss: 0.5084 - val_mse: 0.5024\n",
      "Epoch 636/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5501 - mse: 0.5442 - val_loss: 0.5101 - val_mse: 0.5041\n",
      "Epoch 637/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5458 - mse: 0.5399 - val_loss: 0.5116 - val_mse: 0.5057\n",
      "Epoch 638/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5509 - mse: 0.5450 - val_loss: 0.5143 - val_mse: 0.5083\n",
      "Epoch 639/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5562 - mse: 0.5503 - val_loss: 0.5080 - val_mse: 0.5021\n",
      "Epoch 640/1000\n",
      "309/312 [============================>.] - ETA: 0s - loss: 0.5560 - mse: 0.5501\n",
      "Epoch 00640: saving model to Regression_Model/thle2.mse.linear-0640.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5561 - mse: 0.5501 - val_loss: 0.5226 - val_mse: 0.5166\n",
      "Epoch 641/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5496 - mse: 0.5436 - val_loss: 0.5118 - val_mse: 0.5058\n",
      "Epoch 642/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5536 - mse: 0.5477 - val_loss: 0.5156 - val_mse: 0.5096\n",
      "Epoch 643/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5478 - mse: 0.5419 - val_loss: 0.5077 - val_mse: 0.5018\n",
      "Epoch 644/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5554 - mse: 0.5495 - val_loss: 0.5063 - val_mse: 0.5003\n",
      "Epoch 645/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5508 - mse: 0.5449 - val_loss: 0.5057 - val_mse: 0.4997\n",
      "Epoch 646/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5551 - mse: 0.5492 - val_loss: 0.5156 - val_mse: 0.5097\n",
      "Epoch 647/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5520 - mse: 0.5461 - val_loss: 0.5068 - val_mse: 0.5009\n",
      "Epoch 648/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5473 - mse: 0.5414 - val_loss: 0.5058 - val_mse: 0.4999\n",
      "Epoch 649/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5469 - mse: 0.5410 - val_loss: 0.5118 - val_mse: 0.5058\n",
      "Epoch 650/1000\n",
      "308/312 [============================>.] - ETA: 0s - loss: 0.5471 - mse: 0.5412\n",
      "Epoch 00650: saving model to Regression_Model/thle2.mse.linear-0650.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5483 - mse: 0.5424 - val_loss: 0.5098 - val_mse: 0.5038\n",
      "Epoch 651/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5559 - mse: 0.5499 - val_loss: 0.5035 - val_mse: 0.4976\n",
      "Epoch 652/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5480 - mse: 0.5421 - val_loss: 0.5111 - val_mse: 0.5051\n",
      "Epoch 653/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5453 - mse: 0.5394 - val_loss: 0.5055 - val_mse: 0.4996\n",
      "Epoch 654/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5497 - mse: 0.5438 - val_loss: 0.5046 - val_mse: 0.4987\n",
      "Epoch 655/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5480 - mse: 0.5421 - val_loss: 0.5063 - val_mse: 0.5004\n",
      "Epoch 656/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5517 - mse: 0.5458 - val_loss: 0.5130 - val_mse: 0.5071\n",
      "Epoch 657/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5487 - mse: 0.5428 - val_loss: 0.5039 - val_mse: 0.4980\n",
      "Epoch 658/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5543 - mse: 0.5484 - val_loss: 0.5089 - val_mse: 0.5030\n",
      "Epoch 659/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5507 - mse: 0.5448 - val_loss: 0.5125 - val_mse: 0.5066\n",
      "Epoch 660/1000\n",
      "299/312 [===========================>..] - ETA: 0s - loss: 0.5513 - mse: 0.5454\n",
      "Epoch 00660: saving model to Regression_Model/thle2.mse.linear-0660.ckpt\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5512 - mse: 0.5453 - val_loss: 0.5029 - val_mse: 0.4970\n",
      "Epoch 661/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5461 - mse: 0.5402 - val_loss: 0.5095 - val_mse: 0.5036\n",
      "Epoch 662/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5449 - mse: 0.5390 - val_loss: 0.5090 - val_mse: 0.5031\n",
      "Epoch 663/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5434 - mse: 0.5375 - val_loss: 0.5102 - val_mse: 0.5043\n",
      "Epoch 664/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5492 - mse: 0.5433 - val_loss: 0.5103 - val_mse: 0.5044\n",
      "Epoch 665/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5526 - mse: 0.5467 - val_loss: 0.5132 - val_mse: 0.5074\n",
      "Epoch 666/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5495 - mse: 0.5436 - val_loss: 0.5067 - val_mse: 0.5009\n",
      "Epoch 667/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5503 - mse: 0.5444 - val_loss: 0.5010 - val_mse: 0.4951\n",
      "Epoch 668/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5534 - mse: 0.5475 - val_loss: 0.5052 - val_mse: 0.4993\n",
      "Epoch 669/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5502 - mse: 0.5443 - val_loss: 0.5027 - val_mse: 0.4968\n",
      "Epoch 670/1000\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.5447 - mse: 0.5388\n",
      "Epoch 00670: saving model to Regression_Model/thle2.mse.linear-0670.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5457 - mse: 0.5398 - val_loss: 0.5097 - val_mse: 0.5038\n",
      "Epoch 671/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5477 - mse: 0.5418 - val_loss: 0.5127 - val_mse: 0.5068\n",
      "Epoch 672/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5473 - mse: 0.5415 - val_loss: 0.5132 - val_mse: 0.5073\n",
      "Epoch 673/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5472 - mse: 0.5413 - val_loss: 0.5056 - val_mse: 0.4997\n",
      "Epoch 674/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5486 - mse: 0.5427 - val_loss: 0.5089 - val_mse: 0.5030\n",
      "Epoch 675/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5483 - mse: 0.5424 - val_loss: 0.5024 - val_mse: 0.4965\n",
      "Epoch 676/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5435 - mse: 0.5376 - val_loss: 0.5098 - val_mse: 0.5039\n",
      "Epoch 677/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5506 - mse: 0.5447 - val_loss: 0.5038 - val_mse: 0.4979\n",
      "Epoch 678/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5476 - mse: 0.5417 - val_loss: 0.5154 - val_mse: 0.5095\n",
      "Epoch 679/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5460 - mse: 0.5401 - val_loss: 0.5103 - val_mse: 0.5044\n",
      "Epoch 680/1000\n",
      "309/312 [============================>.] - ETA: 0s - loss: 0.5512 - mse: 0.5453\n",
      "Epoch 00680: saving model to Regression_Model/thle2.mse.linear-0680.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5511 - mse: 0.5452 - val_loss: 0.5072 - val_mse: 0.5014\n",
      "Epoch 681/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5501 - mse: 0.5442 - val_loss: 0.5041 - val_mse: 0.4982\n",
      "Epoch 682/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5505 - mse: 0.5446 - val_loss: 0.5086 - val_mse: 0.5027\n",
      "Epoch 683/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5460 - mse: 0.5401 - val_loss: 0.5071 - val_mse: 0.5012\n",
      "Epoch 684/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5487 - mse: 0.5429 - val_loss: 0.5103 - val_mse: 0.5044\n",
      "Epoch 685/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5529 - mse: 0.5470 - val_loss: 0.5055 - val_mse: 0.4997\n",
      "Epoch 686/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5475 - mse: 0.5417 - val_loss: 0.5173 - val_mse: 0.5115\n",
      "Epoch 687/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5531 - mse: 0.5473 - val_loss: 0.5170 - val_mse: 0.5111\n",
      "Epoch 688/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5444 - mse: 0.5385 - val_loss: 0.5055 - val_mse: 0.4996\n",
      "Epoch 689/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5500 - mse: 0.5441 - val_loss: 0.5058 - val_mse: 0.4999\n",
      "Epoch 690/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5517 - mse: 0.5459\n",
      "Epoch 00690: saving model to Regression_Model/thle2.mse.linear-0690.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5517 - mse: 0.5458 - val_loss: 0.5086 - val_mse: 0.5028\n",
      "Epoch 691/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5429 - mse: 0.5371 - val_loss: 0.5083 - val_mse: 0.5024\n",
      "Epoch 692/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5474 - mse: 0.5416 - val_loss: 0.5157 - val_mse: 0.5098\n",
      "Epoch 693/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5486 - mse: 0.5427 - val_loss: 0.5097 - val_mse: 0.5039\n",
      "Epoch 694/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5485 - mse: 0.5427 - val_loss: 0.5026 - val_mse: 0.4967\n",
      "Epoch 695/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5510 - mse: 0.5451 - val_loss: 0.5082 - val_mse: 0.5023\n",
      "Epoch 696/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5447 - mse: 0.5388 - val_loss: 0.5093 - val_mse: 0.5034\n",
      "Epoch 697/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5434 - mse: 0.5376 - val_loss: 0.5075 - val_mse: 0.5016\n",
      "Epoch 698/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5510 - mse: 0.5452 - val_loss: 0.5089 - val_mse: 0.5031\n",
      "Epoch 699/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5507 - mse: 0.5449 - val_loss: 0.5063 - val_mse: 0.5005\n",
      "Epoch 700/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5475 - mse: 0.5417\n",
      "Epoch 00700: saving model to Regression_Model/thle2.mse.linear-0700.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5480 - mse: 0.5422 - val_loss: 0.5160 - val_mse: 0.5101\n",
      "Epoch 701/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5484 - mse: 0.5426 - val_loss: 0.5085 - val_mse: 0.5026\n",
      "Epoch 702/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5388 - mse: 0.5330 - val_loss: 0.5068 - val_mse: 0.5010\n",
      "Epoch 703/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5479 - mse: 0.5421 - val_loss: 0.5076 - val_mse: 0.5018\n",
      "Epoch 704/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5558 - mse: 0.5499 - val_loss: 0.5039 - val_mse: 0.4981\n",
      "Epoch 705/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5420 - mse: 0.5362 - val_loss: 0.5078 - val_mse: 0.5019\n",
      "Epoch 706/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5460 - mse: 0.5402 - val_loss: 0.5057 - val_mse: 0.4998\n",
      "Epoch 707/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5569 - mse: 0.5511 - val_loss: 0.5058 - val_mse: 0.5000\n",
      "Epoch 708/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5528 - mse: 0.5470 - val_loss: 0.5007 - val_mse: 0.4949\n",
      "Epoch 709/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5474 - mse: 0.5415 - val_loss: 0.5036 - val_mse: 0.4977\n",
      "Epoch 710/1000\n",
      "310/312 [============================>.] - ETA: 0s - loss: 0.5478 - mse: 0.5420\n",
      "Epoch 00710: saving model to Regression_Model/thle2.mse.linear-0710.ckpt\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5475 - mse: 0.5417 - val_loss: 0.5120 - val_mse: 0.5062\n",
      "Epoch 711/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5524 - mse: 0.5466 - val_loss: 0.5076 - val_mse: 0.5018\n",
      "Epoch 712/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5424 - mse: 0.5366 - val_loss: 0.5096 - val_mse: 0.5038\n",
      "Epoch 713/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5514 - mse: 0.5455 - val_loss: 0.5083 - val_mse: 0.5025\n",
      "Epoch 714/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5419 - mse: 0.5361 - val_loss: 0.5130 - val_mse: 0.5071\n",
      "Epoch 715/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5459 - mse: 0.5401 - val_loss: 0.5097 - val_mse: 0.5039\n",
      "Epoch 716/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5431 - mse: 0.5373 - val_loss: 0.5104 - val_mse: 0.5046\n",
      "Epoch 717/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5397 - mse: 0.5339 - val_loss: 0.5064 - val_mse: 0.5005\n",
      "Epoch 718/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5432 - mse: 0.5374 - val_loss: 0.5093 - val_mse: 0.5035\n",
      "Epoch 719/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5398 - mse: 0.5340 - val_loss: 0.5089 - val_mse: 0.5031\n",
      "Epoch 720/1000\n",
      "303/312 [============================>.] - ETA: 0s - loss: 0.5458 - mse: 0.5399\n",
      "Epoch 00720: saving model to Regression_Model/thle2.mse.linear-0720.ckpt\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5470 - mse: 0.5411 - val_loss: 0.5115 - val_mse: 0.5057\n",
      "Epoch 721/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5455 - mse: 0.5397 - val_loss: 0.5083 - val_mse: 0.5025\n",
      "Epoch 722/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5516 - mse: 0.5458 - val_loss: 0.5147 - val_mse: 0.5089\n",
      "Epoch 723/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5432 - mse: 0.5374 - val_loss: 0.5079 - val_mse: 0.5021\n",
      "Epoch 724/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5460 - mse: 0.5402 - val_loss: 0.5091 - val_mse: 0.5033\n",
      "Epoch 725/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5424 - mse: 0.5366 - val_loss: 0.5133 - val_mse: 0.5075\n",
      "Epoch 726/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5412 - mse: 0.5354 - val_loss: 0.5148 - val_mse: 0.5090\n",
      "Epoch 727/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5428 - mse: 0.5370 - val_loss: 0.5079 - val_mse: 0.5021\n",
      "Epoch 728/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5445 - mse: 0.5387 - val_loss: 0.5089 - val_mse: 0.5031\n",
      "Epoch 729/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5525 - mse: 0.5467 - val_loss: 0.5109 - val_mse: 0.5051\n",
      "Epoch 730/1000\n",
      "309/312 [============================>.] - ETA: 0s - loss: 0.5458 - mse: 0.5400\n",
      "Epoch 00730: saving model to Regression_Model/thle2.mse.linear-0730.ckpt\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.5457 - mse: 0.5399 - val_loss: 0.5082 - val_mse: 0.5024\n",
      "Epoch 731/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5480 - mse: 0.5422 - val_loss: 0.5058 - val_mse: 0.5000\n",
      "Epoch 732/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5452 - mse: 0.5394 - val_loss: 0.5060 - val_mse: 0.5002\n",
      "Epoch 733/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5483 - mse: 0.5425 - val_loss: 0.5089 - val_mse: 0.5032\n",
      "Epoch 734/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5459 - mse: 0.5401 - val_loss: 0.5027 - val_mse: 0.4969\n",
      "Epoch 735/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5411 - mse: 0.5353 - val_loss: 0.5054 - val_mse: 0.4996\n",
      "Epoch 736/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5466 - mse: 0.5408 - val_loss: 0.5022 - val_mse: 0.4964\n",
      "Epoch 737/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5401 - mse: 0.5343 - val_loss: 0.5072 - val_mse: 0.5014\n",
      "Epoch 738/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5432 - mse: 0.5375 - val_loss: 0.5095 - val_mse: 0.5037\n",
      "Epoch 739/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5475 - mse: 0.5417 - val_loss: 0.5079 - val_mse: 0.5021\n",
      "Epoch 740/1000\n",
      "308/312 [============================>.] - ETA: 0s - loss: 0.5464 - mse: 0.5406\n",
      "Epoch 00740: saving model to Regression_Model/thle2.mse.linear-0740.ckpt\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.5460 - mse: 0.5402 - val_loss: 0.5087 - val_mse: 0.5029\n",
      "Epoch 741/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5488 - mse: 0.5430 - val_loss: 0.5125 - val_mse: 0.5067\n",
      "Epoch 742/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5496 - mse: 0.5438 - val_loss: 0.5100 - val_mse: 0.5042\n",
      "Epoch 743/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5404 - mse: 0.5346 - val_loss: 0.5118 - val_mse: 0.5061\n",
      "Epoch 744/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5477 - mse: 0.5419 - val_loss: 0.5072 - val_mse: 0.5014\n",
      "Epoch 745/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5496 - mse: 0.5438 - val_loss: 0.5085 - val_mse: 0.5028\n",
      "Epoch 746/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5507 - mse: 0.5449 - val_loss: 0.5058 - val_mse: 0.5000\n",
      "Epoch 747/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5507 - mse: 0.5449 - val_loss: 0.5073 - val_mse: 0.5015\n",
      "Epoch 748/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5431 - mse: 0.5373 - val_loss: 0.5030 - val_mse: 0.4972\n",
      "Epoch 749/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5509 - mse: 0.5451 - val_loss: 0.5119 - val_mse: 0.5061\n",
      "Epoch 750/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5415 - mse: 0.5357\n",
      "Epoch 00750: saving model to Regression_Model/thle2.mse.linear-0750.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5455 - mse: 0.5397 - val_loss: 0.5081 - val_mse: 0.5024\n",
      "Epoch 751/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5454 - mse: 0.5396 - val_loss: 0.5062 - val_mse: 0.5005\n",
      "Epoch 752/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5419 - mse: 0.5361 - val_loss: 0.5125 - val_mse: 0.5067\n",
      "Epoch 753/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5441 - mse: 0.5383 - val_loss: 0.5030 - val_mse: 0.4973\n",
      "Epoch 754/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5465 - mse: 0.5407 - val_loss: 0.5098 - val_mse: 0.5040\n",
      "Epoch 755/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5395 - mse: 0.5337 - val_loss: 0.5080 - val_mse: 0.5022\n",
      "Epoch 756/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5457 - mse: 0.5400 - val_loss: 0.5081 - val_mse: 0.5023\n",
      "Epoch 757/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5403 - mse: 0.5346 - val_loss: 0.5067 - val_mse: 0.5009\n",
      "Epoch 758/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5539 - mse: 0.5481 - val_loss: 0.5121 - val_mse: 0.5063\n",
      "Epoch 759/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5447 - mse: 0.5390 - val_loss: 0.5150 - val_mse: 0.5092\n",
      "Epoch 760/1000\n",
      "301/312 [===========================>..] - ETA: 0s - loss: 0.5402 - mse: 0.5344\n",
      "Epoch 00760: saving model to Regression_Model/thle2.mse.linear-0760.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5397 - mse: 0.5339 - val_loss: 0.5070 - val_mse: 0.5012\n",
      "Epoch 761/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5476 - mse: 0.5418 - val_loss: 0.5035 - val_mse: 0.4978\n",
      "Epoch 762/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5487 - mse: 0.5429 - val_loss: 0.5082 - val_mse: 0.5025\n",
      "Epoch 763/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5514 - mse: 0.5457 - val_loss: 0.5087 - val_mse: 0.5029\n",
      "Epoch 764/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5437 - mse: 0.5379 - val_loss: 0.5049 - val_mse: 0.4991\n",
      "Epoch 765/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5503 - mse: 0.5446 - val_loss: 0.5091 - val_mse: 0.5033\n",
      "Epoch 766/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5473 - mse: 0.5415 - val_loss: 0.5069 - val_mse: 0.5011\n",
      "Epoch 767/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5480 - mse: 0.5423 - val_loss: 0.5059 - val_mse: 0.5002\n",
      "Epoch 768/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5407 - mse: 0.5349 - val_loss: 0.5143 - val_mse: 0.5085\n",
      "Epoch 769/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5388 - mse: 0.5330 - val_loss: 0.5040 - val_mse: 0.4983\n",
      "Epoch 770/1000\n",
      "300/312 [===========================>..] - ETA: 0s - loss: 0.5498 - mse: 0.5440\n",
      "Epoch 00770: saving model to Regression_Model/thle2.mse.linear-0770.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5491 - mse: 0.5433 - val_loss: 0.5051 - val_mse: 0.4993\n",
      "Epoch 771/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5431 - mse: 0.5373 - val_loss: 0.5039 - val_mse: 0.4982\n",
      "Epoch 772/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5511 - mse: 0.5453 - val_loss: 0.5049 - val_mse: 0.4992\n",
      "Epoch 773/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5466 - mse: 0.5409 - val_loss: 0.5082 - val_mse: 0.5025\n",
      "Epoch 774/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5438 - mse: 0.5381 - val_loss: 0.5136 - val_mse: 0.5078\n",
      "Epoch 775/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5445 - mse: 0.5387 - val_loss: 0.5033 - val_mse: 0.4976\n",
      "Epoch 776/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5531 - mse: 0.5474 - val_loss: 0.5101 - val_mse: 0.5043\n",
      "Epoch 777/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5427 - mse: 0.5370 - val_loss: 0.5071 - val_mse: 0.5013\n",
      "Epoch 778/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5504 - mse: 0.5446 - val_loss: 0.5110 - val_mse: 0.5052\n",
      "Epoch 779/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5517 - mse: 0.5459 - val_loss: 0.5077 - val_mse: 0.5020\n",
      "Epoch 780/1000\n",
      "300/312 [===========================>..] - ETA: 0s - loss: 0.5486 - mse: 0.5428\n",
      "Epoch 00780: saving model to Regression_Model/thle2.mse.linear-0780.ckpt\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.5458 - mse: 0.5401 - val_loss: 0.5113 - val_mse: 0.5055\n",
      "Epoch 781/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5430 - mse: 0.5373 - val_loss: 0.5046 - val_mse: 0.4989\n",
      "Epoch 782/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5458 - mse: 0.5401 - val_loss: 0.5071 - val_mse: 0.5014\n",
      "Epoch 783/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5504 - mse: 0.5447 - val_loss: 0.5041 - val_mse: 0.4984\n",
      "Epoch 784/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5440 - mse: 0.5382 - val_loss: 0.5041 - val_mse: 0.4984\n",
      "Epoch 785/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5414 - mse: 0.5357 - val_loss: 0.5116 - val_mse: 0.5059\n",
      "Epoch 786/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5431 - mse: 0.5374 - val_loss: 0.5072 - val_mse: 0.5014\n",
      "Epoch 787/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5450 - mse: 0.5393 - val_loss: 0.5051 - val_mse: 0.4993\n",
      "Epoch 788/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5413 - mse: 0.5356 - val_loss: 0.5036 - val_mse: 0.4978\n",
      "Epoch 789/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5395 - mse: 0.5338 - val_loss: 0.5062 - val_mse: 0.5004\n",
      "Epoch 790/1000\n",
      "303/312 [============================>.] - ETA: 0s - loss: 0.5491 - mse: 0.5434\n",
      "Epoch 00790: saving model to Regression_Model/thle2.mse.linear-0790.ckpt\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.5489 - mse: 0.5432 - val_loss: 0.5083 - val_mse: 0.5025\n",
      "Epoch 791/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5439 - mse: 0.5382 - val_loss: 0.5062 - val_mse: 0.5005\n",
      "Epoch 792/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5470 - mse: 0.5413 - val_loss: 0.5149 - val_mse: 0.5092\n",
      "Epoch 793/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5429 - mse: 0.5372 - val_loss: 0.5057 - val_mse: 0.5000\n",
      "Epoch 794/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5468 - mse: 0.5411 - val_loss: 0.5194 - val_mse: 0.5137\n",
      "Epoch 795/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5405 - mse: 0.5348 - val_loss: 0.5050 - val_mse: 0.4993\n",
      "Epoch 796/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5444 - mse: 0.5387 - val_loss: 0.5074 - val_mse: 0.5016\n",
      "Epoch 797/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5406 - mse: 0.5349 - val_loss: 0.5099 - val_mse: 0.5042\n",
      "Epoch 798/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5470 - mse: 0.5413 - val_loss: 0.5100 - val_mse: 0.5043\n",
      "Epoch 799/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5450 - mse: 0.5392 - val_loss: 0.5099 - val_mse: 0.5042\n",
      "Epoch 800/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5452 - mse: 0.5395\n",
      "Epoch 00800: saving model to Regression_Model/thle2.mse.linear-0800.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5437 - mse: 0.5380 - val_loss: 0.5093 - val_mse: 0.5036\n",
      "Epoch 801/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5493 - mse: 0.5436 - val_loss: 0.5100 - val_mse: 0.5043\n",
      "Epoch 802/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5360 - mse: 0.5303 - val_loss: 0.5077 - val_mse: 0.5020\n",
      "Epoch 803/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5497 - mse: 0.5440 - val_loss: 0.5093 - val_mse: 0.5036\n",
      "Epoch 804/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5421 - mse: 0.5363 - val_loss: 0.5078 - val_mse: 0.5021\n",
      "Epoch 805/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5451 - mse: 0.5394 - val_loss: 0.5025 - val_mse: 0.4968\n",
      "Epoch 806/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5448 - mse: 0.5391 - val_loss: 0.5161 - val_mse: 0.5104\n",
      "Epoch 807/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5468 - mse: 0.5411 - val_loss: 0.5062 - val_mse: 0.5005\n",
      "Epoch 808/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5482 - mse: 0.5425 - val_loss: 0.5055 - val_mse: 0.4998\n",
      "Epoch 809/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5390 - mse: 0.5333 - val_loss: 0.5056 - val_mse: 0.4999\n",
      "Epoch 810/1000\n",
      "309/312 [============================>.] - ETA: 0s - loss: 0.5457 - mse: 0.5400\n",
      "Epoch 00810: saving model to Regression_Model/thle2.mse.linear-0810.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5466 - mse: 0.5409 - val_loss: 0.5115 - val_mse: 0.5058\n",
      "Epoch 811/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5435 - mse: 0.5378 - val_loss: 0.5055 - val_mse: 0.4998\n",
      "Epoch 812/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5498 - mse: 0.5441 - val_loss: 0.5056 - val_mse: 0.4999\n",
      "Epoch 813/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5425 - mse: 0.5368 - val_loss: 0.5159 - val_mse: 0.5102\n",
      "Epoch 814/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5434 - mse: 0.5377 - val_loss: 0.5088 - val_mse: 0.5031\n",
      "Epoch 815/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5398 - mse: 0.5341 - val_loss: 0.5123 - val_mse: 0.5066\n",
      "Epoch 816/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5451 - mse: 0.5394 - val_loss: 0.5100 - val_mse: 0.5044\n",
      "Epoch 817/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5405 - mse: 0.5348 - val_loss: 0.5027 - val_mse: 0.4970\n",
      "Epoch 818/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5455 - mse: 0.5398 - val_loss: 0.5173 - val_mse: 0.5116\n",
      "Epoch 819/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5390 - mse: 0.5333 - val_loss: 0.5100 - val_mse: 0.5043\n",
      "Epoch 820/1000\n",
      "305/312 [============================>.] - ETA: 0s - loss: 0.5446 - mse: 0.5389\n",
      "Epoch 00820: saving model to Regression_Model/thle2.mse.linear-0820.ckpt\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5441 - mse: 0.5384 - val_loss: 0.5075 - val_mse: 0.5018\n",
      "Epoch 821/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5457 - mse: 0.5400 - val_loss: 0.5065 - val_mse: 0.5008\n",
      "Epoch 822/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5420 - mse: 0.5363 - val_loss: 0.5058 - val_mse: 0.5001\n",
      "Epoch 823/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5424 - mse: 0.5367 - val_loss: 0.5102 - val_mse: 0.5045\n",
      "Epoch 824/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5406 - mse: 0.5350 - val_loss: 0.5127 - val_mse: 0.5070\n",
      "Epoch 825/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5466 - mse: 0.5409 - val_loss: 0.5095 - val_mse: 0.5038\n",
      "Epoch 826/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5436 - mse: 0.5379 - val_loss: 0.5055 - val_mse: 0.4998\n",
      "Epoch 827/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5454 - mse: 0.5397 - val_loss: 0.5037 - val_mse: 0.4981\n",
      "Epoch 828/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5436 - mse: 0.5379 - val_loss: 0.5071 - val_mse: 0.5014\n",
      "Epoch 829/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5495 - mse: 0.5438 - val_loss: 0.5099 - val_mse: 0.5042\n",
      "Epoch 830/1000\n",
      "303/312 [============================>.] - ETA: 0s - loss: 0.5501 - mse: 0.5444\n",
      "Epoch 00830: saving model to Regression_Model/thle2.mse.linear-0830.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5486 - mse: 0.5429 - val_loss: 0.5055 - val_mse: 0.4998\n",
      "Epoch 831/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5418 - mse: 0.5361 - val_loss: 0.5035 - val_mse: 0.4979\n",
      "Epoch 832/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5445 - mse: 0.5388 - val_loss: 0.5067 - val_mse: 0.5010\n",
      "Epoch 833/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5439 - mse: 0.5382 - val_loss: 0.5122 - val_mse: 0.5065\n",
      "Epoch 834/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5473 - mse: 0.5416 - val_loss: 0.5131 - val_mse: 0.5075\n",
      "Epoch 835/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5451 - mse: 0.5394 - val_loss: 0.5043 - val_mse: 0.4987\n",
      "Epoch 836/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5420 - mse: 0.5363 - val_loss: 0.5022 - val_mse: 0.4965\n",
      "Epoch 837/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5427 - mse: 0.5370 - val_loss: 0.5080 - val_mse: 0.5024\n",
      "Epoch 838/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5432 - mse: 0.5376 - val_loss: 0.5090 - val_mse: 0.5033\n",
      "Epoch 839/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5415 - mse: 0.5358 - val_loss: 0.5037 - val_mse: 0.4980\n",
      "Epoch 840/1000\n",
      "311/312 [============================>.] - ETA: 0s - loss: 0.5472 - mse: 0.5415\n",
      "Epoch 00840: saving model to Regression_Model/thle2.mse.linear-0840.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5465 - mse: 0.5408 - val_loss: 0.5057 - val_mse: 0.5000\n",
      "Epoch 841/1000\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5405 - mse: 0.5348 - val_loss: 0.5092 - val_mse: 0.5035\n",
      "Epoch 842/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5501 - mse: 0.5445 - val_loss: 0.5040 - val_mse: 0.4984\n",
      "Epoch 843/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5508 - mse: 0.5452 - val_loss: 0.5090 - val_mse: 0.5033\n",
      "Epoch 844/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5462 - mse: 0.5405 - val_loss: 0.5069 - val_mse: 0.5013\n",
      "Epoch 845/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5396 - mse: 0.5340 - val_loss: 0.5059 - val_mse: 0.5003\n",
      "Epoch 846/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5441 - mse: 0.5384 - val_loss: 0.5107 - val_mse: 0.5051\n",
      "Epoch 847/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5439 - mse: 0.5382 - val_loss: 0.5096 - val_mse: 0.5039\n",
      "Epoch 848/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5487 - mse: 0.5430 - val_loss: 0.5141 - val_mse: 0.5085\n",
      "Epoch 849/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5382 - mse: 0.5326 - val_loss: 0.5098 - val_mse: 0.5041\n",
      "Epoch 850/1000\n",
      "302/312 [============================>.] - ETA: 0s - loss: 0.5386 - mse: 0.5330\n",
      "Epoch 00850: saving model to Regression_Model/thle2.mse.linear-0850.ckpt\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.5404 - mse: 0.5347 - val_loss: 0.5115 - val_mse: 0.5058\n",
      "Epoch 851/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5444 - mse: 0.5387 - val_loss: 0.5097 - val_mse: 0.5040\n",
      "Epoch 852/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5424 - mse: 0.5367 - val_loss: 0.5080 - val_mse: 0.5023\n",
      "Epoch 853/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5411 - mse: 0.5354 - val_loss: 0.5097 - val_mse: 0.5040\n",
      "Epoch 854/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5439 - mse: 0.5382 - val_loss: 0.5078 - val_mse: 0.5021\n",
      "Epoch 855/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5358 - mse: 0.5301 - val_loss: 0.5059 - val_mse: 0.5002\n",
      "Epoch 856/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5422 - mse: 0.5366 - val_loss: 0.5040 - val_mse: 0.4983\n",
      "Epoch 857/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5421 - mse: 0.5364 - val_loss: 0.5044 - val_mse: 0.4987\n",
      "Epoch 858/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5410 - mse: 0.5354 - val_loss: 0.5078 - val_mse: 0.5022\n",
      "Epoch 859/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5419 - mse: 0.5362 - val_loss: 0.5114 - val_mse: 0.5058\n",
      "Epoch 860/1000\n",
      "300/312 [===========================>..] - ETA: 0s - loss: 0.5425 - mse: 0.5368\n",
      "Epoch 00860: saving model to Regression_Model/thle2.mse.linear-0860.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5448 - mse: 0.5391 - val_loss: 0.5118 - val_mse: 0.5061\n",
      "Epoch 861/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5462 - mse: 0.5405 - val_loss: 0.5035 - val_mse: 0.4978\n",
      "Epoch 862/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5386 - mse: 0.5329 - val_loss: 0.5030 - val_mse: 0.4974\n",
      "Epoch 863/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5432 - mse: 0.5375 - val_loss: 0.5107 - val_mse: 0.5051\n",
      "Epoch 864/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5424 - mse: 0.5368 - val_loss: 0.5085 - val_mse: 0.5029\n",
      "Epoch 865/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5474 - mse: 0.5417 - val_loss: 0.5071 - val_mse: 0.5015\n",
      "Epoch 866/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5450 - mse: 0.5393 - val_loss: 0.5068 - val_mse: 0.5012\n",
      "Epoch 867/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5354 - mse: 0.5298 - val_loss: 0.5107 - val_mse: 0.5050\n",
      "Epoch 868/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5416 - mse: 0.5359 - val_loss: 0.5072 - val_mse: 0.5016\n",
      "Epoch 869/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5465 - mse: 0.5409 - val_loss: 0.5070 - val_mse: 0.5014\n",
      "Epoch 870/1000\n",
      "306/312 [============================>.] - ETA: 0s - loss: 0.5481 - mse: 0.5425\n",
      "Epoch 00870: saving model to Regression_Model/thle2.mse.linear-0870.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5466 - mse: 0.5409 - val_loss: 0.5072 - val_mse: 0.5016\n",
      "Epoch 871/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5406 - mse: 0.5350 - val_loss: 0.5159 - val_mse: 0.5103\n",
      "Epoch 872/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5444 - mse: 0.5388 - val_loss: 0.5062 - val_mse: 0.5005\n",
      "Epoch 873/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5437 - mse: 0.5381 - val_loss: 0.5028 - val_mse: 0.4972\n",
      "Epoch 874/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5392 - mse: 0.5336 - val_loss: 0.5061 - val_mse: 0.5005\n",
      "Epoch 875/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5467 - mse: 0.5411 - val_loss: 0.5109 - val_mse: 0.5053\n",
      "Epoch 876/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5460 - mse: 0.5404 - val_loss: 0.5117 - val_mse: 0.5061\n",
      "Epoch 877/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5433 - mse: 0.5377 - val_loss: 0.5080 - val_mse: 0.5024\n",
      "Epoch 878/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5452 - mse: 0.5395 - val_loss: 0.5101 - val_mse: 0.5044\n",
      "Epoch 879/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5478 - mse: 0.5421 - val_loss: 0.5087 - val_mse: 0.5031\n",
      "Epoch 880/1000\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 0.5349 - mse: 0.5292\n",
      "Epoch 00880: saving model to Regression_Model/thle2.mse.linear-0880.ckpt\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.5405 - mse: 0.5349 - val_loss: 0.5043 - val_mse: 0.4987\n",
      "Epoch 881/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5443 - mse: 0.5387 - val_loss: 0.5080 - val_mse: 0.5024\n",
      "Epoch 882/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5450 - mse: 0.5393 - val_loss: 0.5109 - val_mse: 0.5053\n",
      "Epoch 883/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5463 - mse: 0.5406 - val_loss: 0.5093 - val_mse: 0.5037\n",
      "Epoch 884/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5459 - mse: 0.5403 - val_loss: 0.5064 - val_mse: 0.5008\n",
      "Epoch 885/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5448 - mse: 0.5392 - val_loss: 0.5080 - val_mse: 0.5024\n",
      "Epoch 886/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5410 - mse: 0.5353 - val_loss: 0.5041 - val_mse: 0.4985\n",
      "Epoch 887/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5400 - mse: 0.5344 - val_loss: 0.5061 - val_mse: 0.5005\n",
      "Epoch 888/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5533 - mse: 0.5477 - val_loss: 0.5071 - val_mse: 0.5015\n",
      "Epoch 889/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5369 - mse: 0.5313 - val_loss: 0.5070 - val_mse: 0.5014\n",
      "Epoch 890/1000\n",
      "309/312 [============================>.] - ETA: 0s - loss: 0.5476 - mse: 0.5420\n",
      "Epoch 00890: saving model to Regression_Model/thle2.mse.linear-0890.ckpt\n",
      "312/312 [==============================] - 4s 12ms/step - loss: 0.5471 - mse: 0.5415 - val_loss: 0.5036 - val_mse: 0.4980\n",
      "Epoch 891/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5405 - mse: 0.5349 - val_loss: 0.5080 - val_mse: 0.5024\n",
      "Epoch 892/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5461 - mse: 0.5404 - val_loss: 0.5054 - val_mse: 0.4998\n",
      "Epoch 893/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5364 - mse: 0.5308 - val_loss: 0.5037 - val_mse: 0.4980\n",
      "Epoch 894/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5475 - mse: 0.5419 - val_loss: 0.5123 - val_mse: 0.5067\n",
      "Epoch 895/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5453 - mse: 0.5397 - val_loss: 0.5105 - val_mse: 0.5049\n",
      "Epoch 896/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5436 - mse: 0.5379 - val_loss: 0.5071 - val_mse: 0.5015\n",
      "Epoch 897/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5452 - mse: 0.5396 - val_loss: 0.5128 - val_mse: 0.5072\n",
      "Epoch 898/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5520 - mse: 0.5464 - val_loss: 0.5052 - val_mse: 0.4996\n",
      "Epoch 899/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5408 - mse: 0.5352 - val_loss: 0.5063 - val_mse: 0.5007\n",
      "Epoch 900/1000\n",
      "308/312 [============================>.] - ETA: 0s - loss: 0.5377 - mse: 0.5321\n",
      "Epoch 00900: saving model to Regression_Model/thle2.mse.linear-0900.ckpt\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 0.5389 - mse: 0.5332 - val_loss: 0.5070 - val_mse: 0.5014\n",
      "Epoch 901/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5447 - mse: 0.5391 - val_loss: 0.5074 - val_mse: 0.5018\n",
      "Epoch 902/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5454 - mse: 0.5398 - val_loss: 0.5116 - val_mse: 0.5060\n",
      "Epoch 903/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5444 - mse: 0.5388 - val_loss: 0.5099 - val_mse: 0.5043\n",
      "Epoch 904/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5454 - mse: 0.5398 - val_loss: 0.5047 - val_mse: 0.4991\n",
      "Epoch 905/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5421 - mse: 0.5365 - val_loss: 0.5113 - val_mse: 0.5057\n",
      "Epoch 906/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5454 - mse: 0.5397 - val_loss: 0.5108 - val_mse: 0.5052\n",
      "Epoch 907/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5447 - mse: 0.5391 - val_loss: 0.5167 - val_mse: 0.5111\n",
      "Epoch 908/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5428 - mse: 0.5372 - val_loss: 0.5073 - val_mse: 0.5017\n",
      "Epoch 909/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5460 - mse: 0.5404 - val_loss: 0.5085 - val_mse: 0.5029\n",
      "Epoch 910/1000\n",
      "305/312 [============================>.] - ETA: 0s - loss: 0.5409 - mse: 0.5354\n",
      "Epoch 00910: saving model to Regression_Model/thle2.mse.linear-0910.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5413 - mse: 0.5357 - val_loss: 0.5066 - val_mse: 0.5010\n",
      "Epoch 911/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5425 - mse: 0.5369 - val_loss: 0.5083 - val_mse: 0.5027\n",
      "Epoch 912/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5381 - mse: 0.5325 - val_loss: 0.5081 - val_mse: 0.5025\n",
      "Epoch 913/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5432 - mse: 0.5376 - val_loss: 0.5074 - val_mse: 0.5018\n",
      "Epoch 914/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5416 - mse: 0.5360 - val_loss: 0.5020 - val_mse: 0.4964\n",
      "Epoch 915/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5430 - mse: 0.5374 - val_loss: 0.5097 - val_mse: 0.5041\n",
      "Epoch 916/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5436 - mse: 0.5381 - val_loss: 0.5102 - val_mse: 0.5046\n",
      "Epoch 917/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5415 - mse: 0.5360 - val_loss: 0.5145 - val_mse: 0.5089\n",
      "Epoch 918/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5388 - mse: 0.5332 - val_loss: 0.5093 - val_mse: 0.5037\n",
      "Epoch 919/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5487 - mse: 0.5431 - val_loss: 0.5084 - val_mse: 0.5028\n",
      "Epoch 920/1000\n",
      "307/312 [============================>.] - ETA: 0s - loss: 0.5408 - mse: 0.5352\n",
      "Epoch 00920: saving model to Regression_Model/thle2.mse.linear-0920.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5441 - mse: 0.5385 - val_loss: 0.5099 - val_mse: 0.5043\n",
      "Epoch 921/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5429 - mse: 0.5373 - val_loss: 0.5096 - val_mse: 0.5040\n",
      "Epoch 922/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5478 - mse: 0.5422 - val_loss: 0.5070 - val_mse: 0.5014\n",
      "Epoch 923/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5394 - mse: 0.5338 - val_loss: 0.5084 - val_mse: 0.5028\n",
      "Epoch 924/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5416 - mse: 0.5360 - val_loss: 0.5075 - val_mse: 0.5019\n",
      "Epoch 925/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5447 - mse: 0.5392 - val_loss: 0.5077 - val_mse: 0.5021\n",
      "Epoch 926/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5390 - mse: 0.5334 - val_loss: 0.5101 - val_mse: 0.5046\n",
      "Epoch 927/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5399 - mse: 0.5343 - val_loss: 0.5046 - val_mse: 0.4990\n",
      "Epoch 928/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5348 - mse: 0.5292 - val_loss: 0.5050 - val_mse: 0.4995\n",
      "Epoch 929/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5474 - mse: 0.5418 - val_loss: 0.5116 - val_mse: 0.5061\n",
      "Epoch 930/1000\n",
      "302/312 [============================>.] - ETA: 0s - loss: 0.5424 - mse: 0.5369\n",
      "Epoch 00930: saving model to Regression_Model/thle2.mse.linear-0930.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5431 - mse: 0.5375 - val_loss: 0.5123 - val_mse: 0.5068\n",
      "Epoch 931/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5440 - mse: 0.5384 - val_loss: 0.5070 - val_mse: 0.5014\n",
      "Epoch 932/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5422 - mse: 0.5366 - val_loss: 0.5059 - val_mse: 0.5003\n",
      "Epoch 933/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5439 - mse: 0.5383 - val_loss: 0.5054 - val_mse: 0.4998\n",
      "Epoch 934/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5404 - mse: 0.5348 - val_loss: 0.5141 - val_mse: 0.5085\n",
      "Epoch 935/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5339 - mse: 0.5283 - val_loss: 0.5083 - val_mse: 0.5027\n",
      "Epoch 936/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5465 - mse: 0.5410 - val_loss: 0.5025 - val_mse: 0.4969\n",
      "Epoch 937/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5448 - mse: 0.5392 - val_loss: 0.5085 - val_mse: 0.5029\n",
      "Epoch 938/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5402 - mse: 0.5346 - val_loss: 0.5055 - val_mse: 0.4999\n",
      "Epoch 939/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5380 - mse: 0.5324 - val_loss: 0.5096 - val_mse: 0.5040\n",
      "Epoch 940/1000\n",
      "308/312 [============================>.] - ETA: 0s - loss: 0.5396 - mse: 0.5340\n",
      "Epoch 00940: saving model to Regression_Model/thle2.mse.linear-0940.ckpt\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.5395 - mse: 0.5339 - val_loss: 0.5053 - val_mse: 0.4998\n",
      "Epoch 941/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5432 - mse: 0.5376 - val_loss: 0.5062 - val_mse: 0.5006\n",
      "Epoch 942/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5436 - mse: 0.5380 - val_loss: 0.5089 - val_mse: 0.5034\n",
      "Epoch 943/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5440 - mse: 0.5384 - val_loss: 0.5079 - val_mse: 0.5023\n",
      "Epoch 944/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5408 - mse: 0.5352 - val_loss: 0.5108 - val_mse: 0.5052\n",
      "Epoch 945/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5361 - mse: 0.5305 - val_loss: 0.5060 - val_mse: 0.5004\n",
      "Epoch 946/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5421 - mse: 0.5365 - val_loss: 0.5120 - val_mse: 0.5065\n",
      "Epoch 947/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5411 - mse: 0.5355 - val_loss: 0.5045 - val_mse: 0.4990\n",
      "Epoch 948/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5390 - mse: 0.5335 - val_loss: 0.5033 - val_mse: 0.4978\n",
      "Epoch 949/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5403 - mse: 0.5347 - val_loss: 0.5128 - val_mse: 0.5072\n",
      "Epoch 950/1000\n",
      "308/312 [============================>.] - ETA: 0s - loss: 0.5445 - mse: 0.5390\n",
      "Epoch 00950: saving model to Regression_Model/thle2.mse.linear-0950.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5449 - mse: 0.5394 - val_loss: 0.5054 - val_mse: 0.4998\n",
      "Epoch 951/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5429 - mse: 0.5373 - val_loss: 0.5066 - val_mse: 0.5010\n",
      "Epoch 952/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5381 - mse: 0.5325 - val_loss: 0.5059 - val_mse: 0.5003\n",
      "Epoch 953/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5351 - mse: 0.5295 - val_loss: 0.5101 - val_mse: 0.5046\n",
      "Epoch 954/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5327 - mse: 0.5272 - val_loss: 0.5092 - val_mse: 0.5037\n",
      "Epoch 955/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5472 - mse: 0.5417 - val_loss: 0.5099 - val_mse: 0.5043\n",
      "Epoch 956/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5356 - mse: 0.5300 - val_loss: 0.5130 - val_mse: 0.5074\n",
      "Epoch 957/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5419 - mse: 0.5364 - val_loss: 0.5070 - val_mse: 0.5015\n",
      "Epoch 958/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5421 - mse: 0.5365 - val_loss: 0.5038 - val_mse: 0.4982\n",
      "Epoch 959/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5419 - mse: 0.5364 - val_loss: 0.5067 - val_mse: 0.5011\n",
      "Epoch 960/1000\n",
      "302/312 [============================>.] - ETA: 0s - loss: 0.5436 - mse: 0.5381\n",
      "Epoch 00960: saving model to Regression_Model/thle2.mse.linear-0960.ckpt\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.5419 - mse: 0.5364 - val_loss: 0.5075 - val_mse: 0.5020\n",
      "Epoch 961/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5450 - mse: 0.5394 - val_loss: 0.5065 - val_mse: 0.5010\n",
      "Epoch 962/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5359 - mse: 0.5304 - val_loss: 0.5083 - val_mse: 0.5028\n",
      "Epoch 963/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5427 - mse: 0.5371 - val_loss: 0.5043 - val_mse: 0.4987\n",
      "Epoch 964/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5444 - mse: 0.5389 - val_loss: 0.5067 - val_mse: 0.5011\n",
      "Epoch 965/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5390 - mse: 0.5334 - val_loss: 0.5087 - val_mse: 0.5032\n",
      "Epoch 966/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5392 - mse: 0.5336 - val_loss: 0.5104 - val_mse: 0.5049\n",
      "Epoch 967/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5396 - mse: 0.5341 - val_loss: 0.5092 - val_mse: 0.5037\n",
      "Epoch 968/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5405 - mse: 0.5350 - val_loss: 0.5053 - val_mse: 0.4997\n",
      "Epoch 969/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5457 - mse: 0.5402 - val_loss: 0.5053 - val_mse: 0.4998\n",
      "Epoch 970/1000\n",
      "311/312 [============================>.] - ETA: 0s - loss: 0.5448 - mse: 0.5393\n",
      "Epoch 00970: saving model to Regression_Model/thle2.mse.linear-0970.ckpt\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5448 - mse: 0.5393 - val_loss: 0.5080 - val_mse: 0.5025\n",
      "Epoch 971/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5413 - mse: 0.5357 - val_loss: 0.5079 - val_mse: 0.5023\n",
      "Epoch 972/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5396 - mse: 0.5340 - val_loss: 0.5144 - val_mse: 0.5089\n",
      "Epoch 973/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5461 - mse: 0.5406 - val_loss: 0.5118 - val_mse: 0.5062\n",
      "Epoch 974/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5442 - mse: 0.5386 - val_loss: 0.5075 - val_mse: 0.5020\n",
      "Epoch 975/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5500 - mse: 0.5445 - val_loss: 0.5075 - val_mse: 0.5019\n",
      "Epoch 976/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5414 - mse: 0.5359 - val_loss: 0.5064 - val_mse: 0.5008\n",
      "Epoch 977/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5407 - mse: 0.5351 - val_loss: 0.5086 - val_mse: 0.5030\n",
      "Epoch 978/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5445 - mse: 0.5390 - val_loss: 0.5093 - val_mse: 0.5037\n",
      "Epoch 979/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5467 - mse: 0.5412 - val_loss: 0.5072 - val_mse: 0.5016\n",
      "Epoch 980/1000\n",
      "311/312 [============================>.] - ETA: 0s - loss: 0.5398 - mse: 0.5343\n",
      "Epoch 00980: saving model to Regression_Model/thle2.mse.linear-0980.ckpt\n",
      "312/312 [==============================] - 4s 12ms/step - loss: 0.5392 - mse: 0.5336 - val_loss: 0.5054 - val_mse: 0.4999\n",
      "Epoch 981/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5437 - mse: 0.5381 - val_loss: 0.5061 - val_mse: 0.5005\n",
      "Epoch 982/1000\n",
      "312/312 [==============================] - 1s 5ms/step - loss: 0.5445 - mse: 0.5390 - val_loss: 0.5075 - val_mse: 0.5020\n",
      "Epoch 983/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5444 - mse: 0.5389 - val_loss: 0.5041 - val_mse: 0.4986\n",
      "Epoch 984/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5422 - mse: 0.5367 - val_loss: 0.5062 - val_mse: 0.5006\n",
      "Epoch 985/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5387 - mse: 0.5331 - val_loss: 0.5075 - val_mse: 0.5020\n",
      "Epoch 986/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5382 - mse: 0.5327 - val_loss: 0.5042 - val_mse: 0.4986\n",
      "Epoch 987/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5393 - mse: 0.5338 - val_loss: 0.5106 - val_mse: 0.5050\n",
      "Epoch 988/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5451 - mse: 0.5395 - val_loss: 0.5114 - val_mse: 0.5058\n",
      "Epoch 989/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5441 - mse: 0.5386 - val_loss: 0.5066 - val_mse: 0.5010\n",
      "Epoch 990/1000\n",
      "305/312 [============================>.] - ETA: 0s - loss: 0.5420 - mse: 0.5364\n",
      "Epoch 00990: saving model to Regression_Model/thle2.mse.linear-0990.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5424 - mse: 0.5369 - val_loss: 0.5057 - val_mse: 0.5002\n",
      "Epoch 991/1000\n",
      "312/312 [==============================] - 2s 5ms/step - loss: 0.5398 - mse: 0.5343 - val_loss: 0.5071 - val_mse: 0.5016\n",
      "Epoch 992/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5360 - mse: 0.5305 - val_loss: 0.5099 - val_mse: 0.5044\n",
      "Epoch 993/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5390 - mse: 0.5335 - val_loss: 0.5042 - val_mse: 0.4986\n",
      "Epoch 994/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5420 - mse: 0.5364 - val_loss: 0.5089 - val_mse: 0.5033\n",
      "Epoch 995/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5467 - mse: 0.5411 - val_loss: 0.5075 - val_mse: 0.5019\n",
      "Epoch 996/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5420 - mse: 0.5364 - val_loss: 0.5067 - val_mse: 0.5011\n",
      "Epoch 997/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5441 - mse: 0.5385 - val_loss: 0.5083 - val_mse: 0.5028\n",
      "Epoch 998/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5444 - mse: 0.5389 - val_loss: 0.5055 - val_mse: 0.5000\n",
      "Epoch 999/1000\n",
      "312/312 [==============================] - 1s 4ms/step - loss: 0.5371 - mse: 0.5316 - val_loss: 0.5071 - val_mse: 0.5016\n",
      "Epoch 1000/1000\n",
      "305/312 [============================>.] - ETA: 0s - loss: 0.5416 - mse: 0.5361\n",
      "Epoch 01000: saving model to Regression_Model/thle2.mse.linear-1000.ckpt\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 0.5430 - mse: 0.5374 - val_loss: 0.5162 - val_mse: 0.5106\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=1000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "mse\n",
      "val_loss\n",
      "val_mse\n"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7071b8b128>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,MODEL_PATH,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    \n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "testid=trainid\n",
    "bestEpoch = '1000'\n",
    "MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "evaluate(train_x,train_y,train_id,MODEL_PATH,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate() takes 7 positional arguments but 8 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c510b86b1580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbestEpoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: evaluate() takes 7 positional arguments but 8 were given"
     ]
    }
   ],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data,test_labels,test_id,test2_data,test2_labels,test2_id = prep_data('coverage_data/K562_Chen.usage.txt',5,33.3)\n",
    "testid=trainid\n",
    "data_mean = -1.09\n",
    "data_std  = 1.79\n",
    "label_mean = 2.39\n",
    "label_std = 1.65\n",
    "MODEL_PATH = 'bestModel/thle2.mse.linear-0980.ckpt'\n",
    "test_x,test_y = standardize(test_data,test_labels,data_mean,data_std,label_mean,label_std)\n",
    "evaluate(test_x,test_y,test_id,MODEL_PATH,'test',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/thle2_control.pAs.usage.txt',5)\n",
    "train_data,train_labels,train_pasid,valid_data,valid_labels,valid_pasid = prep_data('coverage_data/Finetune.snu398_control.usage.txt',5)\n",
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='thle2.mle.linear'\n",
    "bestEpoch = '0980'\n",
    "evaluate(train_x,train_y,train_pasid,testid,'train',label_mean,label_std,bestEpoch)\n",
    "evaluate(valid_x,valid_y,valid_pasid,testid,'valid',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train_data,train_labels,data_mean,data_std,label_mean,label_std):\n",
    "    train_data = np.log(train_data+0.05)\n",
    "    train_labels = np.log(train_labels)\n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    return train_data,train_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1(x,y,pasid,trainid,dataset,label_mean,label_std,bestEpoch=2000):\n",
    "    test_generator = EvaDataGenerator(x,LENGTH)\n",
    "    model = Regression_CNN(LENGTH)\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-'+str(bestEpoch)+'.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)-1\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)-1\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1,train_labels1,train_pasid1,valid_data1,valid_labels1,valid_pasid1 = prep_data('coverage_data/all.snu398_control.usage.txt',5)\n",
    "x=np.concatenate((train_data1, valid_data1), axis=0)\n",
    "y=np.concatenate((train_labels1, valid_labels1), axis=0)\n",
    "pasid=np.concatenate((train_pasid1, valid_pasid1), axis=0)\n",
    "x,y= standardize(x,y,data_mean,data_std,label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=1001\n",
    "testid='Regression.f_snu398.shift16.1001'\n",
    "bestEpoch = '2000'\n",
    "evaluate1(x,y,pasid,testid,'all',label_mean,label_std,bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((train_pasid1, valid_pasid1), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[3,4,5,6]\n",
    "a.remove(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(a == None):\n",
    "    print('fafa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'chromosme,start,end,score,id,strand\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,c,d = a.split(',')[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
