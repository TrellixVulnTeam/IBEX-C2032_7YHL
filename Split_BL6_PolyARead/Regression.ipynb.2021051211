{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 14753\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.predict.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    return data_mean,data_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4bf9471f98>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4bf9410438>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxU1Z338c+vqqtXaGigaZpFQMQFF1BbFLeIglGyoCYmJKMxPmaYLOaJycQJSZ5EJ8skMdskM0aDy4iOYyYmGo1LUIkRDW4NAoIszeLSdAMNyr70Ur/nj7rVFG03dHcVXV1V3/frVa+699x7q84p6PrVWe455u6IiEjuCqU7AyIikl4KBCIiOU6BQEQkxykQiIjkOAUCEZEcl5fuDHTHoEGDfNSoUenOhohIRlm4cOEWdy9vm56RgWDUqFFUV1enOxsiIhnFzN5qL11NQyIiOU6BQEQkx6UkEJjZJWa2yszWmNmsdo5fYGbbzWxx8PhuZ68VEZEjK+k+AjMLA7cCU4Fa4FUze9Td32hz6vPu/uFuXisiIkdIKmoEE4E17r7O3RuB3wHTe+BaERFJgVQEgmHAOwn7tUFaW5PMbImZPWlmJ3bxWsxspplVm1l1Q0NDCrItIiKQmkBg7aS1ndJ0ETDS3ccD/wH8qQvXxhLdZ7t7lbtXlZe/bxisiIh0UyruI6gFRiTsDwfqEk9w9x0J20+Y2W/MbFBnrpXssbZhF0++Xk8oZHz89OEM7luY7iyJCKkJBK8CY81sNLABmAF8OvEEMxsCbHJ3N7OJxGoiW4Fth7tWMtvKjTuYs+At+hbmMXv+utb0nz+1mkX/byr9iiNpzJ2IQAoCgbs3m9n1wFwgDNzt7svN7PPB8duBjwNfMLNmYC8ww2Mr4rR7bbJ5kp71yOINvLL+XS44bjDrGnaxYO1WJo0ZyOc/MIY5C97igVfeBuD4IX351YxTeb6mgR88voLx33uK5f/6QUoKMvIGd5GsYZm4QllVVZVriokjo27bXnbsa+LoQX3IzwtRt20vv69+h/pt+yiMhLh60kiOGdyXzTv2MXv+Ogb0yeeWv6xq97UWf3cqE773NACnjyxj9tWnM7BPAe7OCd/9C/uaojz25XM5aVi/niyiSM4ys4XuXtU2XT/FpNWmHfs49yd/JeowdVwF5x4ziJsejVXQiiJh9ja1MOfFt/inDxzNb59b977rjx5UwmcmjeS51Q08u6qBK36zAIDxI/rzxy+c3XqemXHPtROZMfsltu1p6pnCiUiHFAik1YZte4k6lPct4Ok3NvH0G5s4elAJP7z8ZM46egDL63bwT/ctbA0C+XkhTjuqP4P7FnLLx0+hMBIG4OTh/Xh2VQPrtuwG4L7rJr7vvcqK8wHYtrexh0onIh1RIDjCtu9t4tHFG6jdtpc7n1/PCZV9mX11FUP7F6U7a++zbU/sS/lXMybw6TteBuDe6yYyvKwYgJOG9eOhL57NbX9byyfPGMEJlaXtvs7pIwfw+3+axDV3v8JJw0opLXx/h3BZ0En8XidqBO6OWXsjjUUkFRQIkvRG3Q5umbuSYf2L+ETVCCr7FVKYH2798rvrhfX8el5N6/nLNuzgngVv8q1pJwDQEnX2NbX0ig7Tx5bUAzC0XxEPfn4Su/Y1twaBuIrSQm7+6IntXX6QiaMHsPimqYQ6+ALvH68R7G6ksTlKJGztftnf9MgynnpjExePq2DM4D5cfdbIds/bsa+JO+evY9zQUi45qfKw+RORA9L/7ZPhrn9gEesaYk0g978cGx2TFzLu/9yZjBnch4VvvQvAdeeO5szRA/jVvBpW1Mduq3ihZgtff3AJu/c388KsC+lXlN6hlA+9tgGAAX3yGTWoJOnXK8gLd3gsPy9ESX6Y52u28POnV/OlyWO48YPHH3TOu7sbmfNibPr0e196C3foU5DHFacNbz2nqSXKf/51DfNrGnjt7W0A6oAW6SJNQ52EvY0trN+ymwuOK+ePXzibH15+Ejd/ZBxRdz45+yWqfvAMf1+zlWsmjeQ7Hx7HxScO4YTKUlbU7wTge48tZ+OOfezc38y3HnqddI/gCoeM0YNK2m3KORL6F+fzypuxQHnrs2vfd3zVxtjn9N/Xncmq719Kv6IIX/v9EuavPjDFyEOLavnVvBrWb9nNDVPGMqhPAV+8fxG3/W1t2j9PkUyhGkESXnnzXdzhE1UjOH1kGaePLAPg+MpSnl25mWV125k+fhhTx1W0XjOuspQ/LKzlrhfWs3rTLq466yi27Gzk8dfrKf5DmJ9eOT4tZXl3dyMtUWfGGSMOf3KKhEPW+twSdTbt2EdF6YG7jfc0NgNQWpRHfl6IOf9nIh+7bQH/8/LbnH9sbJqRZ1Zs5qgBxTx34wWYGRNG9Odrv1/CT/6ykmV127n106f1WHlEMpVqBEl4oaaB/LwQFx4/+KD0s44eyDenncD9nzuLT5wxgrKS/NZjl586jEjY+P5jsZm2Z543htuuOo2Ljh/Mn5fW0RJ1mlqiPVoOgOdWb27Ne0+58vThnDd2ELd++lQAzvy3eQcd37U/FgiK82O/VyaM6M/k4wbzl+Ub+dCvn+dHT66IjWwqL2ntN7jguMEsmHUhAI8vrVetQKQTFAiS8Pa7exheVtQ6bLIzykryueqskQAcM7gPRw0sxsz48PhK9jVFufL2BZx001yuu+dVajbtPFJZP8iyDdv50RMrGdSngJN7sG39yxeN5b7rzjyoPf/PS+r431djfS2797cAsX6BuG9Oi/UjLK/b0TqMtbLfwXMWFUbCfKIq1o/QsHP/kSuASJZQIOimnfuamLt8E+V9Crp87U0fOZE3f/whnvnaB1rTLh43hDNGlbG2YTf7m6PMW7mZOS++mboMH8Ltz61l8879fOOS4wiFen6Y5tB+B4bSfvmB1/jGH1+nsTna2jRUUnAg0I4p78NzN17AZyaNbE37xiUHdzIDrcH2q79fzNZdCgYih6JA0E312/cBcOboASl5vZKCPB78/Nksueli3vzxhzh5WD/e2ronJa99OG/U7WDquAqurOq5/oFEoZDx3Q+POyht9vy1vBp0JMebhuJGDizhe9NPYtTAYr5+8bGtQ1ETnTK8P5+aOIK/r9nKvcHIIxFpnzqLu+m93bGbryaOPjJt6scP6cuDC2uZ9KN5jK3oy7Vnj+KEylKG9Evt1M1PLd/Iui27mTExPUEg7iPjh7J1937OOWYQ33rodX721GogNhQ33EEt5W83Tj7ka/7oilNYWrudRW+/l/L8imQT1Qi6KX5HbP8jNI1y/Nd5/fZ9zF/dwLX3vMrn/3thyt/ntXdiY+8vO7XdheF6THnfAm784PGcPWYQX5kytjX9B5edlNTrDi8rYmNQexOR9qlG0E3x6RgSRwSl0qlH9WfKCRWcMaqMKeMq+I95NTy5bCMtUe/wF3J37NrXTP/iSK9aJGb6+GEsrd0OxIbmJmNIaSEL1m5NRbZEspYCQRf9eUkd9730FuePHQRA/yN0N3AkHOLOaw7MFjtpzED+tLiO2vf2MHJg8nf9xu3e30xJfu/6bxAKGTd95PDTWHTGsUP6snNfM799bi0zzz9acxaJtENNQ130y2dW88r6d7ntb2vJD4cozu/80NFkjK3oC0DNpl0pfd1d+5vpW9i7AkEqXXHqcAaU5POjJ1dyyb8/zz1/X8/expZ0Z0ukV1Eg6KKjBsQmYdvd2EJjS7THfmEeM7gPADWbUx8IesOEd0dKUX6YuTecz3ljB7F6805u/vMbnHTzXJbWbkt31kR6DQWCw9jf3MLXH1zCFb/5Ow9Wv8PG7fsYNbD48BemWGlhhCGlhfzHX2tSerfs7v3NB92wlY3K+xZw33VnUv3tKXznw7G5oP66cnO6syXSa6TkG8DMLgF+RWzd4Tvd/cdtjv8D8I1gdxfwBXdfEhx7E9gJtADN7S2jlk5X3/lK68Roi4LZLb865VhGDSpmX1PPNjGcUNmXZ1c18O/P1HD9hccQCScfx3fuf/9U09lqYJ8Crjt3NHOXb+SRxXXcMOXYdGdJpFdI+pvEzMLArcClwDjgU2Y2rs1p64EPuPspwPeB2W2OT3b3Cb0lCDS1RNmyaz879jWx6O33OGlYKfP++cBdwOccM5DpE4bxyTOO6tF8XXvOaAB+Na+Gh4Mpo5OVCzWCti4eV8H6LbuZt2JTurMi0iukomloIrDG3de5eyPwO2B64gnuvsDd43f1vAQMpxf7hztepuoHz3D+Lc/SHHWuPXs0Y8r7cNKw2Ipco1MwV393nD6yjA+dHFt05Y26HSl5zd37e8eiOD3p0uAzfHLZxjTnRKR3SEUgGAa8k7BfG6R15DrgyYR9B54ys4VmNrOji8xspplVm1l1Q0NDR6clLRp1FgcdifGF1UuDIaIP/ONZ3HfdRAZ2Y36hVCgpyOPWfziNYf2L2LE3+UXfo1Fn1/5m+hT0zMin3mJY/yLOP7aclRtTE0xFMl0qAkF7w2ba7c00s8nEAsE3EpLPcffTiDUtfcnMzm/vWnef7e5V7l5VXl6ebJ479PU/LKGxOcqpR/VvTYsPr+xbGOG8sUfuvTurX1GE7d0IBD+du5JRsx5n1KzHeXndVvYEfRx9snj4aEcGleS3BnqRXJeKQFALJN7+ORyoa3uSmZ0C3AlMd/fWWz3dvS543gw8TKypKS3cnedWNVAYCfHDy05uTe+pFbs6qzuBIBp1/uvvb7bu//zp1Wx4b2/r6+WafsURtisQiACpCQSvAmPNbLSZ5QMzgEcTTzCzo4CHgKvdfXVCeomZ9Y1vAxcDy1KQp26p376Prbsb+da0Exg3tLQ1vbfdcNW/uOuBYNPOfexpbOH6yccwsCSffU0tvLBmC0Dral+5pF9RhJ37m2lOwyJAIr1N0t9w7t5sZtcDc4kNH73b3Zeb2eeD47cD3wUGAr8JbsCKDxOtAB4O0vKA/3H3vySbp67YvHMfpYUR9jS28J0/xWJQfKGUmz8yjvk1W1I+42eyOlMj2Lh9Hx+7bQFHl5dQWhRhWP/YnP9njB7Ae3sauf/ltynIC9GnII8hpb2rfD0hPjXIW+/uYUx5nzTnRiS9UvJT192fAJ5ok3Z7wvbngM+1c906ID2L9AIv1GzhqrtePijt6EEljB8e6x/47Dmj+WwwZLM36UwgeGbFJjZs28uGbXsPSj9z9AD2NrZw/8tv8+qb73Hi0NKcnH/n9JGxdSSm/uI5Vnz/EgrycqvDXCRRTt9ZHF/4JNEDM89K6eyeR0JpUYT9zdFD3tDW3hxIM84YQWEkzAXHHWgK+uIFxxyRPPZ2Jw/vxyerRhB1+PbDy9KyTrRIb5HTgWDB2i0cV9GXp756Pi98YzJLvnsxFRnQTBLv3D1UrSBxRMzPrhxPfl6Ij50eu32jMBLm5GH9mHHGCD50SuWRzWwvdsPU2LoHf1hYy6vr3/+jQCRX9K5e0B72Rt0OrqwawbHBzJ6Z4ujy2A1tr739Hpec9P4v8t/8bQ33BCOErj1nFB8/fTgfO23YQU1Af/7yuT2S196ssl8R82+czPk/fZbaNk1oIrkkZwOBu7OnqaXXjQjqjKqgfXtNm5lIG5ujfOK3L7L4nW0cXV7ClVXDufGDsYXdc7EfoDPiAwH+5Q9LGVCcz5RxFWnOkUjPy9mmof3NUdxjzSSZJj8vREl++KDmn7ptezn2/z3J4ne2MX5Ef+757MTWICAdy88LtS6Hed9LWuReclPm/RxOkfjiJD21sEyq9S/Ob103GWBxsPbwjDNG8IPLTiIvBTOT5oqrzhrJO+/u4a4X1sdWbMuxuZdEcurbYuuu/by8LnZTc3x6haIMrBFAfAhpI9Gos7R2G8+taiBkcPNHT1QQ6IZTjyqjOeqtAVUkl+TUN8a/PbGSmfctpKkl2lojKMrYGkGEbXuamF/TwEf/8+/8b/U7nD1mUEY2dfUG4ypjd5Lf8fy6NOdEpOflVB14ygmD+eOiWqrffI/ldduBzK0R9C+OsHrTLp4NVtq6/arTmTh6QJpzlbmOGljMcRV9qd+2L91ZEelxORUI4vMHfeqOl1rTSjN0wrV+Rfms2byrdeTQxeMqCPXyG+F6u8nHD+b259ay8K13W+88FskFOdU0NLys+H2dwxNG9O/g7N6tf/HBAUxBIHnxO64/dtuLvF67Pc25Eek5ORUIwiHjif97Xuv+glkXZmyb+sCS/Nbt5/9lchpzkj3OHD2Ae649A4DnVmtxe8kdORUIAEYlLDM5NJiRMxOdMSrWdHHK8H6MGJAbi88faWbGBccNprJfIWsbdqc7OyI9Jqf6COLm3ziZTL/R9pTh/bjzM1UcX5lZ02NkghFlxTz82ga+N/1E+vayRYlEjoScqxFAbIRIpv+KNjOmjKtgeFlml6M3Om/sIADWqVYgOSInA4HIoUw9MTbf0O9efSfNORHpGQoEIm3EVyxru6iPSLZKSSAws0vMbJWZrTGzWe0cNzP7dXB8qZmd1tlrRXpaJBzijFFlWs9YckbSgcDMwsCtwKXAOOBTZjauzWmXAmODx0zgti5cK9Lj8kIhrVomOSMVNYKJwBp3X+fujcDvgOltzpkO3OsxLwH9zayyk9eK9LhIXojGFk93NkR6RCoCwTAgsVetNkjrzDmduVakx+WHTU1DkjNSEQjaG5Hf9qdUR+d05trYC5jNNLNqM6tuaGjoYhZFukZNQ5JLUhEIaoERCfvDgbpOntOZawFw99nuXuXuVeXl5UlnWuRQInkhmtQ0JDkiFYHgVWCsmY02s3xgBvBom3MeBT4TjB46C9ju7vWdvFakx0XCphqB5Iykp5hw92Yzux6YC4SBu919uZl9Pjh+O/AEMA1YA+wBrj3UtcnmSSRZETUNSQ5JyVxD7v4EsS/7xLTbE7Yd+FJnrxVJt0ieqWlIcobuLBZpRySsGoHkDgUCkXYoEEguUSAQaUess1hNQ5IbFAhE2hEJh2iJum4qk5ygQCDSjvjqdW+/uyfNORE58hQIRNpxwpBSAFZu3JnmnIgceTm5VKXI4Yyt6EPI4J4Fb7L4nW3kh0Ncd+5oykry0501kZRTIBBpR2EkzOTjBrNg7VaW1m5jX1OUwaUFfGbSqHRnTSTlLHavV2apqqry6urqdGdDcoS7M/5fn6JvYYSThpXy809MoE+BfkNJ5jGzhe5e1TZdfQQih2Fm/ON5R9OvKMLc5ZtY9NZ76c6SSEopEIh0wpcvGsu9100EoGbzrjTnRiS1FAhEOmlgST75eSE279iX7qyIpJQCgUgnmRllxRHe29OY7qyIpJQCgUgXlBXn8+7upnRnQySlFAhEuqCsOJ9nVmzi3hffTHdWRFJGgUCkC66eNBKAucs3pjknIqmjQCDSBdNOruS8sYPY09iS7qyIpIwCgUgXFUXC7FUgkCySVCAwswFm9rSZ1QTPZe2cM8LMnjWzFWa23My+knDsZjPbYGaLg8e0ZPIj0hNKCvLY3dic7myIpEyyNYJZwDx3HwvMC/bbagb+2d1PAM4CvmRm4xKO/9LdJwQPrV0svV5RvmoEkl2SDQTTgTnB9hzgsrYnuHu9uy8KtncCK4BhSb6vSNoUR8LqI5CskmwgqHD3eoh94QODD3WymY0CTgVeTki+3syWmtnd7TUtJVw708yqzay6oaEhyWyLdF9hEAhWaa0CyRKHDQRm9oyZLWvnMb0rb2RmfYA/Aje4+44g+TZgDDABqAd+3tH17j7b3avcvaq8vLwrby2SUuNH9AegZrMCgWSHw86l6+5TOjpmZpvMrNLd682sEtjcwXkRYkHgfnd/KOG1NyWccwfwWFcyL5IOxwzuA0Bjs9YzluyQbNPQo8A1wfY1wCNtTzAzA+4CVrj7L9ocq0zYvRxYlmR+RI64/LzYn02TFraXLJFsIPgxMNXMaoCpwT5mNtTM4iOAzgGuBi5sZ5joLWb2upktBSYDX00yPyJHXH449mejGoFki6SWWXL3rcBF7aTXAdOC7RcA6+D6q5N5f5F0iNcI9isQSJbQncUiXVQQBIJGNQ1JllAgEOkiNQ1JtlEgEOmiUMjIC5kCgWQNBQKRboiEQwoEkjUUCES6IT8vpOGjkjUUCES6IRI25rz4FvubNeeQZD4FApFuKC2KAPB67fY050QkeQoEIt3ww8tOBjSEVLKDAoFIN0TCsXskm1s8zTkRSZ4CgUg35AX3EjRHVSOQzKdAININeSHVCCR7KBCIdENevGkoqkAgmU+BQKQb8kKailqyhwKBSDeos1iyiQKBSDfEO4tb1DQkWUCBQKQb4p3FTRo1JFlAgUCkGzRqSLKJAoFIN8SbhtRZLNkgqUBgZgPM7Gkzqwmeyzo4781gbeLFZlbd1etFepuIho9KFkm2RjALmOfuY4F5wX5HJrv7BHev6ub1Ir1GOGgaUmexZINkA8F0YE6wPQe4rIevF0mLiO4jkCySbCCocPd6gOB5cAfnOfCUmS00s5nduB4zm2lm1WZW3dDQkGS2RZITChkhU2exZIe8w51gZs8AQ9o59O0uvM857l5nZoOBp81spbvP78L1uPtsYDZAVVWV/vok7fLCIQ0flaxw2EDg7lM6OmZmm8ys0t3rzawS2NzBa9QFz5vN7GFgIjAf6NT1Ir1RXshoUY1AskCyTUOPAtcE29cAj7Q9wcxKzKxvfBu4GFjW2etFequ8kGnUkGSFZAPBj4GpZlYDTA32MbOhZvZEcE4F8IKZLQFeAR53978c6nqRTBAJawF7yQ6HbRo6FHffClzUTnodMC3YXgeM78r1IpkgL2zqLJasoDuLRbopLxRS05BkBQUCkW7KC5uWqpSsoEAg0k15ITUNSXZQIBDpJnUWS7ZQIBDppnDINNeQZAUFApFuit1ZrEAgmU+BQKSbIiGjWU1DkgUUCES6SfcRSLZQIBDppkg4pOGjkhUUCES6Kay5hiRLKBCIdFNeKESTmoYkCygQiHRTJKzOYskOCgQi3VSQF6JRgUCygAKBSDcV5YfZ29iS7myIJE2BQKSbCiNh9jYpEEjmUyAQ6aaiSJh9CgSSBRQIRLqpKBKmqcU18ZxkPAUCkW4qyg8DqHlIMl5SgcDMBpjZ02ZWEzyXtXPOcWa2OOGxw8xuCI7dbGYbEo5NSyY/Ij2pMBILBDv2NqU5JyLJSbZGMAuY5+5jgXnB/kHcfZW7T3D3CcDpwB7g4YRTfhk/7u5PtL1epLfqWxhb8vv8W56lsVnNQ5K5kg0E04E5wfYc4LLDnH8RsNbd30ryfUXSbsoJFRw/pC9Rh137m9OdHZFuSzYQVLh7PUDwPPgw588AHmiTdr2ZLTWzu9trWoozs5lmVm1m1Q0NDcnlWiQFSgryuPacUQAaPSQZ7bCBwMyeMbNl7Tymd+WNzCwf+CjwYELybcAYYAJQD/y8o+vdfba7V7l7VXl5eVfeWuSIKciL9RPsV9OQZLC8w53g7lM6OmZmm8ys0t3rzawS2HyIl7oUWOTumxJeu3XbzO4AHutctkV6h4K82G+p/c2qEUjmSrZp6FHgmmD7GuCRQ5z7Kdo0CwXBI+5yYFmS+RHpUQWRIBA0qUYgmSvZQPBjYKqZ1QBTg33MbKiZtY4AMrPi4PhDba6/xcxeN7OlwGTgq0nmR6RHFQZNQ+ojkEx22KahQ3H3rcRGArVNrwOmJezvAQa2c97Vyby/SLq11gjURyAZTHcWiyRBncWSDRQIRJKgzmLJBgoEIkmIhGN/QrqzWDKZAoFIEsIhA0Br2EsmUyAQSYLF4gBRRQLJYAoEIkmI1whaXIFAMpcCgUgSwhZvGlIgkMylQCCSBIsHAjUNSQZTIBBJQmvTkAKBZDAFApEkHGgaSnNGRJKgQCCSBAv+gtRHIJlMgUAkCfEagZqGJJMpEIgkQTeUSTZIavZRkVzXekOZmoaE2HTkjy2tP6JzT00+bjBD+xel9DUVCESSoKYhSTRvxWa+/uCSI/oe91x7hgKBSG9yoGlIgUBgT2MzAA9/8WyGpfjLOq60KJLy11QgEEmCbiiTRPGa4ZB+hQwuLUxzbjpPncUiSQqHTHMNCQBNQSCI1xQzRVKBwMyuNLPlZhY1s6pDnHeJma0yszVmNishfYCZPW1mNcFzWTL5EUmHsJlGDQkALS2xdSkiocz6jZ1sbpcBVwDzOzrBzMLArcClwDjgU2Y2Ljg8C5jn7mOBecG+SEYxU9OQxDTHawThHKoRuPsKd191mNMmAmvcfZ27NwK/A6YHx6YDc4LtOcBlyeRHJB3CIdOoIQEOBIJcqxF0xjDgnYT92iANoMLd6wGC58EdvYiZzTSzajOrbmhoOGKZFekqNQ1JXHPQNJRpfQSHHTVkZs8AQ9o59G13f6QT79HeJ9LlPxt3nw3MBqiqqtKfnfQaZho+KjGtNYIMaxo6bCBw9ylJvkctMCJhfzhQF2xvMrNKd683s0pgc5LvJdLj1DQkcc0tTjhkrcOKM0VPNA29Cow1s9Fmlg/MAB4Njj0KXBNsXwN0poYh0quEzFQjECBWI8i0ZiFIfvjo5WZWC0wCHjezuUH6UDN7AsDdm4HrgbnACuD37r48eIkfA1PNrAaYGuyLZJRQSIFAYppbokQyMBAkdWexuz8MPNxOeh0wLWH/CeCJds7bClyUTB5E0i1sRjSa7lxIb5CTNQIRgZChO4sFgOZolEg4875WMy/HIr1MKGS6oUyA2FxDqhGI5KCw+ggk0NTiGVkj0OyjIkkKmbF1dyOvvf0eABWlhSmfL156p31NLayo39G637Bzf0bWCBQIRJLUpyCP52u28HzNFgBK8sO8fvMHCWXgF4J0zU/nruKuF9YflHbi0NI05ab7FAhEknTbVadRs3kXAH9eUsdDizbQ4k6o3ZvqJZts39vEwJJ8fvaJ8a1px5T3SWOOukeBQCRJw8uKGV5WDMAbdbFmgpaoEwmnM1fSE6JRpyg/zOTjOpwmLSNkXq+GSC+mpStzS4tn5iihthQIRFIovpi9RpPmhqgf+DfPZAoEIikU/07QJHS5IRp1siAOKBCIpFJr05ACQU7I1BvI2lIgEEkh9RHklqg7oSyoEigQiKRQfB56zT2UGxQIROR9WjuLNRtpTlDTkIi8T3yaGTUN5YwPagQAAAaZSURBVIaokxV3kCsQiKRQa9OQOotzQqxpKN25SJ4CgUgKHbiPQIEgF7REXfcRmNmVZrbczKJmVtXBOSPM7FkzWxGc+5WEYzeb2QYzWxw8prX3GiKZ4sCooTRnRHpE1D0rmoaSnWtoGXAF8NtDnNMM/LO7LzKzvsBCM3va3d8Ijv/S3X+WZD5EegXdUJZbolEIZUG7SrJrFq+AA+2iHZxTD9QH2zvNbAUwDHijw4tEMpTuI8gtLe5EsiAS9GgJzGwUcCrwckLy9Wa21MzuNrOynsyPSKqpjyC35Mx9BGb2jJkta+cxvStvZGZ9gD8CN7h7fEmf24AxwARitYafH+L6mWZWbWbVDQ0NXXlrkR6jUUO5JRrNjkBw2KYhd5+S7JuYWYRYELjf3R9KeO1NCefcATx2iHzMBmYDVFVV6a9MeqUDcw2lOSPSIzQNdSdZ7CfSXcAKd/9Fm2OVCbuXE+t8FslYuqEst0SjZEWNINnho5ebWS0wCXjczOYG6UPN7IngtHOAq4EL2xkmeouZvW5mS4HJwFeTyY9IummuodySLTeUJTtq6GHg4XbS64BpwfYL0P7ire5+dTLvL9LbxDuLXYEgJ0TVNCQibYVaO4vTnBHpES1Z0lmsQCCSQvEh5Ro1lBs06ZyIvI+ahnJL1J1w5scBBQKRVIr/OlRncW5Q05CIvE9IN5TllGg0OyadUyAQSaH4CBJVCHJD1NE01CJysJBmH80pLe6afVREDhZvGvrOI8v4yV9Wpjk3cqS9u7sxK/oIFAhEUmhsRR8+NXEE2/c2pTsr0gOOrejLZacOS3c2kqZAIJJCBXlhfnTFKenOhkiXZEHrloiIJEOBQEQkxykQiIjkOAUCEZEcp0AgIpLjFAhERHKcAoGISI5TIBARyXGWifOmm1kD8FY3Lx8EbElhdjKBypwbVObckEyZR7p7edvEjAwEyTCzanevSnc+epLKnBtU5txwJMqspiERkRynQCAikuNyMRDMTncG0kBlzg0qc25IeZlzro9AREQOlos1AhERSaBAICKS43IqEJjZJWa2yszWmNmsdOcnFcxshJk9a2YrzGy5mX0lSB9gZk+bWU3wXJZwzTeDz2CVmX0wfblPjpmFzew1M3ss2M/qMptZfzP7g5mtDP69J+VAmb8a/L9eZmYPmFlhtpXZzO42s81mtiwhrctlNLPTzez14Nivzbqwhqa758QDCANrgaOBfGAJMC7d+UpBuSqB04LtvsBqYBxwCzArSJ8F/CTYHheUvQAYHXwm4XSXo5tl/xrwP8BjwX5WlxmYA3wu2M4H+mdzmYFhwHqgKNj/PfDZbCszcD5wGrAsIa3LZQReASYBBjwJXNrZPORSjWAisMbd17l7I/A7YHqa85Q0d69390XB9k5gBbE/oOnEvjgIni8LtqcDv3P3/e6+HlhD7LPJKGY2HPgQcGdCctaW2cxKiX1h3AXg7o3uvo0sLnMgDygyszygGKgjy8rs7vOBd9skd6mMZlYJlLr7ix6LCvcmXHNYuRQIhgHvJOzXBmlZw8xGAacCLwMV7l4PsWABDA5Oy5bP4d+BfwGiCWnZXOajgQbgv4LmsDvNrIQsLrO7bwB+BrwN1APb3f0psrjMCbpaxmHBdtv0TsmlQNBee1nWjJ01sz7AH4Eb3H3HoU5tJy2jPgcz+zCw2d0XdvaSdtIyqszEfhmfBtzm7qcCu4k1GXQk48sctItPJ9YEMhQoMbOrDnVJO2kZVeZO6KiMSZU9lwJBLTAiYX84sWpmxjOzCLEgcL+7PxQkbwqqiwTPm4P0bPgczgE+amZvEmviu9DM/pvsLnMtUOvuLwf7fyAWGLK5zFOA9e7e4O5NwEPA2WR3meO6WsbaYLtteqfkUiB4FRhrZqPNLB+YATya5jwlLRgZcBewwt1/kXDoUeCaYPsa4JGE9BlmVmBmo4GxxDqZMoa7f9Pdh7v7KGL/jn9196vI7jJvBN4xs+OCpIuAN8jiMhNrEjrLzIqD/+cXEesDy+Yyx3WpjEHz0U4zOyv4rD6TcM3hpbvHvId756cRG1WzFvh2uvOTojKdS6wKuBRYHDymAQOBeUBN8Dwg4ZpvB5/BKrowsqA3PoALODBqKKvLDEwAqoN/6z8BZTlQ5n8FVgLLgPuIjZbJqjIDDxDrA2ki9sv+uu6UEagKPqe1wH8SzBzRmYemmBARyXG51DQkIiLtUCAQEclxCgQiIjlOgUBEJMcpEIiI5DgFAhGRHKdAICKS4/4/oYd2czPkgg0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=10000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 368 steps, validate for 368 steps\n",
      "Epoch 1/3000\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.7021 - mse: 0.6956 - val_loss: 0.5691 - val_mse: 0.5625\n",
      "Epoch 2/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.6210 - mse: 0.6143 - val_loss: 0.5380 - val_mse: 0.5313\n",
      "Epoch 3/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.6053 - mse: 0.5986 - val_loss: 0.5492 - val_mse: 0.5425\n",
      "Epoch 4/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5998 - mse: 0.5931 - val_loss: 0.5304 - val_mse: 0.5237\n",
      "Epoch 5/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5985 - mse: 0.5918 - val_loss: 0.5281 - val_mse: 0.5214\n",
      "Epoch 6/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5867 - mse: 0.5800 - val_loss: 0.5335 - val_mse: 0.5268\n",
      "Epoch 7/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5811 - mse: 0.5744 - val_loss: 0.5500 - val_mse: 0.5433\n",
      "Epoch 8/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5962 - mse: 0.5895 - val_loss: 0.5548 - val_mse: 0.5481\n",
      "Epoch 9/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5810 - mse: 0.5743 - val_loss: 0.5315 - val_mse: 0.5248\n",
      "Epoch 10/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5677 - mse: 0.5610\n",
      "Epoch 00010: saving model to Regression_Model/mle.linear-0010.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5693 - mse: 0.5625 - val_loss: 0.5353 - val_mse: 0.5285\n",
      "Epoch 11/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5651 - mse: 0.5584 - val_loss: 0.4974 - val_mse: 0.4907\n",
      "Epoch 12/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5616 - mse: 0.5548 - val_loss: 0.5505 - val_mse: 0.5438\n",
      "Epoch 13/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5759 - mse: 0.5691 - val_loss: 0.5125 - val_mse: 0.5057\n",
      "Epoch 14/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5640 - mse: 0.5572 - val_loss: 0.5055 - val_mse: 0.4988\n",
      "Epoch 15/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5555 - mse: 0.5487 - val_loss: 0.5006 - val_mse: 0.4939\n",
      "Epoch 16/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5494 - mse: 0.5426 - val_loss: 0.5047 - val_mse: 0.4979\n",
      "Epoch 17/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5578 - mse: 0.5511 - val_loss: 0.5088 - val_mse: 0.5020\n",
      "Epoch 18/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5543 - mse: 0.5475 - val_loss: 0.5127 - val_mse: 0.5060\n",
      "Epoch 19/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5543 - mse: 0.5475 - val_loss: 0.4974 - val_mse: 0.4906\n",
      "Epoch 20/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5604 - mse: 0.5536\n",
      "Epoch 00020: saving model to Regression_Model/mle.linear-0020.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5587 - mse: 0.5520 - val_loss: 0.4862 - val_mse: 0.4794\n",
      "Epoch 21/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5555 - mse: 0.5488 - val_loss: 0.4964 - val_mse: 0.4896\n",
      "Epoch 22/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5590 - mse: 0.5522 - val_loss: 0.4981 - val_mse: 0.4913\n",
      "Epoch 23/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5609 - mse: 0.5541 - val_loss: 0.4986 - val_mse: 0.4918\n",
      "Epoch 24/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5524 - mse: 0.5456 - val_loss: 0.5065 - val_mse: 0.4997\n",
      "Epoch 25/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5501 - mse: 0.5433 - val_loss: 0.5032 - val_mse: 0.4964\n",
      "Epoch 26/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5396 - mse: 0.5328 - val_loss: 0.4886 - val_mse: 0.4817\n",
      "Epoch 27/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5459 - mse: 0.5391 - val_loss: 0.4847 - val_mse: 0.4779\n",
      "Epoch 28/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5398 - mse: 0.5330 - val_loss: 0.4858 - val_mse: 0.4790\n",
      "Epoch 29/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5429 - mse: 0.5361 - val_loss: 0.4941 - val_mse: 0.4873\n",
      "Epoch 30/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5591 - mse: 0.5523\n",
      "Epoch 00030: saving model to Regression_Model/mle.linear-0030.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5596 - mse: 0.5528 - val_loss: 0.5458 - val_mse: 0.5390\n",
      "Epoch 31/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5524 - mse: 0.5456 - val_loss: 0.5071 - val_mse: 0.5003\n",
      "Epoch 32/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5445 - mse: 0.5377 - val_loss: 0.5029 - val_mse: 0.4961\n",
      "Epoch 33/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5460 - mse: 0.5391 - val_loss: 0.4962 - val_mse: 0.4894\n",
      "Epoch 34/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5538 - mse: 0.5470 - val_loss: 0.5029 - val_mse: 0.4960\n",
      "Epoch 35/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5527 - mse: 0.5458 - val_loss: 0.4900 - val_mse: 0.4831\n",
      "Epoch 36/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5487 - mse: 0.5418 - val_loss: 0.4868 - val_mse: 0.4800\n",
      "Epoch 37/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5389 - mse: 0.5321 - val_loss: 0.4791 - val_mse: 0.4723\n",
      "Epoch 38/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5540 - mse: 0.5472 - val_loss: 0.4905 - val_mse: 0.4836\n",
      "Epoch 39/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5405 - mse: 0.5336 - val_loss: 0.4838 - val_mse: 0.4770\n",
      "Epoch 40/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5360 - mse: 0.5291\n",
      "Epoch 00040: saving model to Regression_Model/mle.linear-0040.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5370 - mse: 0.5302 - val_loss: 0.4980 - val_mse: 0.4911\n",
      "Epoch 41/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5448 - mse: 0.5380 - val_loss: 0.4826 - val_mse: 0.4757\n",
      "Epoch 42/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5365 - mse: 0.5296 - val_loss: 0.4942 - val_mse: 0.4874\n",
      "Epoch 43/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5438 - mse: 0.5370 - val_loss: 0.4932 - val_mse: 0.4863\n",
      "Epoch 44/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5425 - mse: 0.5356 - val_loss: 0.4773 - val_mse: 0.4705\n",
      "Epoch 45/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5381 - mse: 0.5312 - val_loss: 0.4786 - val_mse: 0.4718\n",
      "Epoch 46/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5502 - mse: 0.5434 - val_loss: 0.4891 - val_mse: 0.4822\n",
      "Epoch 47/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5318 - mse: 0.5249 - val_loss: 0.4798 - val_mse: 0.4730\n",
      "Epoch 48/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5452 - mse: 0.5384 - val_loss: 0.4739 - val_mse: 0.4671\n",
      "Epoch 49/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5391 - mse: 0.5322 - val_loss: 0.4881 - val_mse: 0.4813\n",
      "Epoch 50/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5392 - mse: 0.5324\n",
      "Epoch 00050: saving model to Regression_Model/mle.linear-0050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5402 - mse: 0.5334 - val_loss: 0.4917 - val_mse: 0.4849\n",
      "Epoch 51/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5377 - mse: 0.5309 - val_loss: 0.4741 - val_mse: 0.4672\n",
      "Epoch 52/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5412 - mse: 0.5343 - val_loss: 0.4926 - val_mse: 0.4858\n",
      "Epoch 53/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5419 - mse: 0.5350 - val_loss: 0.4775 - val_mse: 0.4706\n",
      "Epoch 54/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5457 - mse: 0.5389 - val_loss: 0.4706 - val_mse: 0.4638\n",
      "Epoch 55/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5416 - mse: 0.5348 - val_loss: 0.4864 - val_mse: 0.4795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5348 - mse: 0.5279 - val_loss: 0.4749 - val_mse: 0.4680\n",
      "Epoch 57/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5339 - mse: 0.5271 - val_loss: 0.4699 - val_mse: 0.4631\n",
      "Epoch 58/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5402 - mse: 0.5334 - val_loss: 0.4735 - val_mse: 0.4667\n",
      "Epoch 59/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5355 - mse: 0.5287 - val_loss: 0.4930 - val_mse: 0.4861\n",
      "Epoch 60/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5423 - mse: 0.5355\n",
      "Epoch 00060: saving model to Regression_Model/mle.linear-0060.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5415 - mse: 0.5347 - val_loss: 0.4737 - val_mse: 0.4669\n",
      "Epoch 61/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5375 - mse: 0.5306 - val_loss: 0.4681 - val_mse: 0.4613\n",
      "Epoch 62/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5356 - mse: 0.5288 - val_loss: 0.4710 - val_mse: 0.4641\n",
      "Epoch 63/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5374 - mse: 0.5305 - val_loss: 0.4927 - val_mse: 0.4859\n",
      "Epoch 64/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5348 - mse: 0.5279 - val_loss: 0.4761 - val_mse: 0.4692\n",
      "Epoch 65/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5359 - mse: 0.5290 - val_loss: 0.4772 - val_mse: 0.4703\n",
      "Epoch 66/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5311 - mse: 0.5242 - val_loss: 0.4713 - val_mse: 0.4645\n",
      "Epoch 67/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5298 - mse: 0.5229 - val_loss: 0.4694 - val_mse: 0.4625\n",
      "Epoch 68/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5256 - mse: 0.5188 - val_loss: 0.4630 - val_mse: 0.4562\n",
      "Epoch 69/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5378 - mse: 0.5310 - val_loss: 0.4686 - val_mse: 0.4618\n",
      "Epoch 70/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5364 - mse: 0.5296\n",
      "Epoch 00070: saving model to Regression_Model/mle.linear-0070.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5359 - mse: 0.5290 - val_loss: 0.4903 - val_mse: 0.4835\n",
      "Epoch 71/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5319 - mse: 0.5251 - val_loss: 0.4669 - val_mse: 0.4601\n",
      "Epoch 72/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5296 - mse: 0.5227 - val_loss: 0.4639 - val_mse: 0.4571\n",
      "Epoch 73/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5346 - mse: 0.5277 - val_loss: 0.4696 - val_mse: 0.4627\n",
      "Epoch 74/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5317 - mse: 0.5248 - val_loss: 0.4765 - val_mse: 0.4696\n",
      "Epoch 75/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5330 - mse: 0.5261 - val_loss: 0.4732 - val_mse: 0.4663\n",
      "Epoch 76/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5217 - mse: 0.5149 - val_loss: 0.4699 - val_mse: 0.4631\n",
      "Epoch 77/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5385 - mse: 0.5316 - val_loss: 0.4915 - val_mse: 0.4847\n",
      "Epoch 78/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5345 - mse: 0.5276 - val_loss: 0.4590 - val_mse: 0.4522\n",
      "Epoch 79/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5217 - mse: 0.5149 - val_loss: 0.4697 - val_mse: 0.4629\n",
      "Epoch 80/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5285 - mse: 0.5217\n",
      "Epoch 00080: saving model to Regression_Model/mle.linear-0080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5276 - mse: 0.5207 - val_loss: 0.4605 - val_mse: 0.4537\n",
      "Epoch 81/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5186 - val_loss: 0.4568 - val_mse: 0.4499\n",
      "Epoch 82/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5340 - mse: 0.5272 - val_loss: 0.4795 - val_mse: 0.4726\n",
      "Epoch 83/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5354 - mse: 0.5285 - val_loss: 0.4999 - val_mse: 0.4930\n",
      "Epoch 84/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5379 - mse: 0.5310 - val_loss: 0.4656 - val_mse: 0.4587\n",
      "Epoch 85/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5288 - mse: 0.5220 - val_loss: 0.4575 - val_mse: 0.4506\n",
      "Epoch 86/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5313 - mse: 0.5245 - val_loss: 0.4608 - val_mse: 0.4539\n",
      "Epoch 87/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5340 - mse: 0.5271 - val_loss: 0.4652 - val_mse: 0.4584\n",
      "Epoch 88/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5269 - mse: 0.5200 - val_loss: 0.4586 - val_mse: 0.4517\n",
      "Epoch 89/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5315 - mse: 0.5246 - val_loss: 0.4719 - val_mse: 0.4650\n",
      "Epoch 90/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5321 - mse: 0.5253\n",
      "Epoch 00090: saving model to Regression_Model/mle.linear-0090.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5301 - mse: 0.5233 - val_loss: 0.4811 - val_mse: 0.4742\n",
      "Epoch 91/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5331 - mse: 0.5263 - val_loss: 0.4694 - val_mse: 0.4625\n",
      "Epoch 92/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5357 - mse: 0.5289 - val_loss: 0.4636 - val_mse: 0.4568\n",
      "Epoch 93/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5224 - mse: 0.5155 - val_loss: 0.4681 - val_mse: 0.4613\n",
      "Epoch 94/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5361 - mse: 0.5293 - val_loss: 0.4701 - val_mse: 0.4632\n",
      "Epoch 95/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5302 - mse: 0.5233 - val_loss: 0.4624 - val_mse: 0.4555\n",
      "Epoch 96/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5240 - mse: 0.5171 - val_loss: 0.4563 - val_mse: 0.4494\n",
      "Epoch 97/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5262 - mse: 0.5193 - val_loss: 0.4860 - val_mse: 0.4792\n",
      "Epoch 98/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5282 - mse: 0.5213 - val_loss: 0.4700 - val_mse: 0.4631\n",
      "Epoch 99/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5318 - mse: 0.5250 - val_loss: 0.4721 - val_mse: 0.4652\n",
      "Epoch 100/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5236 - mse: 0.5167\n",
      "Epoch 00100: saving model to Regression_Model/mle.linear-0100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5219 - mse: 0.5150 - val_loss: 0.4663 - val_mse: 0.4594\n",
      "Epoch 101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5249 - mse: 0.5181 - val_loss: 0.4793 - val_mse: 0.4725\n",
      "Epoch 102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5239 - mse: 0.5170 - val_loss: 0.4688 - val_mse: 0.4619\n",
      "Epoch 103/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5186 - val_loss: 0.4783 - val_mse: 0.4714\n",
      "Epoch 104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5204 - mse: 0.5135 - val_loss: 0.4609 - val_mse: 0.4540\n",
      "Epoch 105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5224 - mse: 0.5155 - val_loss: 0.4644 - val_mse: 0.4576\n",
      "Epoch 106/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5225 - mse: 0.5156 - val_loss: 0.4635 - val_mse: 0.4566\n",
      "Epoch 107/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5215 - mse: 0.5147 - val_loss: 0.4603 - val_mse: 0.4534\n",
      "Epoch 108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5253 - mse: 0.5184 - val_loss: 0.4606 - val_mse: 0.4537\n",
      "Epoch 109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5215 - mse: 0.5146 - val_loss: 0.4663 - val_mse: 0.4594\n",
      "Epoch 110/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5263 - mse: 0.5194\n",
      "Epoch 00110: saving model to Regression_Model/mle.linear-0110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5245 - mse: 0.5176 - val_loss: 0.4653 - val_mse: 0.4584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5247 - mse: 0.5178 - val_loss: 0.4571 - val_mse: 0.4502\n",
      "Epoch 112/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5295 - mse: 0.5226 - val_loss: 0.4620 - val_mse: 0.4551\n",
      "Epoch 113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5234 - mse: 0.5165 - val_loss: 0.4682 - val_mse: 0.4614\n",
      "Epoch 114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5224 - mse: 0.5155 - val_loss: 0.4546 - val_mse: 0.4478\n",
      "Epoch 115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5254 - mse: 0.5185 - val_loss: 0.4827 - val_mse: 0.4758\n",
      "Epoch 116/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5066 - val_loss: 0.4615 - val_mse: 0.4547\n",
      "Epoch 117/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5198 - mse: 0.5129 - val_loss: 0.4728 - val_mse: 0.4659\n",
      "Epoch 118/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5177 - mse: 0.5108 - val_loss: 0.4658 - val_mse: 0.4589\n",
      "Epoch 119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5220 - mse: 0.5151 - val_loss: 0.4610 - val_mse: 0.4541\n",
      "Epoch 120/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5194 - mse: 0.5125\n",
      "Epoch 00120: saving model to Regression_Model/mle.linear-0120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5191 - mse: 0.5122 - val_loss: 0.4634 - val_mse: 0.4565\n",
      "Epoch 121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5218 - mse: 0.5149 - val_loss: 0.4660 - val_mse: 0.4591\n",
      "Epoch 122/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5313 - mse: 0.5244 - val_loss: 0.4551 - val_mse: 0.4482\n",
      "Epoch 123/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5179 - mse: 0.5110 - val_loss: 0.4587 - val_mse: 0.4518\n",
      "Epoch 124/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5234 - mse: 0.5165 - val_loss: 0.4864 - val_mse: 0.4795\n",
      "Epoch 125/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5171 - mse: 0.5102 - val_loss: 0.4485 - val_mse: 0.4416\n",
      "Epoch 126/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5242 - mse: 0.5173 - val_loss: 0.4599 - val_mse: 0.4531\n",
      "Epoch 127/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5162 - mse: 0.5093 - val_loss: 0.4522 - val_mse: 0.4453\n",
      "Epoch 128/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5248 - mse: 0.5179 - val_loss: 0.4549 - val_mse: 0.4480\n",
      "Epoch 129/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5204 - mse: 0.5135 - val_loss: 0.4582 - val_mse: 0.4513\n",
      "Epoch 130/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5239 - mse: 0.5170\n",
      "Epoch 00130: saving model to Regression_Model/mle.linear-0130.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5237 - mse: 0.5168 - val_loss: 0.4599 - val_mse: 0.4530\n",
      "Epoch 131/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5217 - mse: 0.5148 - val_loss: 0.4670 - val_mse: 0.4601\n",
      "Epoch 132/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5246 - mse: 0.5177 - val_loss: 0.4780 - val_mse: 0.4711\n",
      "Epoch 133/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5238 - mse: 0.5169 - val_loss: 0.4723 - val_mse: 0.4654\n",
      "Epoch 134/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5226 - mse: 0.5157 - val_loss: 0.5035 - val_mse: 0.4966\n",
      "Epoch 135/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5280 - mse: 0.5211 - val_loss: 0.4520 - val_mse: 0.4451\n",
      "Epoch 136/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5173 - mse: 0.5104 - val_loss: 0.4709 - val_mse: 0.4640\n",
      "Epoch 137/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5239 - mse: 0.5169 - val_loss: 0.4509 - val_mse: 0.4440\n",
      "Epoch 138/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5137 - val_loss: 0.4567 - val_mse: 0.4497\n",
      "Epoch 139/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5253 - mse: 0.5184 - val_loss: 0.4957 - val_mse: 0.4888\n",
      "Epoch 140/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5233 - mse: 0.5164\n",
      "Epoch 00140: saving model to Regression_Model/mle.linear-0140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5245 - mse: 0.5176 - val_loss: 0.4520 - val_mse: 0.4451\n",
      "Epoch 141/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5143 - mse: 0.5074 - val_loss: 0.4590 - val_mse: 0.4521\n",
      "Epoch 142/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5220 - mse: 0.5151 - val_loss: 0.4766 - val_mse: 0.4696\n",
      "Epoch 143/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5259 - mse: 0.5190 - val_loss: 0.4521 - val_mse: 0.4452\n",
      "Epoch 144/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5193 - mse: 0.5124 - val_loss: 0.4600 - val_mse: 0.4531\n",
      "Epoch 145/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5195 - mse: 0.5126 - val_loss: 0.4560 - val_mse: 0.4491\n",
      "Epoch 146/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5207 - mse: 0.5138 - val_loss: 0.4530 - val_mse: 0.4461\n",
      "Epoch 147/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5268 - mse: 0.5199 - val_loss: 0.4555 - val_mse: 0.4486\n",
      "Epoch 148/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5183 - mse: 0.5114 - val_loss: 0.4568 - val_mse: 0.4498\n",
      "Epoch 149/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5063 - val_loss: 0.4603 - val_mse: 0.4533\n",
      "Epoch 150/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5311 - mse: 0.5241\n",
      "Epoch 00150: saving model to Regression_Model/mle.linear-0150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5312 - mse: 0.5243 - val_loss: 0.4730 - val_mse: 0.4661\n",
      "Epoch 151/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5243 - mse: 0.5174 - val_loss: 0.4617 - val_mse: 0.4548\n",
      "Epoch 152/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5144 - mse: 0.5075 - val_loss: 0.4525 - val_mse: 0.4455\n",
      "Epoch 153/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5227 - mse: 0.5158 - val_loss: 0.4494 - val_mse: 0.4425\n",
      "Epoch 154/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5176 - mse: 0.5106 - val_loss: 0.4739 - val_mse: 0.4670\n",
      "Epoch 155/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5143 - mse: 0.5073 - val_loss: 0.4541 - val_mse: 0.4472\n",
      "Epoch 156/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5216 - mse: 0.5147 - val_loss: 0.4555 - val_mse: 0.4485\n",
      "Epoch 157/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5211 - mse: 0.5142 - val_loss: 0.4587 - val_mse: 0.4518\n",
      "Epoch 158/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5180 - mse: 0.5111 - val_loss: 0.4488 - val_mse: 0.4419\n",
      "Epoch 159/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5054 - val_loss: 0.4548 - val_mse: 0.4479\n",
      "Epoch 160/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5146 - mse: 0.5076\n",
      "Epoch 00160: saving model to Regression_Model/mle.linear-0160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5162 - mse: 0.5092 - val_loss: 0.4473 - val_mse: 0.4403\n",
      "Epoch 161/3000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5216 - mse: 0.5147 - val_loss: 0.4565 - val_mse: 0.4495\n",
      "Epoch 162/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5289 - mse: 0.5220 - val_loss: 0.4666 - val_mse: 0.4597\n",
      "Epoch 163/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5218 - mse: 0.5149 - val_loss: 0.4607 - val_mse: 0.4537\n",
      "Epoch 164/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5233 - mse: 0.5164 - val_loss: 0.4644 - val_mse: 0.4574\n",
      "Epoch 165/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5175 - mse: 0.5105 - val_loss: 0.4657 - val_mse: 0.4588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5065 - val_loss: 0.4586 - val_mse: 0.4516\n",
      "Epoch 167/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5254 - mse: 0.5185 - val_loss: 0.4496 - val_mse: 0.4426\n",
      "Epoch 168/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5197 - mse: 0.5127 - val_loss: 0.4477 - val_mse: 0.4407\n",
      "Epoch 169/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5246 - mse: 0.5176 - val_loss: 0.4654 - val_mse: 0.4584\n",
      "Epoch 170/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5159 - mse: 0.5089\n",
      "Epoch 00170: saving model to Regression_Model/mle.linear-0170.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5152 - mse: 0.5082 - val_loss: 0.4485 - val_mse: 0.4415\n",
      "Epoch 171/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5182 - mse: 0.5112 - val_loss: 0.4468 - val_mse: 0.4398\n",
      "Epoch 172/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5158 - mse: 0.5088 - val_loss: 0.4586 - val_mse: 0.4516\n",
      "Epoch 173/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5185 - val_loss: 0.4464 - val_mse: 0.4394\n",
      "Epoch 174/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5070 - val_loss: 0.4531 - val_mse: 0.4461\n",
      "Epoch 175/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5178 - mse: 0.5108 - val_loss: 0.4563 - val_mse: 0.4493\n",
      "Epoch 176/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5152 - mse: 0.5082 - val_loss: 0.4600 - val_mse: 0.4530\n",
      "Epoch 177/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5158 - mse: 0.5088 - val_loss: 0.4539 - val_mse: 0.4469\n",
      "Epoch 178/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5178 - mse: 0.5108 - val_loss: 0.4637 - val_mse: 0.4567\n",
      "Epoch 179/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5070 - val_loss: 0.4579 - val_mse: 0.4509\n",
      "Epoch 180/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5148 - mse: 0.5078\n",
      "Epoch 00180: saving model to Regression_Model/mle.linear-0180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5138 - mse: 0.5068 - val_loss: 0.4488 - val_mse: 0.4418\n",
      "Epoch 181/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5152 - mse: 0.5082 - val_loss: 0.4478 - val_mse: 0.4408\n",
      "Epoch 182/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5201 - mse: 0.5131 - val_loss: 0.4568 - val_mse: 0.4497\n",
      "Epoch 183/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5195 - mse: 0.5125 - val_loss: 0.4432 - val_mse: 0.4362\n",
      "Epoch 184/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5187 - mse: 0.5117 - val_loss: 0.4514 - val_mse: 0.4444\n",
      "Epoch 185/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5185 - mse: 0.5115 - val_loss: 0.4469 - val_mse: 0.4398\n",
      "Epoch 186/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5176 - mse: 0.5106 - val_loss: 0.4580 - val_mse: 0.4509\n",
      "Epoch 187/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5186 - mse: 0.5115 - val_loss: 0.4467 - val_mse: 0.4397\n",
      "Epoch 188/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5065 - val_loss: 0.4473 - val_mse: 0.4403\n",
      "Epoch 189/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5136 - mse: 0.5065 - val_loss: 0.4457 - val_mse: 0.4386\n",
      "Epoch 190/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5046 - mse: 0.4975\n",
      "Epoch 00190: saving model to Regression_Model/mle.linear-0190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.4996 - val_loss: 0.4523 - val_mse: 0.4453\n",
      "Epoch 191/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5151 - mse: 0.5081 - val_loss: 0.4556 - val_mse: 0.4486\n",
      "Epoch 192/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5188 - mse: 0.5117 - val_loss: 0.4455 - val_mse: 0.4385\n",
      "Epoch 193/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5138 - mse: 0.5068 - val_loss: 0.4518 - val_mse: 0.4447\n",
      "Epoch 194/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5042 - val_loss: 0.4423 - val_mse: 0.4353\n",
      "Epoch 195/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5071 - val_loss: 0.4637 - val_mse: 0.4567\n",
      "Epoch 196/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5221 - mse: 0.5150 - val_loss: 0.4491 - val_mse: 0.4420\n",
      "Epoch 197/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5062 - val_loss: 0.4428 - val_mse: 0.4358\n",
      "Epoch 198/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5014 - val_loss: 0.4448 - val_mse: 0.4377\n",
      "Epoch 199/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5125 - mse: 0.5055 - val_loss: 0.4607 - val_mse: 0.4536\n",
      "Epoch 200/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5174 - mse: 0.5103\n",
      "Epoch 00200: saving model to Regression_Model/mle.linear-0200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5178 - mse: 0.5107 - val_loss: 0.4557 - val_mse: 0.4487\n",
      "Epoch 201/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5150 - mse: 0.5079 - val_loss: 0.4491 - val_mse: 0.4421\n",
      "Epoch 202/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5215 - mse: 0.5144 - val_loss: 0.4503 - val_mse: 0.4432\n",
      "Epoch 203/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5062 - val_loss: 0.4473 - val_mse: 0.4402\n",
      "Epoch 204/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5168 - mse: 0.5098 - val_loss: 0.4410 - val_mse: 0.4339\n",
      "Epoch 205/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5189 - mse: 0.5118 - val_loss: 0.4429 - val_mse: 0.4359\n",
      "Epoch 206/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5089 - val_loss: 0.4417 - val_mse: 0.4347\n",
      "Epoch 207/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5167 - mse: 0.5096 - val_loss: 0.4410 - val_mse: 0.4339\n",
      "Epoch 208/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5194 - mse: 0.5123 - val_loss: 0.4484 - val_mse: 0.4413\n",
      "Epoch 209/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5134 - mse: 0.5063 - val_loss: 0.4480 - val_mse: 0.4410\n",
      "Epoch 210/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5113 - mse: 0.5042\n",
      "Epoch 00210: saving model to Regression_Model/mle.linear-0210.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5106 - mse: 0.5035 - val_loss: 0.4510 - val_mse: 0.4440\n",
      "Epoch 211/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5120 - mse: 0.5049 - val_loss: 0.4484 - val_mse: 0.4413\n",
      "Epoch 212/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5053 - val_loss: 0.4558 - val_mse: 0.4487\n",
      "Epoch 213/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5023 - val_loss: 0.4550 - val_mse: 0.4479\n",
      "Epoch 214/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5207 - mse: 0.5135 - val_loss: 0.4499 - val_mse: 0.4428\n",
      "Epoch 215/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5134 - mse: 0.5063 - val_loss: 0.4375 - val_mse: 0.4304\n",
      "Epoch 216/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5146 - mse: 0.5075 - val_loss: 0.4518 - val_mse: 0.4446\n",
      "Epoch 217/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5151 - mse: 0.5079 - val_loss: 0.4487 - val_mse: 0.4416\n",
      "Epoch 218/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5010 - val_loss: 0.4359 - val_mse: 0.4287\n",
      "Epoch 219/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5130 - mse: 0.5059 - val_loss: 0.4445 - val_mse: 0.4374\n",
      "Epoch 220/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5167 - mse: 0.5096\n",
      "Epoch 00220: saving model to Regression_Model/mle.linear-0220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5161 - mse: 0.5090 - val_loss: 0.4400 - val_mse: 0.4329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5003 - val_loss: 0.4359 - val_mse: 0.4288\n",
      "Epoch 222/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5069 - val_loss: 0.4396 - val_mse: 0.4325\n",
      "Epoch 223/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.4998 - val_loss: 0.4438 - val_mse: 0.4367\n",
      "Epoch 224/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5195 - mse: 0.5123 - val_loss: 0.4615 - val_mse: 0.4544\n",
      "Epoch 225/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5164 - mse: 0.5093 - val_loss: 0.4519 - val_mse: 0.4447\n",
      "Epoch 226/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5165 - mse: 0.5094 - val_loss: 0.4498 - val_mse: 0.4426\n",
      "Epoch 227/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4961 - val_loss: 0.4455 - val_mse: 0.4384\n",
      "Epoch 228/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5157 - mse: 0.5085 - val_loss: 0.4441 - val_mse: 0.4370\n",
      "Epoch 229/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5083 - mse: 0.5012 - val_loss: 0.4447 - val_mse: 0.4375\n",
      "Epoch 230/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5124 - mse: 0.5052\n",
      "Epoch 00230: saving model to Regression_Model/mle.linear-0230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5155 - mse: 0.5083 - val_loss: 0.4438 - val_mse: 0.4366\n",
      "Epoch 231/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4961 - val_loss: 0.4409 - val_mse: 0.4337\n",
      "Epoch 232/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5107 - mse: 0.5035 - val_loss: 0.4476 - val_mse: 0.4404\n",
      "Epoch 233/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5092 - mse: 0.5020 - val_loss: 0.4442 - val_mse: 0.4370\n",
      "Epoch 234/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4965 - val_loss: 0.4533 - val_mse: 0.4461\n",
      "Epoch 235/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5027 - val_loss: 0.4482 - val_mse: 0.4410\n",
      "Epoch 236/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4981 - val_loss: 0.4507 - val_mse: 0.4435\n",
      "Epoch 237/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5017 - val_loss: 0.4487 - val_mse: 0.4416\n",
      "Epoch 238/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5010 - val_loss: 0.4371 - val_mse: 0.4299\n",
      "Epoch 239/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5124 - mse: 0.5052 - val_loss: 0.4360 - val_mse: 0.4288\n",
      "Epoch 240/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5142 - mse: 0.5070\n",
      "Epoch 00240: saving model to Regression_Model/mle.linear-0240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5068 - val_loss: 0.4415 - val_mse: 0.4343\n",
      "Epoch 241/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5156 - mse: 0.5084 - val_loss: 0.4455 - val_mse: 0.4383\n",
      "Epoch 242/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5051 - val_loss: 0.4420 - val_mse: 0.4348\n",
      "Epoch 243/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5171 - mse: 0.5099 - val_loss: 0.4419 - val_mse: 0.4347\n",
      "Epoch 244/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4984 - val_loss: 0.4477 - val_mse: 0.4405\n",
      "Epoch 245/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5012 - val_loss: 0.4510 - val_mse: 0.4438\n",
      "Epoch 246/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4967 - val_loss: 0.4463 - val_mse: 0.4391\n",
      "Epoch 247/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5030 - val_loss: 0.4662 - val_mse: 0.4590\n",
      "Epoch 248/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5130 - mse: 0.5058 - val_loss: 0.4834 - val_mse: 0.4762\n",
      "Epoch 249/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5039 - val_loss: 0.4460 - val_mse: 0.4388\n",
      "Epoch 250/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5085 - mse: 0.5013\n",
      "Epoch 00250: saving model to Regression_Model/mle.linear-0250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5022 - val_loss: 0.4379 - val_mse: 0.4307\n",
      "Epoch 251/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5115 - mse: 0.5043 - val_loss: 0.4436 - val_mse: 0.4364\n",
      "Epoch 252/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5027 - val_loss: 0.4374 - val_mse: 0.4302\n",
      "Epoch 253/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4984 - val_loss: 0.4585 - val_mse: 0.4512\n",
      "Epoch 254/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5128 - mse: 0.5055 - val_loss: 0.4368 - val_mse: 0.4296\n",
      "Epoch 255/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5161 - mse: 0.5089 - val_loss: 0.4412 - val_mse: 0.4340\n",
      "Epoch 256/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5103 - mse: 0.5031 - val_loss: 0.4582 - val_mse: 0.4509\n",
      "Epoch 257/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5161 - mse: 0.5089 - val_loss: 0.4412 - val_mse: 0.4339\n",
      "Epoch 258/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5128 - mse: 0.5056 - val_loss: 0.4495 - val_mse: 0.4423\n",
      "Epoch 259/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5010 - val_loss: 0.4570 - val_mse: 0.4497\n",
      "Epoch 260/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5113 - mse: 0.5041\n",
      "Epoch 00260: saving model to Regression_Model/mle.linear-0260.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5117 - mse: 0.5045 - val_loss: 0.4410 - val_mse: 0.4337\n",
      "Epoch 261/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5129 - mse: 0.5057 - val_loss: 0.4466 - val_mse: 0.4393\n",
      "Epoch 262/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5059 - val_loss: 0.4573 - val_mse: 0.4501\n",
      "Epoch 263/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5177 - mse: 0.5104 - val_loss: 0.4485 - val_mse: 0.4412\n",
      "Epoch 264/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5147 - mse: 0.5074 - val_loss: 0.4443 - val_mse: 0.4370\n",
      "Epoch 265/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5045 - val_loss: 0.4470 - val_mse: 0.4398\n",
      "Epoch 266/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4979 - val_loss: 0.4476 - val_mse: 0.4403\n",
      "Epoch 267/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.4989 - val_loss: 0.4475 - val_mse: 0.4402\n",
      "Epoch 268/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5003 - val_loss: 0.4409 - val_mse: 0.4337\n",
      "Epoch 269/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5040 - val_loss: 0.4640 - val_mse: 0.4568\n",
      "Epoch 270/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5139 - mse: 0.5066\n",
      "Epoch 00270: saving model to Regression_Model/mle.linear-0270.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5130 - mse: 0.5057 - val_loss: 0.4452 - val_mse: 0.4380\n",
      "Epoch 271/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5023 - val_loss: 0.4432 - val_mse: 0.4360\n",
      "Epoch 272/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5035 - val_loss: 0.4368 - val_mse: 0.4296\n",
      "Epoch 273/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5150 - mse: 0.5077 - val_loss: 0.4402 - val_mse: 0.4329\n",
      "Epoch 274/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5127 - mse: 0.5054 - val_loss: 0.4392 - val_mse: 0.4319\n",
      "Epoch 275/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4958 - val_loss: 0.4522 - val_mse: 0.4449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5036 - val_loss: 0.4467 - val_mse: 0.4395\n",
      "Epoch 277/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4947 - val_loss: 0.4468 - val_mse: 0.4395\n",
      "Epoch 278/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5008 - val_loss: 0.4470 - val_mse: 0.4397\n",
      "Epoch 279/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5021 - val_loss: 0.4335 - val_mse: 0.4262\n",
      "Epoch 280/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5033 - mse: 0.4960\n",
      "Epoch 00280: saving model to Regression_Model/mle.linear-0280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4965 - val_loss: 0.4490 - val_mse: 0.4417\n",
      "Epoch 281/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4965 - val_loss: 0.4369 - val_mse: 0.4296\n",
      "Epoch 282/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.4987 - val_loss: 0.4407 - val_mse: 0.4334\n",
      "Epoch 283/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5062 - val_loss: 0.4411 - val_mse: 0.4338\n",
      "Epoch 284/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4984 - val_loss: 0.4868 - val_mse: 0.4795\n",
      "Epoch 285/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5186 - mse: 0.5113 - val_loss: 0.4378 - val_mse: 0.4305\n",
      "Epoch 286/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4929 - val_loss: 0.4411 - val_mse: 0.4338\n",
      "Epoch 287/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5007 - val_loss: 0.4400 - val_mse: 0.4327\n",
      "Epoch 288/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5051 - val_loss: 0.4423 - val_mse: 0.4350\n",
      "Epoch 289/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5001 - val_loss: 0.4399 - val_mse: 0.4326\n",
      "Epoch 290/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5053 - mse: 0.4980\n",
      "Epoch 00290: saving model to Regression_Model/mle.linear-0290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4966 - val_loss: 0.4461 - val_mse: 0.4388\n",
      "Epoch 291/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5015 - val_loss: 0.4472 - val_mse: 0.4399\n",
      "Epoch 292/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5000 - val_loss: 0.4366 - val_mse: 0.4293\n",
      "Epoch 293/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5028 - val_loss: 0.4483 - val_mse: 0.4410\n",
      "Epoch 294/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.4998 - val_loss: 0.4430 - val_mse: 0.4357\n",
      "Epoch 295/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5009 - val_loss: 0.4387 - val_mse: 0.4314\n",
      "Epoch 296/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4948 - val_loss: 0.4335 - val_mse: 0.4262\n",
      "Epoch 297/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5012 - val_loss: 0.4450 - val_mse: 0.4377\n",
      "Epoch 298/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5011 - val_loss: 0.4426 - val_mse: 0.4352\n",
      "Epoch 299/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.4993 - val_loss: 0.4427 - val_mse: 0.4354\n",
      "Epoch 300/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5023 - mse: 0.4949\n",
      "Epoch 00300: saving model to Regression_Model/mle.linear-0300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4948 - val_loss: 0.4471 - val_mse: 0.4397\n",
      "Epoch 301/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4953 - val_loss: 0.4323 - val_mse: 0.4249\n",
      "Epoch 302/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4973 - val_loss: 0.4370 - val_mse: 0.4296\n",
      "Epoch 303/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5015 - val_loss: 0.4411 - val_mse: 0.4337\n",
      "Epoch 304/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5181 - mse: 0.5108 - val_loss: 0.4356 - val_mse: 0.4283\n",
      "Epoch 305/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4956 - val_loss: 0.4325 - val_mse: 0.4252\n",
      "Epoch 306/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5153 - mse: 0.5079 - val_loss: 0.4460 - val_mse: 0.4386\n",
      "Epoch 307/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4969 - val_loss: 0.4455 - val_mse: 0.4381\n",
      "Epoch 308/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5121 - mse: 0.5047 - val_loss: 0.4385 - val_mse: 0.4311\n",
      "Epoch 309/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5014 - val_loss: 0.4360 - val_mse: 0.4286\n",
      "Epoch 310/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.5001 - mse: 0.4927\n",
      "Epoch 00310: saving model to Regression_Model/mle.linear-0310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4977 - val_loss: 0.4292 - val_mse: 0.4219\n",
      "Epoch 311/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5018 - val_loss: 0.4416 - val_mse: 0.4342\n",
      "Epoch 312/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4957 - val_loss: 0.4494 - val_mse: 0.4420\n",
      "Epoch 313/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5017 - val_loss: 0.4338 - val_mse: 0.4264\n",
      "Epoch 314/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4980 - val_loss: 0.4424 - val_mse: 0.4350\n",
      "Epoch 315/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5015 - val_loss: 0.4311 - val_mse: 0.4237\n",
      "Epoch 316/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5050 - val_loss: 0.4421 - val_mse: 0.4347\n",
      "Epoch 317/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4930 - val_loss: 0.4430 - val_mse: 0.4356\n",
      "Epoch 318/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5005 - val_loss: 0.4411 - val_mse: 0.4337\n",
      "Epoch 319/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4970 - val_loss: 0.4376 - val_mse: 0.4302\n",
      "Epoch 320/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5069 - mse: 0.4995\n",
      "Epoch 00320: saving model to Regression_Model/mle.linear-0320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5011 - val_loss: 0.4419 - val_mse: 0.4345\n",
      "Epoch 321/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5027 - val_loss: 0.4390 - val_mse: 0.4316\n",
      "Epoch 322/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5015 - val_loss: 0.4475 - val_mse: 0.4400\n",
      "Epoch 323/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4975 - val_loss: 0.4409 - val_mse: 0.4335\n",
      "Epoch 324/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5010 - val_loss: 0.4345 - val_mse: 0.4271\n",
      "Epoch 325/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4963 - val_loss: 0.4664 - val_mse: 0.4590\n",
      "Epoch 326/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4930 - val_loss: 0.4321 - val_mse: 0.4246\n",
      "Epoch 327/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.4992 - val_loss: 0.4451 - val_mse: 0.4377\n",
      "Epoch 328/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4970 - val_loss: 0.4331 - val_mse: 0.4257\n",
      "Epoch 329/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4976 - val_loss: 0.4323 - val_mse: 0.4249\n",
      "Epoch 330/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5011 - mse: 0.4936\n",
      "Epoch 00330: saving model to Regression_Model/mle.linear-0330.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4997 - mse: 0.4923 - val_loss: 0.4291 - val_mse: 0.4217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.4990 - val_loss: 0.4311 - val_mse: 0.4236\n",
      "Epoch 332/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5048 - val_loss: 0.4540 - val_mse: 0.4466\n",
      "Epoch 333/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5109 - mse: 0.5034 - val_loss: 0.4417 - val_mse: 0.4342\n",
      "Epoch 334/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5079 - mse: 0.5004 - val_loss: 0.4383 - val_mse: 0.4309\n",
      "Epoch 335/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4934 - val_loss: 0.4351 - val_mse: 0.4277\n",
      "Epoch 336/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5019 - val_loss: 0.4422 - val_mse: 0.4347\n",
      "Epoch 337/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4994 - mse: 0.4919 - val_loss: 0.4365 - val_mse: 0.4291\n",
      "Epoch 338/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.4996 - val_loss: 0.4415 - val_mse: 0.4341\n",
      "Epoch 339/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.4989 - val_loss: 0.4309 - val_mse: 0.4234\n",
      "Epoch 340/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4995 - mse: 0.4921\n",
      "Epoch 00340: saving model to Regression_Model/mle.linear-0340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4979 - mse: 0.4904 - val_loss: 0.4321 - val_mse: 0.4247\n",
      "Epoch 341/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4970 - val_loss: 0.4376 - val_mse: 0.4302\n",
      "Epoch 342/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4931 - val_loss: 0.4341 - val_mse: 0.4266\n",
      "Epoch 343/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.4989 - val_loss: 0.4387 - val_mse: 0.4313\n",
      "Epoch 344/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.4984 - val_loss: 0.4375 - val_mse: 0.4301\n",
      "Epoch 345/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4938 - val_loss: 0.4340 - val_mse: 0.4265\n",
      "Epoch 346/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4969 - val_loss: 0.4325 - val_mse: 0.4250\n",
      "Epoch 347/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4931 - val_loss: 0.4341 - val_mse: 0.4267\n",
      "Epoch 348/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4998 - mse: 0.4923 - val_loss: 0.4449 - val_mse: 0.4374\n",
      "Epoch 349/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.4984 - val_loss: 0.4316 - val_mse: 0.4242\n",
      "Epoch 350/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5088 - mse: 0.5014\n",
      "Epoch 00350: saving model to Regression_Model/mle.linear-0350.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5017 - val_loss: 0.4382 - val_mse: 0.4308\n",
      "Epoch 351/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4928 - val_loss: 0.4532 - val_mse: 0.4458\n",
      "Epoch 352/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4931 - val_loss: 0.4356 - val_mse: 0.4282\n",
      "Epoch 353/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4949 - val_loss: 0.4511 - val_mse: 0.4436\n",
      "Epoch 354/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4941 - val_loss: 0.4388 - val_mse: 0.4313\n",
      "Epoch 355/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5028 - mse: 0.4953 - val_loss: 0.4327 - val_mse: 0.4252\n",
      "Epoch 356/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4974 - mse: 0.4900 - val_loss: 0.4305 - val_mse: 0.4230\n",
      "Epoch 357/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4937 - val_loss: 0.4353 - val_mse: 0.4279\n",
      "Epoch 358/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4935 - val_loss: 0.4343 - val_mse: 0.4268\n",
      "Epoch 359/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4968 - val_loss: 0.4432 - val_mse: 0.4357\n",
      "Epoch 360/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5001 - mse: 0.4926\n",
      "Epoch 00360: saving model to Regression_Model/mle.linear-0360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4933 - val_loss: 0.4293 - val_mse: 0.4218\n",
      "Epoch 361/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4946 - val_loss: 0.4427 - val_mse: 0.4353\n",
      "Epoch 362/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4978 - val_loss: 0.4432 - val_mse: 0.4357\n",
      "Epoch 363/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5047 - val_loss: 0.4354 - val_mse: 0.4279\n",
      "Epoch 364/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4949 - val_loss: 0.4328 - val_mse: 0.4253\n",
      "Epoch 365/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4917 - val_loss: 0.4388 - val_mse: 0.4313\n",
      "Epoch 366/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4962 - mse: 0.4887 - val_loss: 0.4370 - val_mse: 0.4295\n",
      "Epoch 367/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4980 - val_loss: 0.4313 - val_mse: 0.4238\n",
      "Epoch 368/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4970 - val_loss: 0.4291 - val_mse: 0.4216\n",
      "Epoch 369/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4979 - val_loss: 0.4300 - val_mse: 0.4225\n",
      "Epoch 370/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5127 - mse: 0.5052\n",
      "Epoch 00370: saving model to Regression_Model/mle.linear-0370.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5131 - mse: 0.5056 - val_loss: 0.4474 - val_mse: 0.4398\n",
      "Epoch 371/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4938 - val_loss: 0.4323 - val_mse: 0.4248\n",
      "Epoch 372/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4974 - mse: 0.4899 - val_loss: 0.4316 - val_mse: 0.4241\n",
      "Epoch 373/3000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5045 - mse: 0.4970 - val_loss: 0.4427 - val_mse: 0.4352\n",
      "Epoch 374/3000\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5015 - mse: 0.4940 - val_loss: 0.4353 - val_mse: 0.4278\n",
      "Epoch 375/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5042 - val_loss: 0.4401 - val_mse: 0.4325\n",
      "Epoch 376/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5035 - mse: 0.4959 - val_loss: 0.4324 - val_mse: 0.4249\n",
      "Epoch 377/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5095 - mse: 0.5020 - val_loss: 0.4343 - val_mse: 0.4268\n",
      "Epoch 378/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4977 - val_loss: 0.4348 - val_mse: 0.4272\n",
      "Epoch 379/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5049 - mse: 0.4974 - val_loss: 0.4339 - val_mse: 0.4264\n",
      "Epoch 380/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4990 - mse: 0.4915\n",
      "Epoch 00380: saving model to Regression_Model/mle.linear-0380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4939 - val_loss: 0.4314 - val_mse: 0.4239\n",
      "Epoch 381/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4939 - val_loss: 0.4296 - val_mse: 0.4221\n",
      "Epoch 382/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5061 - mse: 0.4985 - val_loss: 0.4365 - val_mse: 0.4289\n",
      "Epoch 383/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4974 - val_loss: 0.4295 - val_mse: 0.4220\n",
      "Epoch 384/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5057 - mse: 0.4981 - val_loss: 0.4346 - val_mse: 0.4270\n",
      "Epoch 385/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5040 - mse: 0.4965 - val_loss: 0.4539 - val_mse: 0.4464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4964 - val_loss: 0.4328 - val_mse: 0.4253\n",
      "Epoch 387/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5017 - mse: 0.4942 - val_loss: 0.4302 - val_mse: 0.4226\n",
      "Epoch 388/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5020 - mse: 0.4944 - val_loss: 0.4382 - val_mse: 0.4307\n",
      "Epoch 389/3000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4997 - mse: 0.4922 - val_loss: 0.4349 - val_mse: 0.4273\n",
      "Epoch 390/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4961 - mse: 0.4886\n",
      "Epoch 00390: saving model to Regression_Model/mle.linear-0390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4968 - mse: 0.4892 - val_loss: 0.4408 - val_mse: 0.4332\n",
      "Epoch 391/3000\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.5089 - mse: 0.5013 - val_loss: 0.4479 - val_mse: 0.4403\n",
      "Epoch 392/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4927 - val_loss: 0.4359 - val_mse: 0.4283\n",
      "Epoch 393/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4927 - val_loss: 0.4292 - val_mse: 0.4217\n",
      "Epoch 394/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5080 - mse: 0.5004 - val_loss: 0.4314 - val_mse: 0.4238\n",
      "Epoch 395/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.4984 - val_loss: 0.4328 - val_mse: 0.4252\n",
      "Epoch 396/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4967 - val_loss: 0.4325 - val_mse: 0.4249\n",
      "Epoch 397/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4988 - mse: 0.4912 - val_loss: 0.4295 - val_mse: 0.4219\n",
      "Epoch 398/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5031 - mse: 0.4955 - val_loss: 0.4307 - val_mse: 0.4231\n",
      "Epoch 399/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5090 - mse: 0.5014 - val_loss: 0.4396 - val_mse: 0.4320\n",
      "Epoch 400/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5042 - mse: 0.4966\n",
      "Epoch 00400: saving model to Regression_Model/mle.linear-0400.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4968 - val_loss: 0.4320 - val_mse: 0.4244\n",
      "Epoch 401/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5049 - mse: 0.4973 - val_loss: 0.4280 - val_mse: 0.4204\n",
      "Epoch 402/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4955 - mse: 0.4879 - val_loss: 0.4371 - val_mse: 0.4295\n",
      "Epoch 403/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5058 - mse: 0.4982 - val_loss: 0.4325 - val_mse: 0.4249\n",
      "Epoch 404/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5007 - val_loss: 0.4340 - val_mse: 0.4264\n",
      "Epoch 405/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5023 - mse: 0.4947 - val_loss: 0.4341 - val_mse: 0.4265\n",
      "Epoch 406/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5052 - mse: 0.4977 - val_loss: 0.4366 - val_mse: 0.4291\n",
      "Epoch 407/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5038 - mse: 0.4962 - val_loss: 0.4272 - val_mse: 0.4196\n",
      "Epoch 408/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4984 - mse: 0.4908 - val_loss: 0.4353 - val_mse: 0.4277\n",
      "Epoch 409/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5056 - mse: 0.4980 - val_loss: 0.4337 - val_mse: 0.4261\n",
      "Epoch 410/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5048 - mse: 0.4972\n",
      "Epoch 00410: saving model to Regression_Model/mle.linear-0410.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4968 - val_loss: 0.4331 - val_mse: 0.4255\n",
      "Epoch 411/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4953 - mse: 0.4877 - val_loss: 0.4376 - val_mse: 0.4300\n",
      "Epoch 412/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5007 - mse: 0.4931 - val_loss: 0.4336 - val_mse: 0.4260\n",
      "Epoch 413/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5051 - mse: 0.4975 - val_loss: 0.4317 - val_mse: 0.4241\n",
      "Epoch 414/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5023 - mse: 0.4946 - val_loss: 0.4494 - val_mse: 0.4418\n",
      "Epoch 415/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4932 - val_loss: 0.4268 - val_mse: 0.4192\n",
      "Epoch 416/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5027 - mse: 0.4951 - val_loss: 0.4376 - val_mse: 0.4300\n",
      "Epoch 417/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4978 - mse: 0.4902 - val_loss: 0.4351 - val_mse: 0.4275\n",
      "Epoch 418/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5048 - mse: 0.4972 - val_loss: 0.4519 - val_mse: 0.4443\n",
      "Epoch 419/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5000 - mse: 0.4924 - val_loss: 0.4262 - val_mse: 0.4186\n",
      "Epoch 420/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5033 - mse: 0.4956\n",
      "Epoch 00420: saving model to Regression_Model/mle.linear-0420.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5059 - mse: 0.4983 - val_loss: 0.4402 - val_mse: 0.4326\n",
      "Epoch 421/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5038 - mse: 0.4962 - val_loss: 0.4438 - val_mse: 0.4362\n",
      "Epoch 422/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5044 - mse: 0.4968 - val_loss: 0.4418 - val_mse: 0.4341\n",
      "Epoch 423/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5026 - mse: 0.4949 - val_loss: 0.4290 - val_mse: 0.4214\n",
      "Epoch 424/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5003 - mse: 0.4926 - val_loss: 0.4293 - val_mse: 0.4216\n",
      "Epoch 425/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5016 - mse: 0.4940 - val_loss: 0.4364 - val_mse: 0.4287\n",
      "Epoch 426/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5009 - mse: 0.4932 - val_loss: 0.4270 - val_mse: 0.4193\n",
      "Epoch 427/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5016 - mse: 0.4940 - val_loss: 0.4369 - val_mse: 0.4293\n",
      "Epoch 428/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4975 - mse: 0.4898 - val_loss: 0.4250 - val_mse: 0.4173\n",
      "Epoch 429/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4926 - mse: 0.4850 - val_loss: 0.4344 - val_mse: 0.4268\n",
      "Epoch 430/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5090 - mse: 0.5014\n",
      "Epoch 00430: saving model to Regression_Model/mle.linear-0430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5012 - val_loss: 0.4244 - val_mse: 0.4168\n",
      "Epoch 431/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5104 - mse: 0.5027 - val_loss: 0.4404 - val_mse: 0.4327\n",
      "Epoch 432/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5091 - mse: 0.5015 - val_loss: 0.4384 - val_mse: 0.4308\n",
      "Epoch 433/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4998 - mse: 0.4921 - val_loss: 0.4450 - val_mse: 0.4374\n",
      "Epoch 434/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5006 - val_loss: 0.4364 - val_mse: 0.4287\n",
      "Epoch 435/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5002 - mse: 0.4926 - val_loss: 0.4406 - val_mse: 0.4330\n",
      "Epoch 436/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5038 - mse: 0.4962 - val_loss: 0.4318 - val_mse: 0.4242\n",
      "Epoch 437/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5022 - mse: 0.4946 - val_loss: 0.4323 - val_mse: 0.4247\n",
      "Epoch 438/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5002 - mse: 0.4925 - val_loss: 0.4292 - val_mse: 0.4215\n",
      "Epoch 439/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5000 - mse: 0.4923 - val_loss: 0.4321 - val_mse: 0.4244\n",
      "Epoch 440/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4907 - mse: 0.4831\n",
      "Epoch 00440: saving model to Regression_Model/mle.linear-0440.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4834 - val_loss: 0.4295 - val_mse: 0.4218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4921 - val_loss: 0.4297 - val_mse: 0.4220\n",
      "Epoch 442/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4965 - mse: 0.4889 - val_loss: 0.4287 - val_mse: 0.4211\n",
      "Epoch 443/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4958 - mse: 0.4882 - val_loss: 0.4327 - val_mse: 0.4250\n",
      "Epoch 444/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5004 - mse: 0.4927 - val_loss: 0.4355 - val_mse: 0.4278\n",
      "Epoch 445/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4958 - mse: 0.4882 - val_loss: 0.4284 - val_mse: 0.4207\n",
      "Epoch 446/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5073 - mse: 0.4996 - val_loss: 0.4434 - val_mse: 0.4357\n",
      "Epoch 447/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5024 - mse: 0.4948 - val_loss: 0.4289 - val_mse: 0.4212\n",
      "Epoch 448/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5030 - mse: 0.4953 - val_loss: 0.4316 - val_mse: 0.4239\n",
      "Epoch 449/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4982 - mse: 0.4905 - val_loss: 0.4438 - val_mse: 0.4362\n",
      "Epoch 450/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5016 - mse: 0.4940\n",
      "Epoch 00450: saving model to Regression_Model/mle.linear-0450.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4949 - val_loss: 0.4453 - val_mse: 0.4377\n",
      "Epoch 451/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5028 - mse: 0.4951 - val_loss: 0.4386 - val_mse: 0.4309\n",
      "Epoch 452/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5053 - mse: 0.4976 - val_loss: 0.4302 - val_mse: 0.4225\n",
      "Epoch 453/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4988 - mse: 0.4911 - val_loss: 0.4225 - val_mse: 0.4148\n",
      "Epoch 454/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4988 - mse: 0.4911 - val_loss: 0.4419 - val_mse: 0.4342\n",
      "Epoch 455/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4885 - mse: 0.4808 - val_loss: 0.4359 - val_mse: 0.4282\n",
      "Epoch 456/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4942 - mse: 0.4865 - val_loss: 0.4352 - val_mse: 0.4275\n",
      "Epoch 457/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5036 - mse: 0.4959 - val_loss: 0.4303 - val_mse: 0.4226\n",
      "Epoch 458/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4907 - mse: 0.4830 - val_loss: 0.4330 - val_mse: 0.4253\n",
      "Epoch 459/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5006 - mse: 0.4929 - val_loss: 0.4351 - val_mse: 0.4274\n",
      "Epoch 460/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.4944 - mse: 0.4867\n",
      "Epoch 00460: saving model to Regression_Model/mle.linear-0460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4950 - mse: 0.4873 - val_loss: 0.4306 - val_mse: 0.4229\n",
      "Epoch 461/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4961 - mse: 0.4884 - val_loss: 0.4259 - val_mse: 0.4182\n",
      "Epoch 462/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5056 - mse: 0.4979 - val_loss: 0.4370 - val_mse: 0.4293\n",
      "Epoch 463/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4955 - val_loss: 0.4317 - val_mse: 0.4240\n",
      "Epoch 464/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4981 - mse: 0.4904 - val_loss: 0.4259 - val_mse: 0.4182\n",
      "Epoch 465/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4915 - val_loss: 0.4286 - val_mse: 0.4209\n",
      "Epoch 466/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4909 - val_loss: 0.4278 - val_mse: 0.4201\n",
      "Epoch 467/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4955 - mse: 0.4878 - val_loss: 0.4328 - val_mse: 0.4251\n",
      "Epoch 468/3000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4998 - mse: 0.4921 - val_loss: 0.4309 - val_mse: 0.4232\n",
      "Epoch 469/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4932 - mse: 0.4854 - val_loss: 0.4256 - val_mse: 0.4179\n",
      "Epoch 470/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4968 - mse: 0.4891\n",
      "Epoch 00470: saving model to Regression_Model/mle.linear-0470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4953 - mse: 0.4876 - val_loss: 0.4265 - val_mse: 0.4188\n",
      "Epoch 471/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4965 - mse: 0.4888 - val_loss: 0.4184 - val_mse: 0.4107\n",
      "Epoch 472/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4934 - mse: 0.4857 - val_loss: 0.4277 - val_mse: 0.4200\n",
      "Epoch 473/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5023 - mse: 0.4946 - val_loss: 0.4299 - val_mse: 0.4221\n",
      "Epoch 474/3000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4987 - mse: 0.4910 - val_loss: 0.4402 - val_mse: 0.4325\n",
      "Epoch 475/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4983 - mse: 0.4905 - val_loss: 0.4254 - val_mse: 0.4177\n",
      "Epoch 476/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4972 - mse: 0.4895 - val_loss: 0.4289 - val_mse: 0.4212\n",
      "Epoch 477/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5085 - mse: 0.5008 - val_loss: 0.4476 - val_mse: 0.4399\n",
      "Epoch 478/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4997 - mse: 0.4920 - val_loss: 0.4280 - val_mse: 0.4203\n",
      "Epoch 479/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5007 - mse: 0.4930 - val_loss: 0.4379 - val_mse: 0.4302\n",
      "Epoch 480/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4997 - mse: 0.4920\n",
      "Epoch 00480: saving model to Regression_Model/mle.linear-0480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4915 - val_loss: 0.4290 - val_mse: 0.4213\n",
      "Epoch 481/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4911 - mse: 0.4833 - val_loss: 0.4363 - val_mse: 0.4286\n",
      "Epoch 482/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5007 - mse: 0.4930 - val_loss: 0.4345 - val_mse: 0.4268\n",
      "Epoch 483/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5042 - mse: 0.4965 - val_loss: 0.4244 - val_mse: 0.4166\n",
      "Epoch 484/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4965 - mse: 0.4887 - val_loss: 0.4334 - val_mse: 0.4257\n",
      "Epoch 485/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4907 - mse: 0.4830 - val_loss: 0.4236 - val_mse: 0.4159\n",
      "Epoch 486/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4909 - mse: 0.4832 - val_loss: 0.4288 - val_mse: 0.4210\n",
      "Epoch 487/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4962 - val_loss: 0.4370 - val_mse: 0.4293\n",
      "Epoch 488/3000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4968 - mse: 0.4890 - val_loss: 0.4265 - val_mse: 0.4188\n",
      "Epoch 489/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4963 - val_loss: 0.4299 - val_mse: 0.4221\n",
      "Epoch 490/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4924 - mse: 0.4847\n",
      "Epoch 00490: saving model to Regression_Model/mle.linear-0490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4929 - mse: 0.4851 - val_loss: 0.4341 - val_mse: 0.4264\n",
      "Epoch 491/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4948 - mse: 0.4870 - val_loss: 0.4291 - val_mse: 0.4213\n",
      "Epoch 492/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4966 - val_loss: 0.4329 - val_mse: 0.4251\n",
      "Epoch 493/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4983 - mse: 0.4905 - val_loss: 0.4326 - val_mse: 0.4248\n",
      "Epoch 494/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4979 - mse: 0.4902 - val_loss: 0.4260 - val_mse: 0.4182\n",
      "Epoch 495/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4939 - mse: 0.4862 - val_loss: 0.4287 - val_mse: 0.4209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4944 - val_loss: 0.4273 - val_mse: 0.4196\n",
      "Epoch 497/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4860 - val_loss: 0.4261 - val_mse: 0.4183\n",
      "Epoch 498/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4913 - val_loss: 0.4348 - val_mse: 0.4271\n",
      "Epoch 499/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5001 - mse: 0.4924 - val_loss: 0.4452 - val_mse: 0.4375\n",
      "Epoch 500/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4996 - mse: 0.4919\n",
      "Epoch 00500: saving model to Regression_Model/mle.linear-0500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4909 - val_loss: 0.4418 - val_mse: 0.4341\n",
      "Epoch 501/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4971 - val_loss: 0.4236 - val_mse: 0.4158\n",
      "Epoch 502/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4854 - val_loss: 0.4360 - val_mse: 0.4283\n",
      "Epoch 503/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4964 - mse: 0.4887 - val_loss: 0.4485 - val_mse: 0.4408\n",
      "Epoch 504/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4934 - val_loss: 0.4334 - val_mse: 0.4256\n",
      "Epoch 505/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4924 - mse: 0.4847 - val_loss: 0.4304 - val_mse: 0.4226\n",
      "Epoch 506/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4910 - val_loss: 0.4333 - val_mse: 0.4256\n",
      "Epoch 507/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4903 - mse: 0.4826 - val_loss: 0.4319 - val_mse: 0.4242\n",
      "Epoch 508/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4883 - val_loss: 0.4319 - val_mse: 0.4242\n",
      "Epoch 509/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4957 - mse: 0.4879 - val_loss: 0.4354 - val_mse: 0.4276\n",
      "Epoch 510/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4871 - mse: 0.4794\n",
      "Epoch 00510: saving model to Regression_Model/mle.linear-0510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4903 - mse: 0.4825 - val_loss: 0.4302 - val_mse: 0.4225\n",
      "Epoch 511/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4944 - mse: 0.4866 - val_loss: 0.4191 - val_mse: 0.4113\n",
      "Epoch 512/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4960 - mse: 0.4882 - val_loss: 0.4308 - val_mse: 0.4230\n",
      "Epoch 513/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4842 - val_loss: 0.4268 - val_mse: 0.4190\n",
      "Epoch 514/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4910 - val_loss: 0.4301 - val_mse: 0.4223\n",
      "Epoch 515/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4998 - mse: 0.4921 - val_loss: 0.4266 - val_mse: 0.4188\n",
      "Epoch 516/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4949 - val_loss: 0.4412 - val_mse: 0.4335\n",
      "Epoch 517/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4800 - val_loss: 0.4236 - val_mse: 0.4159\n",
      "Epoch 518/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4944 - mse: 0.4866 - val_loss: 0.4258 - val_mse: 0.4181\n",
      "Epoch 519/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4942 - mse: 0.4864 - val_loss: 0.4373 - val_mse: 0.4295\n",
      "Epoch 520/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4898 - mse: 0.4820\n",
      "Epoch 00520: saving model to Regression_Model/mle.linear-0520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4904 - mse: 0.4826 - val_loss: 0.4304 - val_mse: 0.4226\n",
      "Epoch 521/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4899 - val_loss: 0.4296 - val_mse: 0.4219\n",
      "Epoch 522/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4829 - val_loss: 0.4215 - val_mse: 0.4137\n",
      "Epoch 523/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4937 - mse: 0.4859 - val_loss: 0.4209 - val_mse: 0.4132\n",
      "Epoch 524/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4951 - mse: 0.4873 - val_loss: 0.4285 - val_mse: 0.4207\n",
      "Epoch 525/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4917 - mse: 0.4839 - val_loss: 0.4294 - val_mse: 0.4216\n",
      "Epoch 526/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4908 - mse: 0.4830 - val_loss: 0.4316 - val_mse: 0.4238\n",
      "Epoch 527/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4954 - val_loss: 0.4373 - val_mse: 0.4295\n",
      "Epoch 528/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4918 - mse: 0.4841 - val_loss: 0.4355 - val_mse: 0.4277\n",
      "Epoch 529/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4978 - mse: 0.4900 - val_loss: 0.4219 - val_mse: 0.4141\n",
      "Epoch 530/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4951 - mse: 0.4873\n",
      "Epoch 00530: saving model to Regression_Model/mle.linear-0530.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4950 - mse: 0.4872 - val_loss: 0.4309 - val_mse: 0.4231\n",
      "Epoch 531/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4908 - mse: 0.4830 - val_loss: 0.4393 - val_mse: 0.4316\n",
      "Epoch 532/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4967 - val_loss: 0.4373 - val_mse: 0.4295\n",
      "Epoch 533/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4956 - mse: 0.4878 - val_loss: 0.4276 - val_mse: 0.4198\n",
      "Epoch 534/3000\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4958 - mse: 0.4880 - val_loss: 0.4291 - val_mse: 0.4213\n",
      "Epoch 535/3000\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.4981 - mse: 0.4903 - val_loss: 0.4209 - val_mse: 0.4132\n",
      "Epoch 536/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4960 - mse: 0.4883 - val_loss: 0.4255 - val_mse: 0.4177\n",
      "Epoch 537/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4972 - mse: 0.4895 - val_loss: 0.4224 - val_mse: 0.4147\n",
      "Epoch 538/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5030 - val_loss: 0.4265 - val_mse: 0.4187\n",
      "Epoch 539/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4938 - val_loss: 0.4328 - val_mse: 0.4250\n",
      "Epoch 540/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5029 - mse: 0.4951\n",
      "Epoch 00540: saving model to Regression_Model/mle.linear-0540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4941 - val_loss: 0.4228 - val_mse: 0.4150\n",
      "Epoch 541/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4981 - mse: 0.4903 - val_loss: 0.4294 - val_mse: 0.4216\n",
      "Epoch 542/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4963 - mse: 0.4885 - val_loss: 0.4350 - val_mse: 0.4272\n",
      "Epoch 543/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4972 - mse: 0.4894 - val_loss: 0.4271 - val_mse: 0.4193\n",
      "Epoch 544/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4909 - val_loss: 0.4307 - val_mse: 0.4229\n",
      "Epoch 545/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4855 - val_loss: 0.4191 - val_mse: 0.4113\n",
      "Epoch 546/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4950 - mse: 0.4872 - val_loss: 0.4184 - val_mse: 0.4106\n",
      "Epoch 547/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4937 - mse: 0.4859 - val_loss: 0.4188 - val_mse: 0.4110\n",
      "Epoch 548/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4934 - mse: 0.4856 - val_loss: 0.4267 - val_mse: 0.4189\n",
      "Epoch 549/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4932 - val_loss: 0.4248 - val_mse: 0.4170\n",
      "Epoch 550/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5027 - mse: 0.4949\n",
      "Epoch 00550: saving model to Regression_Model/mle.linear-0550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4953 - val_loss: 0.4475 - val_mse: 0.4397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4978 - mse: 0.4900 - val_loss: 0.4295 - val_mse: 0.4217\n",
      "Epoch 552/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4929 - mse: 0.4851 - val_loss: 0.4327 - val_mse: 0.4249\n",
      "Epoch 553/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4945 - mse: 0.4867 - val_loss: 0.4246 - val_mse: 0.4167\n",
      "Epoch 554/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4973 - val_loss: 0.4308 - val_mse: 0.4230\n",
      "Epoch 555/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4909 - mse: 0.4831 - val_loss: 0.4274 - val_mse: 0.4196\n",
      "Epoch 556/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4957 - mse: 0.4879 - val_loss: 0.4226 - val_mse: 0.4148\n",
      "Epoch 557/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4962 - mse: 0.4884 - val_loss: 0.4247 - val_mse: 0.4169\n",
      "Epoch 558/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4953 - mse: 0.4875 - val_loss: 0.4337 - val_mse: 0.4259\n",
      "Epoch 559/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4980 - mse: 0.4902 - val_loss: 0.4205 - val_mse: 0.4127\n",
      "Epoch 560/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4924 - mse: 0.4846\n",
      "Epoch 00560: saving model to Regression_Model/mle.linear-0560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4914 - mse: 0.4836 - val_loss: 0.4273 - val_mse: 0.4195\n",
      "Epoch 561/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4923 - mse: 0.4845 - val_loss: 0.4435 - val_mse: 0.4357\n",
      "Epoch 562/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4935 - mse: 0.4857 - val_loss: 0.4209 - val_mse: 0.4131\n",
      "Epoch 563/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4903 - mse: 0.4824 - val_loss: 0.4198 - val_mse: 0.4120\n",
      "Epoch 564/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4838 - val_loss: 0.4306 - val_mse: 0.4228\n",
      "Epoch 565/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4994 - mse: 0.4916 - val_loss: 0.4303 - val_mse: 0.4225\n",
      "Epoch 566/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4883 - val_loss: 0.4220 - val_mse: 0.4142\n",
      "Epoch 567/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4941 - mse: 0.4863 - val_loss: 0.4276 - val_mse: 0.4198\n",
      "Epoch 568/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4906 - val_loss: 0.4304 - val_mse: 0.4226\n",
      "Epoch 569/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4958 - mse: 0.4880 - val_loss: 0.4315 - val_mse: 0.4237\n",
      "Epoch 570/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4960 - mse: 0.4882\n",
      "Epoch 00570: saving model to Regression_Model/mle.linear-0570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4976 - mse: 0.4898 - val_loss: 0.4301 - val_mse: 0.4223\n",
      "Epoch 571/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4971 - mse: 0.4893 - val_loss: 0.4289 - val_mse: 0.4211\n",
      "Epoch 572/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4970 - mse: 0.4892 - val_loss: 0.4243 - val_mse: 0.4164\n",
      "Epoch 573/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4965 - mse: 0.4886 - val_loss: 0.4267 - val_mse: 0.4189\n",
      "Epoch 574/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4900 - mse: 0.4821 - val_loss: 0.4226 - val_mse: 0.4148\n",
      "Epoch 575/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4960 - val_loss: 0.4288 - val_mse: 0.4210\n",
      "Epoch 576/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4838 - val_loss: 0.4244 - val_mse: 0.4166\n",
      "Epoch 577/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4818 - val_loss: 0.4182 - val_mse: 0.4104\n",
      "Epoch 578/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4960 - mse: 0.4882 - val_loss: 0.4319 - val_mse: 0.4241\n",
      "Epoch 579/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4787 - val_loss: 0.4254 - val_mse: 0.4176\n",
      "Epoch 580/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4836 - mse: 0.4757\n",
      "Epoch 00580: saving model to Regression_Model/mle.linear-0580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4758 - val_loss: 0.4327 - val_mse: 0.4249\n",
      "Epoch 581/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4956 - mse: 0.4878 - val_loss: 0.4317 - val_mse: 0.4239\n",
      "Epoch 582/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4959 - mse: 0.4881 - val_loss: 0.4239 - val_mse: 0.4160\n",
      "Epoch 583/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4944 - mse: 0.4866 - val_loss: 0.4181 - val_mse: 0.4103\n",
      "Epoch 584/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4910 - mse: 0.4832 - val_loss: 0.4285 - val_mse: 0.4207\n",
      "Epoch 585/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4957 - mse: 0.4879 - val_loss: 0.4318 - val_mse: 0.4240\n",
      "Epoch 586/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4831 - val_loss: 0.4305 - val_mse: 0.4227\n",
      "Epoch 587/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4967 - mse: 0.4888 - val_loss: 0.4272 - val_mse: 0.4193\n",
      "Epoch 588/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4906 - mse: 0.4828 - val_loss: 0.4174 - val_mse: 0.4096\n",
      "Epoch 589/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4982 - mse: 0.4903 - val_loss: 0.4210 - val_mse: 0.4132\n",
      "Epoch 590/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4997 - mse: 0.4919\n",
      "Epoch 00590: saving model to Regression_Model/mle.linear-0590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4994 - mse: 0.4915 - val_loss: 0.4197 - val_mse: 0.4119\n",
      "Epoch 591/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4763 - val_loss: 0.4274 - val_mse: 0.4195\n",
      "Epoch 592/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4898 - mse: 0.4820 - val_loss: 0.4269 - val_mse: 0.4190\n",
      "Epoch 593/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4811 - val_loss: 0.4216 - val_mse: 0.4138\n",
      "Epoch 594/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4796 - val_loss: 0.4279 - val_mse: 0.4200\n",
      "Epoch 595/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4926 - mse: 0.4847 - val_loss: 0.4328 - val_mse: 0.4250\n",
      "Epoch 596/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4798 - val_loss: 0.4391 - val_mse: 0.4312\n",
      "Epoch 597/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4915 - mse: 0.4836 - val_loss: 0.4286 - val_mse: 0.4207\n",
      "Epoch 598/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4785 - val_loss: 0.4302 - val_mse: 0.4224\n",
      "Epoch 599/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4937 - mse: 0.4859 - val_loss: 0.4209 - val_mse: 0.4131\n",
      "Epoch 600/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4972 - mse: 0.4894\n",
      "Epoch 00600: saving model to Regression_Model/mle.linear-0600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4967 - mse: 0.4889 - val_loss: 0.4239 - val_mse: 0.4160\n",
      "Epoch 601/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4959 - mse: 0.4881 - val_loss: 0.4222 - val_mse: 0.4144\n",
      "Epoch 602/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4930 - mse: 0.4852 - val_loss: 0.4238 - val_mse: 0.4159\n",
      "Epoch 603/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4939 - val_loss: 0.4252 - val_mse: 0.4174\n",
      "Epoch 604/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4893 - mse: 0.4814 - val_loss: 0.4284 - val_mse: 0.4205\n",
      "Epoch 605/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4810 - val_loss: 0.4319 - val_mse: 0.4240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4928 - mse: 0.4850 - val_loss: 0.4316 - val_mse: 0.4238\n",
      "Epoch 607/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4815 - val_loss: 0.4192 - val_mse: 0.4114\n",
      "Epoch 608/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4839 - val_loss: 0.4202 - val_mse: 0.4124\n",
      "Epoch 609/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4927 - val_loss: 0.4222 - val_mse: 0.4143\n",
      "Epoch 610/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4930 - mse: 0.4852\n",
      "Epoch 00610: saving model to Regression_Model/mle.linear-0610.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4855 - val_loss: 0.4237 - val_mse: 0.4159\n",
      "Epoch 611/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4810 - val_loss: 0.4268 - val_mse: 0.4189\n",
      "Epoch 612/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4861 - mse: 0.4783 - val_loss: 0.4316 - val_mse: 0.4237\n",
      "Epoch 613/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4860 - val_loss: 0.4193 - val_mse: 0.4115\n",
      "Epoch 614/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4971 - mse: 0.4893 - val_loss: 0.4304 - val_mse: 0.4226\n",
      "Epoch 615/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4928 - mse: 0.4849 - val_loss: 0.4231 - val_mse: 0.4153\n",
      "Epoch 616/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4928 - mse: 0.4849 - val_loss: 0.4194 - val_mse: 0.4115\n",
      "Epoch 617/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4950 - mse: 0.4871 - val_loss: 0.4192 - val_mse: 0.4114\n",
      "Epoch 618/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4930 - mse: 0.4851 - val_loss: 0.4211 - val_mse: 0.4133\n",
      "Epoch 619/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4937 - mse: 0.4859 - val_loss: 0.4309 - val_mse: 0.4231\n",
      "Epoch 620/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5027 - mse: 0.4948\n",
      "Epoch 00620: saving model to Regression_Model/mle.linear-0620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4933 - val_loss: 0.4172 - val_mse: 0.4094\n",
      "Epoch 621/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4942 - mse: 0.4864 - val_loss: 0.4266 - val_mse: 0.4187\n",
      "Epoch 622/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4831 - val_loss: 0.4172 - val_mse: 0.4094\n",
      "Epoch 623/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4853 - val_loss: 0.4191 - val_mse: 0.4112\n",
      "Epoch 624/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4920 - val_loss: 0.4247 - val_mse: 0.4168\n",
      "Epoch 625/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4901 - mse: 0.4822 - val_loss: 0.4187 - val_mse: 0.4108\n",
      "Epoch 626/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4945 - mse: 0.4866 - val_loss: 0.4227 - val_mse: 0.4148\n",
      "Epoch 627/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4934 - mse: 0.4855 - val_loss: 0.4234 - val_mse: 0.4155\n",
      "Epoch 628/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4920 - mse: 0.4841 - val_loss: 0.4252 - val_mse: 0.4173\n",
      "Epoch 629/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4974 - mse: 0.4895 - val_loss: 0.4367 - val_mse: 0.4289\n",
      "Epoch 630/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4957 - mse: 0.4878\n",
      "Epoch 00630: saving model to Regression_Model/mle.linear-0630.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4952 - mse: 0.4873 - val_loss: 0.4419 - val_mse: 0.4340\n",
      "Epoch 631/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4973 - mse: 0.4894 - val_loss: 0.4187 - val_mse: 0.4108\n",
      "Epoch 632/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4927 - val_loss: 0.4234 - val_mse: 0.4155\n",
      "Epoch 633/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4801 - val_loss: 0.4302 - val_mse: 0.4223\n",
      "Epoch 634/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4817 - val_loss: 0.4182 - val_mse: 0.4103\n",
      "Epoch 635/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4947 - val_loss: 0.4257 - val_mse: 0.4178\n",
      "Epoch 636/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4964 - mse: 0.4885 - val_loss: 0.4269 - val_mse: 0.4191\n",
      "Epoch 637/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4897 - mse: 0.4818 - val_loss: 0.4271 - val_mse: 0.4192\n",
      "Epoch 638/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4828 - val_loss: 0.4163 - val_mse: 0.4085\n",
      "Epoch 639/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4816 - val_loss: 0.4243 - val_mse: 0.4164\n",
      "Epoch 640/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5012 - mse: 0.4933\n",
      "Epoch 00640: saving model to Regression_Model/mle.linear-0640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4936 - val_loss: 0.4278 - val_mse: 0.4199\n",
      "Epoch 641/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4786 - val_loss: 0.4277 - val_mse: 0.4198\n",
      "Epoch 642/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4840 - val_loss: 0.4220 - val_mse: 0.4141\n",
      "Epoch 643/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4736 - val_loss: 0.4156 - val_mse: 0.4077\n",
      "Epoch 644/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4860 - val_loss: 0.4239 - val_mse: 0.4160\n",
      "Epoch 645/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4747 - val_loss: 0.4233 - val_mse: 0.4155\n",
      "Epoch 646/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4976 - mse: 0.4897 - val_loss: 0.4217 - val_mse: 0.4139\n",
      "Epoch 647/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4929 - val_loss: 0.4330 - val_mse: 0.4251\n",
      "Epoch 648/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4758 - val_loss: 0.4232 - val_mse: 0.4153\n",
      "Epoch 649/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4994 - mse: 0.4915 - val_loss: 0.4207 - val_mse: 0.4128\n",
      "Epoch 650/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4874 - mse: 0.4795\n",
      "Epoch 00650: saving model to Regression_Model/mle.linear-0650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4885 - mse: 0.4806 - val_loss: 0.4188 - val_mse: 0.4109\n",
      "Epoch 651/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4844 - mse: 0.4765 - val_loss: 0.4181 - val_mse: 0.4102\n",
      "Epoch 652/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4796 - val_loss: 0.4263 - val_mse: 0.4184\n",
      "Epoch 653/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4940 - mse: 0.4861 - val_loss: 0.4175 - val_mse: 0.4096\n",
      "Epoch 654/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4837 - val_loss: 0.4325 - val_mse: 0.4246\n",
      "Epoch 655/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4905 - val_loss: 0.4205 - val_mse: 0.4126\n",
      "Epoch 656/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4939 - mse: 0.4860 - val_loss: 0.4182 - val_mse: 0.4103\n",
      "Epoch 657/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4820 - val_loss: 0.4264 - val_mse: 0.4185\n",
      "Epoch 658/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4224 - val_mse: 0.4145\n",
      "Epoch 659/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4885 - mse: 0.4806 - val_loss: 0.4277 - val_mse: 0.4198\n",
      "Epoch 660/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4861 - mse: 0.4782\n",
      "Epoch 00660: saving model to Regression_Model/mle.linear-0660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4225 - val_mse: 0.4146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4814 - val_loss: 0.4201 - val_mse: 0.4123\n",
      "Epoch 662/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4944 - mse: 0.4865 - val_loss: 0.4249 - val_mse: 0.4170\n",
      "Epoch 663/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4840 - val_loss: 0.4203 - val_mse: 0.4124\n",
      "Epoch 664/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4949 - mse: 0.4870 - val_loss: 0.4185 - val_mse: 0.4106\n",
      "Epoch 665/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4883 - mse: 0.4805 - val_loss: 0.4171 - val_mse: 0.4092\n",
      "Epoch 666/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4999 - mse: 0.4920 - val_loss: 0.4254 - val_mse: 0.4175\n",
      "Epoch 667/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4861 - mse: 0.4782 - val_loss: 0.4274 - val_mse: 0.4195\n",
      "Epoch 668/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4904 - mse: 0.4825 - val_loss: 0.4253 - val_mse: 0.4174\n",
      "Epoch 669/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4921 - mse: 0.4842 - val_loss: 0.4291 - val_mse: 0.4212\n",
      "Epoch 670/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4948 - mse: 0.4869\n",
      "Epoch 00670: saving model to Regression_Model/mle.linear-0670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4941 - mse: 0.4862 - val_loss: 0.4373 - val_mse: 0.4294\n",
      "Epoch 671/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4982 - mse: 0.4903 - val_loss: 0.4307 - val_mse: 0.4228\n",
      "Epoch 672/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4823 - val_loss: 0.4181 - val_mse: 0.4102\n",
      "Epoch 673/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4789 - val_loss: 0.4274 - val_mse: 0.4196\n",
      "Epoch 674/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4816 - val_loss: 0.4185 - val_mse: 0.4106\n",
      "Epoch 675/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4887 - mse: 0.4808 - val_loss: 0.4260 - val_mse: 0.4182\n",
      "Epoch 676/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4859 - mse: 0.4780 - val_loss: 0.4155 - val_mse: 0.4076\n",
      "Epoch 677/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4930 - mse: 0.4851 - val_loss: 0.4171 - val_mse: 0.4092\n",
      "Epoch 678/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4821 - val_loss: 0.4286 - val_mse: 0.4207\n",
      "Epoch 679/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4934 - mse: 0.4855 - val_loss: 0.4254 - val_mse: 0.4175\n",
      "Epoch 680/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4977 - mse: 0.4898\n",
      "Epoch 00680: saving model to Regression_Model/mle.linear-0680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4983 - mse: 0.4904 - val_loss: 0.4175 - val_mse: 0.4096\n",
      "Epoch 681/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4929 - mse: 0.4850 - val_loss: 0.4193 - val_mse: 0.4114\n",
      "Epoch 682/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4251 - val_mse: 0.4172\n",
      "Epoch 683/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4923 - mse: 0.4844 - val_loss: 0.4232 - val_mse: 0.4153\n",
      "Epoch 684/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4815 - val_loss: 0.4201 - val_mse: 0.4122\n",
      "Epoch 685/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4870 - mse: 0.4791 - val_loss: 0.4162 - val_mse: 0.4083\n",
      "Epoch 686/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4798 - val_loss: 0.4179 - val_mse: 0.4100\n",
      "Epoch 687/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4770 - val_loss: 0.4296 - val_mse: 0.4217\n",
      "Epoch 688/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4883 - mse: 0.4804 - val_loss: 0.4205 - val_mse: 0.4126\n",
      "Epoch 689/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4934 - mse: 0.4855 - val_loss: 0.4167 - val_mse: 0.4088\n",
      "Epoch 690/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4915 - mse: 0.4836\n",
      "Epoch 00690: saving model to Regression_Model/mle.linear-0690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4911 - mse: 0.4832 - val_loss: 0.4325 - val_mse: 0.4246\n",
      "Epoch 691/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4837 - val_loss: 0.4230 - val_mse: 0.4152\n",
      "Epoch 692/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4928 - mse: 0.4849 - val_loss: 0.4255 - val_mse: 0.4176\n",
      "Epoch 693/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4913 - mse: 0.4835 - val_loss: 0.4373 - val_mse: 0.4294\n",
      "Epoch 694/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4904 - mse: 0.4825 - val_loss: 0.4222 - val_mse: 0.4143\n",
      "Epoch 695/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4809 - val_loss: 0.4222 - val_mse: 0.4144\n",
      "Epoch 696/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4762 - val_loss: 0.4142 - val_mse: 0.4063\n",
      "Epoch 697/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4787 - val_loss: 0.4154 - val_mse: 0.4075\n",
      "Epoch 698/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4955 - mse: 0.4876 - val_loss: 0.4214 - val_mse: 0.4135\n",
      "Epoch 699/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4907 - mse: 0.4828 - val_loss: 0.4237 - val_mse: 0.4158\n",
      "Epoch 700/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4837 - mse: 0.4758\n",
      "Epoch 00700: saving model to Regression_Model/mle.linear-0700.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4763 - val_loss: 0.4257 - val_mse: 0.4178\n",
      "Epoch 701/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4904 - mse: 0.4825 - val_loss: 0.4231 - val_mse: 0.4152\n",
      "Epoch 702/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4903 - mse: 0.4824 - val_loss: 0.4254 - val_mse: 0.4175\n",
      "Epoch 703/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4931 - mse: 0.4852 - val_loss: 0.4187 - val_mse: 0.4108\n",
      "Epoch 704/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4908 - mse: 0.4829 - val_loss: 0.4335 - val_mse: 0.4256\n",
      "Epoch 705/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4914 - mse: 0.4835 - val_loss: 0.4193 - val_mse: 0.4114\n",
      "Epoch 706/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4839 - val_loss: 0.4208 - val_mse: 0.4129\n",
      "Epoch 707/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4766 - val_loss: 0.4266 - val_mse: 0.4187\n",
      "Epoch 708/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4839 - val_loss: 0.4237 - val_mse: 0.4158\n",
      "Epoch 709/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4259 - val_mse: 0.4180\n",
      "Epoch 710/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4862 - mse: 0.4783\n",
      "Epoch 00710: saving model to Regression_Model/mle.linear-0710.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4152 - val_mse: 0.4073\n",
      "Epoch 711/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4852 - mse: 0.4773 - val_loss: 0.4246 - val_mse: 0.4167\n",
      "Epoch 712/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4794 - val_loss: 0.4245 - val_mse: 0.4166\n",
      "Epoch 713/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4893 - mse: 0.4814 - val_loss: 0.4161 - val_mse: 0.4082\n",
      "Epoch 714/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4784 - val_loss: 0.4207 - val_mse: 0.4128\n",
      "Epoch 715/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4809 - val_loss: 0.4180 - val_mse: 0.4101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4848 - mse: 0.4769 - val_loss: 0.4311 - val_mse: 0.4232\n",
      "Epoch 717/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4942 - mse: 0.4863 - val_loss: 0.4267 - val_mse: 0.4188\n",
      "Epoch 718/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4796 - val_loss: 0.4151 - val_mse: 0.4072\n",
      "Epoch 719/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4869 - mse: 0.4790 - val_loss: 0.4327 - val_mse: 0.4248\n",
      "Epoch 720/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4803 - mse: 0.4724\n",
      "Epoch 00720: saving model to Regression_Model/mle.linear-0720.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4731 - val_loss: 0.4207 - val_mse: 0.4128\n",
      "Epoch 721/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4817 - val_loss: 0.4267 - val_mse: 0.4188\n",
      "Epoch 722/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4831 - val_loss: 0.4192 - val_mse: 0.4113\n",
      "Epoch 723/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4803 - val_loss: 0.4185 - val_mse: 0.4106\n",
      "Epoch 724/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4908 - mse: 0.4829 - val_loss: 0.4220 - val_mse: 0.4141\n",
      "Epoch 725/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4939 - mse: 0.4860 - val_loss: 0.4250 - val_mse: 0.4171\n",
      "Epoch 726/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4959 - mse: 0.4880 - val_loss: 0.4204 - val_mse: 0.4125\n",
      "Epoch 727/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4951 - mse: 0.4872 - val_loss: 0.4158 - val_mse: 0.4079\n",
      "Epoch 728/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4898 - mse: 0.4819 - val_loss: 0.4258 - val_mse: 0.4179\n",
      "Epoch 729/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4906 - mse: 0.4827 - val_loss: 0.4145 - val_mse: 0.4066\n",
      "Epoch 730/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4866 - mse: 0.4787\n",
      "Epoch 00730: saving model to Regression_Model/mle.linear-0730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4779 - val_loss: 0.4172 - val_mse: 0.4093\n",
      "Epoch 731/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4915 - mse: 0.4836 - val_loss: 0.4247 - val_mse: 0.4167\n",
      "Epoch 732/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4749 - val_loss: 0.4152 - val_mse: 0.4072\n",
      "Epoch 733/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4809 - val_loss: 0.4228 - val_mse: 0.4149\n",
      "Epoch 734/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4808 - val_loss: 0.4202 - val_mse: 0.4123\n",
      "Epoch 735/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4905 - mse: 0.4826 - val_loss: 0.4226 - val_mse: 0.4147\n",
      "Epoch 736/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4774 - val_loss: 0.4262 - val_mse: 0.4183\n",
      "Epoch 737/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4837 - val_loss: 0.4204 - val_mse: 0.4125\n",
      "Epoch 738/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4785 - val_loss: 0.4194 - val_mse: 0.4115\n",
      "Epoch 739/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4820 - val_loss: 0.4178 - val_mse: 0.4099\n",
      "Epoch 740/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4961 - mse: 0.4882\n",
      "Epoch 00740: saving model to Regression_Model/mle.linear-0740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4956 - mse: 0.4877 - val_loss: 0.4261 - val_mse: 0.4182\n",
      "Epoch 741/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4778 - val_loss: 0.4284 - val_mse: 0.4205\n",
      "Epoch 742/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4754 - val_loss: 0.4223 - val_mse: 0.4143\n",
      "Epoch 743/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4871 - mse: 0.4792 - val_loss: 0.4170 - val_mse: 0.4091\n",
      "Epoch 744/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4905 - mse: 0.4826 - val_loss: 0.4176 - val_mse: 0.4096\n",
      "Epoch 745/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4903 - mse: 0.4824 - val_loss: 0.4125 - val_mse: 0.4045\n",
      "Epoch 746/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4885 - mse: 0.4806 - val_loss: 0.4188 - val_mse: 0.4109\n",
      "Epoch 747/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4809 - val_loss: 0.4265 - val_mse: 0.4186\n",
      "Epoch 748/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4881 - mse: 0.4802 - val_loss: 0.4154 - val_mse: 0.4074\n",
      "Epoch 749/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4783 - val_loss: 0.4153 - val_mse: 0.4074\n",
      "Epoch 750/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4921 - mse: 0.4842\n",
      "Epoch 00750: saving model to Regression_Model/mle.linear-0750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4915 - mse: 0.4836 - val_loss: 0.4178 - val_mse: 0.4099\n",
      "Epoch 751/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4836 - val_loss: 0.4212 - val_mse: 0.4133\n",
      "Epoch 752/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4774 - val_loss: 0.4138 - val_mse: 0.4059\n",
      "Epoch 753/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4778 - val_loss: 0.4205 - val_mse: 0.4126\n",
      "Epoch 754/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4945 - mse: 0.4866 - val_loss: 0.4237 - val_mse: 0.4158\n",
      "Epoch 755/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4820 - val_loss: 0.4175 - val_mse: 0.4095\n",
      "Epoch 756/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4913 - mse: 0.4834 - val_loss: 0.4194 - val_mse: 0.4114\n",
      "Epoch 757/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4831 - val_loss: 0.4216 - val_mse: 0.4137\n",
      "Epoch 758/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4846 - mse: 0.4767 - val_loss: 0.4344 - val_mse: 0.4264\n",
      "Epoch 759/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4909 - mse: 0.4830 - val_loss: 0.4174 - val_mse: 0.4094\n",
      "Epoch 760/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4880 - mse: 0.4801\n",
      "Epoch 00760: saving model to Regression_Model/mle.linear-0760.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4812 - val_loss: 0.4190 - val_mse: 0.4111\n",
      "Epoch 761/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4683 - val_loss: 0.4139 - val_mse: 0.4060\n",
      "Epoch 762/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4827 - val_loss: 0.4164 - val_mse: 0.4085\n",
      "Epoch 763/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4798 - val_loss: 0.4202 - val_mse: 0.4123\n",
      "Epoch 764/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4885 - mse: 0.4806 - val_loss: 0.4179 - val_mse: 0.4099\n",
      "Epoch 765/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4870 - mse: 0.4791 - val_loss: 0.4150 - val_mse: 0.4071\n",
      "Epoch 766/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4840 - val_loss: 0.4189 - val_mse: 0.4110\n",
      "Epoch 767/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4935 - mse: 0.4856 - val_loss: 0.4153 - val_mse: 0.4074\n",
      "Epoch 768/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4757 - val_loss: 0.4284 - val_mse: 0.4205\n",
      "Epoch 769/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4718 - val_loss: 0.4213 - val_mse: 0.4134\n",
      "Epoch 770/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4927 - mse: 0.4848\n",
      "Epoch 00770: saving model to Regression_Model/mle.linear-0770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4927 - mse: 0.4848 - val_loss: 0.4196 - val_mse: 0.4117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4893 - mse: 0.4813 - val_loss: 0.4206 - val_mse: 0.4126\n",
      "Epoch 772/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4863 - val_loss: 0.4223 - val_mse: 0.4144\n",
      "Epoch 773/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4735 - val_loss: 0.4322 - val_mse: 0.4243\n",
      "Epoch 774/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4816 - val_loss: 0.4207 - val_mse: 0.4127\n",
      "Epoch 775/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4909 - mse: 0.4829 - val_loss: 0.4179 - val_mse: 0.4099\n",
      "Epoch 776/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4854 - val_loss: 0.4252 - val_mse: 0.4173\n",
      "Epoch 777/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4873 - mse: 0.4794 - val_loss: 0.4147 - val_mse: 0.4068\n",
      "Epoch 778/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4831 - val_loss: 0.4159 - val_mse: 0.4080\n",
      "Epoch 779/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4805 - val_loss: 0.4200 - val_mse: 0.4121\n",
      "Epoch 780/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4924 - mse: 0.4845\n",
      "Epoch 00780: saving model to Regression_Model/mle.linear-0780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4852 - val_loss: 0.4241 - val_mse: 0.4162\n",
      "Epoch 781/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4859 - mse: 0.4780 - val_loss: 0.4158 - val_mse: 0.4078\n",
      "Epoch 782/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4828 - mse: 0.4749 - val_loss: 0.4168 - val_mse: 0.4089\n",
      "Epoch 783/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4883 - mse: 0.4804 - val_loss: 0.4178 - val_mse: 0.4099\n",
      "Epoch 784/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4922 - mse: 0.4842 - val_loss: 0.4217 - val_mse: 0.4137\n",
      "Epoch 785/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4833 - val_loss: 0.4270 - val_mse: 0.4190\n",
      "Epoch 786/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4940 - mse: 0.4861 - val_loss: 0.4198 - val_mse: 0.4118\n",
      "Epoch 787/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4942 - mse: 0.4863 - val_loss: 0.4194 - val_mse: 0.4115\n",
      "Epoch 788/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4743 - val_loss: 0.4218 - val_mse: 0.4138\n",
      "Epoch 789/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4903 - mse: 0.4824 - val_loss: 0.4210 - val_mse: 0.4131\n",
      "Epoch 790/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4837 - mse: 0.4758\n",
      "Epoch 00790: saving model to Regression_Model/mle.linear-0790.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4754 - val_loss: 0.4132 - val_mse: 0.4053\n",
      "Epoch 791/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4900 - mse: 0.4820 - val_loss: 0.4227 - val_mse: 0.4148\n",
      "Epoch 792/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4751 - val_loss: 0.4246 - val_mse: 0.4167\n",
      "Epoch 793/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4813 - val_loss: 0.4135 - val_mse: 0.4056\n",
      "Epoch 794/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4726 - val_loss: 0.4166 - val_mse: 0.4087\n",
      "Epoch 795/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4879 - mse: 0.4800 - val_loss: 0.4335 - val_mse: 0.4256\n",
      "Epoch 796/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4798 - val_loss: 0.4136 - val_mse: 0.4057\n",
      "Epoch 797/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4913 - mse: 0.4834 - val_loss: 0.4151 - val_mse: 0.4072\n",
      "Epoch 798/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4783 - val_loss: 0.4230 - val_mse: 0.4151\n",
      "Epoch 799/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4812 - val_loss: 0.4213 - val_mse: 0.4134\n",
      "Epoch 800/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4857 - mse: 0.4777\n",
      "Epoch 00800: saving model to Regression_Model/mle.linear-0800.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4778 - val_loss: 0.4159 - val_mse: 0.4079\n",
      "Epoch 801/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4942 - mse: 0.4863 - val_loss: 0.4268 - val_mse: 0.4188\n",
      "Epoch 802/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4785 - val_loss: 0.4187 - val_mse: 0.4107\n",
      "Epoch 803/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4776 - val_loss: 0.4175 - val_mse: 0.4095\n",
      "Epoch 804/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4711 - val_loss: 0.4156 - val_mse: 0.4076\n",
      "Epoch 805/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4917 - mse: 0.4837 - val_loss: 0.4161 - val_mse: 0.4081\n",
      "Epoch 806/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4939 - mse: 0.4859 - val_loss: 0.4230 - val_mse: 0.4150\n",
      "Epoch 807/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4831 - val_loss: 0.4177 - val_mse: 0.4098\n",
      "Epoch 808/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4801 - val_loss: 0.4230 - val_mse: 0.4150\n",
      "Epoch 809/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4755 - val_loss: 0.4164 - val_mse: 0.4084\n",
      "Epoch 810/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4880 - mse: 0.4801\n",
      "Epoch 00810: saving model to Regression_Model/mle.linear-0810.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4784 - val_loss: 0.4201 - val_mse: 0.4122\n",
      "Epoch 811/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4941 - mse: 0.4862 - val_loss: 0.4264 - val_mse: 0.4184\n",
      "Epoch 812/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4786 - val_loss: 0.4111 - val_mse: 0.4032\n",
      "Epoch 813/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4859 - val_loss: 0.4190 - val_mse: 0.4110\n",
      "Epoch 814/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4798 - val_loss: 0.4245 - val_mse: 0.4166\n",
      "Epoch 815/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4801 - val_loss: 0.4176 - val_mse: 0.4097\n",
      "Epoch 816/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4778 - val_loss: 0.4140 - val_mse: 0.4061\n",
      "Epoch 817/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4965 - mse: 0.4886 - val_loss: 0.4192 - val_mse: 0.4113\n",
      "Epoch 818/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4901 - mse: 0.4821 - val_loss: 0.4168 - val_mse: 0.4088\n",
      "Epoch 819/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4852 - mse: 0.4773 - val_loss: 0.4186 - val_mse: 0.4107\n",
      "Epoch 820/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4838 - mse: 0.4759\n",
      "Epoch 00820: saving model to Regression_Model/mle.linear-0820.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4762 - val_loss: 0.4154 - val_mse: 0.4075\n",
      "Epoch 821/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4853 - val_loss: 0.4184 - val_mse: 0.4105\n",
      "Epoch 822/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4906 - mse: 0.4826 - val_loss: 0.4170 - val_mse: 0.4090\n",
      "Epoch 823/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4793 - mse: 0.4713 - val_loss: 0.4204 - val_mse: 0.4124\n",
      "Epoch 824/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4810 - val_loss: 0.4161 - val_mse: 0.4082\n",
      "Epoch 825/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4870 - mse: 0.4791 - val_loss: 0.4122 - val_mse: 0.4042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4796 - val_loss: 0.4176 - val_mse: 0.4097\n",
      "Epoch 827/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4833 - val_loss: 0.4150 - val_mse: 0.4071\n",
      "Epoch 828/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4777 - val_loss: 0.4114 - val_mse: 0.4035\n",
      "Epoch 829/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4840 - val_loss: 0.4151 - val_mse: 0.4072\n",
      "Epoch 830/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4848 - mse: 0.4768\n",
      "Epoch 00830: saving model to Regression_Model/mle.linear-0830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4796 - val_loss: 0.4156 - val_mse: 0.4077\n",
      "Epoch 831/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4848 - mse: 0.4769 - val_loss: 0.4170 - val_mse: 0.4090\n",
      "Epoch 832/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4785 - val_loss: 0.4135 - val_mse: 0.4056\n",
      "Epoch 833/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4866 - mse: 0.4786 - val_loss: 0.4149 - val_mse: 0.4069\n",
      "Epoch 834/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4777 - val_loss: 0.4230 - val_mse: 0.4151\n",
      "Epoch 835/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4778 - val_loss: 0.4186 - val_mse: 0.4106\n",
      "Epoch 836/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4823 - val_loss: 0.4157 - val_mse: 0.4077\n",
      "Epoch 837/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4792 - val_loss: 0.4184 - val_mse: 0.4104\n",
      "Epoch 838/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4798 - val_loss: 0.4171 - val_mse: 0.4091\n",
      "Epoch 839/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4786 - val_loss: 0.4182 - val_mse: 0.4102\n",
      "Epoch 840/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4819 - mse: 0.4739\n",
      "Epoch 00840: saving model to Regression_Model/mle.linear-0840.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4833 - mse: 0.4753 - val_loss: 0.4168 - val_mse: 0.4088\n",
      "Epoch 841/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4126 - val_mse: 0.4047\n",
      "Epoch 842/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4131 - val_mse: 0.4052\n",
      "Epoch 843/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4789 - val_loss: 0.4222 - val_mse: 0.4142\n",
      "Epoch 844/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4756 - val_loss: 0.4104 - val_mse: 0.4024\n",
      "Epoch 845/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4784 - val_loss: 0.4130 - val_mse: 0.4051\n",
      "Epoch 846/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4787 - val_loss: 0.4199 - val_mse: 0.4120\n",
      "Epoch 847/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4720 - val_loss: 0.4244 - val_mse: 0.4164\n",
      "Epoch 848/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4750 - val_loss: 0.4169 - val_mse: 0.4090\n",
      "Epoch 849/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4772 - val_loss: 0.4101 - val_mse: 0.4022\n",
      "Epoch 850/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4914 - mse: 0.4835\n",
      "Epoch 00850: saving model to Regression_Model/mle.linear-0850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4839 - val_loss: 0.4197 - val_mse: 0.4117\n",
      "Epoch 851/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4925 - mse: 0.4846 - val_loss: 0.4216 - val_mse: 0.4137\n",
      "Epoch 852/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4762 - val_loss: 0.4160 - val_mse: 0.4081\n",
      "Epoch 853/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4813 - val_loss: 0.4197 - val_mse: 0.4117\n",
      "Epoch 854/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4901 - mse: 0.4822 - val_loss: 0.4146 - val_mse: 0.4066\n",
      "Epoch 855/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4954 - mse: 0.4875 - val_loss: 0.4138 - val_mse: 0.4058\n",
      "Epoch 856/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4774 - val_loss: 0.4157 - val_mse: 0.4077\n",
      "Epoch 857/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4771 - val_loss: 0.4175 - val_mse: 0.4096\n",
      "Epoch 858/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4924 - mse: 0.4844 - val_loss: 0.4282 - val_mse: 0.4203\n",
      "Epoch 859/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4800 - val_loss: 0.4246 - val_mse: 0.4166\n",
      "Epoch 860/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4880 - mse: 0.4800\n",
      "Epoch 00860: saving model to Regression_Model/mle.linear-0860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4808 - val_loss: 0.4135 - val_mse: 0.4055\n",
      "Epoch 861/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4783 - val_loss: 0.4129 - val_mse: 0.4050\n",
      "Epoch 862/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4767 - val_loss: 0.4081 - val_mse: 0.4002\n",
      "Epoch 863/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4771 - val_loss: 0.4197 - val_mse: 0.4118\n",
      "Epoch 864/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4934 - mse: 0.4854 - val_loss: 0.4108 - val_mse: 0.4028\n",
      "Epoch 865/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4881 - mse: 0.4801 - val_loss: 0.4199 - val_mse: 0.4120\n",
      "Epoch 866/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4742 - val_loss: 0.4226 - val_mse: 0.4146\n",
      "Epoch 867/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4798 - val_loss: 0.4162 - val_mse: 0.4082\n",
      "Epoch 868/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4798 - val_loss: 0.4144 - val_mse: 0.4065\n",
      "Epoch 869/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4775 - val_loss: 0.4233 - val_mse: 0.4154\n",
      "Epoch 870/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4769 - mse: 0.4690\n",
      "Epoch 00870: saving model to Regression_Model/mle.linear-0870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4702 - val_loss: 0.4143 - val_mse: 0.4063\n",
      "Epoch 871/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4738 - val_loss: 0.4112 - val_mse: 0.4033\n",
      "Epoch 872/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4774 - val_loss: 0.4141 - val_mse: 0.4061\n",
      "Epoch 873/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4766 - val_loss: 0.4212 - val_mse: 0.4133\n",
      "Epoch 874/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4917 - mse: 0.4838 - val_loss: 0.4157 - val_mse: 0.4078\n",
      "Epoch 875/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4747 - val_loss: 0.4189 - val_mse: 0.4110\n",
      "Epoch 876/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4917 - mse: 0.4837 - val_loss: 0.4155 - val_mse: 0.4075\n",
      "Epoch 877/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4769 - val_loss: 0.4137 - val_mse: 0.4058\n",
      "Epoch 878/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4728 - val_loss: 0.4221 - val_mse: 0.4142\n",
      "Epoch 879/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4771 - val_loss: 0.4222 - val_mse: 0.4142\n",
      "Epoch 880/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4879 - mse: 0.4800\n",
      "Epoch 00880: saving model to Regression_Model/mle.linear-0880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4881 - mse: 0.4802 - val_loss: 0.4145 - val_mse: 0.4066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4762 - val_loss: 0.4154 - val_mse: 0.4075\n",
      "Epoch 882/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4817 - val_loss: 0.4190 - val_mse: 0.4111\n",
      "Epoch 883/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4904 - mse: 0.4824 - val_loss: 0.4126 - val_mse: 0.4047\n",
      "Epoch 884/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4853 - val_loss: 0.4133 - val_mse: 0.4053\n",
      "Epoch 885/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4779 - val_loss: 0.4128 - val_mse: 0.4048\n",
      "Epoch 886/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4860 - mse: 0.4781 - val_loss: 0.4164 - val_mse: 0.4085\n",
      "Epoch 887/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4852 - mse: 0.4772 - val_loss: 0.4165 - val_mse: 0.4085\n",
      "Epoch 888/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4905 - mse: 0.4826 - val_loss: 0.4171 - val_mse: 0.4092\n",
      "Epoch 889/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4745 - val_loss: 0.4172 - val_mse: 0.4093\n",
      "Epoch 890/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4862 - mse: 0.4783\n",
      "Epoch 00890: saving model to Regression_Model/mle.linear-0890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4778 - val_loss: 0.4170 - val_mse: 0.4091\n",
      "Epoch 891/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4758 - val_loss: 0.4136 - val_mse: 0.4057\n",
      "Epoch 892/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4885 - mse: 0.4805 - val_loss: 0.4135 - val_mse: 0.4056\n",
      "Epoch 893/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4786 - val_loss: 0.4213 - val_mse: 0.4133\n",
      "Epoch 894/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4745 - val_loss: 0.4159 - val_mse: 0.4080\n",
      "Epoch 895/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4936 - mse: 0.4857 - val_loss: 0.4176 - val_mse: 0.4096\n",
      "Epoch 896/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4855 - mse: 0.4776 - val_loss: 0.4172 - val_mse: 0.4093\n",
      "Epoch 897/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4746 - val_loss: 0.4231 - val_mse: 0.4152\n",
      "Epoch 898/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4815 - mse: 0.4735 - val_loss: 0.4177 - val_mse: 0.4098\n",
      "Epoch 899/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4771 - val_loss: 0.4139 - val_mse: 0.4060\n",
      "Epoch 900/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4859 - mse: 0.4780\n",
      "Epoch 00900: saving model to Regression_Model/mle.linear-0900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4770 - val_loss: 0.4129 - val_mse: 0.4049\n",
      "Epoch 901/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4794 - val_loss: 0.4170 - val_mse: 0.4091\n",
      "Epoch 902/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4774 - val_loss: 0.4180 - val_mse: 0.4101\n",
      "Epoch 903/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4900 - mse: 0.4821 - val_loss: 0.4150 - val_mse: 0.4071\n",
      "Epoch 904/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4784 - val_loss: 0.4127 - val_mse: 0.4048\n",
      "Epoch 905/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4736 - val_loss: 0.4141 - val_mse: 0.4062\n",
      "Epoch 906/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4742 - val_loss: 0.4123 - val_mse: 0.4043\n",
      "Epoch 907/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4840 - mse: 0.4761 - val_loss: 0.4160 - val_mse: 0.4081\n",
      "Epoch 908/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4852 - mse: 0.4773 - val_loss: 0.4142 - val_mse: 0.4063\n",
      "Epoch 909/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4775 - val_loss: 0.4098 - val_mse: 0.4018\n",
      "Epoch 910/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4826 - mse: 0.4747\n",
      "Epoch 00910: saving model to Regression_Model/mle.linear-0910.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4751 - val_loss: 0.4146 - val_mse: 0.4066\n",
      "Epoch 911/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4075 - val_mse: 0.3995\n",
      "Epoch 912/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4869 - mse: 0.4790 - val_loss: 0.4147 - val_mse: 0.4067\n",
      "Epoch 913/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4764 - val_loss: 0.4163 - val_mse: 0.4084\n",
      "Epoch 914/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4798 - val_loss: 0.4160 - val_mse: 0.4081\n",
      "Epoch 915/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4748 - val_loss: 0.4162 - val_mse: 0.4082\n",
      "Epoch 916/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4733 - val_loss: 0.4107 - val_mse: 0.4028\n",
      "Epoch 917/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4735 - val_loss: 0.4200 - val_mse: 0.4121\n",
      "Epoch 918/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4775 - val_loss: 0.4215 - val_mse: 0.4136\n",
      "Epoch 919/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4867 - mse: 0.4788 - val_loss: 0.4260 - val_mse: 0.4180\n",
      "Epoch 920/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4906 - mse: 0.4827\n",
      "Epoch 00920: saving model to Regression_Model/mle.linear-0920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4813 - val_loss: 0.4189 - val_mse: 0.4110\n",
      "Epoch 921/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4807 - val_loss: 0.4159 - val_mse: 0.4080\n",
      "Epoch 922/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4745 - val_loss: 0.4161 - val_mse: 0.4082\n",
      "Epoch 923/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4770 - val_loss: 0.4123 - val_mse: 0.4044\n",
      "Epoch 924/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4733 - val_loss: 0.4190 - val_mse: 0.4111\n",
      "Epoch 925/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4763 - val_loss: 0.4178 - val_mse: 0.4099\n",
      "Epoch 926/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4122 - val_mse: 0.4043\n",
      "Epoch 927/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4872 - mse: 0.4793 - val_loss: 0.4143 - val_mse: 0.4064\n",
      "Epoch 928/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4808 - val_loss: 0.4147 - val_mse: 0.4067\n",
      "Epoch 929/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4801 - mse: 0.4721 - val_loss: 0.4081 - val_mse: 0.4001\n",
      "Epoch 930/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4865 - mse: 0.4786\n",
      "Epoch 00930: saving model to Regression_Model/mle.linear-0930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4771 - val_loss: 0.4059 - val_mse: 0.3980\n",
      "Epoch 931/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4753 - val_loss: 0.4142 - val_mse: 0.4062\n",
      "Epoch 932/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4872 - mse: 0.4793 - val_loss: 0.4119 - val_mse: 0.4039\n",
      "Epoch 933/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4925 - mse: 0.4846 - val_loss: 0.4128 - val_mse: 0.4049\n",
      "Epoch 934/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4844 - mse: 0.4765 - val_loss: 0.4185 - val_mse: 0.4106\n",
      "Epoch 935/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4869 - mse: 0.4789 - val_loss: 0.4125 - val_mse: 0.4046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4766 - val_loss: 0.4066 - val_mse: 0.3987\n",
      "Epoch 937/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4760 - val_loss: 0.4252 - val_mse: 0.4173\n",
      "Epoch 938/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4734 - val_loss: 0.4135 - val_mse: 0.4056\n",
      "Epoch 939/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4859 - mse: 0.4779 - val_loss: 0.4159 - val_mse: 0.4079\n",
      "Epoch 940/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4832 - mse: 0.4753\n",
      "Epoch 00940: saving model to Regression_Model/mle.linear-0940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4742 - val_loss: 0.4173 - val_mse: 0.4093\n",
      "Epoch 941/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4861 - mse: 0.4782 - val_loss: 0.4138 - val_mse: 0.4059\n",
      "Epoch 942/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4786 - val_loss: 0.4158 - val_mse: 0.4079\n",
      "Epoch 943/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4844 - mse: 0.4765 - val_loss: 0.4177 - val_mse: 0.4098\n",
      "Epoch 944/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4809 - val_loss: 0.4090 - val_mse: 0.4010\n",
      "Epoch 945/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4725 - val_loss: 0.4110 - val_mse: 0.4030\n",
      "Epoch 946/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4822 - val_loss: 0.4154 - val_mse: 0.4075\n",
      "Epoch 947/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4777 - mse: 0.4698 - val_loss: 0.4060 - val_mse: 0.3981\n",
      "Epoch 948/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4774 - val_loss: 0.4108 - val_mse: 0.4028\n",
      "Epoch 949/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4755 - val_loss: 0.4100 - val_mse: 0.4021\n",
      "Epoch 950/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4873 - mse: 0.4793\n",
      "Epoch 00950: saving model to Regression_Model/mle.linear-0950.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4883 - mse: 0.4804 - val_loss: 0.4150 - val_mse: 0.4071\n",
      "Epoch 951/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4801 - mse: 0.4722 - val_loss: 0.4099 - val_mse: 0.4020\n",
      "Epoch 952/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4881 - mse: 0.4802 - val_loss: 0.4102 - val_mse: 0.4022\n",
      "Epoch 953/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4927 - mse: 0.4848 - val_loss: 0.4113 - val_mse: 0.4034\n",
      "Epoch 954/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4778 - val_loss: 0.4192 - val_mse: 0.4113\n",
      "Epoch 955/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4751 - val_loss: 0.4147 - val_mse: 0.4068\n",
      "Epoch 956/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4772 - val_loss: 0.4307 - val_mse: 0.4227\n",
      "Epoch 957/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4732 - val_loss: 0.4108 - val_mse: 0.4029\n",
      "Epoch 958/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4775 - val_loss: 0.4159 - val_mse: 0.4079\n",
      "Epoch 959/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4876 - mse: 0.4797 - val_loss: 0.4134 - val_mse: 0.4055\n",
      "Epoch 960/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4846 - mse: 0.4766\n",
      "Epoch 00960: saving model to Regression_Model/mle.linear-0960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4765 - val_loss: 0.4151 - val_mse: 0.4072\n",
      "Epoch 961/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4785 - val_loss: 0.4171 - val_mse: 0.4092\n",
      "Epoch 962/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4751 - val_loss: 0.4159 - val_mse: 0.4080\n",
      "Epoch 963/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4768 - val_loss: 0.4161 - val_mse: 0.4082\n",
      "Epoch 964/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4840 - val_loss: 0.4119 - val_mse: 0.4040\n",
      "Epoch 965/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4745 - val_loss: 0.4101 - val_mse: 0.4022\n",
      "Epoch 966/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4765 - mse: 0.4685 - val_loss: 0.4129 - val_mse: 0.4050\n",
      "Epoch 967/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4733 - val_loss: 0.4085 - val_mse: 0.4006\n",
      "Epoch 968/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4795 - val_loss: 0.4153 - val_mse: 0.4074\n",
      "Epoch 969/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4736 - val_loss: 0.4200 - val_mse: 0.4121\n",
      "Epoch 970/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4838 - mse: 0.4759\n",
      "Epoch 00970: saving model to Regression_Model/mle.linear-0970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4731 - val_loss: 0.4264 - val_mse: 0.4185\n",
      "Epoch 971/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4828 - val_loss: 0.4219 - val_mse: 0.4139\n",
      "Epoch 972/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4742 - mse: 0.4663 - val_loss: 0.4080 - val_mse: 0.4000\n",
      "Epoch 973/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4867 - mse: 0.4788 - val_loss: 0.4209 - val_mse: 0.4129\n",
      "Epoch 974/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4742 - val_loss: 0.4087 - val_mse: 0.4008\n",
      "Epoch 975/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4755 - val_loss: 0.4152 - val_mse: 0.4072\n",
      "Epoch 976/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4755 - val_loss: 0.4171 - val_mse: 0.4092\n",
      "Epoch 977/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4810 - val_loss: 0.4179 - val_mse: 0.4099\n",
      "Epoch 978/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4794 - val_loss: 0.4160 - val_mse: 0.4081\n",
      "Epoch 979/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4786 - val_loss: 0.4180 - val_mse: 0.4101\n",
      "Epoch 980/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4808 - mse: 0.4729\n",
      "Epoch 00980: saving model to Regression_Model/mle.linear-0980.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4726 - val_loss: 0.4080 - val_mse: 0.4000\n",
      "Epoch 981/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4785 - val_loss: 0.4188 - val_mse: 0.4109\n",
      "Epoch 982/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4793 - mse: 0.4714 - val_loss: 0.4204 - val_mse: 0.4125\n",
      "Epoch 983/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4764 - val_loss: 0.4122 - val_mse: 0.4042\n",
      "Epoch 984/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4812 - val_loss: 0.4109 - val_mse: 0.4030\n",
      "Epoch 985/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4705 - val_loss: 0.4109 - val_mse: 0.4030\n",
      "Epoch 986/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4756 - val_loss: 0.4126 - val_mse: 0.4047\n",
      "Epoch 987/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4754 - val_loss: 0.4180 - val_mse: 0.4100\n",
      "Epoch 988/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4733 - val_loss: 0.4146 - val_mse: 0.4067\n",
      "Epoch 989/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4743 - val_loss: 0.4114 - val_mse: 0.4035\n",
      "Epoch 990/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4757 - mse: 0.4678\n",
      "Epoch 00990: saving model to Regression_Model/mle.linear-0990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4758 - mse: 0.4679 - val_loss: 0.4108 - val_mse: 0.4029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4711 - val_loss: 0.4181 - val_mse: 0.4102\n",
      "Epoch 992/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4702 - val_loss: 0.4143 - val_mse: 0.4064\n",
      "Epoch 993/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4913 - mse: 0.4834 - val_loss: 0.4063 - val_mse: 0.3984\n",
      "Epoch 994/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4794 - val_loss: 0.4110 - val_mse: 0.4031\n",
      "Epoch 995/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4759 - val_loss: 0.4093 - val_mse: 0.4014\n",
      "Epoch 996/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4741 - val_loss: 0.4104 - val_mse: 0.4024\n",
      "Epoch 997/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4770 - val_loss: 0.4121 - val_mse: 0.4042\n",
      "Epoch 998/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4779 - mse: 0.4700 - val_loss: 0.4125 - val_mse: 0.4046\n",
      "Epoch 999/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4772 - val_loss: 0.4118 - val_mse: 0.4038\n",
      "Epoch 1000/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.4865 - mse: 0.4786\n",
      "Epoch 01000: saving model to Regression_Model/mle.linear-1000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4779 - val_loss: 0.4091 - val_mse: 0.4012\n",
      "Epoch 1001/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4792 - val_loss: 0.4067 - val_mse: 0.3988\n",
      "Epoch 1002/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4715 - val_loss: 0.4140 - val_mse: 0.4061\n",
      "Epoch 1003/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4786 - val_loss: 0.4159 - val_mse: 0.4080\n",
      "Epoch 1004/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4726 - val_loss: 0.4190 - val_mse: 0.4111\n",
      "Epoch 1005/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4775 - val_loss: 0.4133 - val_mse: 0.4054\n",
      "Epoch 1006/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4823 - val_loss: 0.4117 - val_mse: 0.4038\n",
      "Epoch 1007/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4751 - val_loss: 0.4151 - val_mse: 0.4072\n",
      "Epoch 1008/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4785 - val_loss: 0.4100 - val_mse: 0.4021\n",
      "Epoch 1009/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4750 - val_loss: 0.4107 - val_mse: 0.4028\n",
      "Epoch 1010/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4820 - mse: 0.4741\n",
      "Epoch 01010: saving model to Regression_Model/mle.linear-1010.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4740 - val_loss: 0.4136 - val_mse: 0.4057\n",
      "Epoch 1011/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4720 - val_loss: 0.4159 - val_mse: 0.4080\n",
      "Epoch 1012/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4846 - mse: 0.4767 - val_loss: 0.4091 - val_mse: 0.4012\n",
      "Epoch 1013/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4820 - val_loss: 0.4092 - val_mse: 0.4013\n",
      "Epoch 1014/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4801 - val_loss: 0.4101 - val_mse: 0.4022\n",
      "Epoch 1015/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4752 - val_loss: 0.4142 - val_mse: 0.4063\n",
      "Epoch 1016/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4795 - val_loss: 0.4199 - val_mse: 0.4120\n",
      "Epoch 1017/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4694 - val_loss: 0.4100 - val_mse: 0.4021\n",
      "Epoch 1018/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4870 - mse: 0.4791 - val_loss: 0.4101 - val_mse: 0.4022\n",
      "Epoch 1019/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4803 - val_loss: 0.4116 - val_mse: 0.4037\n",
      "Epoch 1020/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.4815 - mse: 0.4736\n",
      "Epoch 01020: saving model to Regression_Model/mle.linear-1020.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4808 - mse: 0.4729 - val_loss: 0.4144 - val_mse: 0.4065\n",
      "Epoch 1021/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4787 - val_loss: 0.4116 - val_mse: 0.4037\n",
      "Epoch 1022/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4771 - val_loss: 0.4144 - val_mse: 0.4065\n",
      "Epoch 1023/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4816 - val_loss: 0.4145 - val_mse: 0.4066\n",
      "Epoch 1024/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4699 - val_loss: 0.4109 - val_mse: 0.4030\n",
      "Epoch 1025/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4754 - val_loss: 0.4197 - val_mse: 0.4118\n",
      "Epoch 1026/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4755 - val_loss: 0.4082 - val_mse: 0.4003\n",
      "Epoch 1027/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4753 - val_loss: 0.4147 - val_mse: 0.4068\n",
      "Epoch 1028/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4783 - val_loss: 0.4112 - val_mse: 0.4033\n",
      "Epoch 1029/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4793 - mse: 0.4714 - val_loss: 0.4164 - val_mse: 0.4085\n",
      "Epoch 1030/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4819 - mse: 0.4740\n",
      "Epoch 01030: saving model to Regression_Model/mle.linear-1030.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4741 - val_loss: 0.4075 - val_mse: 0.3996\n",
      "Epoch 1031/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4752 - val_loss: 0.4095 - val_mse: 0.4016\n",
      "Epoch 1032/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4762 - val_loss: 0.4075 - val_mse: 0.3996\n",
      "Epoch 1033/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4748 - val_loss: 0.4083 - val_mse: 0.4004\n",
      "Epoch 1034/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4763 - val_loss: 0.4145 - val_mse: 0.4066\n",
      "Epoch 1035/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4743 - val_loss: 0.4053 - val_mse: 0.3974\n",
      "Epoch 1036/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4744 - val_loss: 0.4136 - val_mse: 0.4057\n",
      "Epoch 1037/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4755 - val_loss: 0.4057 - val_mse: 0.3978\n",
      "Epoch 1038/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4805 - val_loss: 0.4127 - val_mse: 0.4048\n",
      "Epoch 1039/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4703 - val_loss: 0.4162 - val_mse: 0.4083\n",
      "Epoch 1040/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4882 - mse: 0.4803\n",
      "Epoch 01040: saving model to Regression_Model/mle.linear-1040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4778 - val_loss: 0.4074 - val_mse: 0.3995\n",
      "Epoch 1041/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4796 - val_loss: 0.4153 - val_mse: 0.4074\n",
      "Epoch 1042/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4815 - val_loss: 0.4190 - val_mse: 0.4111\n",
      "Epoch 1043/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4759 - val_loss: 0.4192 - val_mse: 0.4113\n",
      "Epoch 1044/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4779 - val_loss: 0.4079 - val_mse: 0.4000\n",
      "Epoch 1045/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4799 - val_loss: 0.4118 - val_mse: 0.4039\n",
      "Epoch 1046/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4768 - val_loss: 0.4085 - val_mse: 0.4007\n",
      "Epoch 1047/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4905 - mse: 0.4827 - val_loss: 0.4142 - val_mse: 0.4063\n",
      "Epoch 1048/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4748 - val_loss: 0.4115 - val_mse: 0.4036\n",
      "Epoch 1049/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4779 - val_loss: 0.4186 - val_mse: 0.4108\n",
      "Epoch 1050/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4827 - mse: 0.4748\n",
      "Epoch 01050: saving model to Regression_Model/mle.linear-1050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4744 - val_loss: 0.4120 - val_mse: 0.4041\n",
      "Epoch 1051/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4759 - val_loss: 0.4151 - val_mse: 0.4072\n",
      "Epoch 1052/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4690 - val_loss: 0.4113 - val_mse: 0.4034\n",
      "Epoch 1053/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4688 - val_loss: 0.4131 - val_mse: 0.4052\n",
      "Epoch 1054/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4870 - mse: 0.4791 - val_loss: 0.4085 - val_mse: 0.4006\n",
      "Epoch 1055/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4731 - val_loss: 0.4151 - val_mse: 0.4072\n",
      "Epoch 1056/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4686 - val_loss: 0.4145 - val_mse: 0.4066\n",
      "Epoch 1057/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4734 - val_loss: 0.4102 - val_mse: 0.4023\n",
      "Epoch 1058/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4706 - val_loss: 0.4077 - val_mse: 0.3998\n",
      "Epoch 1059/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4726 - val_loss: 0.4124 - val_mse: 0.4046\n",
      "Epoch 1060/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4760 - mse: 0.4681\n",
      "Epoch 01060: saving model to Regression_Model/mle.linear-1060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4763 - mse: 0.4684 - val_loss: 0.4089 - val_mse: 0.4010\n",
      "Epoch 1061/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4693 - val_loss: 0.4143 - val_mse: 0.4064\n",
      "Epoch 1062/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4861 - mse: 0.4782 - val_loss: 0.4097 - val_mse: 0.4018\n",
      "Epoch 1063/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4696 - val_loss: 0.4107 - val_mse: 0.4028\n",
      "Epoch 1064/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4777 - val_loss: 0.4136 - val_mse: 0.4057\n",
      "Epoch 1065/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4742 - val_loss: 0.4142 - val_mse: 0.4063\n",
      "Epoch 1066/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4721 - val_loss: 0.4118 - val_mse: 0.4039\n",
      "Epoch 1067/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4844 - mse: 0.4765 - val_loss: 0.4140 - val_mse: 0.4061\n",
      "Epoch 1068/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4860 - mse: 0.4781 - val_loss: 0.4195 - val_mse: 0.4116\n",
      "Epoch 1069/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4687 - val_loss: 0.4102 - val_mse: 0.4024\n",
      "Epoch 1070/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4834 - mse: 0.4755\n",
      "Epoch 01070: saving model to Regression_Model/mle.linear-1070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4750 - val_loss: 0.4172 - val_mse: 0.4093\n",
      "Epoch 1071/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4779 - val_loss: 0.4184 - val_mse: 0.4106\n",
      "Epoch 1072/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4823 - mse: 0.4744 - val_loss: 0.4115 - val_mse: 0.4037\n",
      "Epoch 1073/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4735 - val_loss: 0.4085 - val_mse: 0.4006\n",
      "Epoch 1074/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4855 - mse: 0.4776 - val_loss: 0.4214 - val_mse: 0.4135\n",
      "Epoch 1075/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4732 - val_loss: 0.4144 - val_mse: 0.4066\n",
      "Epoch 1076/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4809 - val_loss: 0.4105 - val_mse: 0.4026\n",
      "Epoch 1077/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4730 - val_loss: 0.4068 - val_mse: 0.3989\n",
      "Epoch 1078/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4870 - mse: 0.4791 - val_loss: 0.4113 - val_mse: 0.4034\n",
      "Epoch 1079/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4810 - mse: 0.4731 - val_loss: 0.4090 - val_mse: 0.4011\n",
      "Epoch 1080/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4837 - mse: 0.4758\n",
      "Epoch 01080: saving model to Regression_Model/mle.linear-1080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4844 - mse: 0.4766 - val_loss: 0.4132 - val_mse: 0.4053\n",
      "Epoch 1081/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4708 - val_loss: 0.4121 - val_mse: 0.4042\n",
      "Epoch 1082/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4788 - mse: 0.4709 - val_loss: 0.4102 - val_mse: 0.4023\n",
      "Epoch 1083/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4736 - val_loss: 0.4166 - val_mse: 0.4087\n",
      "Epoch 1084/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4812 - mse: 0.4733 - val_loss: 0.4092 - val_mse: 0.4013\n",
      "Epoch 1085/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4730 - val_loss: 0.4220 - val_mse: 0.4141\n",
      "Epoch 1086/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4748 - val_loss: 0.4088 - val_mse: 0.4009\n",
      "Epoch 1087/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4724 - val_loss: 0.4081 - val_mse: 0.4002\n",
      "Epoch 1088/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4689 - val_loss: 0.4068 - val_mse: 0.3989\n",
      "Epoch 1089/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4734 - val_loss: 0.4080 - val_mse: 0.4002\n",
      "Epoch 1090/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4869 - mse: 0.4791\n",
      "Epoch 01090: saving model to Regression_Model/mle.linear-1090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4785 - val_loss: 0.4153 - val_mse: 0.4074\n",
      "Epoch 1091/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4725 - val_loss: 0.4144 - val_mse: 0.4065\n",
      "Epoch 1092/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4855 - mse: 0.4776 - val_loss: 0.4090 - val_mse: 0.4011\n",
      "Epoch 1093/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4752 - val_loss: 0.4132 - val_mse: 0.4053\n",
      "Epoch 1094/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4724 - val_loss: 0.4133 - val_mse: 0.4054\n",
      "Epoch 1095/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4711 - val_loss: 0.4065 - val_mse: 0.3986\n",
      "Epoch 1096/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4801 - mse: 0.4722 - val_loss: 0.4095 - val_mse: 0.4017\n",
      "Epoch 1097/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4686 - val_loss: 0.4068 - val_mse: 0.3989\n",
      "Epoch 1098/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4746 - val_loss: 0.4093 - val_mse: 0.4014\n",
      "Epoch 1099/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4801 - mse: 0.4722 - val_loss: 0.4115 - val_mse: 0.4037\n",
      "Epoch 1100/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4798 - mse: 0.4719\n",
      "Epoch 01100: saving model to Regression_Model/mle.linear-1100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4734 - val_loss: 0.4091 - val_mse: 0.4012\n",
      "Epoch 1101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4730 - mse: 0.4651 - val_loss: 0.4112 - val_mse: 0.4033\n",
      "Epoch 1102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4778 - val_loss: 0.4057 - val_mse: 0.3979\n",
      "Epoch 1103/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4852 - mse: 0.4774 - val_loss: 0.4170 - val_mse: 0.4091\n",
      "Epoch 1104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4719 - val_loss: 0.4036 - val_mse: 0.3957\n",
      "Epoch 1105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4783 - val_loss: 0.4099 - val_mse: 0.4020\n",
      "Epoch 1106/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4749 - mse: 0.4670 - val_loss: 0.4095 - val_mse: 0.4016\n",
      "Epoch 1107/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4752 - mse: 0.4674 - val_loss: 0.4044 - val_mse: 0.3965\n",
      "Epoch 1108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4794 - val_loss: 0.4124 - val_mse: 0.4045\n",
      "Epoch 1109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4764 - val_loss: 0.4142 - val_mse: 0.4063\n",
      "Epoch 1110/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4790 - mse: 0.4711\n",
      "Epoch 01110: saving model to Regression_Model/mle.linear-1110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4721 - val_loss: 0.4209 - val_mse: 0.4130\n",
      "Epoch 1111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4751 - val_loss: 0.4098 - val_mse: 0.4019\n",
      "Epoch 1112/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4709 - val_loss: 0.4085 - val_mse: 0.4006\n",
      "Epoch 1113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4763 - val_loss: 0.4097 - val_mse: 0.4019\n",
      "Epoch 1114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4684 - val_loss: 0.4064 - val_mse: 0.3985\n",
      "Epoch 1115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4676 - val_loss: 0.4087 - val_mse: 0.4008\n",
      "Epoch 1116/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4798 - val_loss: 0.4033 - val_mse: 0.3954\n",
      "Epoch 1117/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4741 - val_loss: 0.4074 - val_mse: 0.3996\n",
      "Epoch 1118/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4777 - mse: 0.4698 - val_loss: 0.4100 - val_mse: 0.4021\n",
      "Epoch 1119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4879 - mse: 0.4800 - val_loss: 0.4091 - val_mse: 0.4012\n",
      "Epoch 1120/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4804 - mse: 0.4725\n",
      "Epoch 01120: saving model to Regression_Model/mle.linear-1120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4735 - val_loss: 0.4069 - val_mse: 0.3990\n",
      "Epoch 1121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4718 - val_loss: 0.4074 - val_mse: 0.3995\n",
      "Epoch 1122/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4724 - val_loss: 0.4049 - val_mse: 0.3970\n",
      "Epoch 1123/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4825 - mse: 0.4746 - val_loss: 0.4134 - val_mse: 0.4055\n",
      "Epoch 1124/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4755 - val_loss: 0.4111 - val_mse: 0.4032\n",
      "Epoch 1125/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4832 - mse: 0.4754"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=3000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-1990.ckpt'\n",
    "    #MODEL_PATH = 'Regression_Model/mae.linear-1990.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA_read\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        truth = y[i]\n",
    "        OUT.write('%s\\t%s\\t%s\\n'%(pasid[i],predict,truth))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='mle.linear'\n",
    "evaluate(train_x,train_y,train_id,trainid,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_x,valid_y,train_id,trainid,'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
