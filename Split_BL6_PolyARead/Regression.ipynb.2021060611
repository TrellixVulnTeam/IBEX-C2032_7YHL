{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 55918\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.regression.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    #train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3861275 2.4915485\n",
      "3.8266706 1.8094194\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f28c674e0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0f28bf0048>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='bl6.mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1397 steps, validate for 1397 steps\n",
      "Epoch 1/3000\n",
      "1397/1397 [==============================] - 13s 10ms/step - loss: 0.9093 - mse: 0.9027 - val_loss: 0.7528 - val_mse: 0.7458\n",
      "Epoch 2/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.7351 - mse: 0.7278 - val_loss: 0.6567 - val_mse: 0.6490\n",
      "Epoch 3/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.7292 - mse: 0.7213 - val_loss: 0.6846 - val_mse: 0.6764\n",
      "Epoch 4/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.7272 - mse: 0.7188 - val_loss: 0.6507 - val_mse: 0.6421\n",
      "Epoch 5/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.7053 - mse: 0.6966 - val_loss: 0.6833 - val_mse: 0.6746\n",
      "Epoch 6/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.7095 - mse: 0.7007 - val_loss: 0.6346 - val_mse: 0.6257\n",
      "Epoch 7/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.7057 - mse: 0.6967 - val_loss: 0.6351 - val_mse: 0.6260\n",
      "Epoch 8/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6960 - mse: 0.6869 - val_loss: 0.6421 - val_mse: 0.6329\n",
      "Epoch 9/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6966 - mse: 0.6874 - val_loss: 0.6580 - val_mse: 0.6487\n",
      "Epoch 10/3000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.6914 - mse: 0.6820\n",
      "Epoch 00010: saving model to Regression_Model/bl6.mle.linear-0010.ckpt\n",
      "1397/1397 [==============================] - 8s 6ms/step - loss: 0.6919 - mse: 0.6826 - val_loss: 0.6706 - val_mse: 0.6612\n",
      "Epoch 11/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6928 - mse: 0.6834 - val_loss: 0.6588 - val_mse: 0.6494\n",
      "Epoch 12/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.7016 - mse: 0.6921 - val_loss: 0.6271 - val_mse: 0.6176\n",
      "Epoch 13/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6906 - mse: 0.6810 - val_loss: 0.6447 - val_mse: 0.6352\n",
      "Epoch 14/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6868 - mse: 0.6772 - val_loss: 0.6596 - val_mse: 0.6500\n",
      "Epoch 15/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6854 - mse: 0.6759 - val_loss: 0.6405 - val_mse: 0.6309\n",
      "Epoch 16/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6832 - mse: 0.6737 - val_loss: 0.6279 - val_mse: 0.6183\n",
      "Epoch 17/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6855 - mse: 0.6759 - val_loss: 0.6317 - val_mse: 0.6221\n",
      "Epoch 18/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6911 - mse: 0.6815 - val_loss: 0.6434 - val_mse: 0.6337\n",
      "Epoch 19/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6827 - mse: 0.6730 - val_loss: 0.6319 - val_mse: 0.6222\n",
      "Epoch 20/3000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.6852 - mse: 0.6755\n",
      "Epoch 00020: saving model to Regression_Model/bl6.mle.linear-0020.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6856 - mse: 0.6759 - val_loss: 0.6398 - val_mse: 0.6301\n",
      "Epoch 21/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6889 - mse: 0.6792 - val_loss: 0.6417 - val_mse: 0.6320\n",
      "Epoch 22/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6875 - mse: 0.6778 - val_loss: 0.6303 - val_mse: 0.6206\n",
      "Epoch 23/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6833 - mse: 0.6736 - val_loss: 0.6347 - val_mse: 0.6249\n",
      "Epoch 24/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6817 - mse: 0.6720 - val_loss: 0.6433 - val_mse: 0.6336\n",
      "Epoch 25/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6836 - mse: 0.6739 - val_loss: 0.6277 - val_mse: 0.6179\n",
      "Epoch 26/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6846 - mse: 0.6749 - val_loss: 0.6326 - val_mse: 0.6229\n",
      "Epoch 27/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6829 - mse: 0.6731 - val_loss: 0.6490 - val_mse: 0.6393\n",
      "Epoch 28/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6828 - mse: 0.6731 - val_loss: 0.6263 - val_mse: 0.6166\n",
      "Epoch 29/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6821 - mse: 0.6723 - val_loss: 0.6320 - val_mse: 0.6223\n",
      "Epoch 30/3000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.6850 - mse: 0.6753\n",
      "Epoch 00030: saving model to Regression_Model/bl6.mle.linear-0030.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6846 - mse: 0.6749 - val_loss: 0.6371 - val_mse: 0.6274\n",
      "Epoch 31/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6814 - mse: 0.6716 - val_loss: 0.6265 - val_mse: 0.6168\n",
      "Epoch 32/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6853 - mse: 0.6756 - val_loss: 0.6417 - val_mse: 0.6319\n",
      "Epoch 33/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6844 - mse: 0.6747 - val_loss: 0.6239 - val_mse: 0.6142\n",
      "Epoch 34/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6799 - mse: 0.6702 - val_loss: 0.6305 - val_mse: 0.6208\n",
      "Epoch 35/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6834 - mse: 0.6736 - val_loss: 0.6260 - val_mse: 0.6163\n",
      "Epoch 36/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6830 - mse: 0.6732 - val_loss: 0.6700 - val_mse: 0.6603\n",
      "Epoch 37/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6805 - mse: 0.6708 - val_loss: 0.6268 - val_mse: 0.6170\n",
      "Epoch 38/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6821 - mse: 0.6724 - val_loss: 0.6239 - val_mse: 0.6142\n",
      "Epoch 39/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6826 - mse: 0.6729 - val_loss: 0.6366 - val_mse: 0.6269\n",
      "Epoch 40/3000\n",
      "1381/1397 [============================>.] - ETA: 0s - loss: 0.6824 - mse: 0.6727\n",
      "Epoch 00040: saving model to Regression_Model/bl6.mle.linear-0040.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6827 - mse: 0.6730 - val_loss: 0.6201 - val_mse: 0.6104\n",
      "Epoch 41/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6801 - mse: 0.6704 - val_loss: 0.6254 - val_mse: 0.6158\n",
      "Epoch 42/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6823 - mse: 0.6726 - val_loss: 0.6420 - val_mse: 0.6323\n",
      "Epoch 43/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6807 - mse: 0.6710 - val_loss: 0.6241 - val_mse: 0.6144\n",
      "Epoch 44/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6795 - mse: 0.6698 - val_loss: 0.6322 - val_mse: 0.6225\n",
      "Epoch 45/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6814 - mse: 0.6717 - val_loss: 0.6395 - val_mse: 0.6299\n",
      "Epoch 46/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6836 - mse: 0.6739 - val_loss: 0.6826 - val_mse: 0.6729\n",
      "Epoch 47/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6760 - mse: 0.6663 - val_loss: 0.6284 - val_mse: 0.6188\n",
      "Epoch 48/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6774 - mse: 0.6678 - val_loss: 0.6216 - val_mse: 0.6120\n",
      "Epoch 49/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6785 - mse: 0.6688 - val_loss: 0.6242 - val_mse: 0.6145\n",
      "Epoch 50/3000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.6766 - mse: 0.6670\n",
      "Epoch 00050: saving model to Regression_Model/bl6.mle.linear-0050.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6769 - mse: 0.6673 - val_loss: 0.6257 - val_mse: 0.6161\n",
      "Epoch 51/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6805 - mse: 0.6710 - val_loss: 0.6262 - val_mse: 0.6166\n",
      "Epoch 52/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6773 - mse: 0.6677 - val_loss: 0.6269 - val_mse: 0.6173\n",
      "Epoch 53/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6770 - mse: 0.6674 - val_loss: 0.6319 - val_mse: 0.6223\n",
      "Epoch 54/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6740 - mse: 0.6645 - val_loss: 0.6220 - val_mse: 0.6125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6802 - mse: 0.6706 - val_loss: 0.6312 - val_mse: 0.6216\n",
      "Epoch 56/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6806 - mse: 0.6710 - val_loss: 0.6294 - val_mse: 0.6199\n",
      "Epoch 57/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6778 - mse: 0.6683 - val_loss: 0.6245 - val_mse: 0.6150\n",
      "Epoch 58/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6712 - mse: 0.6617 - val_loss: 0.6263 - val_mse: 0.6168\n",
      "Epoch 59/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6793 - mse: 0.6698 - val_loss: 0.6211 - val_mse: 0.6116\n",
      "Epoch 60/3000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.6787 - mse: 0.6692\n",
      "Epoch 00060: saving model to Regression_Model/bl6.mle.linear-0060.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6785 - mse: 0.6691 - val_loss: 0.6262 - val_mse: 0.6168\n",
      "Epoch 61/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6742 - mse: 0.6647 - val_loss: 0.6215 - val_mse: 0.6121\n",
      "Epoch 62/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6767 - mse: 0.6673 - val_loss: 0.6256 - val_mse: 0.6162\n",
      "Epoch 63/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6754 - mse: 0.6660 - val_loss: 0.6305 - val_mse: 0.6211\n",
      "Epoch 64/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6769 - mse: 0.6675 - val_loss: 0.6262 - val_mse: 0.6168\n",
      "Epoch 65/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6733 - mse: 0.6639 - val_loss: 0.6292 - val_mse: 0.6198\n",
      "Epoch 66/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6779 - mse: 0.6685 - val_loss: 0.6282 - val_mse: 0.6188\n",
      "Epoch 67/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6764 - mse: 0.6671 - val_loss: 0.6282 - val_mse: 0.6189\n",
      "Epoch 68/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6775 - mse: 0.6682 - val_loss: 0.6232 - val_mse: 0.6139\n",
      "Epoch 69/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6739 - mse: 0.6646 - val_loss: 0.6622 - val_mse: 0.6529\n",
      "Epoch 70/3000\n",
      "1387/1397 [============================>.] - ETA: 0s - loss: 0.6735 - mse: 0.6642\n",
      "Epoch 00070: saving model to Regression_Model/bl6.mle.linear-0070.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6731 - mse: 0.6639 - val_loss: 0.6236 - val_mse: 0.6144\n",
      "Epoch 71/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6754 - mse: 0.6662 - val_loss: 0.6207 - val_mse: 0.6114\n",
      "Epoch 72/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6779 - mse: 0.6687 - val_loss: 0.6231 - val_mse: 0.6139\n",
      "Epoch 73/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6769 - mse: 0.6677 - val_loss: 0.6231 - val_mse: 0.6139\n",
      "Epoch 74/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6777 - mse: 0.6685 - val_loss: 0.6244 - val_mse: 0.6152\n",
      "Epoch 75/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6717 - mse: 0.6625 - val_loss: 0.6213 - val_mse: 0.6121\n",
      "Epoch 76/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6756 - mse: 0.6664 - val_loss: 0.6291 - val_mse: 0.6200\n",
      "Epoch 77/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6768 - mse: 0.6676 - val_loss: 0.6256 - val_mse: 0.6165\n",
      "Epoch 78/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6718 - mse: 0.6626 - val_loss: 0.6226 - val_mse: 0.6135\n",
      "Epoch 79/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6768 - mse: 0.6677 - val_loss: 0.6262 - val_mse: 0.6171\n",
      "Epoch 80/3000\n",
      "1382/1397 [============================>.] - ETA: 0s - loss: 0.6702 - mse: 0.6611\n",
      "Epoch 00080: saving model to Regression_Model/bl6.mle.linear-0080.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6709 - mse: 0.6618 - val_loss: 0.6249 - val_mse: 0.6158\n",
      "Epoch 81/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6763 - mse: 0.6672 - val_loss: 0.6292 - val_mse: 0.6201\n",
      "Epoch 82/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6753 - mse: 0.6662 - val_loss: 0.6281 - val_mse: 0.6190\n",
      "Epoch 83/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6735 - mse: 0.6644 - val_loss: 0.6223 - val_mse: 0.6133\n",
      "Epoch 84/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6760 - mse: 0.6669 - val_loss: 0.6223 - val_mse: 0.6133\n",
      "Epoch 85/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6717 - mse: 0.6627 - val_loss: 0.6204 - val_mse: 0.6114\n",
      "Epoch 86/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6724 - mse: 0.6634 - val_loss: 0.6223 - val_mse: 0.6133\n",
      "Epoch 87/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6732 - mse: 0.6642 - val_loss: 0.6201 - val_mse: 0.6111\n",
      "Epoch 88/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6755 - mse: 0.6665 - val_loss: 0.6242 - val_mse: 0.6152\n",
      "Epoch 89/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6780 - mse: 0.6691 - val_loss: 0.6372 - val_mse: 0.6282\n",
      "Epoch 90/3000\n",
      "1392/1397 [============================>.] - ETA: 0s - loss: 0.6768 - mse: 0.6678\n",
      "Epoch 00090: saving model to Regression_Model/bl6.mle.linear-0090.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6767 - mse: 0.6678 - val_loss: 0.6274 - val_mse: 0.6184\n",
      "Epoch 91/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6744 - mse: 0.6655 - val_loss: 0.6222 - val_mse: 0.6133\n",
      "Epoch 92/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6709 - mse: 0.6620 - val_loss: 0.6175 - val_mse: 0.6086\n",
      "Epoch 93/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6747 - mse: 0.6658 - val_loss: 0.6258 - val_mse: 0.6169\n",
      "Epoch 94/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6742 - mse: 0.6653 - val_loss: 0.6232 - val_mse: 0.6144\n",
      "Epoch 95/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6765 - mse: 0.6676 - val_loss: 0.6205 - val_mse: 0.6116\n",
      "Epoch 96/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6712 - mse: 0.6623 - val_loss: 0.6177 - val_mse: 0.6089\n",
      "Epoch 97/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6672 - mse: 0.6584 - val_loss: 0.6170 - val_mse: 0.6082\n",
      "Epoch 98/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6749 - mse: 0.6661 - val_loss: 0.6315 - val_mse: 0.6227\n",
      "Epoch 99/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6739 - mse: 0.6651 - val_loss: 0.6208 - val_mse: 0.6120\n",
      "Epoch 100/3000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.6750 - mse: 0.6662\n",
      "Epoch 00100: saving model to Regression_Model/bl6.mle.linear-0100.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6747 - mse: 0.6660 - val_loss: 0.6222 - val_mse: 0.6135\n",
      "Epoch 101/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6727 - mse: 0.6639 - val_loss: 0.6252 - val_mse: 0.6165\n",
      "Epoch 102/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6731 - mse: 0.6643 - val_loss: 0.6237 - val_mse: 0.6150\n",
      "Epoch 103/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6766 - mse: 0.6679 - val_loss: 0.6227 - val_mse: 0.6140\n",
      "Epoch 104/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6731 - mse: 0.6644 - val_loss: 0.6246 - val_mse: 0.6159\n",
      "Epoch 105/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6741 - mse: 0.6654 - val_loss: 0.6195 - val_mse: 0.6108\n",
      "Epoch 106/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6706 - mse: 0.6619 - val_loss: 0.6175 - val_mse: 0.6088\n",
      "Epoch 107/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6735 - mse: 0.6648 - val_loss: 0.6189 - val_mse: 0.6102\n",
      "Epoch 108/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6774 - mse: 0.6687 - val_loss: 0.6381 - val_mse: 0.6295\n",
      "Epoch 109/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6737 - mse: 0.6650 - val_loss: 0.6206 - val_mse: 0.6120\n",
      "Epoch 110/3000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.6743 - mse: 0.6656\n",
      "Epoch 00110: saving model to Regression_Model/bl6.mle.linear-0110.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6737 - mse: 0.6650 - val_loss: 0.6196 - val_mse: 0.6110\n",
      "Epoch 111/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6740 - mse: 0.6654 - val_loss: 0.6230 - val_mse: 0.6144\n",
      "Epoch 112/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6763 - mse: 0.6677 - val_loss: 0.6221 - val_mse: 0.6134\n",
      "Epoch 113/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6741 - mse: 0.6655 - val_loss: 0.6205 - val_mse: 0.6119\n",
      "Epoch 114/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6694 - mse: 0.6608 - val_loss: 0.6200 - val_mse: 0.6114\n",
      "Epoch 115/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6736 - mse: 0.6651 - val_loss: 0.6262 - val_mse: 0.6177\n",
      "Epoch 116/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6714 - mse: 0.6629 - val_loss: 0.6240 - val_mse: 0.6154\n",
      "Epoch 117/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6741 - mse: 0.6656 - val_loss: 0.6293 - val_mse: 0.6208\n",
      "Epoch 118/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6720 - mse: 0.6634 - val_loss: 0.6200 - val_mse: 0.6115\n",
      "Epoch 119/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6711 - mse: 0.6625 - val_loss: 0.6200 - val_mse: 0.6114\n",
      "Epoch 120/3000\n",
      "1383/1397 [============================>.] - ETA: 0s - loss: 0.6680 - mse: 0.6595\n",
      "Epoch 00120: saving model to Regression_Model/bl6.mle.linear-0120.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6678 - mse: 0.6592 - val_loss: 0.6303 - val_mse: 0.6218\n",
      "Epoch 121/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6746 - mse: 0.6661 - val_loss: 0.6243 - val_mse: 0.6158\n",
      "Epoch 122/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6685 - mse: 0.6599 - val_loss: 0.6219 - val_mse: 0.6134\n",
      "Epoch 123/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6695 - mse: 0.6610 - val_loss: 0.6187 - val_mse: 0.6102\n",
      "Epoch 124/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6712 - mse: 0.6627 - val_loss: 0.6211 - val_mse: 0.6126\n",
      "Epoch 125/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6701 - mse: 0.6616 - val_loss: 0.6201 - val_mse: 0.6116\n",
      "Epoch 126/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6710 - mse: 0.6625 - val_loss: 0.6214 - val_mse: 0.6129\n",
      "Epoch 127/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6701 - mse: 0.6616 - val_loss: 0.6231 - val_mse: 0.6146\n",
      "Epoch 128/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6732 - mse: 0.6648 - val_loss: 0.6221 - val_mse: 0.6136\n",
      "Epoch 129/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6690 - mse: 0.6606 - val_loss: 0.6211 - val_mse: 0.6127\n",
      "Epoch 130/3000\n",
      "1386/1397 [============================>.] - ETA: 0s - loss: 0.6677 - mse: 0.6592\n",
      "Epoch 00130: saving model to Regression_Model/bl6.mle.linear-0130.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6680 - mse: 0.6596 - val_loss: 0.6221 - val_mse: 0.6137\n",
      "Epoch 131/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6704 - mse: 0.6620 - val_loss: 0.6213 - val_mse: 0.6129\n",
      "Epoch 132/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6721 - mse: 0.6637 - val_loss: 0.6182 - val_mse: 0.6098\n",
      "Epoch 133/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6693 - mse: 0.6609 - val_loss: 0.6197 - val_mse: 0.6114\n",
      "Epoch 134/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6694 - mse: 0.6610 - val_loss: 0.6216 - val_mse: 0.6133\n",
      "Epoch 135/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6723 - mse: 0.6640 - val_loss: 0.6247 - val_mse: 0.6163\n",
      "Epoch 136/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6711 - mse: 0.6628 - val_loss: 0.6322 - val_mse: 0.6239\n",
      "Epoch 137/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6693 - mse: 0.6610 - val_loss: 0.6239 - val_mse: 0.6156\n",
      "Epoch 138/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6752 - mse: 0.6668 - val_loss: 0.6210 - val_mse: 0.6127\n",
      "Epoch 139/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6687 - mse: 0.6604 - val_loss: 0.6212 - val_mse: 0.6128\n",
      "Epoch 140/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.6736 - mse: 0.6653\n",
      "Epoch 00140: saving model to Regression_Model/bl6.mle.linear-0140.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6732 - mse: 0.6649 - val_loss: 0.6289 - val_mse: 0.6206\n",
      "Epoch 141/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6719 - mse: 0.6636 - val_loss: 0.6319 - val_mse: 0.6236\n",
      "Epoch 142/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6711 - mse: 0.6628 - val_loss: 0.6181 - val_mse: 0.6098\n",
      "Epoch 143/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6690 - mse: 0.6607 - val_loss: 0.6177 - val_mse: 0.6094\n",
      "Epoch 144/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6717 - mse: 0.6635 - val_loss: 0.6341 - val_mse: 0.6258\n",
      "Epoch 145/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6672 - mse: 0.6589 - val_loss: 0.6242 - val_mse: 0.6159\n",
      "Epoch 146/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6719 - mse: 0.6637 - val_loss: 0.6240 - val_mse: 0.6157\n",
      "Epoch 147/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6667 - mse: 0.6585 - val_loss: 0.6172 - val_mse: 0.6090\n",
      "Epoch 148/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6717 - mse: 0.6635 - val_loss: 0.6197 - val_mse: 0.6114\n",
      "Epoch 149/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6699 - mse: 0.6616 - val_loss: 0.6244 - val_mse: 0.6162\n",
      "Epoch 150/3000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.6685 - mse: 0.6603\n",
      "Epoch 00150: saving model to Regression_Model/bl6.mle.linear-0150.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6689 - mse: 0.6607 - val_loss: 0.6298 - val_mse: 0.6216\n",
      "Epoch 151/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6699 - mse: 0.6617 - val_loss: 0.6204 - val_mse: 0.6122\n",
      "Epoch 152/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6712 - mse: 0.6630 - val_loss: 0.6230 - val_mse: 0.6148\n",
      "Epoch 153/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6699 - mse: 0.6618 - val_loss: 0.6161 - val_mse: 0.6079\n",
      "Epoch 154/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6704 - mse: 0.6623 - val_loss: 0.6222 - val_mse: 0.6140\n",
      "Epoch 155/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6679 - mse: 0.6598 - val_loss: 0.6242 - val_mse: 0.6161\n",
      "Epoch 156/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6691 - mse: 0.6609 - val_loss: 0.6209 - val_mse: 0.6128\n",
      "Epoch 157/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6701 - mse: 0.6620 - val_loss: 0.6254 - val_mse: 0.6172\n",
      "Epoch 158/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6673 - mse: 0.6591 - val_loss: 0.6184 - val_mse: 0.6103\n",
      "Epoch 159/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6708 - mse: 0.6626 - val_loss: 0.6186 - val_mse: 0.6105\n",
      "Epoch 160/3000\n",
      "1392/1397 [============================>.] - ETA: 0s - loss: 0.6677 - mse: 0.6596\n",
      "Epoch 00160: saving model to Regression_Model/bl6.mle.linear-0160.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6676 - mse: 0.6595 - val_loss: 0.6198 - val_mse: 0.6116\n",
      "Epoch 161/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6700 - mse: 0.6619 - val_loss: 0.6199 - val_mse: 0.6118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6718 - mse: 0.6636 - val_loss: 0.6223 - val_mse: 0.6142\n",
      "Epoch 163/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6690 - mse: 0.6609 - val_loss: 0.6197 - val_mse: 0.6116\n",
      "Epoch 164/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6708 - mse: 0.6627 - val_loss: 0.6263 - val_mse: 0.6183\n",
      "Epoch 165/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6706 - mse: 0.6625 - val_loss: 0.6244 - val_mse: 0.6163\n",
      "Epoch 166/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6697 - mse: 0.6616 - val_loss: 0.6226 - val_mse: 0.6145\n",
      "Epoch 167/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6688 - mse: 0.6607 - val_loss: 0.6205 - val_mse: 0.6125\n",
      "Epoch 168/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6694 - mse: 0.6613 - val_loss: 0.6194 - val_mse: 0.6113\n",
      "Epoch 169/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6714 - mse: 0.6633 - val_loss: 0.6201 - val_mse: 0.6121\n",
      "Epoch 170/3000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.6735 - mse: 0.6655\n",
      "Epoch 00170: saving model to Regression_Model/bl6.mle.linear-0170.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6733 - mse: 0.6653 - val_loss: 0.6225 - val_mse: 0.6144\n",
      "Epoch 171/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6722 - mse: 0.6642 - val_loss: 0.6193 - val_mse: 0.6113\n",
      "Epoch 172/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6694 - mse: 0.6613 - val_loss: 0.6244 - val_mse: 0.6164\n",
      "Epoch 173/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6737 - mse: 0.6657 - val_loss: 0.6169 - val_mse: 0.6089\n",
      "Epoch 174/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6678 - mse: 0.6598 - val_loss: 0.6163 - val_mse: 0.6083\n",
      "Epoch 175/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6703 - mse: 0.6623 - val_loss: 0.6175 - val_mse: 0.6095\n",
      "Epoch 176/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6681 - mse: 0.6601 - val_loss: 0.6209 - val_mse: 0.6129\n",
      "Epoch 177/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6691 - mse: 0.6611 - val_loss: 0.6197 - val_mse: 0.6117\n",
      "Epoch 178/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6671 - mse: 0.6591 - val_loss: 0.6224 - val_mse: 0.6144\n",
      "Epoch 179/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6698 - mse: 0.6618 - val_loss: 0.6191 - val_mse: 0.6111\n",
      "Epoch 180/3000\n",
      "1393/1397 [============================>.] - ETA: 0s - loss: 0.6695 - mse: 0.6615\n",
      "Epoch 00180: saving model to Regression_Model/bl6.mle.linear-0180.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6693 - mse: 0.6613 - val_loss: 0.6223 - val_mse: 0.6144\n",
      "Epoch 181/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6672 - mse: 0.6592 - val_loss: 0.6182 - val_mse: 0.6103\n",
      "Epoch 182/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6674 - mse: 0.6594 - val_loss: 0.6169 - val_mse: 0.6089\n",
      "Epoch 183/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6662 - mse: 0.6582 - val_loss: 0.6190 - val_mse: 0.6110\n",
      "Epoch 184/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6675 - mse: 0.6595 - val_loss: 0.6165 - val_mse: 0.6086\n",
      "Epoch 185/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6701 - mse: 0.6621 - val_loss: 0.6206 - val_mse: 0.6126\n",
      "Epoch 186/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6668 - mse: 0.6589 - val_loss: 0.6187 - val_mse: 0.6108\n",
      "Epoch 187/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6703 - mse: 0.6624 - val_loss: 0.6180 - val_mse: 0.6101\n",
      "Epoch 188/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6649 - mse: 0.6570 - val_loss: 0.6172 - val_mse: 0.6093\n",
      "Epoch 189/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6633 - mse: 0.6553 - val_loss: 0.6197 - val_mse: 0.6118\n",
      "Epoch 190/3000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.6705 - mse: 0.6626\n",
      "Epoch 00190: saving model to Regression_Model/bl6.mle.linear-0190.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6703 - mse: 0.6624 - val_loss: 0.6207 - val_mse: 0.6128\n",
      "Epoch 191/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6679 - mse: 0.6600 - val_loss: 0.6191 - val_mse: 0.6112\n",
      "Epoch 192/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6677 - mse: 0.6598 - val_loss: 0.6177 - val_mse: 0.6098\n",
      "Epoch 193/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6673 - mse: 0.6594 - val_loss: 0.6202 - val_mse: 0.6123\n",
      "Epoch 194/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6649 - mse: 0.6570 - val_loss: 0.6168 - val_mse: 0.6089\n",
      "Epoch 195/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6660 - mse: 0.6581 - val_loss: 0.6167 - val_mse: 0.6088\n",
      "Epoch 196/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6682 - mse: 0.6603 - val_loss: 0.6215 - val_mse: 0.6137\n",
      "Epoch 197/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6644 - mse: 0.6565 - val_loss: 0.6218 - val_mse: 0.6139\n",
      "Epoch 198/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6651 - mse: 0.6572 - val_loss: 0.6257 - val_mse: 0.6179\n",
      "Epoch 199/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6655 - mse: 0.6577 - val_loss: 0.6189 - val_mse: 0.6111\n",
      "Epoch 200/3000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.6685 - mse: 0.6607\n",
      "Epoch 00200: saving model to Regression_Model/bl6.mle.linear-0200.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6684 - mse: 0.6606 - val_loss: 0.6163 - val_mse: 0.6085\n",
      "Epoch 201/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6676 - mse: 0.6597 - val_loss: 0.6219 - val_mse: 0.6141\n",
      "Epoch 202/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6679 - mse: 0.6600 - val_loss: 0.6181 - val_mse: 0.6102\n",
      "Epoch 203/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6689 - mse: 0.6611 - val_loss: 0.6191 - val_mse: 0.6113\n",
      "Epoch 204/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6662 - mse: 0.6584 - val_loss: 0.6190 - val_mse: 0.6112\n",
      "Epoch 205/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6671 - mse: 0.6592 - val_loss: 0.6168 - val_mse: 0.6089\n",
      "Epoch 206/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6644 - mse: 0.6565 - val_loss: 0.6177 - val_mse: 0.6099\n",
      "Epoch 207/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6665 - mse: 0.6587 - val_loss: 0.6189 - val_mse: 0.6111\n",
      "Epoch 208/3000\n",
      " 960/1397 [===================>..........] - ETA: 1s - loss: 0.6660 - mse: 0.6582"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=3000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-2900.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testid='bl6.mle.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
