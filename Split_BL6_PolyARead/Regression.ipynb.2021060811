{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 14753\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.predict.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    #train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    #valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    #train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493.88113 3219.6182\n",
      "5.729239 1.606415\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8bfcbcaa58>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8bfcb55f98>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "#model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='bl6.mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 368 steps, validate for 368 steps\n",
      "Epoch 1/2000\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.1778 - mse: 110.2467 - val_loss: 0.0985 - val_mse: 1.1076\n",
      "Epoch 2/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1267 - mse: 1.6401 - val_loss: 0.1220 - val_mse: 1.1218\n",
      "Epoch 3/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1206 - mse: 1.1622 - val_loss: 0.1168 - val_mse: 1.0855\n",
      "Epoch 4/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1174 - mse: 1.1297 - val_loss: 0.1103 - val_mse: 1.0576\n",
      "Epoch 5/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1097 - mse: 1.1862 - val_loss: 0.1057 - val_mse: 1.0483\n",
      "Epoch 6/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1096 - mse: 1.2284 - val_loss: 0.0890 - val_mse: 1.2557\n",
      "Epoch 7/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.1044 - mse: 1.5991 - val_loss: 0.1000 - val_mse: 1.1348\n",
      "Epoch 8/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1020 - mse: 1.9224 - val_loss: 0.0929 - val_mse: 1.2896\n",
      "Epoch 9/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1032 - mse: 1.5671 - val_loss: 0.0975 - val_mse: 1.4089\n",
      "Epoch 10/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.1041 - mse: 1.9755\n",
      "Epoch 00010: saving model to Regression_Model/bl6.mle.linear-0010.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.1041 - mse: 1.9732 - val_loss: 0.0912 - val_mse: 1.7740\n",
      "Epoch 11/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1037 - mse: 1.5943 - val_loss: 0.0997 - val_mse: 1.4137\n",
      "Epoch 12/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1024 - mse: 2.0902 - val_loss: 0.0922 - val_mse: 1.7526\n",
      "Epoch 13/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.1002 - mse: 1.5881 - val_loss: 0.0882 - val_mse: 1.5482\n",
      "Epoch 14/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0996 - mse: 2.2629 - val_loss: 0.0854 - val_mse: 1.3765\n",
      "Epoch 15/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1041 - mse: 1.6965 - val_loss: 0.0883 - val_mse: 1.5002\n",
      "Epoch 16/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1027 - mse: 1.7708 - val_loss: 0.0857 - val_mse: 1.5609\n",
      "Epoch 17/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1146 - mse: 4.6685 - val_loss: 0.1109 - val_mse: 1.1441\n",
      "Epoch 18/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1073 - mse: 1.8806 - val_loss: 0.0880 - val_mse: 1.6099\n",
      "Epoch 19/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0990 - mse: 4.4433 - val_loss: 0.0883 - val_mse: 1.5954\n",
      "Epoch 20/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.1000 - mse: 1.8453\n",
      "Epoch 00020: saving model to Regression_Model/bl6.mle.linear-0020.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.1005 - mse: 1.9431 - val_loss: 0.0857 - val_mse: 1.6440\n",
      "Epoch 21/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1010 - mse: 2.1884 - val_loss: 0.0883 - val_mse: 1.6374\n",
      "Epoch 22/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0971 - mse: 2.3300 - val_loss: 0.0858 - val_mse: 1.4680\n",
      "Epoch 23/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0960 - mse: 3.4427 - val_loss: 0.0776 - val_mse: 1.5559\n",
      "Epoch 24/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0959 - mse: 1.9355 - val_loss: 0.0918 - val_mse: 1.3716\n",
      "Epoch 25/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0985 - mse: 1.5971 - val_loss: 0.0894 - val_mse: 1.4191\n",
      "Epoch 26/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0993 - mse: 1.9294 - val_loss: 0.0852 - val_mse: 1.5114\n",
      "Epoch 27/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0992 - mse: 2.1704 - val_loss: 0.0855 - val_mse: 1.3227\n",
      "Epoch 28/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0990 - mse: 2.1083 - val_loss: 0.0947 - val_mse: 1.2300\n",
      "Epoch 29/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0952 - mse: 2.0828 - val_loss: 0.0917 - val_mse: 1.3551\n",
      "Epoch 30/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0960 - mse: 2.1638\n",
      "Epoch 00030: saving model to Regression_Model/bl6.mle.linear-0030.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0964 - mse: 2.2114 - val_loss: 0.0774 - val_mse: 1.3184\n",
      "Epoch 31/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1058 - mse: 5.3011 - val_loss: 0.1128 - val_mse: 1.2539\n",
      "Epoch 32/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1066 - mse: 1.3306 - val_loss: 0.0931 - val_mse: 1.3671\n",
      "Epoch 33/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1012 - mse: 2.8934 - val_loss: 0.0836 - val_mse: 1.3638\n",
      "Epoch 34/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0995 - mse: 2.5455 - val_loss: 0.0784 - val_mse: 1.4240\n",
      "Epoch 35/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0978 - mse: 1.9716 - val_loss: 0.0813 - val_mse: 1.3807\n",
      "Epoch 36/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0931 - mse: 3.4380 - val_loss: 0.0803 - val_mse: 1.3769\n",
      "Epoch 37/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0970 - mse: 2.3437 - val_loss: 0.0764 - val_mse: 1.3151\n",
      "Epoch 38/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0989 - mse: 2.9217 - val_loss: 0.0878 - val_mse: 1.3172\n",
      "Epoch 39/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0960 - mse: 2.0833 - val_loss: 0.0864 - val_mse: 1.2168\n",
      "Epoch 40/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.1001 - mse: 2.8317\n",
      "Epoch 00040: saving model to Regression_Model/bl6.mle.linear-0040.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.1002 - mse: 2.7949 - val_loss: 0.0883 - val_mse: 1.2773\n",
      "Epoch 41/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0969 - mse: 4.1878 - val_loss: 0.0846 - val_mse: 1.6174\n",
      "Epoch 42/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0979 - mse: 4.0779 - val_loss: 0.0857 - val_mse: 1.7822\n",
      "Epoch 43/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0959 - mse: 4.0916 - val_loss: 0.0811 - val_mse: 1.4256\n",
      "Epoch 44/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0943 - mse: 2.5783 - val_loss: 0.0814 - val_mse: 1.3831\n",
      "Epoch 45/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1027 - mse: 2.2091 - val_loss: 0.1055 - val_mse: 1.3031\n",
      "Epoch 46/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1001 - mse: 1.8809 - val_loss: 0.0852 - val_mse: 1.4914\n",
      "Epoch 47/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0974 - mse: 1.7883 - val_loss: 0.0921 - val_mse: 1.2315\n",
      "Epoch 48/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0962 - mse: 3.4744 - val_loss: 0.0901 - val_mse: 1.1989\n",
      "Epoch 49/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0976 - mse: 1.8399 - val_loss: 0.0949 - val_mse: 1.3341\n",
      "Epoch 50/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0963 - mse: 2.2688\n",
      "Epoch 00050: saving model to Regression_Model/bl6.mle.linear-0050.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0970 - mse: 2.3415 - val_loss: 0.0861 - val_mse: 1.5447\n",
      "Epoch 51/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0970 - mse: 1.6393 - val_loss: 0.0918 - val_mse: 1.3791\n",
      "Epoch 52/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0952 - mse: 5.3907 - val_loss: 0.0895 - val_mse: 1.3704\n",
      "Epoch 53/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0962 - mse: 2.1231 - val_loss: 0.0839 - val_mse: 2.5555\n",
      "Epoch 54/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0948 - mse: 6.2663 - val_loss: 0.0927 - val_mse: 2.1555\n",
      "Epoch 55/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0969 - mse: 4.1871 - val_loss: 0.0824 - val_mse: 2.2994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0959 - mse: 6.9381 - val_loss: 0.0803 - val_mse: 2.1671\n",
      "Epoch 57/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0976 - mse: 1.8912 - val_loss: 0.0810 - val_mse: 1.9735\n",
      "Epoch 58/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0980 - mse: 2.0065 - val_loss: 0.0873 - val_mse: 1.6613\n",
      "Epoch 59/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0916 - mse: 1.7051 - val_loss: 0.0801 - val_mse: 1.6802\n",
      "Epoch 60/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0948 - mse: 3.3021\n",
      "Epoch 00060: saving model to Regression_Model/bl6.mle.linear-0060.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0945 - mse: 3.4920 - val_loss: 0.0790 - val_mse: 1.7066\n",
      "Epoch 61/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0959 - mse: 1.6851 - val_loss: 0.0793 - val_mse: 1.6459\n",
      "Epoch 62/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0933 - mse: 2.9761 - val_loss: 0.0820 - val_mse: 1.4511\n",
      "Epoch 63/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0933 - mse: 1.5786 - val_loss: 0.0804 - val_mse: 1.3982\n",
      "Epoch 64/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0974 - mse: 1.9954 - val_loss: 0.0808 - val_mse: 1.6416\n",
      "Epoch 65/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0947 - mse: 2.5551 - val_loss: 0.0818 - val_mse: 1.4164\n",
      "Epoch 66/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0904 - mse: 1.5599 - val_loss: 0.0779 - val_mse: 1.2566\n",
      "Epoch 67/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0931 - mse: 2.9667 - val_loss: 0.0813 - val_mse: 1.7224\n",
      "Epoch 68/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0975 - mse: 1.3289 - val_loss: 0.1139 - val_mse: 1.0891\n",
      "Epoch 69/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1167 - mse: 1.1461 - val_loss: 0.1128 - val_mse: 1.0916\n",
      "Epoch 70/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.1154 - mse: 1.3880\n",
      "Epoch 00070: saving model to Regression_Model/bl6.mle.linear-0070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1154 - mse: 1.3865 - val_loss: 0.1096 - val_mse: 1.1058\n",
      "Epoch 71/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1138 - mse: 1.5363 - val_loss: 0.1059 - val_mse: 1.1652\n",
      "Epoch 72/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1112 - mse: 1.2991 - val_loss: 0.1046 - val_mse: 1.2037\n",
      "Epoch 73/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1131 - mse: 1.4305 - val_loss: 0.1031 - val_mse: 1.1946\n",
      "Epoch 74/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1099 - mse: 1.9497 - val_loss: 0.1012 - val_mse: 1.2604\n",
      "Epoch 75/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1079 - mse: 2.5945 - val_loss: 0.0978 - val_mse: 1.3485\n",
      "Epoch 76/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1033 - mse: 3.1051 - val_loss: 0.0884 - val_mse: 1.6033\n",
      "Epoch 77/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0955 - mse: 2.0176 - val_loss: 0.0831 - val_mse: 1.6426\n",
      "Epoch 78/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0942 - mse: 3.2307 - val_loss: 0.0762 - val_mse: 1.5297\n",
      "Epoch 79/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0948 - mse: 2.0802 - val_loss: 0.0793 - val_mse: 1.2067\n",
      "Epoch 80/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0909 - mse: 1.4237\n",
      "Epoch 00080: saving model to Regression_Model/bl6.mle.linear-0080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0913 - mse: 1.4097 - val_loss: 0.0805 - val_mse: 1.1905\n",
      "Epoch 81/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0903 - mse: 3.2130 - val_loss: 0.0774 - val_mse: 1.5442\n",
      "Epoch 82/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0932 - mse: 6.4192 - val_loss: 0.0774 - val_mse: 1.5489\n",
      "Epoch 83/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0905 - mse: 3.2754 - val_loss: 0.0765 - val_mse: 1.5714\n",
      "Epoch 84/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0929 - mse: 4.4115 - val_loss: 0.0781 - val_mse: 1.4781\n",
      "Epoch 85/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0919 - mse: 4.9928 - val_loss: 0.0802 - val_mse: 1.3462\n",
      "Epoch 86/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0933 - mse: 3.3653 - val_loss: 0.0892 - val_mse: 1.3616\n",
      "Epoch 87/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0943 - mse: 2.8908 - val_loss: 0.0786 - val_mse: 1.4766\n",
      "Epoch 88/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0937 - mse: 3.3505 - val_loss: 0.0866 - val_mse: 1.3240\n",
      "Epoch 89/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0899 - mse: 3.3097 - val_loss: 0.0815 - val_mse: 1.5981\n",
      "Epoch 90/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0926 - mse: 2.2557\n",
      "Epoch 00090: saving model to Regression_Model/bl6.mle.linear-0090.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0926 - mse: 2.2376 - val_loss: 0.0793 - val_mse: 1.3070\n",
      "Epoch 91/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0940 - mse: 2.9518 - val_loss: 0.0847 - val_mse: 1.2705\n",
      "Epoch 92/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0920 - mse: 2.0706 - val_loss: 0.0864 - val_mse: 1.2518\n",
      "Epoch 93/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0933 - mse: 2.6039 - val_loss: 0.0825 - val_mse: 1.5097\n",
      "Epoch 94/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0925 - mse: 2.0324 - val_loss: 0.0780 - val_mse: 1.1920\n",
      "Epoch 95/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0915 - mse: 1.6916 - val_loss: 0.0826 - val_mse: 1.1417\n",
      "Epoch 96/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0904 - mse: 1.5638 - val_loss: 0.0804 - val_mse: 1.3778\n",
      "Epoch 97/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0899 - mse: 2.7880 - val_loss: 0.0800 - val_mse: 1.3592\n",
      "Epoch 98/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0930 - mse: 2.3688 - val_loss: 0.0824 - val_mse: 1.1426\n",
      "Epoch 99/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0917 - mse: 1.4000 - val_loss: 0.0750 - val_mse: 1.1410\n",
      "Epoch 100/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0892 - mse: 2.5548\n",
      "Epoch 00100: saving model to Regression_Model/bl6.mle.linear-0100.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0889 - mse: 2.5093 - val_loss: 0.0752 - val_mse: 1.1303\n",
      "Epoch 101/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1020 - mse: 2.2425 - val_loss: 0.0823 - val_mse: 1.2174\n",
      "Epoch 102/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0940 - mse: 2.9191 - val_loss: 0.0902 - val_mse: 1.2903\n",
      "Epoch 103/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0926 - mse: 2.9603 - val_loss: 0.0750 - val_mse: 1.2620\n",
      "Epoch 104/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0937 - mse: 2.4365 - val_loss: 0.0832 - val_mse: 1.2346\n",
      "Epoch 105/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0916 - mse: 2.2313 - val_loss: 0.0765 - val_mse: 1.2529\n",
      "Epoch 106/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0902 - mse: 2.4164 - val_loss: 0.0787 - val_mse: 1.4068\n",
      "Epoch 107/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0909 - mse: 2.5975 - val_loss: 0.0799 - val_mse: 1.2764\n",
      "Epoch 108/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0886 - mse: 1.5646 - val_loss: 0.0806 - val_mse: 1.3223\n",
      "Epoch 109/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0938 - mse: 5.3836 - val_loss: 0.0789 - val_mse: 1.4896\n",
      "Epoch 110/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0929 - mse: 4.5358\n",
      "Epoch 00110: saving model to Regression_Model/bl6.mle.linear-0110.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0929 - mse: 4.5162 - val_loss: 0.0764 - val_mse: 1.2250\n",
      "Epoch 111/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0915 - mse: 2.9837 - val_loss: 0.0764 - val_mse: 1.3048\n",
      "Epoch 112/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0948 - mse: 1.8563 - val_loss: 0.0767 - val_mse: 1.2416\n",
      "Epoch 113/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0893 - mse: 2.7257 - val_loss: 0.0747 - val_mse: 1.2291\n",
      "Epoch 114/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0902 - mse: 2.5771 - val_loss: 0.0778 - val_mse: 1.1330\n",
      "Epoch 115/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0929 - mse: 3.9081 - val_loss: 0.0825 - val_mse: 1.1968\n",
      "Epoch 116/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0936 - mse: 1.8304 - val_loss: 0.0997 - val_mse: 1.1612\n",
      "Epoch 117/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0992 - mse: 1.7344 - val_loss: 0.0941 - val_mse: 1.3360\n",
      "Epoch 118/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0953 - mse: 2.3568 - val_loss: 0.0789 - val_mse: 1.5079\n",
      "Epoch 119/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0903 - mse: 1.8627 - val_loss: 0.0803 - val_mse: 1.6969\n",
      "Epoch 120/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.1072 - mse: 3.3525\n",
      "Epoch 00120: saving model to Regression_Model/bl6.mle.linear-0120.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.1071 - mse: 3.3298 - val_loss: 0.0766 - val_mse: 1.3261\n",
      "Epoch 121/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0967 - mse: 1.7071 - val_loss: 0.0935 - val_mse: 1.4404\n",
      "Epoch 122/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0948 - mse: 4.4667 - val_loss: 0.0750 - val_mse: 1.3744\n",
      "Epoch 123/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0912 - mse: 2.4999 - val_loss: 0.0737 - val_mse: 1.2991\n",
      "Epoch 124/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0912 - mse: 2.2699 - val_loss: 0.0832 - val_mse: 1.3678\n",
      "Epoch 125/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0908 - mse: 2.6983 - val_loss: 0.0775 - val_mse: 1.3877\n",
      "Epoch 126/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1064 - mse: 4.8858 - val_loss: 0.0873 - val_mse: 1.2198\n",
      "Epoch 127/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0921 - mse: 2.6176 - val_loss: 0.0763 - val_mse: 1.2620\n",
      "Epoch 128/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0890 - mse: 2.0313 - val_loss: 0.0753 - val_mse: 1.2288\n",
      "Epoch 129/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0924 - mse: 2.4854 - val_loss: 0.0908 - val_mse: 1.3770\n",
      "Epoch 130/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0922 - mse: 4.6700\n",
      "Epoch 00130: saving model to Regression_Model/bl6.mle.linear-0130.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0921 - mse: 4.5077 - val_loss: 0.0774 - val_mse: 1.3401\n",
      "Epoch 131/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0891 - mse: 6.6274 - val_loss: 0.0779 - val_mse: 1.4398\n",
      "Epoch 132/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0878 - mse: 3.3561 - val_loss: 0.0741 - val_mse: 1.2613\n",
      "Epoch 133/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0881 - mse: 2.6150 - val_loss: 0.0755 - val_mse: 1.4200\n",
      "Epoch 134/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0908 - mse: 2.7487 - val_loss: 0.0735 - val_mse: 1.2761\n",
      "Epoch 135/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0908 - mse: 1.9628 - val_loss: 0.0734 - val_mse: 1.2624\n",
      "Epoch 136/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0899 - mse: 3.3731 - val_loss: 0.0763 - val_mse: 1.4587\n",
      "Epoch 137/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0912 - mse: 5.1430 - val_loss: 0.0733 - val_mse: 1.2849\n",
      "Epoch 138/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0954 - mse: 5.9184 - val_loss: 0.0837 - val_mse: 1.6887\n",
      "Epoch 139/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0894 - mse: 2.9864 - val_loss: 0.0773 - val_mse: 1.3311\n",
      "Epoch 140/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0912 - mse: 3.2586\n",
      "Epoch 00140: saving model to Regression_Model/bl6.mle.linear-0140.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0914 - mse: 3.1997 - val_loss: 0.0729 - val_mse: 1.2051\n",
      "Epoch 141/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0930 - mse: 3.7735 - val_loss: 0.0799 - val_mse: 1.1654\n",
      "Epoch 142/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0919 - mse: 1.5727 - val_loss: 0.0748 - val_mse: 1.2786\n",
      "Epoch 143/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0901 - mse: 3.2140 - val_loss: 0.0800 - val_mse: 1.5350\n",
      "Epoch 144/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0868 - mse: 2.1570 - val_loss: 0.0737 - val_mse: 1.4305\n",
      "Epoch 145/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0900 - mse: 2.8399 - val_loss: 0.0727 - val_mse: 1.3137\n",
      "Epoch 146/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0875 - mse: 2.1438 - val_loss: 0.0799 - val_mse: 1.2906\n",
      "Epoch 147/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0926 - mse: 2.7275 - val_loss: 0.0779 - val_mse: 1.4896\n",
      "Epoch 148/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0946 - mse: 1.7498 - val_loss: 0.0821 - val_mse: 1.4635\n",
      "Epoch 149/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0940 - mse: 2.1930 - val_loss: 0.0791 - val_mse: 1.3108\n",
      "Epoch 150/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0891 - mse: 2.1786\n",
      "Epoch 00150: saving model to Regression_Model/bl6.mle.linear-0150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0888 - mse: 2.1332 - val_loss: 0.0815 - val_mse: 1.1931\n",
      "Epoch 151/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0924 - mse: 1.7695 - val_loss: 0.0753 - val_mse: 1.2119\n",
      "Epoch 152/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0953 - mse: 1.6872 - val_loss: 0.0795 - val_mse: 1.3979\n",
      "Epoch 153/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0927 - mse: 1.4098 - val_loss: 0.0878 - val_mse: 1.2546\n",
      "Epoch 154/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0908 - mse: 1.8023 - val_loss: 0.0740 - val_mse: 1.2834\n",
      "Epoch 155/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0898 - mse: 2.9438 - val_loss: 0.0781 - val_mse: 1.4023\n",
      "Epoch 156/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0969 - mse: 2.0390 - val_loss: 0.0733 - val_mse: 1.3812\n",
      "Epoch 157/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0903 - mse: 1.8933 - val_loss: 0.0785 - val_mse: 1.2878\n",
      "Epoch 158/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0899 - mse: 2.3908 - val_loss: 0.0788 - val_mse: 1.1942\n",
      "Epoch 159/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0927 - mse: 2.4404 - val_loss: 0.0827 - val_mse: 1.2964\n",
      "Epoch 160/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0895 - mse: 2.4249\n",
      "Epoch 00160: saving model to Regression_Model/bl6.mle.linear-0160.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0898 - mse: 2.3968 - val_loss: 0.0784 - val_mse: 1.1423\n",
      "Epoch 161/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0894 - mse: 1.9109 - val_loss: 0.0727 - val_mse: 1.1962\n",
      "Epoch 162/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0926 - mse: 1.8667 - val_loss: 0.0797 - val_mse: 1.8758\n",
      "Epoch 163/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0906 - mse: 2.4882 - val_loss: 0.0822 - val_mse: 1.7606\n",
      "Epoch 164/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0917 - mse: 2.2086 - val_loss: 0.0744 - val_mse: 1.8117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0880 - mse: 5.4847 - val_loss: 0.0732 - val_mse: 1.9013\n",
      "Epoch 166/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0961 - mse: 2.9329 - val_loss: 0.0759 - val_mse: 1.6116\n",
      "Epoch 167/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0902 - mse: 3.4987 - val_loss: 0.0775 - val_mse: 1.6965\n",
      "Epoch 168/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0927 - mse: 5.1453 - val_loss: 0.0793 - val_mse: 1.7555\n",
      "Epoch 169/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0883 - mse: 2.3731 - val_loss: 0.0768 - val_mse: 1.8670\n",
      "Epoch 170/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0897 - mse: 5.3075\n",
      "Epoch 00170: saving model to Regression_Model/bl6.mle.linear-0170.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0895 - mse: 5.2050 - val_loss: 0.0730 - val_mse: 1.7530\n",
      "Epoch 171/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0904 - mse: 1.7693 - val_loss: 0.0827 - val_mse: 1.5173\n",
      "Epoch 172/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0928 - mse: 3.1836 - val_loss: 0.0716 - val_mse: 1.5065\n",
      "Epoch 173/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0887 - mse: 7.1059 - val_loss: 0.0786 - val_mse: 1.5357\n",
      "Epoch 174/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0889 - mse: 2.1108 - val_loss: 0.0731 - val_mse: 1.4750\n",
      "Epoch 175/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0945 - mse: 5.2182 - val_loss: 0.0753 - val_mse: 1.5802\n",
      "Epoch 176/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0887 - mse: 2.8248 - val_loss: 0.0776 - val_mse: 1.3701\n",
      "Epoch 177/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0919 - mse: 2.9973 - val_loss: 0.0775 - val_mse: 1.3678\n",
      "Epoch 178/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0925 - mse: 2.2987 - val_loss: 0.0729 - val_mse: 1.6088\n",
      "Epoch 179/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0907 - mse: 3.1143 - val_loss: 0.0739 - val_mse: 1.3871\n",
      "Epoch 180/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0909 - mse: 4.1119\n",
      "Epoch 00180: saving model to Regression_Model/bl6.mle.linear-0180.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0909 - mse: 3.9945 - val_loss: 0.0746 - val_mse: 1.5145\n",
      "Epoch 181/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0898 - mse: 3.3818 - val_loss: 0.0751 - val_mse: 1.2476\n",
      "Epoch 182/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0895 - mse: 1.9625 - val_loss: 0.0776 - val_mse: 1.4951\n",
      "Epoch 183/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0906 - mse: 2.5043 - val_loss: 0.0742 - val_mse: 1.3360\n",
      "Epoch 184/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0935 - mse: 1.8611 - val_loss: 0.0755 - val_mse: 1.6071\n",
      "Epoch 185/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0917 - mse: 1.7572 - val_loss: 0.0728 - val_mse: 1.3450\n",
      "Epoch 186/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0951 - mse: 4.1693 - val_loss: 0.0747 - val_mse: 1.3354\n",
      "Epoch 187/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0925 - mse: 2.1627 - val_loss: 0.0919 - val_mse: 1.4205\n",
      "Epoch 188/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0928 - mse: 1.4013 - val_loss: 0.0725 - val_mse: 1.2815\n",
      "Epoch 189/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0859 - mse: 3.1670 - val_loss: 0.0758 - val_mse: 1.2158\n",
      "Epoch 190/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0906 - mse: 2.4394\n",
      "Epoch 00190: saving model to Regression_Model/bl6.mle.linear-0190.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0906 - mse: 2.4359 - val_loss: 0.0867 - val_mse: 1.2525\n",
      "Epoch 191/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0898 - mse: 1.6919 - val_loss: 0.0726 - val_mse: 1.2924\n",
      "Epoch 192/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0901 - mse: 2.0401 - val_loss: 0.0794 - val_mse: 1.1525\n",
      "Epoch 193/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1015 - mse: 1.9868 - val_loss: 0.0949 - val_mse: 1.1999\n",
      "Epoch 194/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0942 - mse: 1.7671 - val_loss: 0.0742 - val_mse: 1.2210\n",
      "Epoch 195/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0875 - mse: 2.2057 - val_loss: 0.0877 - val_mse: 1.3036\n",
      "Epoch 196/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0884 - mse: 2.2218 - val_loss: 0.0796 - val_mse: 1.2386\n",
      "Epoch 197/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0879 - mse: 2.3126 - val_loss: 0.0798 - val_mse: 1.1803\n",
      "Epoch 198/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0893 - mse: 2.9129 - val_loss: 0.0753 - val_mse: 1.1331\n",
      "Epoch 199/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0894 - mse: 1.8134 - val_loss: 0.0809 - val_mse: 1.1534\n",
      "Epoch 200/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0878 - mse: 2.1307\n",
      "Epoch 00200: saving model to Regression_Model/bl6.mle.linear-0200.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0876 - mse: 2.1169 - val_loss: 0.0747 - val_mse: 1.5051\n",
      "Epoch 201/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0865 - mse: 2.0663 - val_loss: 0.0741 - val_mse: 1.2731\n",
      "Epoch 202/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0860 - mse: 2.1974 - val_loss: 0.0741 - val_mse: 1.3619\n",
      "Epoch 203/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0909 - mse: 2.5586 - val_loss: 0.0772 - val_mse: 1.3053\n",
      "Epoch 204/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0892 - mse: 1.4954 - val_loss: 0.0723 - val_mse: 1.4461\n",
      "Epoch 205/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0890 - mse: 2.1602 - val_loss: 0.0718 - val_mse: 1.3295\n",
      "Epoch 206/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0906 - mse: 2.7442 - val_loss: 0.0778 - val_mse: 1.3162\n",
      "Epoch 207/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0921 - mse: 3.0518 - val_loss: 0.0803 - val_mse: 1.3015\n",
      "Epoch 208/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0909 - mse: 3.0801 - val_loss: 0.0814 - val_mse: 1.3465\n",
      "Epoch 209/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0899 - mse: 1.8728 - val_loss: 0.0744 - val_mse: 1.2347\n",
      "Epoch 210/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0914 - mse: 1.8955\n",
      "Epoch 00210: saving model to Regression_Model/bl6.mle.linear-0210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0920 - mse: 1.9066 - val_loss: 0.0881 - val_mse: 1.2130\n",
      "Epoch 211/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0906 - mse: 2.0793 - val_loss: 0.0729 - val_mse: 1.1513\n",
      "Epoch 212/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0871 - mse: 1.6261 - val_loss: 0.0801 - val_mse: 1.4441\n",
      "Epoch 213/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0897 - mse: 1.8021 - val_loss: 0.0743 - val_mse: 1.1799\n",
      "Epoch 214/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0877 - mse: 2.7802 - val_loss: 0.0751 - val_mse: 1.1078\n",
      "Epoch 215/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0886 - mse: 2.3878 - val_loss: 0.0748 - val_mse: 1.0522\n",
      "Epoch 216/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0887 - mse: 1.7948 - val_loss: 0.0752 - val_mse: 1.0778\n",
      "Epoch 217/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0868 - mse: 1.3351 - val_loss: 0.0726 - val_mse: 1.1061\n",
      "Epoch 218/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0891 - mse: 3.1478 - val_loss: 0.0786 - val_mse: 1.3528\n",
      "Epoch 219/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0905 - mse: 1.6462 - val_loss: 0.0740 - val_mse: 1.0171\n",
      "Epoch 220/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0874 - mse: 1.5248\n",
      "Epoch 00220: saving model to Regression_Model/bl6.mle.linear-0220.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0876 - mse: 1.5164 - val_loss: 0.0713 - val_mse: 0.9918\n",
      "Epoch 221/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0865 - mse: 4.7650 - val_loss: 0.0729 - val_mse: 1.3040\n",
      "Epoch 222/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0880 - mse: 2.5676 - val_loss: 0.0737 - val_mse: 1.3383\n",
      "Epoch 223/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0914 - mse: 2.1283 - val_loss: 0.0724 - val_mse: 1.3213\n",
      "Epoch 224/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0875 - mse: 2.2289 - val_loss: 0.0725 - val_mse: 1.3381\n",
      "Epoch 225/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0865 - mse: 1.9628 - val_loss: 0.0766 - val_mse: 1.2381\n",
      "Epoch 226/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0866 - mse: 3.0585 - val_loss: 0.0723 - val_mse: 1.1894\n",
      "Epoch 227/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0915 - mse: 1.8358 - val_loss: 0.0792 - val_mse: 1.1081\n",
      "Epoch 228/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0881 - mse: 2.1132 - val_loss: 0.0784 - val_mse: 1.2269\n",
      "Epoch 229/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0877 - mse: 1.6687 - val_loss: 0.0725 - val_mse: 1.2326\n",
      "Epoch 230/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0876 - mse: 1.8896\n",
      "Epoch 00230: saving model to Regression_Model/bl6.mle.linear-0230.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0877 - mse: 2.0473 - val_loss: 0.0757 - val_mse: 1.1658\n",
      "Epoch 231/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0904 - mse: 2.5538 - val_loss: 0.0755 - val_mse: 1.2873\n",
      "Epoch 232/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0870 - mse: 1.6792 - val_loss: 0.0784 - val_mse: 1.1093\n",
      "Epoch 233/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0860 - mse: 1.8109 - val_loss: 0.0733 - val_mse: 1.1554\n",
      "Epoch 234/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0903 - mse: 1.6961 - val_loss: 0.0770 - val_mse: 1.1064\n",
      "Epoch 235/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0881 - mse: 3.4845 - val_loss: 0.0863 - val_mse: 1.0690\n",
      "Epoch 236/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0912 - mse: 1.9522 - val_loss: 0.0726 - val_mse: 1.1271\n",
      "Epoch 237/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0868 - mse: 2.2418 - val_loss: 0.0936 - val_mse: 1.0209\n",
      "Epoch 238/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0949 - mse: 2.6880 - val_loss: 0.0745 - val_mse: 1.0904\n",
      "Epoch 239/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0910 - mse: 2.7867 - val_loss: 0.0744 - val_mse: 1.1238\n",
      "Epoch 240/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0864 - mse: 1.7441\n",
      "Epoch 00240: saving model to Regression_Model/bl6.mle.linear-0240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0867 - mse: 1.7338 - val_loss: 0.0715 - val_mse: 1.0232\n",
      "Epoch 241/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0856 - mse: 2.1497 - val_loss: 0.0739 - val_mse: 1.1337\n",
      "Epoch 242/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0928 - mse: 2.2743 - val_loss: 0.0748 - val_mse: 1.0086\n",
      "Epoch 243/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0900 - mse: 2.1725 - val_loss: 0.0722 - val_mse: 1.0477\n",
      "Epoch 244/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0888 - mse: 1.7528 - val_loss: 0.0750 - val_mse: 1.0077\n",
      "Epoch 245/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0905 - mse: 1.9542 - val_loss: 0.0756 - val_mse: 0.9358\n",
      "Epoch 246/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0890 - mse: 1.4581 - val_loss: 0.0779 - val_mse: 0.9491\n",
      "Epoch 247/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0887 - mse: 1.5038 - val_loss: 0.0733 - val_mse: 0.9868\n",
      "Epoch 248/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0838 - mse: 3.1984 - val_loss: 0.0738 - val_mse: 0.9689\n",
      "Epoch 249/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0851 - mse: 1.4507 - val_loss: 0.0835 - val_mse: 0.9906\n",
      "Epoch 250/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0903 - mse: 1.5501\n",
      "Epoch 00250: saving model to Regression_Model/bl6.mle.linear-0250.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0902 - mse: 1.5458 - val_loss: 0.0749 - val_mse: 1.0392\n",
      "Epoch 251/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0894 - mse: 2.2354 - val_loss: 0.0744 - val_mse: 1.2290\n",
      "Epoch 252/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0884 - mse: 1.4363 - val_loss: 0.0732 - val_mse: 1.3954\n",
      "Epoch 253/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0854 - mse: 2.4341 - val_loss: 0.0717 - val_mse: 1.1376\n",
      "Epoch 254/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0917 - mse: 1.7189 - val_loss: 0.0841 - val_mse: 1.1970\n",
      "Epoch 255/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0873 - mse: 2.1083 - val_loss: 0.0814 - val_mse: 1.1436\n",
      "Epoch 256/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0884 - mse: 2.0922 - val_loss: 0.0738 - val_mse: 1.2673\n",
      "Epoch 257/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0881 - mse: 3.9013 - val_loss: 0.0704 - val_mse: 1.1250\n",
      "Epoch 258/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0894 - mse: 5.1789 - val_loss: 0.0893 - val_mse: 1.2006\n",
      "Epoch 259/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0850 - mse: 3.1623 - val_loss: 0.0726 - val_mse: 1.1523\n",
      "Epoch 260/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0915 - mse: 1.9111\n",
      "Epoch 00260: saving model to Regression_Model/bl6.mle.linear-0260.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0921 - mse: 1.9136 - val_loss: 0.0809 - val_mse: 1.2740\n",
      "Epoch 261/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0895 - mse: 2.9829 - val_loss: 0.0753 - val_mse: 1.2070\n",
      "Epoch 262/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0868 - mse: 2.3692 - val_loss: 0.0783 - val_mse: 1.2938\n",
      "Epoch 263/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0870 - mse: 1.5536 - val_loss: 0.0771 - val_mse: 1.1543\n",
      "Epoch 264/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0877 - mse: 1.5145 - val_loss: 0.0765 - val_mse: 1.1073\n",
      "Epoch 265/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0903 - mse: 2.9359 - val_loss: 0.0758 - val_mse: 1.1487\n",
      "Epoch 266/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0892 - mse: 1.8939 - val_loss: 0.0731 - val_mse: 1.1250\n",
      "Epoch 267/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0850 - mse: 2.1855 - val_loss: 0.0719 - val_mse: 1.1025\n",
      "Epoch 268/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0891 - mse: 1.9518 - val_loss: 0.0740 - val_mse: 1.1766\n",
      "Epoch 269/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0898 - mse: 1.4034 - val_loss: 0.0717 - val_mse: 1.0642\n",
      "Epoch 270/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0902 - mse: 2.2209\n",
      "Epoch 00270: saving model to Regression_Model/bl6.mle.linear-0270.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0900 - mse: 2.1794 - val_loss: 0.0805 - val_mse: 1.0561\n",
      "Epoch 271/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0923 - mse: 2.3255 - val_loss: 0.0875 - val_mse: 1.0910\n",
      "Epoch 272/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0883 - mse: 1.3480 - val_loss: 0.0709 - val_mse: 1.1168\n",
      "Epoch 273/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0857 - mse: 2.6270 - val_loss: 0.0802 - val_mse: 1.3757\n",
      "Epoch 274/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0891 - mse: 2.2858 - val_loss: 0.0735 - val_mse: 1.3285\n",
      "Epoch 275/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0896 - mse: 4.0842 - val_loss: 0.0707 - val_mse: 1.3047\n",
      "Epoch 276/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0899 - mse: 2.8543 - val_loss: 0.0719 - val_mse: 1.0724\n",
      "Epoch 277/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0879 - mse: 1.6127 - val_loss: 0.0730 - val_mse: 1.1183\n",
      "Epoch 278/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0898 - mse: 5.4877 - val_loss: 0.0746 - val_mse: 1.2671\n",
      "Epoch 279/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0864 - mse: 3.4070 - val_loss: 0.0832 - val_mse: 1.1284\n",
      "Epoch 280/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0886 - mse: 3.5497\n",
      "Epoch 00280: saving model to Regression_Model/bl6.mle.linear-0280.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0888 - mse: 3.4550 - val_loss: 0.0767 - val_mse: 1.3224\n",
      "Epoch 281/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0885 - mse: 1.8271 - val_loss: 0.0772 - val_mse: 1.2401\n",
      "Epoch 282/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0887 - mse: 2.5034 - val_loss: 0.0709 - val_mse: 1.0914\n",
      "Epoch 283/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0873 - mse: 2.7278 - val_loss: 0.0725 - val_mse: 1.0625\n",
      "Epoch 284/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0884 - mse: 2.9869 - val_loss: 0.0758 - val_mse: 1.2088\n",
      "Epoch 285/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0847 - mse: 1.7680 - val_loss: 0.0702 - val_mse: 1.0565\n",
      "Epoch 286/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0849 - mse: 2.5157 - val_loss: 0.0732 - val_mse: 1.1023\n",
      "Epoch 287/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0872 - mse: 1.6523 - val_loss: 0.0715 - val_mse: 1.1055\n",
      "Epoch 288/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0883 - mse: 1.8068 - val_loss: 0.0910 - val_mse: 2.1624\n",
      "Epoch 289/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0889 - mse: 1.4500 - val_loss: 0.0730 - val_mse: 1.0990\n",
      "Epoch 290/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0865 - mse: 2.3382\n",
      "Epoch 00290: saving model to Regression_Model/bl6.mle.linear-0290.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0879 - mse: 2.4241 - val_loss: 0.0717 - val_mse: 1.0433\n",
      "Epoch 291/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0873 - mse: 2.6367 - val_loss: 0.0720 - val_mse: 1.0360\n",
      "Epoch 292/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0900 - mse: 1.6336 - val_loss: 0.0761 - val_mse: 1.3440\n",
      "Epoch 293/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0885 - mse: 2.2609 - val_loss: 0.0720 - val_mse: 1.0818\n",
      "Epoch 294/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0881 - mse: 2.2408 - val_loss: 0.0736 - val_mse: 1.1386\n",
      "Epoch 295/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0859 - mse: 2.2535 - val_loss: 0.0710 - val_mse: 1.1209\n",
      "Epoch 296/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 4.2401 - val_loss: 0.0741 - val_mse: 1.1872\n",
      "Epoch 297/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0869 - mse: 2.9889 - val_loss: 0.0731 - val_mse: 1.1732\n",
      "Epoch 298/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0894 - mse: 2.2574 - val_loss: 0.0781 - val_mse: 1.0599\n",
      "Epoch 299/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0890 - mse: 3.3344 - val_loss: 0.0742 - val_mse: 1.1945\n",
      "Epoch 300/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0853 - mse: 2.7184\n",
      "Epoch 00300: saving model to Regression_Model/bl6.mle.linear-0300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0853 - mse: 2.7017 - val_loss: 0.0724 - val_mse: 1.1173\n",
      "Epoch 301/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0848 - mse: 1.3989 - val_loss: 0.0804 - val_mse: 1.5472\n",
      "Epoch 302/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0883 - mse: 2.0173 - val_loss: 0.0716 - val_mse: 1.1164\n",
      "Epoch 303/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0879 - mse: 1.8643 - val_loss: 0.0761 - val_mse: 1.1338\n",
      "Epoch 304/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0890 - mse: 2.6814 - val_loss: 0.0723 - val_mse: 1.1970\n",
      "Epoch 305/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0874 - mse: 2.1452 - val_loss: 0.0724 - val_mse: 1.1354\n",
      "Epoch 306/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0864 - mse: 1.7362 - val_loss: 0.0724 - val_mse: 1.0205\n",
      "Epoch 307/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0877 - mse: 1.4759 - val_loss: 0.0730 - val_mse: 1.1411\n",
      "Epoch 308/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0848 - mse: 2.2449 - val_loss: 0.0737 - val_mse: 1.0255\n",
      "Epoch 309/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0888 - mse: 1.7663 - val_loss: 0.0710 - val_mse: 1.0470\n",
      "Epoch 310/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0888 - mse: 2.4662\n",
      "Epoch 00310: saving model to Regression_Model/bl6.mle.linear-0310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0888 - mse: 2.4479 - val_loss: 0.0760 - val_mse: 1.0563\n",
      "Epoch 311/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0861 - mse: 1.5822 - val_loss: 0.0815 - val_mse: 1.1625\n",
      "Epoch 312/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0900 - mse: 2.6836 - val_loss: 0.0717 - val_mse: 1.0834\n",
      "Epoch 313/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0855 - mse: 2.6434 - val_loss: 0.0712 - val_mse: 1.0596\n",
      "Epoch 314/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0878 - mse: 1.9511 - val_loss: 0.0765 - val_mse: 1.0123\n",
      "Epoch 315/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0859 - mse: 1.5546 - val_loss: 0.0726 - val_mse: 1.0242\n",
      "Epoch 316/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0936 - mse: 1.5284 - val_loss: 0.0733 - val_mse: 1.0428\n",
      "Epoch 317/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0873 - mse: 2.0557 - val_loss: 0.0726 - val_mse: 1.1228\n",
      "Epoch 318/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0887 - mse: 1.5875 - val_loss: 0.0713 - val_mse: 1.0750\n",
      "Epoch 319/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0963 - mse: 2.5046 - val_loss: 0.0836 - val_mse: 0.9765\n",
      "Epoch 320/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0873 - mse: 1.4851\n",
      "Epoch 00320: saving model to Regression_Model/bl6.mle.linear-0320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0873 - mse: 1.4829 - val_loss: 0.0782 - val_mse: 1.0055\n",
      "Epoch 321/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0906 - mse: 2.3753 - val_loss: 0.0731 - val_mse: 1.0556\n",
      "Epoch 322/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0864 - mse: 2.8164 - val_loss: 0.0743 - val_mse: 1.0029\n",
      "Epoch 323/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0872 - mse: 2.8923 - val_loss: 0.0760 - val_mse: 1.0466\n",
      "Epoch 324/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0878 - mse: 2.3736 - val_loss: 0.0751 - val_mse: 1.0077\n",
      "Epoch 325/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0854 - mse: 1.4798 - val_loss: 0.0722 - val_mse: 0.9618\n",
      "Epoch 326/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0881 - mse: 2.0673 - val_loss: 0.0721 - val_mse: 1.0353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0850 - mse: 1.8076 - val_loss: 0.0725 - val_mse: 1.0063\n",
      "Epoch 328/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0850 - mse: 1.6078 - val_loss: 0.0708 - val_mse: 0.9957\n",
      "Epoch 329/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0858 - mse: 2.7389 - val_loss: 0.0849 - val_mse: 1.8438\n",
      "Epoch 330/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0848 - mse: 1.5769\n",
      "Epoch 00330: saving model to Regression_Model/bl6.mle.linear-0330.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0848 - mse: 1.5727 - val_loss: 0.0735 - val_mse: 1.0201\n",
      "Epoch 331/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0901 - mse: 2.3294 - val_loss: 0.0716 - val_mse: 1.0949\n",
      "Epoch 332/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0857 - mse: 1.9354 - val_loss: 0.0730 - val_mse: 1.0281\n",
      "Epoch 333/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0876 - mse: 2.9804 - val_loss: 0.0857 - val_mse: 1.1860\n",
      "Epoch 334/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0865 - mse: 1.8036 - val_loss: 0.0811 - val_mse: 1.1423\n",
      "Epoch 335/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0842 - mse: 2.1342 - val_loss: 0.0704 - val_mse: 1.0064\n",
      "Epoch 336/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0858 - mse: 2.9515 - val_loss: 0.0844 - val_mse: 1.0907\n",
      "Epoch 337/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0870 - mse: 1.8011 - val_loss: 0.0713 - val_mse: 1.0305\n",
      "Epoch 338/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0817 - mse: 2.5951 - val_loss: 0.0709 - val_mse: 1.0910\n",
      "Epoch 339/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0882 - mse: 4.0613 - val_loss: 0.0718 - val_mse: 0.9762\n",
      "Epoch 340/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0854 - mse: 2.5342\n",
      "Epoch 00340: saving model to Regression_Model/bl6.mle.linear-0340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0852 - mse: 2.6427 - val_loss: 0.0707 - val_mse: 0.9827\n",
      "Epoch 341/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0904 - mse: 1.8513 - val_loss: 0.0700 - val_mse: 1.1050\n",
      "Epoch 342/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0882 - mse: 2.3981 - val_loss: 0.0814 - val_mse: 1.1601\n",
      "Epoch 343/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0878 - mse: 2.2866 - val_loss: 0.0711 - val_mse: 1.0613\n",
      "Epoch 344/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0837 - mse: 2.7017 - val_loss: 0.0745 - val_mse: 1.0982\n",
      "Epoch 345/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0882 - mse: 1.4316 - val_loss: 0.0724 - val_mse: 1.0342\n",
      "Epoch 346/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0872 - mse: 1.6172 - val_loss: 0.0717 - val_mse: 1.0756\n",
      "Epoch 347/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0899 - mse: 2.0658 - val_loss: 0.0799 - val_mse: 1.3918\n",
      "Epoch 348/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0842 - mse: 2.6451 - val_loss: 0.0692 - val_mse: 1.1467\n",
      "Epoch 349/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0849 - mse: 1.6458 - val_loss: 0.0707 - val_mse: 1.2797\n",
      "Epoch 350/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0862 - mse: 1.8066\n",
      "Epoch 00350: saving model to Regression_Model/bl6.mle.linear-0350.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0864 - mse: 1.7932 - val_loss: 0.0692 - val_mse: 1.1734\n",
      "Epoch 351/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0835 - mse: 1.5532 - val_loss: 0.0745 - val_mse: 1.4122\n",
      "Epoch 352/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0864 - mse: 1.8308 - val_loss: 0.0699 - val_mse: 1.1148\n",
      "Epoch 353/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0899 - mse: 2.7963 - val_loss: 0.0706 - val_mse: 1.1829\n",
      "Epoch 354/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0858 - mse: 3.0764 - val_loss: 0.0795 - val_mse: 1.0929\n",
      "Epoch 355/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0860 - mse: 2.4108 - val_loss: 0.0752 - val_mse: 1.2425\n",
      "Epoch 356/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0882 - mse: 2.1071 - val_loss: 0.0710 - val_mse: 1.2742\n",
      "Epoch 357/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0922 - mse: 4.6798 - val_loss: 0.0729 - val_mse: 1.2824\n",
      "Epoch 358/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0862 - mse: 1.7807 - val_loss: 0.0785 - val_mse: 1.2375\n",
      "Epoch 359/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0852 - mse: 1.5167 - val_loss: 0.0717 - val_mse: 1.1878\n",
      "Epoch 360/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0858 - mse: 3.3461\n",
      "Epoch 00360: saving model to Regression_Model/bl6.mle.linear-0360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0859 - mse: 3.2817 - val_loss: 0.0791 - val_mse: 1.2410\n",
      "Epoch 361/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0842 - mse: 3.6799 - val_loss: 0.0716 - val_mse: 1.2622\n",
      "Epoch 362/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0846 - mse: 3.9899 - val_loss: 0.0688 - val_mse: 1.1747\n",
      "Epoch 363/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0868 - mse: 3.3175 - val_loss: 0.0698 - val_mse: 1.1847\n",
      "Epoch 364/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 2.7543 - val_loss: 0.0705 - val_mse: 1.1327\n",
      "Epoch 365/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0866 - mse: 1.7989 - val_loss: 0.0747 - val_mse: 1.1293\n",
      "Epoch 366/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0876 - mse: 2.2214 - val_loss: 0.0715 - val_mse: 1.1632\n",
      "Epoch 367/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0863 - mse: 2.0626 - val_loss: 0.0759 - val_mse: 1.2521\n",
      "Epoch 368/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0854 - mse: 3.2942 - val_loss: 0.0778 - val_mse: 1.5009\n",
      "Epoch 369/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0861 - mse: 2.6561 - val_loss: 0.0711 - val_mse: 1.1898\n",
      "Epoch 370/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0853 - mse: 2.3782\n",
      "Epoch 00370: saving model to Regression_Model/bl6.mle.linear-0370.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0854 - mse: 2.3584 - val_loss: 0.0767 - val_mse: 1.1488\n",
      "Epoch 371/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0846 - mse: 2.2847 - val_loss: 0.0744 - val_mse: 1.1017\n",
      "Epoch 372/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0862 - mse: 2.8511 - val_loss: 0.0729 - val_mse: 1.1113\n",
      "Epoch 373/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0858 - mse: 2.9926 - val_loss: 0.0726 - val_mse: 1.1460\n",
      "Epoch 374/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0865 - mse: 2.5278 - val_loss: 0.0759 - val_mse: 1.1504\n",
      "Epoch 375/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0869 - mse: 2.1050 - val_loss: 0.0778 - val_mse: 1.0261\n",
      "Epoch 376/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0850 - mse: 1.6503 - val_loss: 0.0717 - val_mse: 1.0030\n",
      "Epoch 377/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0855 - mse: 3.0104 - val_loss: 0.0748 - val_mse: 1.2499\n",
      "Epoch 378/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0852 - mse: 1.7165 - val_loss: 0.0713 - val_mse: 1.0945\n",
      "Epoch 379/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0862 - mse: 1.6261 - val_loss: 0.0754 - val_mse: 1.0533\n",
      "Epoch 380/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0884 - mse: 2.1841\n",
      "Epoch 00380: saving model to Regression_Model/bl6.mle.linear-0380.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0883 - mse: 2.1553 - val_loss: 0.0718 - val_mse: 1.1603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1007 - mse: 2.2774 - val_loss: 0.0829 - val_mse: 1.1662\n",
      "Epoch 382/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0953 - mse: 2.3043 - val_loss: 0.0778 - val_mse: 1.0152\n",
      "Epoch 383/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0975 - mse: 2.6347 - val_loss: 0.0779 - val_mse: 1.0624\n",
      "Epoch 384/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0860 - mse: 1.8156 - val_loss: 0.0786 - val_mse: 1.0514\n",
      "Epoch 385/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0867 - mse: 1.6321 - val_loss: 0.0866 - val_mse: 1.1363\n",
      "Epoch 386/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0854 - mse: 1.5896 - val_loss: 0.0781 - val_mse: 1.0866\n",
      "Epoch 387/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0831 - mse: 1.6419 - val_loss: 0.0716 - val_mse: 1.0992\n",
      "Epoch 388/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0857 - mse: 3.1572 - val_loss: 0.0733 - val_mse: 1.0150\n",
      "Epoch 389/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0868 - mse: 2.4997 - val_loss: 0.0747 - val_mse: 1.2230\n",
      "Epoch 390/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0856 - mse: 2.0120\n",
      "Epoch 00390: saving model to Regression_Model/bl6.mle.linear-0390.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0858 - mse: 1.9796 - val_loss: 0.0852 - val_mse: 1.4007\n",
      "Epoch 391/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0854 - mse: 2.6316 - val_loss: 0.0742 - val_mse: 1.4091\n",
      "Epoch 392/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0874 - mse: 2.8574 - val_loss: 0.0723 - val_mse: 1.3079\n",
      "Epoch 393/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0871 - mse: 4.3608 - val_loss: 0.0777 - val_mse: 1.4367\n",
      "Epoch 394/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0840 - mse: 2.8519 - val_loss: 0.0711 - val_mse: 1.2203\n",
      "Epoch 395/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0858 - mse: 2.5688 - val_loss: 0.0726 - val_mse: 1.1583\n",
      "Epoch 396/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0869 - mse: 2.5389 - val_loss: 0.0731 - val_mse: 1.2158\n",
      "Epoch 397/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0864 - mse: 3.2187 - val_loss: 0.0714 - val_mse: 1.0973\n",
      "Epoch 398/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0835 - mse: 2.1012 - val_loss: 0.0712 - val_mse: 1.1642\n",
      "Epoch 399/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0872 - mse: 2.8641 - val_loss: 0.0720 - val_mse: 1.2329\n",
      "Epoch 400/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0836 - mse: 1.9481\n",
      "Epoch 00400: saving model to Regression_Model/bl6.mle.linear-0400.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0832 - mse: 1.9288 - val_loss: 0.0792 - val_mse: 1.6285\n",
      "Epoch 401/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0877 - mse: 2.3923 - val_loss: 0.0708 - val_mse: 1.1806\n",
      "Epoch 402/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0860 - mse: 2.3740 - val_loss: 0.0737 - val_mse: 1.2246\n",
      "Epoch 403/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0839 - mse: 3.6998 - val_loss: 0.0701 - val_mse: 1.1793\n",
      "Epoch 404/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0869 - mse: 2.2414 - val_loss: 0.0706 - val_mse: 1.1307\n",
      "Epoch 405/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0825 - mse: 2.3089 - val_loss: 0.0788 - val_mse: 1.1258\n",
      "Epoch 406/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0872 - mse: 1.8093 - val_loss: 0.0740 - val_mse: 1.2421\n",
      "Epoch 407/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0855 - mse: 1.8134 - val_loss: 0.0702 - val_mse: 1.2570\n",
      "Epoch 408/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0842 - mse: 3.0029 - val_loss: 0.0725 - val_mse: 1.1352\n",
      "Epoch 409/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0853 - mse: 2.5566 - val_loss: 0.0730 - val_mse: 1.1151\n",
      "Epoch 410/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0850 - mse: 1.5102\n",
      "Epoch 00410: saving model to Regression_Model/bl6.mle.linear-0410.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0850 - mse: 1.4921 - val_loss: 0.0737 - val_mse: 1.0925\n",
      "Epoch 411/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0858 - mse: 1.5945 - val_loss: 0.0798 - val_mse: 1.5179\n",
      "Epoch 412/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0857 - mse: 2.2292 - val_loss: 0.0720 - val_mse: 1.0531\n",
      "Epoch 413/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0851 - mse: 2.3431 - val_loss: 0.0714 - val_mse: 1.0884\n",
      "Epoch 414/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0838 - mse: 1.5304 - val_loss: 0.0730 - val_mse: 1.2012\n",
      "Epoch 415/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0847 - mse: 2.6314 - val_loss: 0.0754 - val_mse: 1.2288\n",
      "Epoch 416/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0850 - mse: 1.9676 - val_loss: 0.0717 - val_mse: 1.1248\n",
      "Epoch 417/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0867 - mse: 3.0614 - val_loss: 0.0712 - val_mse: 1.1269\n",
      "Epoch 418/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0827 - mse: 2.7150 - val_loss: 0.0727 - val_mse: 1.0604\n",
      "Epoch 419/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0856 - mse: 1.8081 - val_loss: 0.0707 - val_mse: 1.0781\n",
      "Epoch 420/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0849 - mse: 1.9709\n",
      "Epoch 00420: saving model to Regression_Model/bl6.mle.linear-0420.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0848 - mse: 1.9600 - val_loss: 0.0725 - val_mse: 1.0655\n",
      "Epoch 421/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0846 - mse: 1.8489 - val_loss: 0.0718 - val_mse: 1.0859\n",
      "Epoch 422/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0826 - mse: 2.2150 - val_loss: 0.0710 - val_mse: 1.1485\n",
      "Epoch 423/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0853 - mse: 2.2366 - val_loss: 0.0686 - val_mse: 1.1534\n",
      "Epoch 424/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0839 - mse: 2.1245 - val_loss: 0.0721 - val_mse: 1.0965\n",
      "Epoch 425/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0824 - mse: 1.9764 - val_loss: 0.0706 - val_mse: 1.0682\n",
      "Epoch 426/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0854 - mse: 2.0656 - val_loss: 0.0703 - val_mse: 1.0832\n",
      "Epoch 427/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0850 - mse: 1.8288 - val_loss: 0.0694 - val_mse: 1.1020\n",
      "Epoch 428/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0829 - mse: 2.1085 - val_loss: 0.0702 - val_mse: 1.0238\n",
      "Epoch 429/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0881 - mse: 1.5880 - val_loss: 0.0741 - val_mse: 1.0562\n",
      "Epoch 430/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0862 - mse: 1.8409\n",
      "Epoch 00430: saving model to Regression_Model/bl6.mle.linear-0430.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0859 - mse: 1.7997 - val_loss: 0.0719 - val_mse: 1.1178\n",
      "Epoch 431/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0850 - mse: 1.5085 - val_loss: 0.0705 - val_mse: 1.0523\n",
      "Epoch 432/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0868 - mse: 1.8136 - val_loss: 0.0713 - val_mse: 1.0855\n",
      "Epoch 433/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0819 - mse: 2.4151 - val_loss: 0.0722 - val_mse: 1.1409\n",
      "Epoch 434/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0838 - mse: 1.5422 - val_loss: 0.0733 - val_mse: 1.0158\n",
      "Epoch 435/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0838 - mse: 1.7652 - val_loss: 0.0716 - val_mse: 1.0381\n",
      "Epoch 436/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0817 - mse: 3.1281 - val_loss: 0.0723 - val_mse: 0.9943\n",
      "Epoch 437/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0855 - mse: 1.7680 - val_loss: 0.0691 - val_mse: 1.0941\n",
      "Epoch 438/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 1.8545 - val_loss: 0.0699 - val_mse: 1.0506\n",
      "Epoch 439/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0847 - mse: 1.9257 - val_loss: 0.0771 - val_mse: 1.0945\n",
      "Epoch 440/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0845 - mse: 1.8286\n",
      "Epoch 00440: saving model to Regression_Model/bl6.mle.linear-0440.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0843 - mse: 1.7909 - val_loss: 0.0742 - val_mse: 1.0942\n",
      "Epoch 441/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0844 - mse: 2.2227 - val_loss: 0.0703 - val_mse: 1.2269\n",
      "Epoch 442/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0823 - mse: 1.4716 - val_loss: 0.0706 - val_mse: 1.1228\n",
      "Epoch 443/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0866 - mse: 1.8894 - val_loss: 0.0744 - val_mse: 1.2376\n",
      "Epoch 444/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0828 - mse: 1.8573 - val_loss: 0.0714 - val_mse: 1.0873\n",
      "Epoch 445/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0831 - mse: 1.7163 - val_loss: 0.0724 - val_mse: 1.0127\n",
      "Epoch 446/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0830 - mse: 1.3459 - val_loss: 0.0698 - val_mse: 1.0559\n",
      "Epoch 447/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0851 - mse: 1.3837 - val_loss: 0.0718 - val_mse: 1.1465\n",
      "Epoch 448/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0819 - mse: 1.7082 - val_loss: 0.0710 - val_mse: 1.1163\n",
      "Epoch 449/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0850 - mse: 1.9016 - val_loss: 0.0736 - val_mse: 0.9461\n",
      "Epoch 450/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0835 - mse: 1.4615\n",
      "Epoch 00450: saving model to Regression_Model/bl6.mle.linear-0450.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0836 - mse: 1.4541 - val_loss: 0.0719 - val_mse: 1.0599\n",
      "Epoch 451/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0893 - mse: 2.1067 - val_loss: 0.0737 - val_mse: 1.1040\n",
      "Epoch 452/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0881 - mse: 1.8121 - val_loss: 0.0728 - val_mse: 1.0717\n",
      "Epoch 453/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0845 - mse: 2.1113 - val_loss: 0.0816 - val_mse: 1.6763\n",
      "Epoch 454/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0847 - mse: 1.2606 - val_loss: 0.0717 - val_mse: 1.0810\n",
      "Epoch 455/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0848 - mse: 2.0708 - val_loss: 0.0714 - val_mse: 0.9958\n",
      "Epoch 456/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0815 - mse: 1.3967 - val_loss: 0.0714 - val_mse: 1.1082\n",
      "Epoch 457/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0817 - mse: 1.3832 - val_loss: 0.0711 - val_mse: 0.9822\n",
      "Epoch 458/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0820 - mse: 1.4262 - val_loss: 0.0704 - val_mse: 1.0713\n",
      "Epoch 459/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0872 - mse: 1.5396 - val_loss: 0.0711 - val_mse: 1.0211\n",
      "Epoch 460/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0830 - mse: 1.5481\n",
      "Epoch 00460: saving model to Regression_Model/bl6.mle.linear-0460.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0826 - mse: 1.5337 - val_loss: 0.0762 - val_mse: 1.4380\n",
      "Epoch 461/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0828 - mse: 2.0474 - val_loss: 0.0712 - val_mse: 1.1062\n",
      "Epoch 462/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0823 - mse: 1.4775 - val_loss: 0.0731 - val_mse: 1.0030\n",
      "Epoch 463/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0820 - mse: 1.5881 - val_loss: 0.0709 - val_mse: 1.0104\n",
      "Epoch 464/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0820 - mse: 1.2344 - val_loss: 0.0704 - val_mse: 1.0969\n",
      "Epoch 465/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0857 - mse: 2.2516 - val_loss: 0.0713 - val_mse: 1.1624\n",
      "Epoch 466/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0856 - mse: 1.5718 - val_loss: 0.0690 - val_mse: 1.0496\n",
      "Epoch 467/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0809 - mse: 1.3870 - val_loss: 0.0703 - val_mse: 1.0310\n",
      "Epoch 468/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0833 - mse: 1.5625 - val_loss: 0.0770 - val_mse: 1.4050\n",
      "Epoch 469/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0839 - mse: 2.5425 - val_loss: 0.0688 - val_mse: 1.0036\n",
      "Epoch 470/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0825 - mse: 1.4015\n",
      "Epoch 00470: saving model to Regression_Model/bl6.mle.linear-0470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0829 - mse: 1.3849 - val_loss: 0.0732 - val_mse: 0.9646\n",
      "Epoch 471/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0824 - mse: 1.6299 - val_loss: 0.0719 - val_mse: 0.9798\n",
      "Epoch 472/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0834 - mse: 1.8258 - val_loss: 0.0727 - val_mse: 1.1534\n",
      "Epoch 473/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0799 - mse: 1.5425 - val_loss: 0.0684 - val_mse: 0.9801\n",
      "Epoch 474/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0853 - mse: 1.5593 - val_loss: 0.0717 - val_mse: 1.1249\n",
      "Epoch 475/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0826 - mse: 1.7076 - val_loss: 0.0706 - val_mse: 1.0801\n",
      "Epoch 476/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0828 - mse: 1.5992 - val_loss: 0.0687 - val_mse: 1.0460\n",
      "Epoch 477/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0812 - mse: 1.5074 - val_loss: 0.0701 - val_mse: 1.1189\n",
      "Epoch 478/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0810 - mse: 1.8902 - val_loss: 0.0695 - val_mse: 1.0272\n",
      "Epoch 479/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0826 - mse: 2.2441 - val_loss: 0.0694 - val_mse: 0.9636\n",
      "Epoch 480/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0805 - mse: 1.5846\n",
      "Epoch 00480: saving model to Regression_Model/bl6.mle.linear-0480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0807 - mse: 1.5919 - val_loss: 0.0700 - val_mse: 1.0188\n",
      "Epoch 481/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0844 - mse: 1.8670 - val_loss: 0.0717 - val_mse: 0.9976\n",
      "Epoch 482/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0851 - mse: 2.1060 - val_loss: 0.0711 - val_mse: 1.0006\n",
      "Epoch 483/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0924 - mse: 1.4572 - val_loss: 0.0753 - val_mse: 1.0562\n",
      "Epoch 484/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 2.0774 - val_loss: 0.0713 - val_mse: 1.0535\n",
      "Epoch 485/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0825 - mse: 2.0679 - val_loss: 0.0719 - val_mse: 1.0012\n",
      "Epoch 486/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0826 - mse: 1.4380 - val_loss: 0.0688 - val_mse: 1.0170\n",
      "Epoch 487/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0828 - mse: 1.7691 - val_loss: 0.0675 - val_mse: 1.1398\n",
      "Epoch 488/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 1.5632 - val_loss: 0.0694 - val_mse: 1.0051\n",
      "Epoch 489/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0858 - mse: 2.2772 - val_loss: 0.0705 - val_mse: 1.0860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0837 - mse: 2.2676\n",
      "Epoch 00490: saving model to Regression_Model/bl6.mle.linear-0490.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.0836 - mse: 2.2624 - val_loss: 0.0671 - val_mse: 1.0098\n",
      "Epoch 491/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 1.8056 - val_loss: 0.0712 - val_mse: 1.1110\n",
      "Epoch 492/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0829 - mse: 1.7628 - val_loss: 0.0707 - val_mse: 0.9719\n",
      "Epoch 493/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0830 - mse: 1.5041 - val_loss: 0.0719 - val_mse: 0.9817\n",
      "Epoch 494/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 2.1349 - val_loss: 0.0729 - val_mse: 0.9712\n",
      "Epoch 495/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0822 - mse: 2.4261 - val_loss: 0.0705 - val_mse: 1.0032\n",
      "Epoch 496/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.3121 - val_loss: 0.0721 - val_mse: 1.0520\n",
      "Epoch 497/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0839 - mse: 1.7128 - val_loss: 0.0702 - val_mse: 0.9836\n",
      "Epoch 498/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0821 - mse: 1.6365 - val_loss: 0.0696 - val_mse: 1.0670\n",
      "Epoch 499/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0828 - mse: 1.5353 - val_loss: 0.0688 - val_mse: 0.9958\n",
      "Epoch 500/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0853 - mse: 1.6438\n",
      "Epoch 00500: saving model to Regression_Model/bl6.mle.linear-0500.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0859 - mse: 1.8295 - val_loss: 0.0835 - val_mse: 1.0599\n",
      "Epoch 501/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0808 - mse: 2.4139 - val_loss: 0.0707 - val_mse: 1.0323\n",
      "Epoch 502/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0821 - mse: 1.4607 - val_loss: 0.0727 - val_mse: 0.9659\n",
      "Epoch 503/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0837 - mse: 1.9173 - val_loss: 0.0709 - val_mse: 0.9884\n",
      "Epoch 504/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0828 - mse: 1.4215 - val_loss: 0.0710 - val_mse: 0.9861\n",
      "Epoch 505/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0839 - mse: 1.6499 - val_loss: 0.0704 - val_mse: 1.0111\n",
      "Epoch 506/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0828 - mse: 1.9254 - val_loss: 0.0710 - val_mse: 1.0960\n",
      "Epoch 507/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0850 - mse: 1.6893 - val_loss: 0.0688 - val_mse: 0.9626\n",
      "Epoch 508/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0844 - mse: 1.8051 - val_loss: 0.0703 - val_mse: 0.9856\n",
      "Epoch 509/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0879 - mse: 1.7317 - val_loss: 0.0691 - val_mse: 0.9896\n",
      "Epoch 510/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0839 - mse: 2.2864\n",
      "Epoch 00510: saving model to Regression_Model/bl6.mle.linear-0510.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0837 - mse: 2.2411 - val_loss: 0.0715 - val_mse: 1.1125\n",
      "Epoch 511/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0799 - mse: 1.4550 - val_loss: 0.0699 - val_mse: 0.9843\n",
      "Epoch 512/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0823 - mse: 1.4554 - val_loss: 0.0713 - val_mse: 0.9482\n",
      "Epoch 513/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.4986 - val_loss: 0.0689 - val_mse: 1.0010\n",
      "Epoch 514/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 2.8344 - val_loss: 0.0678 - val_mse: 1.0683\n",
      "Epoch 515/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0832 - mse: 2.1189 - val_loss: 0.0677 - val_mse: 1.0044\n",
      "Epoch 516/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0810 - mse: 1.7528 - val_loss: 0.0676 - val_mse: 0.9828\n",
      "Epoch 517/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0835 - mse: 1.6447 - val_loss: 0.0705 - val_mse: 0.9993\n",
      "Epoch 518/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0822 - mse: 1.7182 - val_loss: 0.0684 - val_mse: 0.9726\n",
      "Epoch 519/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.6682 - val_loss: 0.0673 - val_mse: 1.0052\n",
      "Epoch 520/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0807 - mse: 1.9689\n",
      "Epoch 00520: saving model to Regression_Model/bl6.mle.linear-0520.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0807 - mse: 1.9423 - val_loss: 0.0677 - val_mse: 0.9768\n",
      "Epoch 521/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.8118 - val_loss: 0.0701 - val_mse: 0.9458\n",
      "Epoch 522/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0801 - mse: 1.6478 - val_loss: 0.0691 - val_mse: 1.0054\n",
      "Epoch 523/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0815 - mse: 1.8153 - val_loss: 0.0669 - val_mse: 0.9895\n",
      "Epoch 524/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 3.2932 - val_loss: 0.0681 - val_mse: 0.9652\n",
      "Epoch 525/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0830 - mse: 1.3797 - val_loss: 0.0666 - val_mse: 0.9746\n",
      "Epoch 526/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0820 - mse: 1.4678 - val_loss: 0.0670 - val_mse: 0.9756\n",
      "Epoch 527/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0828 - mse: 1.8660 - val_loss: 0.0688 - val_mse: 0.9889\n",
      "Epoch 528/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.7865 - val_loss: 0.0730 - val_mse: 1.1852\n",
      "Epoch 529/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0823 - mse: 1.4470 - val_loss: 0.0660 - val_mse: 0.9972\n",
      "Epoch 530/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0838 - mse: 1.6852\n",
      "Epoch 00530: saving model to Regression_Model/bl6.mle.linear-0530.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0838 - mse: 1.6775 - val_loss: 0.0659 - val_mse: 1.0112\n",
      "Epoch 531/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0837 - mse: 1.5248 - val_loss: 0.0671 - val_mse: 0.9821\n",
      "Epoch 532/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.4895 - val_loss: 0.0691 - val_mse: 1.0811\n",
      "Epoch 533/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0813 - mse: 1.7734 - val_loss: 0.0706 - val_mse: 1.0205\n",
      "Epoch 534/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0832 - mse: 1.4884 - val_loss: 0.0674 - val_mse: 0.9704\n",
      "Epoch 535/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 1.4552 - val_loss: 0.0686 - val_mse: 0.9630\n",
      "Epoch 536/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0817 - mse: 1.7262 - val_loss: 0.0708 - val_mse: 0.9640\n",
      "Epoch 537/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 1.6133 - val_loss: 0.0677 - val_mse: 1.0436\n",
      "Epoch 538/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 1.7021 - val_loss: 0.0693 - val_mse: 0.9728\n",
      "Epoch 539/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.7666 - val_loss: 0.0726 - val_mse: 0.9831\n",
      "Epoch 540/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0834 - mse: 1.5382\n",
      "Epoch 00540: saving model to Regression_Model/bl6.mle.linear-0540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0832 - mse: 2.0613 - val_loss: 0.0672 - val_mse: 1.0520\n",
      "Epoch 541/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0813 - mse: 1.4989 - val_loss: 0.0714 - val_mse: 0.9591\n",
      "Epoch 542/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0827 - mse: 1.9346 - val_loss: 0.0703 - val_mse: 0.9941\n",
      "Epoch 543/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0818 - mse: 3.2784 - val_loss: 0.0760 - val_mse: 1.0546\n",
      "Epoch 544/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0831 - mse: 1.5946 - val_loss: 0.0681 - val_mse: 1.1247\n",
      "Epoch 545/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.6533 - val_loss: 0.0734 - val_mse: 0.9364\n",
      "Epoch 546/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0848 - mse: 1.8789 - val_loss: 0.0708 - val_mse: 1.0052\n",
      "Epoch 547/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0846 - mse: 1.5923 - val_loss: 0.0684 - val_mse: 0.9925\n",
      "Epoch 548/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0793 - mse: 1.8125 - val_loss: 0.0664 - val_mse: 1.0042\n",
      "Epoch 549/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0797 - mse: 1.3778 - val_loss: 0.0662 - val_mse: 1.0107\n",
      "Epoch 550/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0823 - mse: 1.7471\n",
      "Epoch 00550: saving model to Regression_Model/bl6.mle.linear-0550.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0823 - mse: 1.7433 - val_loss: 0.0666 - val_mse: 1.0380\n",
      "Epoch 551/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0826 - mse: 1.9800 - val_loss: 0.0692 - val_mse: 0.9649\n",
      "Epoch 552/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0802 - mse: 2.1780 - val_loss: 0.0669 - val_mse: 1.0033\n",
      "Epoch 553/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.6262 - val_loss: 0.0691 - val_mse: 1.0264\n",
      "Epoch 554/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 2.3225 - val_loss: 0.0679 - val_mse: 1.0470\n",
      "Epoch 555/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0816 - mse: 1.2937 - val_loss: 0.0719 - val_mse: 0.9439\n",
      "Epoch 556/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.4079 - val_loss: 0.0754 - val_mse: 1.2358\n",
      "Epoch 557/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0839 - mse: 1.7346 - val_loss: 0.0670 - val_mse: 1.0242\n",
      "Epoch 558/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0810 - mse: 3.4439 - val_loss: 0.0664 - val_mse: 1.0200\n",
      "Epoch 559/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0822 - mse: 1.5554 - val_loss: 0.0683 - val_mse: 0.9897\n",
      "Epoch 560/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0815 - mse: 2.1663\n",
      "Epoch 00560: saving model to Regression_Model/bl6.mle.linear-0560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0815 - mse: 2.1676 - val_loss: 0.0684 - val_mse: 1.0352\n",
      "Epoch 561/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0834 - mse: 3.0078 - val_loss: 0.0689 - val_mse: 0.9787\n",
      "Epoch 562/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0790 - mse: 1.4494 - val_loss: 0.0680 - val_mse: 1.0126\n",
      "Epoch 563/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0816 - mse: 2.1106 - val_loss: 0.0706 - val_mse: 0.9818\n",
      "Epoch 564/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0803 - mse: 2.4964 - val_loss: 0.0679 - val_mse: 0.9942\n",
      "Epoch 565/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0825 - mse: 1.6530 - val_loss: 0.0683 - val_mse: 0.9903\n",
      "Epoch 566/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0816 - mse: 1.7777 - val_loss: 0.0705 - val_mse: 0.9543\n",
      "Epoch 567/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0818 - mse: 1.3757 - val_loss: 0.0699 - val_mse: 0.9442\n",
      "Epoch 568/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.8281 - val_loss: 0.0696 - val_mse: 0.9418\n",
      "Epoch 569/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 2.1860 - val_loss: 0.0680 - val_mse: 0.9626\n",
      "Epoch 570/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0816 - mse: 2.0883\n",
      "Epoch 00570: saving model to Regression_Model/bl6.mle.linear-0570.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0816 - mse: 2.0573 - val_loss: 0.0688 - val_mse: 0.9291\n",
      "Epoch 571/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.2370 - val_loss: 0.0715 - val_mse: 0.9206\n",
      "Epoch 572/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 1.7666 - val_loss: 0.0695 - val_mse: 0.9259\n",
      "Epoch 573/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0815 - mse: 1.2795 - val_loss: 0.0690 - val_mse: 0.9272\n",
      "Epoch 574/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0815 - mse: 1.4752 - val_loss: 0.0682 - val_mse: 0.9310\n",
      "Epoch 575/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 1.3235 - val_loss: 0.0684 - val_mse: 0.9385\n",
      "Epoch 576/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0806 - mse: 1.4285 - val_loss: 0.0675 - val_mse: 0.9519\n",
      "Epoch 577/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0808 - mse: 1.2857 - val_loss: 0.0691 - val_mse: 0.9817\n",
      "Epoch 578/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.6526 - val_loss: 0.0692 - val_mse: 1.0159\n",
      "Epoch 579/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0827 - mse: 1.5914 - val_loss: 0.0707 - val_mse: 0.9542\n",
      "Epoch 580/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0832 - mse: 1.4452\n",
      "Epoch 00580: saving model to Regression_Model/bl6.mle.linear-0580.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0828 - mse: 1.4296 - val_loss: 0.0687 - val_mse: 0.9854\n",
      "Epoch 581/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0815 - mse: 1.4168 - val_loss: 0.0700 - val_mse: 0.9256\n",
      "Epoch 582/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0810 - mse: 1.6894 - val_loss: 0.0690 - val_mse: 0.9275\n",
      "Epoch 583/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0799 - mse: 1.3076 - val_loss: 0.0693 - val_mse: 1.0537\n",
      "Epoch 584/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0802 - mse: 1.6555 - val_loss: 0.0685 - val_mse: 0.9581\n",
      "Epoch 585/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0813 - mse: 1.3785 - val_loss: 0.0706 - val_mse: 0.9741\n",
      "Epoch 586/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.2211 - val_loss: 0.0694 - val_mse: 0.9866\n",
      "Epoch 587/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.8534 - val_loss: 0.0718 - val_mse: 1.0977\n",
      "Epoch 588/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0819 - mse: 2.5716 - val_loss: 0.0716 - val_mse: 0.9389\n",
      "Epoch 589/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0874 - mse: 1.8940 - val_loss: 0.0686 - val_mse: 1.0259\n",
      "Epoch 590/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0826 - mse: 2.1284\n",
      "Epoch 00590: saving model to Regression_Model/bl6.mle.linear-0590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0817 - mse: 2.0841 - val_loss: 0.0679 - val_mse: 0.9925\n",
      "Epoch 591/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0792 - mse: 1.1388 - val_loss: 0.0686 - val_mse: 0.9844\n",
      "Epoch 592/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.4726 - val_loss: 0.0752 - val_mse: 0.9215\n",
      "Epoch 593/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0810 - mse: 2.1201 - val_loss: 0.0720 - val_mse: 0.9239\n",
      "Epoch 594/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0797 - mse: 1.3126 - val_loss: 0.0675 - val_mse: 0.9773\n",
      "Epoch 595/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0799 - mse: 1.3625 - val_loss: 0.0699 - val_mse: 0.9435\n",
      "Epoch 596/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.6219 - val_loss: 0.0700 - val_mse: 0.9391\n",
      "Epoch 597/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0803 - mse: 1.7939 - val_loss: 0.0693 - val_mse: 0.9481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.8744 - val_loss: 0.0681 - val_mse: 0.9502\n",
      "Epoch 599/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.5097 - val_loss: 0.0680 - val_mse: 0.9396\n",
      "Epoch 600/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0790 - mse: 1.4406\n",
      "Epoch 00600: saving model to Regression_Model/bl6.mle.linear-0600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.4321 - val_loss: 0.0689 - val_mse: 0.9382\n",
      "Epoch 601/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0828 - mse: 1.5034 - val_loss: 0.0693 - val_mse: 0.9809\n",
      "Epoch 602/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0810 - mse: 1.5637 - val_loss: 0.0665 - val_mse: 0.9598\n",
      "Epoch 603/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0803 - mse: 2.0302 - val_loss: 0.0675 - val_mse: 0.9437\n",
      "Epoch 604/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 1.3350 - val_loss: 0.0672 - val_mse: 0.9505\n",
      "Epoch 605/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0807 - mse: 1.3881 - val_loss: 0.0702 - val_mse: 0.9195\n",
      "Epoch 606/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 2.0068 - val_loss: 0.0672 - val_mse: 0.9260\n",
      "Epoch 607/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0816 - mse: 1.6007 - val_loss: 0.0667 - val_mse: 0.9333\n",
      "Epoch 608/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.3370 - val_loss: 0.0653 - val_mse: 0.9412\n",
      "Epoch 609/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.5082 - val_loss: 0.0675 - val_mse: 0.9467\n",
      "Epoch 610/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0789 - mse: 1.2875\n",
      "Epoch 00610: saving model to Regression_Model/bl6.mle.linear-0610.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 0.0790 - mse: 1.2839 - val_loss: 0.0684 - val_mse: 0.9410\n",
      "Epoch 611/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0820 - mse: 1.2833 - val_loss: 0.0737 - val_mse: 1.1375\n",
      "Epoch 612/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 1.4848 - val_loss: 0.0707 - val_mse: 0.9129\n",
      "Epoch 613/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.2868 - val_loss: 0.0687 - val_mse: 0.9824\n",
      "Epoch 614/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0809 - mse: 1.4318 - val_loss: 0.0685 - val_mse: 0.9296\n",
      "Epoch 615/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0812 - mse: 1.3681 - val_loss: 0.0659 - val_mse: 0.9327\n",
      "Epoch 616/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0799 - mse: 1.2176 - val_loss: 0.0651 - val_mse: 0.9481\n",
      "Epoch 617/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.6133 - val_loss: 0.0693 - val_mse: 0.9647\n",
      "Epoch 618/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0834 - mse: 1.2112 - val_loss: 0.0717 - val_mse: 1.0709\n",
      "Epoch 619/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0801 - mse: 1.4140 - val_loss: 0.0702 - val_mse: 0.9430\n",
      "Epoch 620/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0803 - mse: 1.9138\n",
      "Epoch 00620: saving model to Regression_Model/bl6.mle.linear-0620.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0801 - mse: 1.8981 - val_loss: 0.0665 - val_mse: 0.9204\n",
      "Epoch 621/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0797 - mse: 1.7863 - val_loss: 0.0668 - val_mse: 0.9571\n",
      "Epoch 622/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.6942 - val_loss: 0.0680 - val_mse: 0.9165\n",
      "Epoch 623/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 1.4397 - val_loss: 0.0677 - val_mse: 0.9275\n",
      "Epoch 624/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 2.0584 - val_loss: 0.0806 - val_mse: 0.9419\n",
      "Epoch 625/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0792 - mse: 1.5098 - val_loss: 0.0666 - val_mse: 0.9251\n",
      "Epoch 626/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.7197 - val_loss: 0.0672 - val_mse: 0.9679\n",
      "Epoch 627/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 2.0652 - val_loss: 0.0673 - val_mse: 0.9894\n",
      "Epoch 628/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0821 - mse: 2.1858 - val_loss: 0.0691 - val_mse: 0.9217\n",
      "Epoch 629/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.3781 - val_loss: 0.0685 - val_mse: 0.9417\n",
      "Epoch 630/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0789 - mse: 1.6209\n",
      "Epoch 00630: saving model to Regression_Model/bl6.mle.linear-0630.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0788 - mse: 1.6138 - val_loss: 0.0695 - val_mse: 0.9204\n",
      "Epoch 631/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.5661 - val_loss: 0.0680 - val_mse: 0.9448\n",
      "Epoch 632/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0801 - mse: 1.5564 - val_loss: 0.0663 - val_mse: 0.9511\n",
      "Epoch 633/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.6940 - val_loss: 0.0692 - val_mse: 1.0205\n",
      "Epoch 634/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.3349 - val_loss: 0.0695 - val_mse: 0.9412\n",
      "Epoch 635/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0835 - mse: 1.6465 - val_loss: 0.0691 - val_mse: 1.0007\n",
      "Epoch 636/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0807 - mse: 1.2712 - val_loss: 0.0702 - val_mse: 1.0792\n",
      "Epoch 637/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 1.3931 - val_loss: 0.0691 - val_mse: 0.9235\n",
      "Epoch 638/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0802 - mse: 1.6522 - val_loss: 0.0681 - val_mse: 1.0258\n",
      "Epoch 639/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.4704 - val_loss: 0.0677 - val_mse: 0.9955\n",
      "Epoch 640/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0814 - mse: 2.5721\n",
      "Epoch 00640: saving model to Regression_Model/bl6.mle.linear-0640.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.0810 - mse: 2.5237 - val_loss: 0.0670 - val_mse: 0.9617\n",
      "Epoch 641/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.5520 - val_loss: 0.0717 - val_mse: 0.9454\n",
      "Epoch 642/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0797 - mse: 1.6104 - val_loss: 0.0669 - val_mse: 0.9364\n",
      "Epoch 643/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0793 - mse: 1.4296 - val_loss: 0.0663 - val_mse: 0.9471\n",
      "Epoch 644/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0801 - mse: 1.5975 - val_loss: 0.0662 - val_mse: 0.9490\n",
      "Epoch 645/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0812 - mse: 1.6699 - val_loss: 0.0670 - val_mse: 0.9914\n",
      "Epoch 646/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 1.9212 - val_loss: 0.0674 - val_mse: 0.9402\n",
      "Epoch 647/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.5841 - val_loss: 0.0668 - val_mse: 0.9475\n",
      "Epoch 648/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0801 - mse: 1.7242 - val_loss: 0.0661 - val_mse: 0.9680\n",
      "Epoch 649/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.9847 - val_loss: 0.0695 - val_mse: 1.0459\n",
      "Epoch 650/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0794 - mse: 1.6472\n",
      "Epoch 00650: saving model to Regression_Model/bl6.mle.linear-0650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.6324 - val_loss: 0.0661 - val_mse: 0.9308\n",
      "Epoch 651/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.2407 - val_loss: 0.0662 - val_mse: 0.9407\n",
      "Epoch 652/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.5294 - val_loss: 0.0700 - val_mse: 1.0046\n",
      "Epoch 653/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0816 - mse: 1.5903 - val_loss: 0.0660 - val_mse: 0.9463\n",
      "Epoch 654/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0815 - mse: 1.2146 - val_loss: 0.0753 - val_mse: 1.0106\n",
      "Epoch 655/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0820 - mse: 1.5969 - val_loss: 0.0691 - val_mse: 0.9387\n",
      "Epoch 656/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0806 - mse: 1.7628 - val_loss: 0.0687 - val_mse: 0.9746\n",
      "Epoch 657/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.6224 - val_loss: 0.0661 - val_mse: 0.9381\n",
      "Epoch 658/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0792 - mse: 1.3229 - val_loss: 0.0678 - val_mse: 0.9261\n",
      "Epoch 659/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0836 - mse: 1.4585 - val_loss: 0.0662 - val_mse: 0.9389\n",
      "Epoch 660/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0804 - mse: 1.5900\n",
      "Epoch 00660: saving model to Regression_Model/bl6.mle.linear-0660.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0801 - mse: 1.5693 - val_loss: 0.0698 - val_mse: 0.9094\n",
      "Epoch 661/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0812 - mse: 1.6262 - val_loss: 0.0681 - val_mse: 0.9227\n",
      "Epoch 662/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0815 - mse: 1.5917 - val_loss: 0.0696 - val_mse: 1.0234\n",
      "Epoch 663/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.3546 - val_loss: 0.0678 - val_mse: 0.9295\n",
      "Epoch 664/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.5744 - val_loss: 0.0669 - val_mse: 0.9161\n",
      "Epoch 665/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.4652 - val_loss: 0.0676 - val_mse: 0.9746\n",
      "Epoch 666/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 1.4092 - val_loss: 0.0662 - val_mse: 0.9297\n",
      "Epoch 667/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0812 - mse: 1.7703 - val_loss: 0.0711 - val_mse: 0.8999\n",
      "Epoch 668/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.5879 - val_loss: 0.0647 - val_mse: 0.9088\n",
      "Epoch 669/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0807 - mse: 1.4076 - val_loss: 0.0689 - val_mse: 0.8928\n",
      "Epoch 670/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0812 - mse: 1.5440\n",
      "Epoch 00670: saving model to Regression_Model/bl6.mle.linear-0670.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0807 - mse: 1.5169 - val_loss: 0.0674 - val_mse: 0.9927\n",
      "Epoch 671/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0802 - mse: 1.3121 - val_loss: 0.0698 - val_mse: 0.9223\n",
      "Epoch 672/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0810 - mse: 1.3767 - val_loss: 0.0671 - val_mse: 0.9061\n",
      "Epoch 673/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0792 - mse: 1.2315 - val_loss: 0.0683 - val_mse: 1.0136\n",
      "Epoch 674/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.2715 - val_loss: 0.0688 - val_mse: 0.9713\n",
      "Epoch 675/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 1.3763 - val_loss: 0.0695 - val_mse: 0.9314\n",
      "Epoch 676/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.2772 - val_loss: 0.0684 - val_mse: 0.9938\n",
      "Epoch 677/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.3665 - val_loss: 0.0670 - val_mse: 0.9835\n",
      "Epoch 678/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0801 - mse: 1.1937 - val_loss: 0.0679 - val_mse: 0.8928\n",
      "Epoch 679/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.5373 - val_loss: 0.0707 - val_mse: 0.8819\n",
      "Epoch 680/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0807 - mse: 1.4714\n",
      "Epoch 00680: saving model to Regression_Model/bl6.mle.linear-0680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0809 - mse: 1.4611 - val_loss: 0.0680 - val_mse: 0.8921\n",
      "Epoch 681/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.9274 - val_loss: 0.0676 - val_mse: 0.9213\n",
      "Epoch 682/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.2571 - val_loss: 0.0707 - val_mse: 0.8869\n",
      "Epoch 683/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.3404 - val_loss: 0.0683 - val_mse: 0.8807\n",
      "Epoch 684/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.6226 - val_loss: 0.0661 - val_mse: 0.9031\n",
      "Epoch 685/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.4921 - val_loss: 0.0672 - val_mse: 0.9431\n",
      "Epoch 686/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0805 - mse: 1.6963 - val_loss: 0.0666 - val_mse: 0.9730\n",
      "Epoch 687/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0802 - mse: 1.1658 - val_loss: 0.0739 - val_mse: 0.9644\n",
      "Epoch 688/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0809 - mse: 1.2443 - val_loss: 0.0689 - val_mse: 0.8988\n",
      "Epoch 689/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0787 - mse: 1.5610 - val_loss: 0.0691 - val_mse: 0.8906\n",
      "Epoch 690/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0798 - mse: 1.3715\n",
      "Epoch 00690: saving model to Regression_Model/bl6.mle.linear-0690.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0801 - mse: 1.3658 - val_loss: 0.0682 - val_mse: 0.8954\n",
      "Epoch 691/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.2817 - val_loss: 0.0669 - val_mse: 0.9229\n",
      "Epoch 692/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0812 - mse: 1.4263 - val_loss: 0.0673 - val_mse: 0.9182\n",
      "Epoch 693/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.5036 - val_loss: 0.0683 - val_mse: 0.8815\n",
      "Epoch 694/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.7232 - val_loss: 0.0704 - val_mse: 0.8912\n",
      "Epoch 695/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.3550 - val_loss: 0.0667 - val_mse: 0.8952\n",
      "Epoch 696/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0819 - mse: 1.6489 - val_loss: 0.0666 - val_mse: 0.9448\n",
      "Epoch 697/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.4646 - val_loss: 0.0664 - val_mse: 0.9322\n",
      "Epoch 698/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0812 - mse: 1.3359 - val_loss: 0.0669 - val_mse: 0.8896\n",
      "Epoch 699/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.6058 - val_loss: 0.0658 - val_mse: 0.8974\n",
      "Epoch 700/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0793 - mse: 1.7599\n",
      "Epoch 00700: saving model to Regression_Model/bl6.mle.linear-0700.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0791 - mse: 1.7933 - val_loss: 0.0649 - val_mse: 0.8952\n",
      "Epoch 701/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.4729 - val_loss: 0.0686 - val_mse: 0.9693\n",
      "Epoch 702/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0797 - mse: 1.2770 - val_loss: 0.0667 - val_mse: 0.9414\n",
      "Epoch 703/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.4898 - val_loss: 0.0654 - val_mse: 0.9192\n",
      "Epoch 704/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.2151 - val_loss: 0.0686 - val_mse: 0.8911\n",
      "Epoch 705/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.3894 - val_loss: 0.0669 - val_mse: 0.9161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 706/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.5554 - val_loss: 0.0661 - val_mse: 0.9125\n",
      "Epoch 707/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.3137 - val_loss: 0.0655 - val_mse: 0.9073\n",
      "Epoch 708/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.2338 - val_loss: 0.0668 - val_mse: 0.9210\n",
      "Epoch 709/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0804 - mse: 1.3730 - val_loss: 0.0646 - val_mse: 0.8954\n",
      "Epoch 710/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0789 - mse: 1.2972\n",
      "Epoch 00710: saving model to Regression_Model/bl6.mle.linear-0710.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0790 - mse: 1.2882 - val_loss: 0.0654 - val_mse: 0.8941\n",
      "Epoch 711/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.5170 - val_loss: 0.0672 - val_mse: 0.8743\n",
      "Epoch 712/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.4491 - val_loss: 0.0704 - val_mse: 1.0792\n",
      "Epoch 713/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0818 - mse: 1.2414 - val_loss: 0.0691 - val_mse: 0.8935\n",
      "Epoch 714/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.3165 - val_loss: 0.0679 - val_mse: 0.9475\n",
      "Epoch 715/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0812 - mse: 1.1757 - val_loss: 0.0686 - val_mse: 0.9765\n",
      "Epoch 716/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0807 - mse: 1.4029 - val_loss: 0.0668 - val_mse: 0.9219\n",
      "Epoch 717/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.3074 - val_loss: 0.0675 - val_mse: 0.8973\n",
      "Epoch 718/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.3130 - val_loss: 0.0691 - val_mse: 0.9891\n",
      "Epoch 719/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0801 - mse: 1.2920 - val_loss: 0.0662 - val_mse: 0.9048\n",
      "Epoch 720/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0803 - mse: 1.3546\n",
      "Epoch 00720: saving model to Regression_Model/bl6.mle.linear-0720.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0804 - mse: 1.3365 - val_loss: 0.0728 - val_mse: 0.8994\n",
      "Epoch 721/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.7156 - val_loss: 0.0673 - val_mse: 0.9150\n",
      "Epoch 722/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.2286 - val_loss: 0.0671 - val_mse: 0.9729\n",
      "Epoch 723/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0792 - mse: 1.3523 - val_loss: 0.0651 - val_mse: 0.8975\n",
      "Epoch 724/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.6323 - val_loss: 0.0665 - val_mse: 0.9076\n",
      "Epoch 725/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.3308 - val_loss: 0.0709 - val_mse: 0.8827\n",
      "Epoch 726/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.9428 - val_loss: 0.0669 - val_mse: 0.9153\n",
      "Epoch 727/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.2717 - val_loss: 0.0648 - val_mse: 0.8790\n",
      "Epoch 728/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.2679 - val_loss: 0.0673 - val_mse: 0.9279\n",
      "Epoch 729/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0795 - mse: 1.4805 - val_loss: 0.0654 - val_mse: 0.8859\n",
      "Epoch 730/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0803 - mse: 1.5947\n",
      "Epoch 00730: saving model to Regression_Model/bl6.mle.linear-0730.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0799 - mse: 1.5670 - val_loss: 0.0697 - val_mse: 0.8793\n",
      "Epoch 731/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.8200 - val_loss: 0.0737 - val_mse: 0.8979\n",
      "Epoch 732/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0802 - mse: 1.3146 - val_loss: 0.0662 - val_mse: 0.9270\n",
      "Epoch 733/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.2408 - val_loss: 0.0672 - val_mse: 0.8860\n",
      "Epoch 734/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.4001 - val_loss: 0.0724 - val_mse: 0.8886\n",
      "Epoch 735/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.2069 - val_loss: 0.0671 - val_mse: 0.8856\n",
      "Epoch 736/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.3912 - val_loss: 0.0666 - val_mse: 0.9272\n",
      "Epoch 737/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.2259 - val_loss: 0.0696 - val_mse: 0.8884\n",
      "Epoch 738/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.4189 - val_loss: 0.0668 - val_mse: 0.9491\n",
      "Epoch 739/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.4289 - val_loss: 0.0671 - val_mse: 0.9117\n",
      "Epoch 740/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0783 - mse: 1.3153\n",
      "Epoch 00740: saving model to Regression_Model/bl6.mle.linear-0740.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0781 - mse: 1.3084 - val_loss: 0.0667 - val_mse: 0.9398\n",
      "Epoch 741/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.3661 - val_loss: 0.0680 - val_mse: 0.8991\n",
      "Epoch 742/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.1361 - val_loss: 0.0686 - val_mse: 1.0217\n",
      "Epoch 743/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.4797 - val_loss: 0.0667 - val_mse: 0.8907\n",
      "Epoch 744/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.3745 - val_loss: 0.0661 - val_mse: 0.8928\n",
      "Epoch 745/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.8725 - val_loss: 0.0678 - val_mse: 0.8867\n",
      "Epoch 746/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.5307 - val_loss: 0.0646 - val_mse: 0.9015\n",
      "Epoch 747/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3199 - val_loss: 0.0655 - val_mse: 0.8960\n",
      "Epoch 748/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0790 - mse: 1.4962 - val_loss: 0.0657 - val_mse: 0.8844\n",
      "Epoch 749/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.1493 - val_loss: 0.0658 - val_mse: 0.9354\n",
      "Epoch 750/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0776 - mse: 1.2651\n",
      "Epoch 00750: saving model to Regression_Model/bl6.mle.linear-0750.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0772 - mse: 1.2544 - val_loss: 0.0675 - val_mse: 0.9125\n",
      "Epoch 751/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0790 - mse: 1.3708 - val_loss: 0.0647 - val_mse: 0.8976\n",
      "Epoch 752/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.3927 - val_loss: 0.0702 - val_mse: 0.8954\n",
      "Epoch 753/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.3542 - val_loss: 0.0699 - val_mse: 0.8879\n",
      "Epoch 754/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.3617 - val_loss: 0.0669 - val_mse: 0.8956\n",
      "Epoch 755/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.4508 - val_loss: 0.0738 - val_mse: 1.1528\n",
      "Epoch 756/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.4043 - val_loss: 0.0634 - val_mse: 0.8905\n",
      "Epoch 757/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.7103 - val_loss: 0.0668 - val_mse: 0.8861\n",
      "Epoch 758/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.4266 - val_loss: 0.0650 - val_mse: 0.9174\n",
      "Epoch 759/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0815 - mse: 1.2956 - val_loss: 0.0651 - val_mse: 0.9000\n",
      "Epoch 760/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0788 - mse: 1.3643\n",
      "Epoch 00760: saving model to Regression_Model/bl6.mle.linear-0760.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.3479 - val_loss: 0.0667 - val_mse: 0.8870\n",
      "Epoch 761/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.3907 - val_loss: 0.0657 - val_mse: 0.9121\n",
      "Epoch 762/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.2904 - val_loss: 0.0672 - val_mse: 0.9107\n",
      "Epoch 763/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0799 - mse: 1.6658 - val_loss: 0.0670 - val_mse: 0.8952\n",
      "Epoch 764/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.5036 - val_loss: 0.0676 - val_mse: 0.8865\n",
      "Epoch 765/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.8635 - val_loss: 0.0672 - val_mse: 0.9417\n",
      "Epoch 766/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0801 - mse: 1.4991 - val_loss: 0.0674 - val_mse: 0.9722\n",
      "Epoch 767/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.3171 - val_loss: 0.0666 - val_mse: 0.9128\n",
      "Epoch 768/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.3485 - val_loss: 0.0675 - val_mse: 0.8906\n",
      "Epoch 769/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0795 - mse: 1.5125 - val_loss: 0.0700 - val_mse: 0.9383\n",
      "Epoch 770/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0803 - mse: 1.2481\n",
      "Epoch 00770: saving model to Regression_Model/bl6.mle.linear-0770.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0801 - mse: 1.2428 - val_loss: 0.0680 - val_mse: 0.9846\n",
      "Epoch 771/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.4972 - val_loss: 0.0648 - val_mse: 0.9086\n",
      "Epoch 772/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.3886 - val_loss: 0.0661 - val_mse: 0.8875\n",
      "Epoch 773/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0814 - mse: 1.4848 - val_loss: 0.0648 - val_mse: 0.9095\n",
      "Epoch 774/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.3731 - val_loss: 0.0672 - val_mse: 0.9167\n",
      "Epoch 775/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.4412 - val_loss: 0.0712 - val_mse: 0.8937\n",
      "Epoch 776/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.1052 - val_loss: 0.0669 - val_mse: 0.8995\n",
      "Epoch 777/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.7269 - val_loss: 0.0641 - val_mse: 0.9028\n",
      "Epoch 778/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.8678 - val_loss: 0.0744 - val_mse: 0.8960\n",
      "Epoch 779/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0792 - mse: 1.5488 - val_loss: 0.0653 - val_mse: 0.9167\n",
      "Epoch 780/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0759 - mse: 1.2199\n",
      "Epoch 00780: saving model to Regression_Model/bl6.mle.linear-0780.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0760 - mse: 1.2154 - val_loss: 0.0653 - val_mse: 0.9192\n",
      "Epoch 781/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.1847 - val_loss: 0.0659 - val_mse: 0.9244\n",
      "Epoch 782/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.6813 - val_loss: 0.0657 - val_mse: 0.9163\n",
      "Epoch 783/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.5956 - val_loss: 0.0693 - val_mse: 0.9005\n",
      "Epoch 784/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0799 - mse: 1.3434 - val_loss: 0.0651 - val_mse: 0.9043\n",
      "Epoch 785/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.5032 - val_loss: 0.0667 - val_mse: 0.9166\n",
      "Epoch 786/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.1892 - val_loss: 0.0652 - val_mse: 0.8986\n",
      "Epoch 787/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3956 - val_loss: 0.0656 - val_mse: 0.9136\n",
      "Epoch 788/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.6526 - val_loss: 0.0647 - val_mse: 0.9131\n",
      "Epoch 789/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.5099 - val_loss: 0.0657 - val_mse: 0.8904\n",
      "Epoch 790/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0778 - mse: 1.6787\n",
      "Epoch 00790: saving model to Regression_Model/bl6.mle.linear-0790.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0777 - mse: 1.6684 - val_loss: 0.0671 - val_mse: 0.9109\n",
      "Epoch 791/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.2838 - val_loss: 0.0664 - val_mse: 0.9104\n",
      "Epoch 792/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.4557 - val_loss: 0.0654 - val_mse: 0.9220\n",
      "Epoch 793/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.3478 - val_loss: 0.0661 - val_mse: 0.9002\n",
      "Epoch 794/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.1543 - val_loss: 0.0650 - val_mse: 0.9128\n",
      "Epoch 795/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.2769 - val_loss: 0.0670 - val_mse: 0.8923\n",
      "Epoch 796/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.5846 - val_loss: 0.0666 - val_mse: 0.9218\n",
      "Epoch 797/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.3626 - val_loss: 0.0652 - val_mse: 0.9105\n",
      "Epoch 798/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.2626 - val_loss: 0.0682 - val_mse: 0.8921\n",
      "Epoch 799/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.4159 - val_loss: 0.0663 - val_mse: 0.8975\n",
      "Epoch 800/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0789 - mse: 1.2893\n",
      "Epoch 00800: saving model to Regression_Model/bl6.mle.linear-0800.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.3023 - val_loss: 0.0650 - val_mse: 0.8942\n",
      "Epoch 801/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.4918 - val_loss: 0.0667 - val_mse: 0.9492\n",
      "Epoch 802/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.6130 - val_loss: 0.0676 - val_mse: 0.8962\n",
      "Epoch 803/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.8190 - val_loss: 0.0660 - val_mse: 0.9355\n",
      "Epoch 804/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0774 - mse: 1.2179 - val_loss: 0.0674 - val_mse: 0.8902\n",
      "Epoch 805/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.3221 - val_loss: 0.0662 - val_mse: 0.9156\n",
      "Epoch 806/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.3983 - val_loss: 0.0671 - val_mse: 0.9796\n",
      "Epoch 807/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.1820 - val_loss: 0.0678 - val_mse: 0.9540\n",
      "Epoch 808/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.4400 - val_loss: 0.0706 - val_mse: 0.9119\n",
      "Epoch 809/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0806 - mse: 1.3017 - val_loss: 0.0678 - val_mse: 0.9771\n",
      "Epoch 810/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0788 - mse: 1.2934\n",
      "Epoch 00810: saving model to Regression_Model/bl6.mle.linear-0810.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0786 - mse: 1.2876 - val_loss: 0.0672 - val_mse: 0.9397\n",
      "Epoch 811/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.2895 - val_loss: 0.0651 - val_mse: 0.8968\n",
      "Epoch 812/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.6059 - val_loss: 0.0647 - val_mse: 0.9035\n",
      "Epoch 813/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0799 - mse: 1.3324 - val_loss: 0.0652 - val_mse: 0.9000\n",
      "Epoch 814/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0799 - mse: 1.3502 - val_loss: 0.0649 - val_mse: 0.9051\n",
      "Epoch 815/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.4029 - val_loss: 0.0696 - val_mse: 0.8856\n",
      "Epoch 816/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.4725 - val_loss: 0.0685 - val_mse: 0.8820\n",
      "Epoch 817/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 1.3422 - val_loss: 0.0654 - val_mse: 0.8869\n",
      "Epoch 818/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.2308 - val_loss: 0.0684 - val_mse: 0.9432\n",
      "Epoch 819/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.2174 - val_loss: 0.0690 - val_mse: 0.9891\n",
      "Epoch 820/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0797 - mse: 1.3369\n",
      "Epoch 00820: saving model to Regression_Model/bl6.mle.linear-0820.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0788 - mse: 1.3221 - val_loss: 0.0682 - val_mse: 0.9075\n",
      "Epoch 821/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.2034 - val_loss: 0.0661 - val_mse: 0.8882\n",
      "Epoch 822/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0803 - mse: 1.6505 - val_loss: 0.0703 - val_mse: 0.8855\n",
      "Epoch 823/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.5158 - val_loss: 0.0671 - val_mse: 0.9166\n",
      "Epoch 824/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.6090 - val_loss: 0.0660 - val_mse: 0.8879\n",
      "Epoch 825/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.4922 - val_loss: 0.0655 - val_mse: 0.8906\n",
      "Epoch 826/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.3795 - val_loss: 0.0690 - val_mse: 0.9551\n",
      "Epoch 827/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0818 - mse: 1.3352 - val_loss: 0.0670 - val_mse: 0.9550\n",
      "Epoch 828/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.6162 - val_loss: 0.0644 - val_mse: 0.8801\n",
      "Epoch 829/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.5793 - val_loss: 0.0665 - val_mse: 0.9229\n",
      "Epoch 830/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0793 - mse: 1.5352\n",
      "Epoch 00830: saving model to Regression_Model/bl6.mle.linear-0830.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0793 - mse: 1.5275 - val_loss: 0.0690 - val_mse: 0.8804\n",
      "Epoch 831/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0797 - mse: 1.6324 - val_loss: 0.0635 - val_mse: 0.8824\n",
      "Epoch 832/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0790 - mse: 1.2963 - val_loss: 0.0658 - val_mse: 0.8809\n",
      "Epoch 833/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.4918 - val_loss: 0.0666 - val_mse: 0.8813\n",
      "Epoch 834/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3940 - val_loss: 0.0673 - val_mse: 0.8829\n",
      "Epoch 835/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.3429 - val_loss: 0.0688 - val_mse: 0.8857\n",
      "Epoch 836/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.2357 - val_loss: 0.0661 - val_mse: 0.9123\n",
      "Epoch 837/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.3117 - val_loss: 0.0673 - val_mse: 0.9319\n",
      "Epoch 838/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.1133 - val_loss: 0.0672 - val_mse: 0.9435\n",
      "Epoch 839/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 1.1247 - val_loss: 0.0686 - val_mse: 0.9625\n",
      "Epoch 840/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0794 - mse: 1.3461\n",
      "Epoch 00840: saving model to Regression_Model/bl6.mle.linear-0840.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.3409 - val_loss: 0.0730 - val_mse: 0.8828\n",
      "Epoch 841/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.3865 - val_loss: 0.0670 - val_mse: 0.8990\n",
      "Epoch 842/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.4305 - val_loss: 0.0665 - val_mse: 0.9317\n",
      "Epoch 843/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.5477 - val_loss: 0.0687 - val_mse: 1.0019\n",
      "Epoch 844/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0805 - mse: 1.2832 - val_loss: 0.0707 - val_mse: 0.8985\n",
      "Epoch 845/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.2190 - val_loss: 0.0690 - val_mse: 0.9257\n",
      "Epoch 846/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.2048 - val_loss: 0.0683 - val_mse: 0.9094\n",
      "Epoch 847/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.4612 - val_loss: 0.0651 - val_mse: 0.8976\n",
      "Epoch 848/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.4267 - val_loss: 0.0705 - val_mse: 0.8851\n",
      "Epoch 849/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.2666 - val_loss: 0.0692 - val_mse: 0.8932\n",
      "Epoch 850/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0778 - mse: 1.8038\n",
      "Epoch 00850: saving model to Regression_Model/bl6.mle.linear-0850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.7936 - val_loss: 0.0656 - val_mse: 0.8998\n",
      "Epoch 851/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.4105 - val_loss: 0.0659 - val_mse: 0.8964\n",
      "Epoch 852/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.1779 - val_loss: 0.0669 - val_mse: 0.9592\n",
      "Epoch 853/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.3661 - val_loss: 0.0697 - val_mse: 0.8791\n",
      "Epoch 854/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.3154 - val_loss: 0.0652 - val_mse: 0.8977\n",
      "Epoch 855/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.2097 - val_loss: 0.0661 - val_mse: 0.8911\n",
      "Epoch 856/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.9170 - val_loss: 0.0653 - val_mse: 0.8838\n",
      "Epoch 857/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0753 - mse: 1.3120 - val_loss: 0.0650 - val_mse: 0.8764\n",
      "Epoch 858/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.5394 - val_loss: 0.0689 - val_mse: 0.8691\n",
      "Epoch 859/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.2608 - val_loss: 0.0665 - val_mse: 0.8741\n",
      "Epoch 860/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0785 - mse: 1.3116\n",
      "Epoch 00860: saving model to Regression_Model/bl6.mle.linear-0860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.2951 - val_loss: 0.0665 - val_mse: 0.9350\n",
      "Epoch 861/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.2613 - val_loss: 0.0657 - val_mse: 0.8830\n",
      "Epoch 862/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.5258 - val_loss: 0.0723 - val_mse: 0.8676\n",
      "Epoch 863/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0803 - mse: 1.3402 - val_loss: 0.0677 - val_mse: 0.8705\n",
      "Epoch 864/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0764 - mse: 1.5640 - val_loss: 0.0676 - val_mse: 0.8938\n",
      "Epoch 865/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.4502 - val_loss: 0.0671 - val_mse: 0.8976\n",
      "Epoch 866/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.4381 - val_loss: 0.0691 - val_mse: 0.8843\n",
      "Epoch 867/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.2012 - val_loss: 0.0666 - val_mse: 0.8745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.2289 - val_loss: 0.0693 - val_mse: 0.8785\n",
      "Epoch 869/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.2023 - val_loss: 0.0670 - val_mse: 0.9079\n",
      "Epoch 870/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0769 - mse: 1.3892\n",
      "Epoch 00870: saving model to Regression_Model/bl6.mle.linear-0870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.3680 - val_loss: 0.0671 - val_mse: 0.9357\n",
      "Epoch 871/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.1570 - val_loss: 0.0685 - val_mse: 0.9157\n",
      "Epoch 872/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.5359 - val_loss: 0.0662 - val_mse: 0.8899\n",
      "Epoch 873/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0797 - mse: 1.2757 - val_loss: 0.0665 - val_mse: 0.8921\n",
      "Epoch 874/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0797 - mse: 1.3828 - val_loss: 0.0652 - val_mse: 0.9042\n",
      "Epoch 875/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.3325 - val_loss: 0.0667 - val_mse: 0.9129\n",
      "Epoch 876/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.4008 - val_loss: 0.0670 - val_mse: 0.8931\n",
      "Epoch 877/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.2895 - val_loss: 0.0689 - val_mse: 0.9136\n",
      "Epoch 878/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.2522 - val_loss: 0.0655 - val_mse: 0.9216\n",
      "Epoch 879/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.3133 - val_loss: 0.0670 - val_mse: 0.9094\n",
      "Epoch 880/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0806 - mse: 1.4887\n",
      "Epoch 00880: saving model to Regression_Model/bl6.mle.linear-0880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0806 - mse: 1.4790 - val_loss: 0.0689 - val_mse: 0.8695\n",
      "Epoch 881/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0762 - mse: 1.2759 - val_loss: 0.0681 - val_mse: 0.8848\n",
      "Epoch 882/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.2616 - val_loss: 0.0665 - val_mse: 0.9415\n",
      "Epoch 883/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.1975 - val_loss: 0.0656 - val_mse: 0.8942\n",
      "Epoch 884/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0783 - mse: 1.1610 - val_loss: 0.0669 - val_mse: 0.9030\n",
      "Epoch 885/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.6007 - val_loss: 0.0664 - val_mse: 0.9184\n",
      "Epoch 886/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0756 - mse: 1.1718 - val_loss: 0.0668 - val_mse: 0.8850\n",
      "Epoch 887/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.2394 - val_loss: 0.0663 - val_mse: 0.9207\n",
      "Epoch 888/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0789 - mse: 1.4897 - val_loss: 0.0686 - val_mse: 0.9105\n",
      "Epoch 889/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.2019 - val_loss: 0.0669 - val_mse: 0.9327\n",
      "Epoch 890/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0774 - mse: 1.6533\n",
      "Epoch 00890: saving model to Regression_Model/bl6.mle.linear-0890.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0775 - mse: 1.6455 - val_loss: 0.0660 - val_mse: 0.9251\n",
      "Epoch 891/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.3138 - val_loss: 0.0669 - val_mse: 0.9023\n",
      "Epoch 892/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0782 - mse: 1.4105 - val_loss: 0.0673 - val_mse: 0.9193\n",
      "Epoch 893/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0769 - mse: 1.1028 - val_loss: 0.0656 - val_mse: 0.8869\n",
      "Epoch 894/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.7913 - val_loss: 0.0649 - val_mse: 0.8692\n",
      "Epoch 895/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.7318 - val_loss: 0.0653 - val_mse: 0.8741\n",
      "Epoch 896/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.3286 - val_loss: 0.0675 - val_mse: 0.8733\n",
      "Epoch 897/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.3064 - val_loss: 0.0653 - val_mse: 0.9045\n",
      "Epoch 898/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.1815 - val_loss: 0.0654 - val_mse: 0.9059\n",
      "Epoch 899/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0808 - mse: 1.3979 - val_loss: 0.0673 - val_mse: 0.8777\n",
      "Epoch 900/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0778 - mse: 1.2874\n",
      "Epoch 00900: saving model to Regression_Model/bl6.mle.linear-0900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.2707 - val_loss: 0.0657 - val_mse: 0.9115\n",
      "Epoch 901/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.3110 - val_loss: 0.0685 - val_mse: 0.8846\n",
      "Epoch 902/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.1871 - val_loss: 0.0671 - val_mse: 0.9153\n",
      "Epoch 903/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.1448 - val_loss: 0.0669 - val_mse: 0.8783\n",
      "Epoch 904/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.3243 - val_loss: 0.0651 - val_mse: 0.8816\n",
      "Epoch 905/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0796 - mse: 1.4225 - val_loss: 0.0656 - val_mse: 0.8941\n",
      "Epoch 906/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.1643 - val_loss: 0.0661 - val_mse: 0.8887\n",
      "Epoch 907/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.4324 - val_loss: 0.0659 - val_mse: 0.8990\n",
      "Epoch 908/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0785 - mse: 1.4949 - val_loss: 0.0679 - val_mse: 0.8774\n",
      "Epoch 909/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0791 - mse: 1.2782 - val_loss: 0.0687 - val_mse: 0.8778\n",
      "Epoch 910/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0771 - mse: 1.2945\n",
      "Epoch 00910: saving model to Regression_Model/bl6.mle.linear-0910.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.2890 - val_loss: 0.0685 - val_mse: 1.0123\n",
      "Epoch 911/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.3533 - val_loss: 0.0695 - val_mse: 0.8801\n",
      "Epoch 912/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.4920 - val_loss: 0.0680 - val_mse: 0.9273\n",
      "Epoch 913/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.1588 - val_loss: 0.0671 - val_mse: 0.9338\n",
      "Epoch 914/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.1950 - val_loss: 0.0674 - val_mse: 0.8950\n",
      "Epoch 915/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.2329 - val_loss: 0.0654 - val_mse: 0.8873\n",
      "Epoch 916/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0769 - mse: 1.1884 - val_loss: 0.0657 - val_mse: 0.8800\n",
      "Epoch 917/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.2032 - val_loss: 0.0644 - val_mse: 0.8855\n",
      "Epoch 918/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.2223 - val_loss: 0.0680 - val_mse: 0.8860\n",
      "Epoch 919/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.5386 - val_loss: 0.0678 - val_mse: 0.8805\n",
      "Epoch 920/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0789 - mse: 1.3900\n",
      "Epoch 00920: saving model to Regression_Model/bl6.mle.linear-0920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.3827 - val_loss: 0.0661 - val_mse: 0.8784\n",
      "Epoch 921/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.1717 - val_loss: 0.0682 - val_mse: 0.9029\n",
      "Epoch 922/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.3820 - val_loss: 0.0675 - val_mse: 0.8868\n",
      "Epoch 923/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.4498 - val_loss: 0.0651 - val_mse: 0.8841\n",
      "Epoch 924/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.3606 - val_loss: 0.0676 - val_mse: 0.8801\n",
      "Epoch 925/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.2112 - val_loss: 0.0680 - val_mse: 0.8910\n",
      "Epoch 926/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0764 - mse: 1.2704 - val_loss: 0.0659 - val_mse: 0.9001\n",
      "Epoch 927/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0754 - mse: 1.3100 - val_loss: 0.0657 - val_mse: 0.8864\n",
      "Epoch 928/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0786 - mse: 1.2297 - val_loss: 0.0648 - val_mse: 0.8945\n",
      "Epoch 929/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0791 - mse: 1.3742 - val_loss: 0.0646 - val_mse: 0.8986\n",
      "Epoch 930/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0764 - mse: 1.1935\n",
      "Epoch 00930: saving model to Regression_Model/bl6.mle.linear-0930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.1947 - val_loss: 0.0663 - val_mse: 0.9065\n",
      "Epoch 931/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.5226 - val_loss: 0.0660 - val_mse: 0.8949\n",
      "Epoch 932/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0766 - mse: 1.4355 - val_loss: 0.0673 - val_mse: 0.9011\n",
      "Epoch 933/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.1531 - val_loss: 0.0662 - val_mse: 0.8927\n",
      "Epoch 934/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0803 - mse: 2.0388 - val_loss: 0.0660 - val_mse: 0.8996\n",
      "Epoch 935/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.4123 - val_loss: 0.0681 - val_mse: 0.9014\n",
      "Epoch 936/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.3595 - val_loss: 0.0671 - val_mse: 0.8965\n",
      "Epoch 937/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.4591 - val_loss: 0.0658 - val_mse: 0.8958\n",
      "Epoch 938/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.3808 - val_loss: 0.0658 - val_mse: 0.8947\n",
      "Epoch 939/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.3834 - val_loss: 0.0678 - val_mse: 0.8849\n",
      "Epoch 940/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0772 - mse: 1.4998\n",
      "Epoch 00940: saving model to Regression_Model/bl6.mle.linear-0940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.4962 - val_loss: 0.0671 - val_mse: 0.9034\n",
      "Epoch 941/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.3471 - val_loss: 0.0658 - val_mse: 0.9091\n",
      "Epoch 942/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0777 - mse: 1.2617 - val_loss: 0.0673 - val_mse: 0.9617\n",
      "Epoch 943/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0759 - mse: 1.2709 - val_loss: 0.0669 - val_mse: 0.8776\n",
      "Epoch 944/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.1584 - val_loss: 0.0660 - val_mse: 0.9197\n",
      "Epoch 945/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.3326 - val_loss: 0.0668 - val_mse: 0.8858\n",
      "Epoch 946/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0797 - mse: 1.3297 - val_loss: 0.0663 - val_mse: 0.8873\n",
      "Epoch 947/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.2773 - val_loss: 0.0666 - val_mse: 0.8881\n",
      "Epoch 948/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.3162 - val_loss: 0.0642 - val_mse: 0.9021\n",
      "Epoch 949/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.8669 - val_loss: 0.0669 - val_mse: 0.8931\n",
      "Epoch 950/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0775 - mse: 1.2248\n",
      "Epoch 00950: saving model to Regression_Model/bl6.mle.linear-0950.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.2187 - val_loss: 0.0647 - val_mse: 0.9005\n",
      "Epoch 951/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.2238 - val_loss: 0.0657 - val_mse: 0.9002\n",
      "Epoch 952/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0807 - mse: 1.5662 - val_loss: 0.0658 - val_mse: 0.9068\n",
      "Epoch 953/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.9110 - val_loss: 0.0692 - val_mse: 0.8899\n",
      "Epoch 954/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.4175 - val_loss: 0.0655 - val_mse: 0.8952\n",
      "Epoch 955/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.1451 - val_loss: 0.0693 - val_mse: 0.9014\n",
      "Epoch 956/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.2340 - val_loss: 0.0670 - val_mse: 0.9337\n",
      "Epoch 957/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.1968 - val_loss: 0.0659 - val_mse: 0.9269\n",
      "Epoch 958/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.3217 - val_loss: 0.0669 - val_mse: 0.8976\n",
      "Epoch 959/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0797 - mse: 1.2858 - val_loss: 0.0663 - val_mse: 0.9286\n",
      "Epoch 960/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0772 - mse: 1.2239\n",
      "Epoch 00960: saving model to Regression_Model/bl6.mle.linear-0960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.2099 - val_loss: 0.0663 - val_mse: 0.8938\n",
      "Epoch 961/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.3544 - val_loss: 0.0661 - val_mse: 0.8862\n",
      "Epoch 962/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.3541 - val_loss: 0.0659 - val_mse: 0.8820\n",
      "Epoch 963/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.3612 - val_loss: 0.0644 - val_mse: 0.8826\n",
      "Epoch 964/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.3448 - val_loss: 0.0649 - val_mse: 0.8932\n",
      "Epoch 965/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0771 - mse: 1.2587 - val_loss: 0.0656 - val_mse: 0.8941\n",
      "Epoch 966/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0797 - mse: 1.4283 - val_loss: 0.0652 - val_mse: 0.8891\n",
      "Epoch 967/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0755 - mse: 1.3511 - val_loss: 0.0647 - val_mse: 0.8885\n",
      "Epoch 968/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0785 - mse: 1.2814 - val_loss: 0.0680 - val_mse: 0.9556\n",
      "Epoch 969/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0789 - mse: 1.1969 - val_loss: 0.0683 - val_mse: 0.9320\n",
      "Epoch 970/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0780 - mse: 1.1825\n",
      "Epoch 00970: saving model to Regression_Model/bl6.mle.linear-0970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.1673 - val_loss: 0.0677 - val_mse: 0.9339\n",
      "Epoch 971/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.4002 - val_loss: 0.0670 - val_mse: 0.8895\n",
      "Epoch 972/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.3761 - val_loss: 0.0656 - val_mse: 0.8981\n",
      "Epoch 973/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0760 - mse: 1.6664 - val_loss: 0.0643 - val_mse: 0.8894\n",
      "Epoch 974/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.3046 - val_loss: 0.0646 - val_mse: 0.9070\n",
      "Epoch 975/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.8985 - val_loss: 0.0643 - val_mse: 0.8849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.2772 - val_loss: 0.0651 - val_mse: 0.9068\n",
      "Epoch 977/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.4661 - val_loss: 0.0672 - val_mse: 0.8989\n",
      "Epoch 978/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.7019 - val_loss: 0.0689 - val_mse: 0.9328\n",
      "Epoch 979/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.9185 - val_loss: 0.0652 - val_mse: 0.9087\n",
      "Epoch 980/2000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.0792 - mse: 1.3961\n",
      "Epoch 00980: saving model to Regression_Model/bl6.mle.linear-0980.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.3742 - val_loss: 0.0666 - val_mse: 0.8852\n",
      "Epoch 981/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.3128 - val_loss: 0.0661 - val_mse: 0.8874\n",
      "Epoch 982/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.3543 - val_loss: 0.0644 - val_mse: 0.8977\n",
      "Epoch 983/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.2635 - val_loss: 0.0673 - val_mse: 0.8916\n",
      "Epoch 984/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0796 - mse: 1.4967 - val_loss: 0.0668 - val_mse: 0.9123\n",
      "Epoch 985/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.3952 - val_loss: 0.0668 - val_mse: 0.8901\n",
      "Epoch 986/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.4130 - val_loss: 0.0657 - val_mse: 0.9047\n",
      "Epoch 987/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.2156 - val_loss: 0.0700 - val_mse: 0.9389\n",
      "Epoch 988/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.1187 - val_loss: 0.0686 - val_mse: 0.9304\n",
      "Epoch 989/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.1918 - val_loss: 0.0667 - val_mse: 0.9488\n",
      "Epoch 990/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0791 - mse: 1.1999\n",
      "Epoch 00990: saving model to Regression_Model/bl6.mle.linear-0990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.1938 - val_loss: 0.0672 - val_mse: 0.9336\n",
      "Epoch 991/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.7697 - val_loss: 0.0678 - val_mse: 0.9253\n",
      "Epoch 992/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.2398 - val_loss: 0.0654 - val_mse: 0.9025\n",
      "Epoch 993/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0810 - mse: 1.2604 - val_loss: 0.0693 - val_mse: 0.9044\n",
      "Epoch 994/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.4122 - val_loss: 0.0655 - val_mse: 0.9080\n",
      "Epoch 995/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0794 - mse: 1.4049 - val_loss: 0.0657 - val_mse: 0.8970\n",
      "Epoch 996/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0785 - mse: 1.2873 - val_loss: 0.0664 - val_mse: 0.8933\n",
      "Epoch 997/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.2707 - val_loss: 0.0654 - val_mse: 0.9007\n",
      "Epoch 998/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0756 - mse: 1.7395 - val_loss: 0.0660 - val_mse: 0.9404\n",
      "Epoch 999/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.2552 - val_loss: 0.0669 - val_mse: 0.9343\n",
      "Epoch 1000/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0776 - mse: 1.4966\n",
      "Epoch 01000: saving model to Regression_Model/bl6.mle.linear-1000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.4768 - val_loss: 0.0663 - val_mse: 0.9007\n",
      "Epoch 1001/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.3367 - val_loss: 0.0669 - val_mse: 0.9084\n",
      "Epoch 1002/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.1805 - val_loss: 0.0649 - val_mse: 0.8969\n",
      "Epoch 1003/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 1.1656 - val_loss: 0.0643 - val_mse: 0.9103\n",
      "Epoch 1004/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.4467 - val_loss: 0.0655 - val_mse: 0.9001\n",
      "Epoch 1005/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.4077 - val_loss: 0.0654 - val_mse: 0.8958\n",
      "Epoch 1006/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.5211 - val_loss: 0.0659 - val_mse: 0.8890\n",
      "Epoch 1007/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.3277 - val_loss: 0.0650 - val_mse: 0.8884\n",
      "Epoch 1008/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.5478 - val_loss: 0.0642 - val_mse: 0.9034\n",
      "Epoch 1009/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.3223 - val_loss: 0.0654 - val_mse: 0.8889\n",
      "Epoch 1010/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0763 - mse: 1.6441\n",
      "Epoch 01010: saving model to Regression_Model/bl6.mle.linear-1010.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.6263 - val_loss: 0.0650 - val_mse: 0.8895\n",
      "Epoch 1011/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.7348 - val_loss: 0.0644 - val_mse: 0.8953\n",
      "Epoch 1012/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.3943 - val_loss: 0.0641 - val_mse: 0.8917\n",
      "Epoch 1013/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.6447 - val_loss: 0.0636 - val_mse: 0.8956\n",
      "Epoch 1014/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.1555 - val_loss: 0.0646 - val_mse: 0.8807\n",
      "Epoch 1015/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0759 - mse: 1.6021 - val_loss: 0.0638 - val_mse: 0.8708\n",
      "Epoch 1016/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.4418 - val_loss: 0.0647 - val_mse: 0.8796\n",
      "Epoch 1017/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.2750 - val_loss: 0.0646 - val_mse: 0.8712\n",
      "Epoch 1018/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.2696 - val_loss: 0.0646 - val_mse: 0.8780\n",
      "Epoch 1019/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0757 - mse: 1.1801 - val_loss: 0.0657 - val_mse: 0.8720\n",
      "Epoch 1020/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0777 - mse: 1.4882\n",
      "Epoch 01020: saving model to Regression_Model/bl6.mle.linear-1020.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.4784 - val_loss: 0.0674 - val_mse: 0.8907\n",
      "Epoch 1021/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.4192 - val_loss: 0.0664 - val_mse: 0.8998\n",
      "Epoch 1022/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.3623 - val_loss: 0.0664 - val_mse: 0.8882\n",
      "Epoch 1023/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3022 - val_loss: 0.0652 - val_mse: 0.9082\n",
      "Epoch 1024/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.2627 - val_loss: 0.0695 - val_mse: 1.0498\n",
      "Epoch 1025/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.2939 - val_loss: 0.0666 - val_mse: 0.9217\n",
      "Epoch 1026/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.2008 - val_loss: 0.0661 - val_mse: 0.8816\n",
      "Epoch 1027/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0781 - mse: 1.5753 - val_loss: 0.0659 - val_mse: 0.8758\n",
      "Epoch 1028/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.1683 - val_loss: 0.0651 - val_mse: 0.9051\n",
      "Epoch 1029/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.4235 - val_loss: 0.0678 - val_mse: 0.8782\n",
      "Epoch 1030/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/368 [============================>.] - ETA: 0s - loss: 0.0783 - mse: 1.2313\n",
      "Epoch 01030: saving model to Regression_Model/bl6.mle.linear-1030.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0782 - mse: 1.2295 - val_loss: 0.0664 - val_mse: 0.8718\n",
      "Epoch 1031/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.4734 - val_loss: 0.0662 - val_mse: 0.8846\n",
      "Epoch 1032/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0779 - mse: 1.5461 - val_loss: 0.0670 - val_mse: 0.9147\n",
      "Epoch 1033/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.2340 - val_loss: 0.0680 - val_mse: 0.8845\n",
      "Epoch 1034/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.2181 - val_loss: 0.0663 - val_mse: 0.9061\n",
      "Epoch 1035/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.3346 - val_loss: 0.0683 - val_mse: 0.8902\n",
      "Epoch 1036/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0807 - mse: 1.4058 - val_loss: 0.0669 - val_mse: 0.8854\n",
      "Epoch 1037/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3241 - val_loss: 0.0664 - val_mse: 0.8825\n",
      "Epoch 1038/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.3678 - val_loss: 0.0652 - val_mse: 0.8896\n",
      "Epoch 1039/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.4159 - val_loss: 0.0650 - val_mse: 0.8929\n",
      "Epoch 1040/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0770 - mse: 1.2509\n",
      "Epoch 01040: saving model to Regression_Model/bl6.mle.linear-1040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.2495 - val_loss: 0.0641 - val_mse: 0.8929\n",
      "Epoch 1041/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.2036 - val_loss: 0.0656 - val_mse: 0.8830\n",
      "Epoch 1042/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.3264 - val_loss: 0.0656 - val_mse: 0.8925\n",
      "Epoch 1043/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.5549 - val_loss: 0.0646 - val_mse: 0.8846\n",
      "Epoch 1044/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.3390 - val_loss: 0.0653 - val_mse: 0.8806\n",
      "Epoch 1045/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0757 - mse: 1.3470 - val_loss: 0.0645 - val_mse: 0.8716\n",
      "Epoch 1046/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.4272 - val_loss: 0.0659 - val_mse: 0.9049\n",
      "Epoch 1047/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.6070 - val_loss: 0.0661 - val_mse: 0.9054\n",
      "Epoch 1048/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.3745 - val_loss: 0.0657 - val_mse: 0.8808\n",
      "Epoch 1049/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.1146 - val_loss: 0.0665 - val_mse: 0.8740\n",
      "Epoch 1050/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0771 - mse: 1.5097\n",
      "Epoch 01050: saving model to Regression_Model/bl6.mle.linear-1050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.4995 - val_loss: 0.0640 - val_mse: 0.8801\n",
      "Epoch 1051/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.2894 - val_loss: 0.0640 - val_mse: 0.8812\n",
      "Epoch 1052/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.3641 - val_loss: 0.0658 - val_mse: 0.8724\n",
      "Epoch 1053/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.3214 - val_loss: 0.0648 - val_mse: 0.8976\n",
      "Epoch 1054/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0752 - mse: 1.2552 - val_loss: 0.0673 - val_mse: 0.9075\n",
      "Epoch 1055/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0754 - mse: 1.4214 - val_loss: 0.0648 - val_mse: 0.8946\n",
      "Epoch 1056/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.2810 - val_loss: 0.0648 - val_mse: 0.8824\n",
      "Epoch 1057/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0771 - mse: 1.2986 - val_loss: 0.0645 - val_mse: 0.8911\n",
      "Epoch 1058/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0790 - mse: 1.7622 - val_loss: 0.0642 - val_mse: 0.8774\n",
      "Epoch 1059/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.2678 - val_loss: 0.0645 - val_mse: 0.8950\n",
      "Epoch 1060/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0770 - mse: 1.3144\n",
      "Epoch 01060: saving model to Regression_Model/bl6.mle.linear-1060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3109 - val_loss: 0.0653 - val_mse: 0.8889\n",
      "Epoch 1061/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.3671 - val_loss: 0.0653 - val_mse: 0.8808\n",
      "Epoch 1062/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.3987 - val_loss: 0.0673 - val_mse: 0.8874\n",
      "Epoch 1063/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.2498 - val_loss: 0.0673 - val_mse: 0.8818\n",
      "Epoch 1064/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.3854 - val_loss: 0.0649 - val_mse: 0.8819\n",
      "Epoch 1065/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.2749 - val_loss: 0.0646 - val_mse: 0.8820\n",
      "Epoch 1066/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.3365 - val_loss: 0.0657 - val_mse: 0.8879\n",
      "Epoch 1067/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.2697 - val_loss: 0.0683 - val_mse: 0.8802\n",
      "Epoch 1068/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.3055 - val_loss: 0.0647 - val_mse: 0.9097\n",
      "Epoch 1069/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.4216 - val_loss: 0.0667 - val_mse: 0.9654\n",
      "Epoch 1070/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0802 - mse: 1.5240\n",
      "Epoch 01070: saving model to Regression_Model/bl6.mle.linear-1070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.5058 - val_loss: 0.0677 - val_mse: 0.8916\n",
      "Epoch 1071/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0802 - mse: 1.2982 - val_loss: 0.0653 - val_mse: 0.8871\n",
      "Epoch 1072/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.3373 - val_loss: 0.0656 - val_mse: 0.8811\n",
      "Epoch 1073/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.3293 - val_loss: 0.0655 - val_mse: 0.9286\n",
      "Epoch 1074/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.4452 - val_loss: 0.0670 - val_mse: 0.9782\n",
      "Epoch 1075/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.4482 - val_loss: 0.0655 - val_mse: 0.9069\n",
      "Epoch 1076/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.6026 - val_loss: 0.0672 - val_mse: 0.8836\n",
      "Epoch 1077/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.4573 - val_loss: 0.0653 - val_mse: 0.8961\n",
      "Epoch 1078/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.4163 - val_loss: 0.0685 - val_mse: 0.9209\n",
      "Epoch 1079/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0801 - mse: 1.4277 - val_loss: 0.0686 - val_mse: 0.8969\n",
      "Epoch 1080/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0798 - mse: 1.3475\n",
      "Epoch 01080: saving model to Regression_Model/bl6.mle.linear-1080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.3464 - val_loss: 0.0658 - val_mse: 0.9210\n",
      "Epoch 1081/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.6942 - val_loss: 0.0657 - val_mse: 0.9001\n",
      "Epoch 1082/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0790 - mse: 1.2822 - val_loss: 0.0669 - val_mse: 0.8931\n",
      "Epoch 1083/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.3373 - val_loss: 0.0664 - val_mse: 0.8917\n",
      "Epoch 1084/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.2771 - val_loss: 0.0640 - val_mse: 0.8989\n",
      "Epoch 1085/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.3366 - val_loss: 0.0641 - val_mse: 0.8835\n",
      "Epoch 1086/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.2728 - val_loss: 0.0636 - val_mse: 0.8818\n",
      "Epoch 1087/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.3573 - val_loss: 0.0653 - val_mse: 0.8893\n",
      "Epoch 1088/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.5233 - val_loss: 0.0666 - val_mse: 0.8824\n",
      "Epoch 1089/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0758 - mse: 1.8732 - val_loss: 0.0664 - val_mse: 0.8945\n",
      "Epoch 1090/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0766 - mse: 1.3531\n",
      "Epoch 01090: saving model to Regression_Model/bl6.mle.linear-1090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.3434 - val_loss: 0.0649 - val_mse: 0.8875\n",
      "Epoch 1091/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0756 - mse: 1.1395 - val_loss: 0.0654 - val_mse: 0.8944\n",
      "Epoch 1092/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.3891 - val_loss: 0.0668 - val_mse: 0.8791\n",
      "Epoch 1093/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.3419 - val_loss: 0.0658 - val_mse: 0.9043\n",
      "Epoch 1094/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.4795 - val_loss: 0.0647 - val_mse: 0.8889\n",
      "Epoch 1095/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.2499 - val_loss: 0.0681 - val_mse: 0.8822\n",
      "Epoch 1096/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.7351 - val_loss: 0.0663 - val_mse: 0.8858\n",
      "Epoch 1097/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.2488 - val_loss: 0.0643 - val_mse: 0.8950\n",
      "Epoch 1098/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0746 - mse: 1.3005 - val_loss: 0.0643 - val_mse: 0.8792\n",
      "Epoch 1099/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.4768 - val_loss: 0.0650 - val_mse: 0.8865\n",
      "Epoch 1100/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0778 - mse: 1.3030\n",
      "Epoch 01100: saving model to Regression_Model/bl6.mle.linear-1100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.2956 - val_loss: 0.0663 - val_mse: 0.8818\n",
      "Epoch 1101/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.2272 - val_loss: 0.0664 - val_mse: 0.8835\n",
      "Epoch 1102/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.2343 - val_loss: 0.0645 - val_mse: 0.8903\n",
      "Epoch 1103/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.3804 - val_loss: 0.0666 - val_mse: 0.8889\n",
      "Epoch 1104/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.2853 - val_loss: 0.0667 - val_mse: 0.8937\n",
      "Epoch 1105/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.5694 - val_loss: 0.0651 - val_mse: 0.8942\n",
      "Epoch 1106/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.5117 - val_loss: 0.0666 - val_mse: 0.9150\n",
      "Epoch 1107/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.3516 - val_loss: 0.0671 - val_mse: 0.9549\n",
      "Epoch 1108/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.2604 - val_loss: 0.0649 - val_mse: 0.9186\n",
      "Epoch 1109/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.2407 - val_loss: 0.0662 - val_mse: 0.9020\n",
      "Epoch 1110/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0767 - mse: 1.3532\n",
      "Epoch 01110: saving model to Regression_Model/bl6.mle.linear-1110.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0769 - mse: 1.5059 - val_loss: 0.0660 - val_mse: 0.9247\n",
      "Epoch 1111/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.2563 - val_loss: 0.0645 - val_mse: 0.8989\n",
      "Epoch 1112/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0802 - mse: 1.3159 - val_loss: 0.0671 - val_mse: 0.8928\n",
      "Epoch 1113/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0740 - mse: 1.4661 - val_loss: 0.0648 - val_mse: 0.8800\n",
      "Epoch 1114/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.4562 - val_loss: 0.0632 - val_mse: 0.8811\n",
      "Epoch 1115/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.2584 - val_loss: 0.0665 - val_mse: 0.8833\n",
      "Epoch 1116/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.5218 - val_loss: 0.0657 - val_mse: 0.9070\n",
      "Epoch 1117/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0790 - mse: 1.3698 - val_loss: 0.0663 - val_mse: 0.8946\n",
      "Epoch 1118/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.3936 - val_loss: 0.0666 - val_mse: 0.8840\n",
      "Epoch 1119/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0755 - mse: 1.1186 - val_loss: 0.0661 - val_mse: 0.9012\n",
      "Epoch 1120/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0756 - mse: 1.3622\n",
      "Epoch 01120: saving model to Regression_Model/bl6.mle.linear-1120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.3548 - val_loss: 0.0649 - val_mse: 0.8990\n",
      "Epoch 1121/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.2720 - val_loss: 0.0649 - val_mse: 0.8888\n",
      "Epoch 1122/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0792 - mse: 1.5480 - val_loss: 0.0674 - val_mse: 0.8778\n",
      "Epoch 1123/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.2001 - val_loss: 0.0652 - val_mse: 0.8818\n",
      "Epoch 1124/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.1952 - val_loss: 0.0656 - val_mse: 0.8888\n",
      "Epoch 1125/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.3409 - val_loss: 0.0654 - val_mse: 0.8824\n",
      "Epoch 1126/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.6566 - val_loss: 0.0656 - val_mse: 0.8811\n",
      "Epoch 1127/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0750 - mse: 1.1312 - val_loss: 0.0666 - val_mse: 0.9092\n",
      "Epoch 1128/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.2769 - val_loss: 0.0657 - val_mse: 0.8970\n",
      "Epoch 1129/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0790 - mse: 1.2412 - val_loss: 0.0669 - val_mse: 0.9189\n",
      "Epoch 1130/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0782 - mse: 1.4007\n",
      "Epoch 01130: saving model to Regression_Model/bl6.mle.linear-1130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.3968 - val_loss: 0.0667 - val_mse: 0.9461\n",
      "Epoch 1131/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0764 - mse: 1.2779 - val_loss: 0.0668 - val_mse: 0.9360\n",
      "Epoch 1132/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0803 - mse: 1.2707 - val_loss: 0.0667 - val_mse: 0.9241\n",
      "Epoch 1133/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0759 - mse: 1.1901 - val_loss: 0.0677 - val_mse: 0.8929\n",
      "Epoch 1134/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.3309 - val_loss: 0.0660 - val_mse: 0.9004\n",
      "Epoch 1135/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0768 - mse: 1.2040 - val_loss: 0.0638 - val_mse: 0.8855\n",
      "Epoch 1136/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.2045 - val_loss: 0.0653 - val_mse: 0.8932\n",
      "Epoch 1137/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.3257 - val_loss: 0.0666 - val_mse: 0.8807\n",
      "Epoch 1138/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0787 - mse: 1.3536 - val_loss: 0.0636 - val_mse: 0.8809\n",
      "Epoch 1139/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.5394 - val_loss: 0.0636 - val_mse: 0.8787\n",
      "Epoch 1140/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0780 - mse: 1.4483\n",
      "Epoch 01140: saving model to Regression_Model/bl6.mle.linear-1140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.4408 - val_loss: 0.0653 - val_mse: 0.8783\n",
      "Epoch 1141/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0759 - mse: 1.2331 - val_loss: 0.0661 - val_mse: 0.8896\n",
      "Epoch 1142/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.3623 - val_loss: 0.0653 - val_mse: 0.8796\n",
      "Epoch 1143/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0758 - mse: 1.1549 - val_loss: 0.0643 - val_mse: 0.8833\n",
      "Epoch 1144/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0782 - mse: 1.1467 - val_loss: 0.0640 - val_mse: 0.8834\n",
      "Epoch 1145/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.4325 - val_loss: 0.0647 - val_mse: 0.8949\n",
      "Epoch 1146/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0769 - mse: 1.4484 - val_loss: 0.0652 - val_mse: 0.8850\n",
      "Epoch 1147/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.3049 - val_loss: 0.0653 - val_mse: 0.8808\n",
      "Epoch 1148/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.3939 - val_loss: 0.0651 - val_mse: 0.8830\n",
      "Epoch 1149/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0779 - mse: 1.4489 - val_loss: 0.0649 - val_mse: 0.8778\n",
      "Epoch 1150/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0774 - mse: 1.5981\n",
      "Epoch 01150: saving model to Regression_Model/bl6.mle.linear-1150.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0770 - mse: 1.5878 - val_loss: 0.0644 - val_mse: 0.8762\n",
      "Epoch 1151/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.3295 - val_loss: 0.0647 - val_mse: 0.8717\n",
      "Epoch 1152/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.4105 - val_loss: 0.0633 - val_mse: 0.8758\n",
      "Epoch 1153/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.3164 - val_loss: 0.0647 - val_mse: 0.8877\n",
      "Epoch 1154/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 1.0993 - val_loss: 0.0645 - val_mse: 0.8859\n",
      "Epoch 1155/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.3873 - val_loss: 0.0670 - val_mse: 0.8806\n",
      "Epoch 1156/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.1870 - val_loss: 0.0656 - val_mse: 0.8750\n",
      "Epoch 1157/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0760 - mse: 1.4133 - val_loss: 0.0647 - val_mse: 0.8814\n",
      "Epoch 1158/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0793 - mse: 1.2981 - val_loss: 0.0648 - val_mse: 0.8821\n",
      "Epoch 1159/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.3622 - val_loss: 0.0671 - val_mse: 0.8778\n",
      "Epoch 1160/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0774 - mse: 1.2727\n",
      "Epoch 01160: saving model to Regression_Model/bl6.mle.linear-1160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.2718 - val_loss: 0.0680 - val_mse: 0.9605\n",
      "Epoch 1161/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0789 - mse: 1.4071 - val_loss: 0.0686 - val_mse: 0.9130\n",
      "Epoch 1162/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.1948 - val_loss: 0.0680 - val_mse: 0.8864\n",
      "Epoch 1163/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.1572 - val_loss: 0.0655 - val_mse: 0.8836\n",
      "Epoch 1164/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.2427 - val_loss: 0.0651 - val_mse: 0.8929\n",
      "Epoch 1165/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.3821 - val_loss: 0.0664 - val_mse: 0.8833\n",
      "Epoch 1166/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0758 - mse: 1.3183 - val_loss: 0.0662 - val_mse: 0.8954\n",
      "Epoch 1167/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.1736 - val_loss: 0.0652 - val_mse: 0.8910\n",
      "Epoch 1168/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0785 - mse: 1.3475 - val_loss: 0.0664 - val_mse: 0.8821\n",
      "Epoch 1169/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.2182 - val_loss: 0.0667 - val_mse: 0.8897\n",
      "Epoch 1170/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0760 - mse: 1.3487\n",
      "Epoch 01170: saving model to Regression_Model/bl6.mle.linear-1170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.4204 - val_loss: 0.0657 - val_mse: 0.8953\n",
      "Epoch 1171/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0756 - mse: 1.3313 - val_loss: 0.0650 - val_mse: 0.8804\n",
      "Epoch 1172/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.4821 - val_loss: 0.0664 - val_mse: 0.8876\n",
      "Epoch 1173/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0790 - mse: 1.4337 - val_loss: 0.0656 - val_mse: 0.8896\n",
      "Epoch 1174/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.0865 - val_loss: 0.0656 - val_mse: 0.8909\n",
      "Epoch 1175/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.3863 - val_loss: 0.0666 - val_mse: 0.8903\n",
      "Epoch 1176/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0790 - mse: 1.1760 - val_loss: 0.0663 - val_mse: 0.8973\n",
      "Epoch 1177/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.3123 - val_loss: 0.0695 - val_mse: 0.8884\n",
      "Epoch 1178/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.3405 - val_loss: 0.0668 - val_mse: 0.9025\n",
      "Epoch 1179/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.3708 - val_loss: 0.0710 - val_mse: 0.8927\n",
      "Epoch 1180/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0780 - mse: 1.4715\n",
      "Epoch 01180: saving model to Regression_Model/bl6.mle.linear-1180.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0785 - mse: 1.4713 - val_loss: 0.0680 - val_mse: 0.8919\n",
      "Epoch 1181/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.2542 - val_loss: 0.0660 - val_mse: 0.9192\n",
      "Epoch 1182/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0758 - mse: 1.2800 - val_loss: 0.0652 - val_mse: 0.8985\n",
      "Epoch 1183/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0760 - mse: 1.1848 - val_loss: 0.0657 - val_mse: 0.8918\n",
      "Epoch 1184/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.2848 - val_loss: 0.0666 - val_mse: 0.8835\n",
      "Epoch 1185/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0784 - mse: 1.2588 - val_loss: 0.0650 - val_mse: 0.9196\n",
      "Epoch 1186/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0753 - mse: 1.3071 - val_loss: 0.0665 - val_mse: 0.8900\n",
      "Epoch 1187/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0793 - mse: 1.4112 - val_loss: 0.0666 - val_mse: 0.8920\n",
      "Epoch 1188/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.2286 - val_loss: 0.0667 - val_mse: 0.9180\n",
      "Epoch 1189/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.2681 - val_loss: 0.0672 - val_mse: 0.8977\n",
      "Epoch 1190/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0770 - mse: 1.1676\n",
      "Epoch 01190: saving model to Regression_Model/bl6.mle.linear-1190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.1723 - val_loss: 0.0653 - val_mse: 0.9051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1191/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3103 - val_loss: 0.0659 - val_mse: 0.8787\n",
      "Epoch 1192/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.4907 - val_loss: 0.0644 - val_mse: 0.8813\n",
      "Epoch 1193/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.5432 - val_loss: 0.0649 - val_mse: 0.8828\n",
      "Epoch 1194/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0784 - mse: 1.3280 - val_loss: 0.0635 - val_mse: 0.8962\n",
      "Epoch 1195/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0759 - mse: 1.1638 - val_loss: 0.0659 - val_mse: 0.8887\n",
      "Epoch 1196/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0768 - mse: 1.1927 - val_loss: 0.0666 - val_mse: 0.8839\n",
      "Epoch 1197/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.3531 - val_loss: 0.0647 - val_mse: 0.8918\n",
      "Epoch 1198/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0768 - mse: 1.2024 - val_loss: 0.0666 - val_mse: 0.8914\n",
      "Epoch 1199/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0786 - mse: 1.2398 - val_loss: 0.0670 - val_mse: 0.9007\n",
      "Epoch 1200/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0767 - mse: 1.2828\n",
      "Epoch 01200: saving model to Regression_Model/bl6.mle.linear-1200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.2996 - val_loss: 0.0658 - val_mse: 0.8986\n",
      "Epoch 1201/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 1.3887 - val_loss: 0.0661 - val_mse: 0.8936\n",
      "Epoch 1202/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.2416 - val_loss: 0.0681 - val_mse: 0.8891\n",
      "Epoch 1203/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0780 - mse: 1.1952 - val_loss: 0.0673 - val_mse: 0.8984\n",
      "Epoch 1204/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0801 - mse: 1.3051 - val_loss: 0.0660 - val_mse: 0.9141\n",
      "Epoch 1205/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.2568 - val_loss: 0.0657 - val_mse: 0.9040\n",
      "Epoch 1206/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0755 - mse: 1.1956 - val_loss: 0.0668 - val_mse: 0.9436\n",
      "Epoch 1207/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0752 - mse: 1.2167 - val_loss: 0.0663 - val_mse: 0.8872\n",
      "Epoch 1208/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.1445 - val_loss: 0.0655 - val_mse: 0.9301\n",
      "Epoch 1209/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.3713 - val_loss: 0.0657 - val_mse: 0.8861\n",
      "Epoch 1210/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0784 - mse: 1.8605\n",
      "Epoch 01210: saving model to Regression_Model/bl6.mle.linear-1210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.8408 - val_loss: 0.0674 - val_mse: 0.8760\n",
      "Epoch 1211/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.2708 - val_loss: 0.0648 - val_mse: 0.9051\n",
      "Epoch 1212/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.4526 - val_loss: 0.0659 - val_mse: 0.8779\n",
      "Epoch 1213/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.2962 - val_loss: 0.0652 - val_mse: 0.8842\n",
      "Epoch 1214/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.2834 - val_loss: 0.0654 - val_mse: 0.8926\n",
      "Epoch 1215/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.4361 - val_loss: 0.0656 - val_mse: 0.8892\n",
      "Epoch 1216/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.3114 - val_loss: 0.0656 - val_mse: 0.8835\n",
      "Epoch 1217/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0746 - mse: 1.2923 - val_loss: 0.0645 - val_mse: 0.8833\n",
      "Epoch 1218/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0779 - mse: 1.4052 - val_loss: 0.0652 - val_mse: 0.8758\n",
      "Epoch 1219/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.4908 - val_loss: 0.0647 - val_mse: 0.8812\n",
      "Epoch 1220/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0780 - mse: 1.5850\n",
      "Epoch 01220: saving model to Regression_Model/bl6.mle.linear-1220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.5885 - val_loss: 0.0644 - val_mse: 0.8840\n",
      "Epoch 1221/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0792 - mse: 1.3433 - val_loss: 0.0651 - val_mse: 0.8834\n",
      "Epoch 1222/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.1334 - val_loss: 0.0650 - val_mse: 0.8811\n",
      "Epoch 1223/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0756 - mse: 1.2597 - val_loss: 0.0649 - val_mse: 0.8801\n",
      "Epoch 1224/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.5514 - val_loss: 0.0639 - val_mse: 0.8828\n",
      "Epoch 1225/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0755 - mse: 1.2907 - val_loss: 0.0655 - val_mse: 0.8919\n",
      "Epoch 1226/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.4288 - val_loss: 0.0655 - val_mse: 0.9075\n",
      "Epoch 1227/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.2191 - val_loss: 0.0656 - val_mse: 0.8868\n",
      "Epoch 1228/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0757 - mse: 1.2451 - val_loss: 0.0644 - val_mse: 0.8822\n",
      "Epoch 1229/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0768 - mse: 1.3783 - val_loss: 0.0645 - val_mse: 0.8756\n",
      "Epoch 1230/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0762 - mse: 1.1583\n",
      "Epoch 01230: saving model to Regression_Model/bl6.mle.linear-1230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.1551 - val_loss: 0.0646 - val_mse: 0.8910\n",
      "Epoch 1231/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.3014 - val_loss: 0.0652 - val_mse: 0.8905\n",
      "Epoch 1232/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.3069 - val_loss: 0.0648 - val_mse: 0.8842\n",
      "Epoch 1233/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0744 - mse: 1.6300 - val_loss: 0.0656 - val_mse: 0.8870\n",
      "Epoch 1234/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.2685 - val_loss: 0.0649 - val_mse: 0.8836\n",
      "Epoch 1235/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0770 - mse: 1.2184 - val_loss: 0.0646 - val_mse: 0.8807\n",
      "Epoch 1236/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.2094 - val_loss: 0.0660 - val_mse: 0.8751\n",
      "Epoch 1237/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.1238 - val_loss: 0.0664 - val_mse: 0.8734\n",
      "Epoch 1238/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.3312 - val_loss: 0.0649 - val_mse: 0.8797\n",
      "Epoch 1239/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.3516 - val_loss: 0.0645 - val_mse: 0.8784\n",
      "Epoch 1240/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0770 - mse: 1.1358\n",
      "Epoch 01240: saving model to Regression_Model/bl6.mle.linear-1240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.1364 - val_loss: 0.0643 - val_mse: 0.8798\n",
      "Epoch 1241/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0771 - mse: 1.5047 - val_loss: 0.0643 - val_mse: 0.8751\n",
      "Epoch 1242/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.2952 - val_loss: 0.0664 - val_mse: 0.8716\n",
      "Epoch 1243/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.2201 - val_loss: 0.0639 - val_mse: 0.8795\n",
      "Epoch 1244/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.4251 - val_loss: 0.0647 - val_mse: 0.8736\n",
      "Epoch 1245/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0779 - mse: 1.3217 - val_loss: 0.0644 - val_mse: 0.8827\n",
      "Epoch 1246/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0787 - mse: 1.4480 - val_loss: 0.0651 - val_mse: 0.8725\n",
      "Epoch 1247/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.1641 - val_loss: 0.0658 - val_mse: 0.8779\n",
      "Epoch 1248/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0753 - mse: 1.1870 - val_loss: 0.0648 - val_mse: 0.8832\n",
      "Epoch 1249/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0771 - mse: 1.4076 - val_loss: 0.0662 - val_mse: 0.8732\n",
      "Epoch 1250/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0784 - mse: 1.2837\n",
      "Epoch 01250: saving model to Regression_Model/bl6.mle.linear-1250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.2716 - val_loss: 0.0648 - val_mse: 0.8841\n",
      "Epoch 1251/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0760 - mse: 1.2662 - val_loss: 0.0649 - val_mse: 0.8864\n",
      "Epoch 1252/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.3140 - val_loss: 0.0648 - val_mse: 0.8798\n",
      "Epoch 1253/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0761 - mse: 1.2471 - val_loss: 0.0641 - val_mse: 0.8798\n",
      "Epoch 1254/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.3279 - val_loss: 0.0663 - val_mse: 0.9105\n",
      "Epoch 1255/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0783 - mse: 1.2698 - val_loss: 0.0672 - val_mse: 0.8887\n",
      "Epoch 1256/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.4038 - val_loss: 0.0670 - val_mse: 0.9210\n",
      "Epoch 1257/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.4427 - val_loss: 0.0668 - val_mse: 0.9011\n",
      "Epoch 1258/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.2521 - val_loss: 0.0664 - val_mse: 0.8994\n",
      "Epoch 1259/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.3186 - val_loss: 0.0654 - val_mse: 0.8873\n",
      "Epoch 1260/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0771 - mse: 1.2266\n",
      "Epoch 01260: saving model to Regression_Model/bl6.mle.linear-1260.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.2205 - val_loss: 0.0670 - val_mse: 0.9011\n",
      "Epoch 1261/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.3666 - val_loss: 0.0660 - val_mse: 0.9105\n",
      "Epoch 1262/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.1408 - val_loss: 0.0657 - val_mse: 0.9077\n",
      "Epoch 1263/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.2255 - val_loss: 0.0653 - val_mse: 0.8820\n",
      "Epoch 1264/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0770 - mse: 1.1952 - val_loss: 0.0650 - val_mse: 0.8809\n",
      "Epoch 1265/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.2177 - val_loss: 0.0661 - val_mse: 0.8958\n",
      "Epoch 1266/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 1.3134 - val_loss: 0.0663 - val_mse: 0.8775\n",
      "Epoch 1267/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.3484 - val_loss: 0.0640 - val_mse: 0.8803\n",
      "Epoch 1268/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0783 - mse: 1.6158 - val_loss: 0.0661 - val_mse: 0.8737\n",
      "Epoch 1269/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0781 - mse: 1.4202 - val_loss: 0.0671 - val_mse: 0.8736\n",
      "Epoch 1270/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0762 - mse: 1.2988\n",
      "Epoch 01270: saving model to Regression_Model/bl6.mle.linear-1270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.2925 - val_loss: 0.0643 - val_mse: 0.8796\n",
      "Epoch 1271/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0782 - mse: 1.3152 - val_loss: 0.0646 - val_mse: 0.8824\n",
      "Epoch 1272/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0796 - mse: 1.3449 - val_loss: 0.0661 - val_mse: 0.8915\n",
      "Epoch 1273/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0763 - mse: 1.1568 - val_loss: 0.0660 - val_mse: 0.8874\n",
      "Epoch 1274/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0782 - mse: 1.3167 - val_loss: 0.0645 - val_mse: 0.8821\n",
      "Epoch 1275/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0780 - mse: 1.3459 - val_loss: 0.0645 - val_mse: 0.8831\n",
      "Epoch 1276/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.3041 - val_loss: 0.0661 - val_mse: 0.8820\n",
      "Epoch 1277/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.7414 - val_loss: 0.0649 - val_mse: 0.8832\n",
      "Epoch 1278/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0779 - mse: 1.4734 - val_loss: 0.0659 - val_mse: 0.8881\n",
      "Epoch 1279/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.7852 - val_loss: 0.0654 - val_mse: 0.8844\n",
      "Epoch 1280/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0780 - mse: 1.5044\n",
      "Epoch 01280: saving model to Regression_Model/bl6.mle.linear-1280.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.5015 - val_loss: 0.0652 - val_mse: 0.8713\n",
      "Epoch 1281/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.5594 - val_loss: 0.0652 - val_mse: 0.8714\n",
      "Epoch 1282/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.2807 - val_loss: 0.0637 - val_mse: 0.8807\n",
      "Epoch 1283/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0766 - mse: 1.4260 - val_loss: 0.0656 - val_mse: 0.8713\n",
      "Epoch 1284/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0793 - mse: 1.6598 - val_loss: 0.0647 - val_mse: 0.8731\n",
      "Epoch 1285/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.4339 - val_loss: 0.0636 - val_mse: 0.8745\n",
      "Epoch 1286/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0758 - mse: 1.1474 - val_loss: 0.0667 - val_mse: 0.8750\n",
      "Epoch 1287/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.4490 - val_loss: 0.0644 - val_mse: 0.8967\n",
      "Epoch 1288/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0777 - mse: 1.3224 - val_loss: 0.0655 - val_mse: 0.8962\n",
      "Epoch 1289/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.1476 - val_loss: 0.0673 - val_mse: 0.8791\n",
      "Epoch 1290/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0767 - mse: 1.2817\n",
      "Epoch 01290: saving model to Regression_Model/bl6.mle.linear-1290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.2738 - val_loss: 0.0649 - val_mse: 0.8973\n",
      "Epoch 1291/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.3521 - val_loss: 0.0651 - val_mse: 0.8836\n",
      "Epoch 1292/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.2794 - val_loss: 0.0658 - val_mse: 0.8784\n",
      "Epoch 1293/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.3237 - val_loss: 0.0649 - val_mse: 0.8837\n",
      "Epoch 1294/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0754 - mse: 1.5637 - val_loss: 0.0645 - val_mse: 0.8865\n",
      "Epoch 1295/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0768 - mse: 1.5448 - val_loss: 0.0659 - val_mse: 0.8781\n",
      "Epoch 1296/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.3266 - val_loss: 0.0650 - val_mse: 0.8743\n",
      "Epoch 1297/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.2602 - val_loss: 0.0639 - val_mse: 0.8804\n",
      "Epoch 1298/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.2822 - val_loss: 0.0642 - val_mse: 0.8772\n",
      "Epoch 1299/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.3702 - val_loss: 0.0641 - val_mse: 0.8732\n",
      "Epoch 1300/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0760 - mse: 1.4312\n",
      "Epoch 01300: saving model to Regression_Model/bl6.mle.linear-1300.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.0758 - mse: 1.4273 - val_loss: 0.0642 - val_mse: 0.8733\n",
      "Epoch 1301/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.1682 - val_loss: 0.0648 - val_mse: 0.8718\n",
      "Epoch 1302/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0766 - mse: 1.6240 - val_loss: 0.0637 - val_mse: 0.8771\n",
      "Epoch 1303/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0743 - mse: 1.1764 - val_loss: 0.0650 - val_mse: 0.8726\n",
      "Epoch 1304/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0783 - mse: 1.3469 - val_loss: 0.0644 - val_mse: 0.8721\n",
      "Epoch 1305/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.2652 - val_loss: 0.0648 - val_mse: 0.8749\n",
      "Epoch 1306/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.2515 - val_loss: 0.0641 - val_mse: 0.8815\n",
      "Epoch 1307/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.3426 - val_loss: 0.0643 - val_mse: 0.8741\n",
      "Epoch 1308/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0760 - mse: 1.1845 - val_loss: 0.0652 - val_mse: 0.8716\n",
      "Epoch 1309/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0786 - mse: 1.4138 - val_loss: 0.0660 - val_mse: 0.8729\n",
      "Epoch 1310/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0771 - mse: 1.2843\n",
      "Epoch 01310: saving model to Regression_Model/bl6.mle.linear-1310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.2819 - val_loss: 0.0642 - val_mse: 0.8881\n",
      "Epoch 1311/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.4934 - val_loss: 0.0646 - val_mse: 0.8824\n",
      "Epoch 1312/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0764 - mse: 1.2487 - val_loss: 0.0656 - val_mse: 0.8904\n",
      "Epoch 1313/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0760 - mse: 1.2602 - val_loss: 0.0658 - val_mse: 0.9009\n",
      "Epoch 1314/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.6095 - val_loss: 0.0652 - val_mse: 0.9070\n",
      "Epoch 1315/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0761 - mse: 1.5557 - val_loss: 0.0646 - val_mse: 0.8916\n",
      "Epoch 1316/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0784 - mse: 1.4098 - val_loss: 0.0654 - val_mse: 0.8813\n",
      "Epoch 1317/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0763 - mse: 1.3783 - val_loss: 0.0653 - val_mse: 0.8809\n",
      "Epoch 1318/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.3547 - val_loss: 0.0648 - val_mse: 0.8787\n",
      "Epoch 1319/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.7340 - val_loss: 0.0651 - val_mse: 0.8783\n",
      "Epoch 1320/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0778 - mse: 1.2805\n",
      "Epoch 01320: saving model to Regression_Model/bl6.mle.linear-1320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.2708 - val_loss: 0.0647 - val_mse: 0.8800\n",
      "Epoch 1321/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0747 - mse: 1.2638 - val_loss: 0.0647 - val_mse: 0.8838\n",
      "Epoch 1322/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0763 - mse: 1.4881 - val_loss: 0.0651 - val_mse: 0.8954\n",
      "Epoch 1323/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.1863 - val_loss: 0.0667 - val_mse: 0.9025\n",
      "Epoch 1324/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0769 - mse: 1.2902 - val_loss: 0.0659 - val_mse: 0.8956\n",
      "Epoch 1325/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.1897 - val_loss: 0.0655 - val_mse: 0.9009\n",
      "Epoch 1326/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.5610 - val_loss: 0.0649 - val_mse: 0.8965\n",
      "Epoch 1327/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.2364 - val_loss: 0.0641 - val_mse: 0.8857\n",
      "Epoch 1328/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.3792 - val_loss: 0.0644 - val_mse: 0.8758\n",
      "Epoch 1329/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.1844 - val_loss: 0.0655 - val_mse: 0.8769\n",
      "Epoch 1330/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0759 - mse: 1.0927\n",
      "Epoch 01330: saving model to Regression_Model/bl6.mle.linear-1330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 1.0884 - val_loss: 0.0647 - val_mse: 0.8827\n",
      "Epoch 1331/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.3913 - val_loss: 0.0658 - val_mse: 0.8820\n",
      "Epoch 1332/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.2628 - val_loss: 0.0645 - val_mse: 0.8897\n",
      "Epoch 1333/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.4070 - val_loss: 0.0646 - val_mse: 0.8799\n",
      "Epoch 1334/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0769 - mse: 1.1793 - val_loss: 0.0642 - val_mse: 0.8843\n",
      "Epoch 1335/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.2931 - val_loss: 0.0645 - val_mse: 0.8784\n",
      "Epoch 1336/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.2341 - val_loss: 0.0658 - val_mse: 0.8758\n",
      "Epoch 1337/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0780 - mse: 1.3562 - val_loss: 0.0644 - val_mse: 0.8779\n",
      "Epoch 1338/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0791 - mse: 1.2642 - val_loss: 0.0649 - val_mse: 0.8809\n",
      "Epoch 1339/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.4508 - val_loss: 0.0649 - val_mse: 0.8904\n",
      "Epoch 1340/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0774 - mse: 1.1428\n",
      "Epoch 01340: saving model to Regression_Model/bl6.mle.linear-1340.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0769 - mse: 1.1315 - val_loss: 0.0655 - val_mse: 0.8869\n",
      "Epoch 1341/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.3489 - val_loss: 0.0658 - val_mse: 0.8788\n",
      "Epoch 1342/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 1.2934 - val_loss: 0.0649 - val_mse: 0.8912\n",
      "Epoch 1343/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.3373 - val_loss: 0.0652 - val_mse: 0.8849\n",
      "Epoch 1344/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0777 - mse: 1.4548 - val_loss: 0.0651 - val_mse: 0.8821\n",
      "Epoch 1345/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.5267 - val_loss: 0.0647 - val_mse: 0.8782\n",
      "Epoch 1346/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.2087 - val_loss: 0.0642 - val_mse: 0.8754\n",
      "Epoch 1347/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3978 - val_loss: 0.0646 - val_mse: 0.8732\n",
      "Epoch 1348/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.2895 - val_loss: 0.0654 - val_mse: 0.8717\n",
      "Epoch 1349/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0749 - mse: 1.3472 - val_loss: 0.0637 - val_mse: 0.8758\n",
      "Epoch 1350/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0775 - mse: 1.1970\n",
      "Epoch 01350: saving model to Regression_Model/bl6.mle.linear-1350.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.1912 - val_loss: 0.0645 - val_mse: 0.8808\n",
      "Epoch 1351/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0770 - mse: 1.5337 - val_loss: 0.0641 - val_mse: 0.8778\n",
      "Epoch 1352/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.6423 - val_loss: 0.0656 - val_mse: 0.8744\n",
      "Epoch 1353/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0753 - mse: 1.2941 - val_loss: 0.0645 - val_mse: 0.8832\n",
      "Epoch 1354/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.3016 - val_loss: 0.0652 - val_mse: 0.8890\n",
      "Epoch 1355/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.5513 - val_loss: 0.0654 - val_mse: 0.8917\n",
      "Epoch 1356/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.6199 - val_loss: 0.0652 - val_mse: 0.9030\n",
      "Epoch 1357/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.1678 - val_loss: 0.0657 - val_mse: 0.8904\n",
      "Epoch 1358/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0777 - mse: 1.2006 - val_loss: 0.0656 - val_mse: 0.8925\n",
      "Epoch 1359/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.7260 - val_loss: 0.0653 - val_mse: 0.8794\n",
      "Epoch 1360/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0772 - mse: 1.2631\n",
      "Epoch 01360: saving model to Regression_Model/bl6.mle.linear-1360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.2424 - val_loss: 0.0652 - val_mse: 0.8740\n",
      "Epoch 1361/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.5627 - val_loss: 0.0650 - val_mse: 0.8836\n",
      "Epoch 1362/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.3141 - val_loss: 0.0656 - val_mse: 0.8990\n",
      "Epoch 1363/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0769 - mse: 1.1700 - val_loss: 0.0655 - val_mse: 0.8815\n",
      "Epoch 1364/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.3453 - val_loss: 0.0660 - val_mse: 0.8789\n",
      "Epoch 1365/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.1851 - val_loss: 0.0659 - val_mse: 0.8958\n",
      "Epoch 1366/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.2332 - val_loss: 0.0654 - val_mse: 0.9021\n",
      "Epoch 1367/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0785 - mse: 1.3087 - val_loss: 0.0654 - val_mse: 0.8868\n",
      "Epoch 1368/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.4108 - val_loss: 0.0642 - val_mse: 0.8893\n",
      "Epoch 1369/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0756 - mse: 1.2239 - val_loss: 0.0653 - val_mse: 0.8875\n",
      "Epoch 1370/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0803 - mse: 1.4082\n",
      "Epoch 01370: saving model to Regression_Model/bl6.mle.linear-1370.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.3922 - val_loss: 0.0655 - val_mse: 0.8777\n",
      "Epoch 1371/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0756 - mse: 1.1985 - val_loss: 0.0644 - val_mse: 0.8787\n",
      "Epoch 1372/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0790 - mse: 1.2125 - val_loss: 0.0645 - val_mse: 0.8727\n",
      "Epoch 1373/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0755 - mse: 1.2544 - val_loss: 0.0646 - val_mse: 0.8866\n",
      "Epoch 1374/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0760 - mse: 1.2737 - val_loss: 0.0646 - val_mse: 0.8758\n",
      "Epoch 1375/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0787 - mse: 1.1483 - val_loss: 0.0654 - val_mse: 0.8856\n",
      "Epoch 1376/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0751 - mse: 1.0775 - val_loss: 0.0648 - val_mse: 0.8872\n",
      "Epoch 1377/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.5249 - val_loss: 0.0650 - val_mse: 0.8892\n",
      "Epoch 1378/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.6848 - val_loss: 0.0656 - val_mse: 0.9091\n",
      "Epoch 1379/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.1836 - val_loss: 0.0660 - val_mse: 0.8979\n",
      "Epoch 1380/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0764 - mse: 1.7138\n",
      "Epoch 01380: saving model to Regression_Model/bl6.mle.linear-1380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.7014 - val_loss: 0.0661 - val_mse: 0.8852\n",
      "Epoch 1381/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.7304 - val_loss: 0.0657 - val_mse: 0.8871\n",
      "Epoch 1382/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.3436 - val_loss: 0.0662 - val_mse: 0.8797\n",
      "Epoch 1383/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.2714 - val_loss: 0.0653 - val_mse: 0.8841\n",
      "Epoch 1384/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.2761 - val_loss: 0.0651 - val_mse: 0.8922\n",
      "Epoch 1385/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0783 - mse: 1.2448 - val_loss: 0.0656 - val_mse: 0.8863\n",
      "Epoch 1386/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.4113 - val_loss: 0.0650 - val_mse: 0.8758\n",
      "Epoch 1387/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0754 - mse: 1.8555 - val_loss: 0.0653 - val_mse: 0.8766\n",
      "Epoch 1388/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.4267 - val_loss: 0.0645 - val_mse: 0.8850\n",
      "Epoch 1389/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.2135 - val_loss: 0.0642 - val_mse: 0.8738\n",
      "Epoch 1390/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0747 - mse: 1.1913\n",
      "Epoch 01390: saving model to Regression_Model/bl6.mle.linear-1390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0745 - mse: 1.1784 - val_loss: 0.0643 - val_mse: 0.8745\n",
      "Epoch 1391/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.2564 - val_loss: 0.0651 - val_mse: 0.8741\n",
      "Epoch 1392/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.2863 - val_loss: 0.0649 - val_mse: 0.8751\n",
      "Epoch 1393/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.2869 - val_loss: 0.0649 - val_mse: 0.8768\n",
      "Epoch 1394/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.2585 - val_loss: 0.0646 - val_mse: 0.8742\n",
      "Epoch 1395/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.1699 - val_loss: 0.0642 - val_mse: 0.8734\n",
      "Epoch 1396/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0763 - mse: 1.5872 - val_loss: 0.0642 - val_mse: 0.8703\n",
      "Epoch 1397/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.4775 - val_loss: 0.0656 - val_mse: 0.8696\n",
      "Epoch 1398/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.2926 - val_loss: 0.0651 - val_mse: 0.8732\n",
      "Epoch 1399/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0768 - mse: 1.2743 - val_loss: 0.0646 - val_mse: 0.8785\n",
      "Epoch 1400/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0760 - mse: 1.3124\n",
      "Epoch 01400: saving model to Regression_Model/bl6.mle.linear-1400.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.3017 - val_loss: 0.0656 - val_mse: 0.8871\n",
      "Epoch 1401/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.1724 - val_loss: 0.0647 - val_mse: 0.8961\n",
      "Epoch 1402/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.3317 - val_loss: 0.0655 - val_mse: 0.8875\n",
      "Epoch 1403/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0760 - mse: 1.7133 - val_loss: 0.0656 - val_mse: 0.8833\n",
      "Epoch 1404/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.4418 - val_loss: 0.0655 - val_mse: 0.8994\n",
      "Epoch 1405/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.2038 - val_loss: 0.0662 - val_mse: 0.8876\n",
      "Epoch 1406/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.4617 - val_loss: 0.0652 - val_mse: 0.8844\n",
      "Epoch 1407/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.1887 - val_loss: 0.0665 - val_mse: 0.8844\n",
      "Epoch 1408/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.3379 - val_loss: 0.0654 - val_mse: 0.8900\n",
      "Epoch 1409/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.4613 - val_loss: 0.0660 - val_mse: 0.8882\n",
      "Epoch 1410/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0778 - mse: 1.2932\n",
      "Epoch 01410: saving model to Regression_Model/bl6.mle.linear-1410.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.2826 - val_loss: 0.0662 - val_mse: 0.9118\n",
      "Epoch 1411/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 1.3026 - val_loss: 0.0658 - val_mse: 0.8967\n",
      "Epoch 1412/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.1464 - val_loss: 0.0651 - val_mse: 0.8827\n",
      "Epoch 1413/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0751 - mse: 1.2421 - val_loss: 0.0649 - val_mse: 0.8874\n",
      "Epoch 1414/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0748 - mse: 1.2724 - val_loss: 0.0653 - val_mse: 0.8911\n",
      "Epoch 1415/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.3626 - val_loss: 0.0660 - val_mse: 0.8800\n",
      "Epoch 1416/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0783 - mse: 1.6522 - val_loss: 0.0653 - val_mse: 0.8871\n",
      "Epoch 1417/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0789 - mse: 1.4642 - val_loss: 0.0652 - val_mse: 0.8882\n",
      "Epoch 1418/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.1532 - val_loss: 0.0655 - val_mse: 0.9027\n",
      "Epoch 1419/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.3101 - val_loss: 0.0660 - val_mse: 0.8908\n",
      "Epoch 1420/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0761 - mse: 1.6604\n",
      "Epoch 01420: saving model to Regression_Model/bl6.mle.linear-1420.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.6439 - val_loss: 0.0652 - val_mse: 0.8897\n",
      "Epoch 1421/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0769 - mse: 1.2919 - val_loss: 0.0649 - val_mse: 0.8934\n",
      "Epoch 1422/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.2383 - val_loss: 0.0662 - val_mse: 0.8840\n",
      "Epoch 1423/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.1799 - val_loss: 0.0658 - val_mse: 0.8817\n",
      "Epoch 1424/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.1359 - val_loss: 0.0653 - val_mse: 0.8834\n",
      "Epoch 1425/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0748 - mse: 1.1976 - val_loss: 0.0651 - val_mse: 0.8942\n",
      "Epoch 1426/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0753 - mse: 1.5042 - val_loss: 0.0652 - val_mse: 0.8961\n",
      "Epoch 1427/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0754 - mse: 1.0991 - val_loss: 0.0659 - val_mse: 0.8935\n",
      "Epoch 1428/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0786 - mse: 1.2901 - val_loss: 0.0662 - val_mse: 0.8840\n",
      "Epoch 1429/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.2989 - val_loss: 0.0646 - val_mse: 0.8942\n",
      "Epoch 1430/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0792 - mse: 1.3609\n",
      "Epoch 01430: saving model to Regression_Model/bl6.mle.linear-1430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0797 - mse: 1.3468 - val_loss: 0.0662 - val_mse: 0.8760\n",
      "Epoch 1431/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.5817 - val_loss: 0.0648 - val_mse: 0.8807\n",
      "Epoch 1432/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.4197 - val_loss: 0.0648 - val_mse: 0.8841\n",
      "Epoch 1433/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0752 - mse: 1.3147 - val_loss: 0.0647 - val_mse: 0.8789\n",
      "Epoch 1434/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.3578 - val_loss: 0.0662 - val_mse: 0.8812\n",
      "Epoch 1435/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0768 - mse: 1.4310 - val_loss: 0.0653 - val_mse: 0.8898\n",
      "Epoch 1436/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.3415 - val_loss: 0.0651 - val_mse: 0.8869\n",
      "Epoch 1437/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0764 - mse: 1.5474 - val_loss: 0.0652 - val_mse: 0.8946\n",
      "Epoch 1438/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.3587 - val_loss: 0.0655 - val_mse: 0.8854\n",
      "Epoch 1439/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0771 - mse: 1.2647 - val_loss: 0.0652 - val_mse: 0.8789\n",
      "Epoch 1440/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0786 - mse: 1.1072\n",
      "Epoch 01440: saving model to Regression_Model/bl6.mle.linear-1440.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0785 - mse: 1.1066 - val_loss: 0.0648 - val_mse: 0.8820\n",
      "Epoch 1441/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0747 - mse: 1.2468 - val_loss: 0.0644 - val_mse: 0.8851\n",
      "Epoch 1442/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.1993 - val_loss: 0.0651 - val_mse: 0.8789\n",
      "Epoch 1443/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.3614 - val_loss: 0.0651 - val_mse: 0.8771\n",
      "Epoch 1444/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.1852 - val_loss: 0.0652 - val_mse: 0.8780\n",
      "Epoch 1445/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.2463 - val_loss: 0.0652 - val_mse: 0.8740\n",
      "Epoch 1446/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.2400 - val_loss: 0.0651 - val_mse: 0.8733\n",
      "Epoch 1447/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0793 - mse: 1.2788 - val_loss: 0.0641 - val_mse: 0.8795\n",
      "Epoch 1448/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.8748 - val_loss: 0.0645 - val_mse: 0.8768\n",
      "Epoch 1449/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.2070 - val_loss: 0.0653 - val_mse: 0.8754\n",
      "Epoch 1450/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0761 - mse: 1.2534\n",
      "Epoch 01450: saving model to Regression_Model/bl6.mle.linear-1450.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.2445 - val_loss: 0.0649 - val_mse: 0.8776\n",
      "Epoch 1451/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0746 - mse: 1.4691 - val_loss: 0.0645 - val_mse: 0.8799\n",
      "Epoch 1452/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0761 - mse: 1.2290 - val_loss: 0.0645 - val_mse: 0.8765\n",
      "Epoch 1453/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0777 - mse: 1.3383 - val_loss: 0.0653 - val_mse: 0.8724\n",
      "Epoch 1454/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0747 - mse: 1.3341 - val_loss: 0.0638 - val_mse: 0.8742\n",
      "Epoch 1455/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.3635 - val_loss: 0.0649 - val_mse: 0.8772\n",
      "Epoch 1456/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0755 - mse: 1.3779 - val_loss: 0.0645 - val_mse: 0.8787\n",
      "Epoch 1457/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.2944 - val_loss: 0.0643 - val_mse: 0.8794\n",
      "Epoch 1458/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0747 - mse: 1.2314 - val_loss: 0.0643 - val_mse: 0.8797\n",
      "Epoch 1459/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0783 - mse: 1.1775 - val_loss: 0.0653 - val_mse: 0.8817\n",
      "Epoch 1460/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/368 [============================>.] - ETA: 0s - loss: 0.0763 - mse: 1.3170\n",
      "Epoch 01460: saving model to Regression_Model/bl6.mle.linear-1460.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0764 - mse: 1.3168 - val_loss: 0.0649 - val_mse: 0.8801\n",
      "Epoch 1461/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.1247 - val_loss: 0.0646 - val_mse: 0.8811\n",
      "Epoch 1462/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0746 - mse: 1.4215 - val_loss: 0.0642 - val_mse: 0.8805\n",
      "Epoch 1463/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.4193 - val_loss: 0.0656 - val_mse: 0.8757\n",
      "Epoch 1464/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0780 - mse: 1.2500 - val_loss: 0.0662 - val_mse: 0.8773\n",
      "Epoch 1465/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.5466 - val_loss: 0.0652 - val_mse: 0.8784\n",
      "Epoch 1466/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.3248 - val_loss: 0.0656 - val_mse: 0.8775\n",
      "Epoch 1467/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.1627 - val_loss: 0.0649 - val_mse: 0.8874\n",
      "Epoch 1468/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0754 - mse: 1.1806 - val_loss: 0.0651 - val_mse: 0.8795\n",
      "Epoch 1469/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3651 - val_loss: 0.0647 - val_mse: 0.8779\n",
      "Epoch 1470/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0762 - mse: 1.4037\n",
      "Epoch 01470: saving model to Regression_Model/bl6.mle.linear-1470.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0766 - mse: 1.3951 - val_loss: 0.0640 - val_mse: 0.8773\n",
      "Epoch 1471/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.4180 - val_loss: 0.0643 - val_mse: 0.8735\n",
      "Epoch 1472/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.0788 - val_loss: 0.0638 - val_mse: 0.8758\n",
      "Epoch 1473/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.3180 - val_loss: 0.0649 - val_mse: 0.8697\n",
      "Epoch 1474/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.6300 - val_loss: 0.0653 - val_mse: 0.8736\n",
      "Epoch 1475/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0753 - mse: 1.0963 - val_loss: 0.0653 - val_mse: 0.8872\n",
      "Epoch 1476/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.1920 - val_loss: 0.0652 - val_mse: 0.8830\n",
      "Epoch 1477/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.4015 - val_loss: 0.0643 - val_mse: 0.8859\n",
      "Epoch 1478/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0762 - mse: 1.4154 - val_loss: 0.0644 - val_mse: 0.8863\n",
      "Epoch 1479/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.2847 - val_loss: 0.0646 - val_mse: 0.8781\n",
      "Epoch 1480/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0791 - mse: 1.2620\n",
      "Epoch 01480: saving model to Regression_Model/bl6.mle.linear-1480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.2543 - val_loss: 0.0641 - val_mse: 0.8810\n",
      "Epoch 1481/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 1.1954 - val_loss: 0.0644 - val_mse: 0.8763\n",
      "Epoch 1482/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.1920 - val_loss: 0.0647 - val_mse: 0.8712\n",
      "Epoch 1483/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.4957 - val_loss: 0.0646 - val_mse: 0.8707\n",
      "Epoch 1484/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.2665 - val_loss: 0.0645 - val_mse: 0.8699\n",
      "Epoch 1485/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0777 - mse: 1.3872 - val_loss: 0.0643 - val_mse: 0.8741\n",
      "Epoch 1486/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.3502 - val_loss: 0.0650 - val_mse: 0.8728\n",
      "Epoch 1487/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 1.2672 - val_loss: 0.0644 - val_mse: 0.8832\n",
      "Epoch 1488/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0749 - mse: 1.2584 - val_loss: 0.0653 - val_mse: 0.8842\n",
      "Epoch 1489/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0759 - mse: 1.1631 - val_loss: 0.0649 - val_mse: 0.8756\n",
      "Epoch 1490/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0790 - mse: 1.2707\n",
      "Epoch 01490: saving model to Regression_Model/bl6.mle.linear-1490.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0791 - mse: 1.2672 - val_loss: 0.0664 - val_mse: 0.8750\n",
      "Epoch 1491/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.1628 - val_loss: 0.0661 - val_mse: 0.8922\n",
      "Epoch 1492/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0747 - mse: 1.2090 - val_loss: 0.0658 - val_mse: 0.9069\n",
      "Epoch 1493/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0763 - mse: 1.5944 - val_loss: 0.0658 - val_mse: 0.8983\n",
      "Epoch 1494/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.4615 - val_loss: 0.0658 - val_mse: 0.8910\n",
      "Epoch 1495/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0762 - mse: 1.1712 - val_loss: 0.0656 - val_mse: 0.8915\n",
      "Epoch 1496/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.3360 - val_loss: 0.0657 - val_mse: 0.8862\n",
      "Epoch 1497/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.3416 - val_loss: 0.0659 - val_mse: 0.8839\n",
      "Epoch 1498/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0771 - mse: 1.4733 - val_loss: 0.0653 - val_mse: 0.8981\n",
      "Epoch 1499/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0771 - mse: 1.1660 - val_loss: 0.0651 - val_mse: 0.8906\n",
      "Epoch 1500/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0767 - mse: 1.1501\n",
      "Epoch 01500: saving model to Regression_Model/bl6.mle.linear-1500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.1454 - val_loss: 0.0666 - val_mse: 0.8942\n",
      "Epoch 1501/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0793 - mse: 1.2717 - val_loss: 0.0665 - val_mse: 0.9048\n",
      "Epoch 1502/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.1125 - val_loss: 0.0692 - val_mse: 0.8874\n",
      "Epoch 1503/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.2358 - val_loss: 0.0667 - val_mse: 0.9058\n",
      "Epoch 1504/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.2816 - val_loss: 0.0663 - val_mse: 0.9045\n",
      "Epoch 1505/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.3495 - val_loss: 0.0661 - val_mse: 0.8990\n",
      "Epoch 1506/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.2548 - val_loss: 0.0671 - val_mse: 0.8848\n",
      "Epoch 1507/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.2250 - val_loss: 0.0662 - val_mse: 0.9065\n",
      "Epoch 1508/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0789 - mse: 1.8028 - val_loss: 0.0666 - val_mse: 0.9087\n",
      "Epoch 1509/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.4322 - val_loss: 0.0662 - val_mse: 0.9084\n",
      "Epoch 1510/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0763 - mse: 1.1749\n",
      "Epoch 01510: saving model to Regression_Model/bl6.mle.linear-1510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.1745 - val_loss: 0.0667 - val_mse: 0.8978\n",
      "Epoch 1511/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.3011 - val_loss: 0.0658 - val_mse: 0.9000\n",
      "Epoch 1512/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.1497 - val_loss: 0.0653 - val_mse: 0.8975\n",
      "Epoch 1513/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.3105 - val_loss: 0.0653 - val_mse: 0.8994\n",
      "Epoch 1514/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.2598 - val_loss: 0.0653 - val_mse: 0.8884\n",
      "Epoch 1515/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0752 - mse: 1.1939 - val_loss: 0.0651 - val_mse: 0.8865\n",
      "Epoch 1516/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0752 - mse: 1.4399 - val_loss: 0.0648 - val_mse: 0.8850\n",
      "Epoch 1517/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0771 - mse: 1.2135 - val_loss: 0.0661 - val_mse: 0.8756\n",
      "Epoch 1518/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.2808 - val_loss: 0.0651 - val_mse: 0.8792\n",
      "Epoch 1519/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0743 - mse: 1.1295 - val_loss: 0.0644 - val_mse: 0.8857\n",
      "Epoch 1520/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0762 - mse: 1.5880\n",
      "Epoch 01520: saving model to Regression_Model/bl6.mle.linear-1520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.5844 - val_loss: 0.0642 - val_mse: 0.8808\n",
      "Epoch 1521/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.4235 - val_loss: 0.0639 - val_mse: 0.8815\n",
      "Epoch 1522/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 1.2645 - val_loss: 0.0647 - val_mse: 0.8756\n",
      "Epoch 1523/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.1441 - val_loss: 0.0648 - val_mse: 0.8789\n",
      "Epoch 1524/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.2068 - val_loss: 0.0646 - val_mse: 0.8822\n",
      "Epoch 1525/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.3257 - val_loss: 0.0646 - val_mse: 0.8817\n",
      "Epoch 1526/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.3467 - val_loss: 0.0655 - val_mse: 0.8749\n",
      "Epoch 1527/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.2547 - val_loss: 0.0649 - val_mse: 0.8776\n",
      "Epoch 1528/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0765 - mse: 1.2336 - val_loss: 0.0651 - val_mse: 0.8755\n",
      "Epoch 1529/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 1.2559 - val_loss: 0.0648 - val_mse: 0.8809\n",
      "Epoch 1530/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0774 - mse: 1.3344\n",
      "Epoch 01530: saving model to Regression_Model/bl6.mle.linear-1530.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.3279 - val_loss: 0.0653 - val_mse: 0.8767\n",
      "Epoch 1531/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0753 - mse: 1.3226 - val_loss: 0.0652 - val_mse: 0.8802\n",
      "Epoch 1532/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0760 - mse: 1.2508 - val_loss: 0.0656 - val_mse: 0.8771\n",
      "Epoch 1533/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.3827 - val_loss: 0.0657 - val_mse: 0.8792\n",
      "Epoch 1534/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.4983 - val_loss: 0.0643 - val_mse: 0.8906\n",
      "Epoch 1535/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.1747 - val_loss: 0.0654 - val_mse: 0.8744\n",
      "Epoch 1536/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.2238 - val_loss: 0.0650 - val_mse: 0.8756\n",
      "Epoch 1537/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.5669 - val_loss: 0.0647 - val_mse: 0.8762\n",
      "Epoch 1538/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.3982 - val_loss: 0.0648 - val_mse: 0.8811\n",
      "Epoch 1539/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0756 - mse: 1.3201 - val_loss: 0.0653 - val_mse: 0.8791\n",
      "Epoch 1540/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0767 - mse: 1.2803\n",
      "Epoch 01540: saving model to Regression_Model/bl6.mle.linear-1540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.2759 - val_loss: 0.0647 - val_mse: 0.8789\n",
      "Epoch 1541/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0746 - mse: 1.1433 - val_loss: 0.0649 - val_mse: 0.8793\n",
      "Epoch 1542/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0750 - mse: 1.1007 - val_loss: 0.0651 - val_mse: 0.8788\n",
      "Epoch 1543/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0769 - mse: 1.2132 - val_loss: 0.0644 - val_mse: 0.8821\n",
      "Epoch 1544/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.3942 - val_loss: 0.0650 - val_mse: 0.8770\n",
      "Epoch 1545/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0787 - mse: 1.4333 - val_loss: 0.0653 - val_mse: 0.8770\n",
      "Epoch 1546/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.3122 - val_loss: 0.0651 - val_mse: 0.8780\n",
      "Epoch 1547/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.4576 - val_loss: 0.0653 - val_mse: 0.8787\n",
      "Epoch 1548/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0758 - mse: 1.2414 - val_loss: 0.0645 - val_mse: 0.9013\n",
      "Epoch 1549/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.5972 - val_loss: 0.0654 - val_mse: 0.8795\n",
      "Epoch 1550/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0762 - mse: 1.2315\n",
      "Epoch 01550: saving model to Regression_Model/bl6.mle.linear-1550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.2214 - val_loss: 0.0648 - val_mse: 0.8791\n",
      "Epoch 1551/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.3880 - val_loss: 0.0649 - val_mse: 0.8801\n",
      "Epoch 1552/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0766 - mse: 1.4063 - val_loss: 0.0649 - val_mse: 0.8790\n",
      "Epoch 1553/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.2320 - val_loss: 0.0650 - val_mse: 0.8786\n",
      "Epoch 1554/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0756 - mse: 1.2604 - val_loss: 0.0648 - val_mse: 0.8797\n",
      "Epoch 1555/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0751 - mse: 1.2291 - val_loss: 0.0648 - val_mse: 0.8791\n",
      "Epoch 1556/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0760 - mse: 1.1638 - val_loss: 0.0654 - val_mse: 0.8741\n",
      "Epoch 1557/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0764 - mse: 1.1903 - val_loss: 0.0648 - val_mse: 0.8848\n",
      "Epoch 1558/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0759 - mse: 1.4509 - val_loss: 0.0644 - val_mse: 0.8880\n",
      "Epoch 1559/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.2910 - val_loss: 0.0657 - val_mse: 0.8794\n",
      "Epoch 1560/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0785 - mse: 1.4992\n",
      "Epoch 01560: saving model to Regression_Model/bl6.mle.linear-1560.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0784 - mse: 1.4798 - val_loss: 0.0655 - val_mse: 0.8823\n",
      "Epoch 1561/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.2734 - val_loss: 0.0650 - val_mse: 0.8810\n",
      "Epoch 1562/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.2178 - val_loss: 0.0644 - val_mse: 0.8912\n",
      "Epoch 1563/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.1020 - val_loss: 0.0645 - val_mse: 0.8800\n",
      "Epoch 1564/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.1811 - val_loss: 0.0643 - val_mse: 0.8777\n",
      "Epoch 1565/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.1795 - val_loss: 0.0653 - val_mse: 0.8737\n",
      "Epoch 1566/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.2538 - val_loss: 0.0650 - val_mse: 0.8723\n",
      "Epoch 1567/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.2461 - val_loss: 0.0652 - val_mse: 0.8718\n",
      "Epoch 1568/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0782 - mse: 1.3467 - val_loss: 0.0649 - val_mse: 0.8743\n",
      "Epoch 1569/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0766 - mse: 1.2349 - val_loss: 0.0654 - val_mse: 0.8741\n",
      "Epoch 1570/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0762 - mse: 1.3703\n",
      "Epoch 01570: saving model to Regression_Model/bl6.mle.linear-1570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.3538 - val_loss: 0.0645 - val_mse: 0.8767\n",
      "Epoch 1571/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0758 - mse: 1.1846 - val_loss: 0.0652 - val_mse: 0.8757\n",
      "Epoch 1572/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0786 - mse: 1.4246 - val_loss: 0.0647 - val_mse: 0.8755\n",
      "Epoch 1573/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.1744 - val_loss: 0.0645 - val_mse: 0.8765\n",
      "Epoch 1574/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.4785 - val_loss: 0.0647 - val_mse: 0.8741\n",
      "Epoch 1575/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0773 - mse: 1.6058 - val_loss: 0.0650 - val_mse: 0.8743\n",
      "Epoch 1576/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.4218 - val_loss: 0.0647 - val_mse: 0.8778\n",
      "Epoch 1577/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.6057 - val_loss: 0.0649 - val_mse: 0.8754\n",
      "Epoch 1578/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.3511 - val_loss: 0.0650 - val_mse: 0.8892\n",
      "Epoch 1579/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.2329 - val_loss: 0.0653 - val_mse: 0.8927\n",
      "Epoch 1580/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0762 - mse: 1.6781\n",
      "Epoch 01580: saving model to Regression_Model/bl6.mle.linear-1580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.6718 - val_loss: 0.0651 - val_mse: 0.8873\n",
      "Epoch 1581/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.2391 - val_loss: 0.0653 - val_mse: 0.8871\n",
      "Epoch 1582/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.2950 - val_loss: 0.0662 - val_mse: 0.8886\n",
      "Epoch 1583/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.4832 - val_loss: 0.0657 - val_mse: 0.8881\n",
      "Epoch 1584/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0760 - mse: 1.3808 - val_loss: 0.0653 - val_mse: 0.8913\n",
      "Epoch 1585/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.4588 - val_loss: 0.0652 - val_mse: 0.8914\n",
      "Epoch 1586/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.1312 - val_loss: 0.0663 - val_mse: 0.8819\n",
      "Epoch 1587/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.4510 - val_loss: 0.0664 - val_mse: 0.8810\n",
      "Epoch 1588/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0779 - mse: 1.5080 - val_loss: 0.0657 - val_mse: 0.8838\n",
      "Epoch 1589/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0748 - mse: 1.2194 - val_loss: 0.0652 - val_mse: 0.8898\n",
      "Epoch 1590/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0767 - mse: 1.1116\n",
      "Epoch 01590: saving model to Regression_Model/bl6.mle.linear-1590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.1138 - val_loss: 0.0650 - val_mse: 0.8888\n",
      "Epoch 1591/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.2522 - val_loss: 0.0653 - val_mse: 0.8810\n",
      "Epoch 1592/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.1455 - val_loss: 0.0650 - val_mse: 0.8845\n",
      "Epoch 1593/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.2716 - val_loss: 0.0649 - val_mse: 0.8797\n",
      "Epoch 1594/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.3228 - val_loss: 0.0649 - val_mse: 0.8760\n",
      "Epoch 1595/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0768 - mse: 1.2878 - val_loss: 0.0645 - val_mse: 0.8779\n",
      "Epoch 1596/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 1.3266 - val_loss: 0.0643 - val_mse: 0.8814\n",
      "Epoch 1597/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.1598 - val_loss: 0.0653 - val_mse: 0.8770\n",
      "Epoch 1598/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.3625 - val_loss: 0.0657 - val_mse: 0.8789\n",
      "Epoch 1599/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0784 - mse: 1.3762 - val_loss: 0.0653 - val_mse: 0.8828\n",
      "Epoch 1600/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0788 - mse: 1.2969\n",
      "Epoch 01600: saving model to Regression_Model/bl6.mle.linear-1600.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0788 - mse: 1.2944 - val_loss: 0.0656 - val_mse: 0.8825\n",
      "Epoch 1601/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 1.5750 - val_loss: 0.0657 - val_mse: 0.8845\n",
      "Epoch 1602/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0762 - mse: 1.2339 - val_loss: 0.0658 - val_mse: 0.8824\n",
      "Epoch 1603/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.2004 - val_loss: 0.0656 - val_mse: 0.8870\n",
      "Epoch 1604/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0776 - mse: 1.2338 - val_loss: 0.0659 - val_mse: 0.8872\n",
      "Epoch 1605/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 1.4970 - val_loss: 0.0655 - val_mse: 0.8845\n",
      "Epoch 1606/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0781 - mse: 1.3167 - val_loss: 0.0652 - val_mse: 0.8829\n",
      "Epoch 1607/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.1365 - val_loss: 0.0649 - val_mse: 0.8873\n",
      "Epoch 1608/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.3412 - val_loss: 0.0652 - val_mse: 0.8825\n",
      "Epoch 1609/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.2192 - val_loss: 0.0652 - val_mse: 0.8897\n",
      "Epoch 1610/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0784 - mse: 1.7025\n",
      "Epoch 01610: saving model to Regression_Model/bl6.mle.linear-1610.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0789 - mse: 1.6996 - val_loss: 0.0651 - val_mse: 0.8885\n",
      "Epoch 1611/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0752 - mse: 1.2873 - val_loss: 0.0647 - val_mse: 0.8894\n",
      "Epoch 1612/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0751 - mse: 1.2451 - val_loss: 0.0652 - val_mse: 0.8849\n",
      "Epoch 1613/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.2252 - val_loss: 0.0650 - val_mse: 0.8847\n",
      "Epoch 1614/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 1.2486 - val_loss: 0.0654 - val_mse: 0.8826\n",
      "Epoch 1615/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.1723 - val_loss: 0.0659 - val_mse: 0.8788\n",
      "Epoch 1616/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.2654 - val_loss: 0.0657 - val_mse: 0.8804\n",
      "Epoch 1617/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0778 - mse: 1.3510 - val_loss: 0.0658 - val_mse: 0.8783\n",
      "Epoch 1618/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0772 - mse: 1.2121 - val_loss: 0.0650 - val_mse: 0.8828\n",
      "Epoch 1619/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0749 - mse: 1.4495 - val_loss: 0.0653 - val_mse: 0.8844\n",
      "Epoch 1620/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0778 - mse: 1.2840\n",
      "Epoch 01620: saving model to Regression_Model/bl6.mle.linear-1620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 1.2707 - val_loss: 0.0666 - val_mse: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1621/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.2326 - val_loss: 0.0651 - val_mse: 0.8880\n",
      "Epoch 1622/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.3273 - val_loss: 0.0650 - val_mse: 0.8842\n",
      "Epoch 1623/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.3253 - val_loss: 0.0650 - val_mse: 0.8825\n",
      "Epoch 1624/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.4357 - val_loss: 0.0654 - val_mse: 0.8802\n",
      "Epoch 1625/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 1.4399 - val_loss: 0.0654 - val_mse: 0.8817\n",
      "Epoch 1626/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0752 - mse: 1.2976 - val_loss: 0.0659 - val_mse: 0.8802\n",
      "Epoch 1627/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.2850 - val_loss: 0.0660 - val_mse: 0.8814\n",
      "Epoch 1628/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0794 - mse: 1.3056 - val_loss: 0.0663 - val_mse: 0.8824\n",
      "Epoch 1629/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0781 - mse: 1.5796 - val_loss: 0.0656 - val_mse: 0.8877\n",
      "Epoch 1630/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0762 - mse: 1.4975\n",
      "Epoch 01630: saving model to Regression_Model/bl6.mle.linear-1630.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.0763 - mse: 1.4963 - val_loss: 0.0649 - val_mse: 0.8939\n",
      "Epoch 1631/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.3399 - val_loss: 0.0654 - val_mse: 0.8869\n",
      "Epoch 1632/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0750 - mse: 1.5041 - val_loss: 0.0652 - val_mse: 0.8865\n",
      "Epoch 1633/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0778 - mse: 1.2839 - val_loss: 0.0663 - val_mse: 0.8847\n",
      "Epoch 1634/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0745 - mse: 1.1708 - val_loss: 0.0653 - val_mse: 0.9008\n",
      "Epoch 1635/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0755 - mse: 1.2767 - val_loss: 0.0653 - val_mse: 0.8977\n",
      "Epoch 1636/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.4818 - val_loss: 0.0661 - val_mse: 0.8877\n",
      "Epoch 1637/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0768 - mse: 1.3536 - val_loss: 0.0659 - val_mse: 0.8924\n",
      "Epoch 1638/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0751 - mse: 1.0764 - val_loss: 0.0656 - val_mse: 0.9028\n",
      "Epoch 1639/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.3280 - val_loss: 0.0660 - val_mse: 0.9018\n",
      "Epoch 1640/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0771 - mse: 1.2402\n",
      "Epoch 01640: saving model to Regression_Model/bl6.mle.linear-1640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.2224 - val_loss: 0.0661 - val_mse: 0.8987\n",
      "Epoch 1641/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.2340 - val_loss: 0.0660 - val_mse: 0.8992\n",
      "Epoch 1642/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.4898 - val_loss: 0.0657 - val_mse: 0.8979\n",
      "Epoch 1643/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 1.3317 - val_loss: 0.0654 - val_mse: 0.9002\n",
      "Epoch 1644/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0761 - mse: 1.3278 - val_loss: 0.0656 - val_mse: 0.8899\n",
      "Epoch 1645/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0752 - mse: 1.2573 - val_loss: 0.0655 - val_mse: 0.8938\n",
      "Epoch 1646/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.4032 - val_loss: 0.0655 - val_mse: 0.8903\n",
      "Epoch 1647/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0759 - mse: 1.2906 - val_loss: 0.0650 - val_mse: 0.8918\n",
      "Epoch 1648/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 1.2932 - val_loss: 0.0650 - val_mse: 0.8912\n",
      "Epoch 1649/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.3356 - val_loss: 0.0654 - val_mse: 0.8854\n",
      "Epoch 1650/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0775 - mse: 1.2021\n",
      "Epoch 01650: saving model to Regression_Model/bl6.mle.linear-1650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.2008 - val_loss: 0.0655 - val_mse: 0.8871\n",
      "Epoch 1651/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 1.3388 - val_loss: 0.0651 - val_mse: 0.8900\n",
      "Epoch 1652/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0777 - mse: 1.6721 - val_loss: 0.0649 - val_mse: 0.8899\n",
      "Epoch 1653/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 1.2125 - val_loss: 0.0655 - val_mse: 0.8811\n",
      "Epoch 1654/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0752 - mse: 1.2505 - val_loss: 0.0655 - val_mse: 0.8835\n",
      "Epoch 1655/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0760 - mse: 1.3036 - val_loss: 0.0651 - val_mse: 0.8829\n",
      "Epoch 1656/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0766 - mse: 1.2629 - val_loss: 0.0648 - val_mse: 0.8843\n",
      "Epoch 1657/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.3746 - val_loss: 0.0652 - val_mse: 0.8811\n",
      "Epoch 1658/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.2846 - val_loss: 0.0655 - val_mse: 0.8782\n",
      "Epoch 1659/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0775 - mse: 1.7958 - val_loss: 0.0649 - val_mse: 0.8796\n",
      "Epoch 1660/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0757 - mse: 1.2425\n",
      "Epoch 01660: saving model to Regression_Model/bl6.mle.linear-1660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 1.2343 - val_loss: 0.0660 - val_mse: 0.8772\n",
      "Epoch 1661/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.2809 - val_loss: 0.0655 - val_mse: 0.8794\n",
      "Epoch 1662/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.4865 - val_loss: 0.0654 - val_mse: 0.8827\n",
      "Epoch 1663/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0763 - mse: 1.1789 - val_loss: 0.0651 - val_mse: 0.8844\n",
      "Epoch 1664/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.2364 - val_loss: 0.0653 - val_mse: 0.8805\n",
      "Epoch 1665/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 1.1766 - val_loss: 0.0646 - val_mse: 0.8833\n",
      "Epoch 1666/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.4186 - val_loss: 0.0647 - val_mse: 0.8820\n",
      "Epoch 1667/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 1.2846 - val_loss: 0.0650 - val_mse: 0.8794\n",
      "Epoch 1668/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0774 - mse: 1.3435 - val_loss: 0.0643 - val_mse: 0.8848\n",
      "Epoch 1669/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0774 - mse: 1.3187 - val_loss: 0.0650 - val_mse: 0.8775\n",
      "Epoch 1670/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0762 - mse: 1.3723\n",
      "Epoch 01670: saving model to Regression_Model/bl6.mle.linear-1670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0767 - mse: 1.3694 - val_loss: 0.0647 - val_mse: 0.8799\n",
      "Epoch 1671/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0791 - mse: 1.4132 - val_loss: 0.0650 - val_mse: 0.8759\n",
      "Epoch 1672/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 1.7644 - val_loss: 0.0649 - val_mse: 0.8798\n",
      "Epoch 1673/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0765 - mse: 1.3883 - val_loss: 0.0646 - val_mse: 0.8870\n",
      "Epoch 1674/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0770 - mse: 1.2278 - val_loss: 0.0650 - val_mse: 0.8854\n",
      "Epoch 1675/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.3915 - val_loss: 0.0650 - val_mse: 0.8829\n",
      "Epoch 1676/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0752 - mse: 1.3194 - val_loss: 0.0655 - val_mse: 0.8852\n",
      "Epoch 1677/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0760 - mse: 1.3495 - val_loss: 0.0659 - val_mse: 0.8830\n",
      "Epoch 1678/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0762 - mse: 1.2211 - val_loss: 0.0652 - val_mse: 0.8911\n",
      "Epoch 1679/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0777 - mse: 1.2701 - val_loss: 0.0655 - val_mse: 0.8859\n",
      "Epoch 1680/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0763 - mse: 1.2934\n",
      "Epoch 01680: saving model to Regression_Model/bl6.mle.linear-1680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0766 - mse: 1.2932 - val_loss: 0.0656 - val_mse: 0.8817\n",
      "Epoch 1681/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0762 - mse: 1.1813 - val_loss: 0.0649 - val_mse: 0.8866\n",
      "Epoch 1682/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0768 - mse: 1.3643 - val_loss: 0.0651 - val_mse: 0.8876\n",
      "Epoch 1683/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 1.3505 - val_loss: 0.0650 - val_mse: 0.8863\n",
      "Epoch 1684/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0766 - mse: 1.4551 - val_loss: 0.0650 - val_mse: 0.8851\n",
      "Epoch 1685/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0759 - mse: 1.4012 - val_loss: 0.0654 - val_mse: 0.8809\n",
      "Epoch 1686/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0803 - mse: 1.2781 - val_loss: 0.0653 - val_mse: 0.8861\n",
      "Epoch 1687/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 1.3167 - val_loss: 0.0652 - val_mse: 0.8888\n",
      "Epoch 1688/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.3306 - val_loss: 0.0653 - val_mse: 0.8842\n",
      "Epoch 1689/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0771 - mse: 1.5557 - val_loss: 0.0655 - val_mse: 0.8800\n",
      "Epoch 1690/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0759 - mse: 1.1607\n",
      "Epoch 01690: saving model to Regression_Model/bl6.mle.linear-1690.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0762 - mse: 1.2678 - val_loss: 0.0646 - val_mse: 0.8918\n",
      "Epoch 1691/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0772 - mse: 1.3415 - val_loss: 0.0650 - val_mse: 0.8865\n",
      "Epoch 1692/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0757 - mse: 1.1266 - val_loss: 0.0647 - val_mse: 0.8839\n",
      "Epoch 1693/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 1.5758 - val_loss: 0.0650 - val_mse: 0.8788\n",
      "Epoch 1694/2000\n",
      " 87/368 [======>.......................] - ETA: 0s - loss: 0.0770 - mse: 1.2314"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=2000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-1750.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testid='bl6.mle.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
