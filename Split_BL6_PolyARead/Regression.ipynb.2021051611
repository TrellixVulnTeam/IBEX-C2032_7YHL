{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 32, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 990, 32)           416       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 990, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 82, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 82, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 2624)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                168000    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 168,481\n",
      "Trainable params: 168,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 14753\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.predict.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    return data_mean,data_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f22e44172b0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f22e43a66a0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=10000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 368 steps, validate for 368 steps\n",
      "Epoch 1/3000\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.7024 - mse: 0.6959 - val_loss: 0.5373 - val_mse: 0.5307\n",
      "Epoch 2/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.6058 - mse: 0.5992 - val_loss: 0.5393 - val_mse: 0.5327\n",
      "Epoch 3/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.6140 - mse: 0.6074 - val_loss: 0.5549 - val_mse: 0.5483\n",
      "Epoch 4/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.6003 - mse: 0.5937 - val_loss: 0.5489 - val_mse: 0.5423\n",
      "Epoch 5/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.6035 - mse: 0.5969 - val_loss: 0.5939 - val_mse: 0.5873\n",
      "Epoch 6/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5924 - mse: 0.5858 - val_loss: 0.5272 - val_mse: 0.5206\n",
      "Epoch 7/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5809 - mse: 0.5743 - val_loss: 0.5353 - val_mse: 0.5287\n",
      "Epoch 8/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5771 - mse: 0.5705 - val_loss: 0.5320 - val_mse: 0.5254\n",
      "Epoch 9/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5813 - mse: 0.5747 - val_loss: 0.5570 - val_mse: 0.5504\n",
      "Epoch 10/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5645 - mse: 0.5579\n",
      "Epoch 00010: saving model to Regression_Model/mle.linear-0010.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5663 - mse: 0.5597 - val_loss: 0.5156 - val_mse: 0.5090\n",
      "Epoch 11/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5738 - mse: 0.5672 - val_loss: 0.5321 - val_mse: 0.5255\n",
      "Epoch 12/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5847 - mse: 0.5781 - val_loss: 0.5163 - val_mse: 0.5097\n",
      "Epoch 13/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5690 - mse: 0.5624 - val_loss: 0.5165 - val_mse: 0.5099\n",
      "Epoch 14/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5780 - mse: 0.5714 - val_loss: 0.5229 - val_mse: 0.5163\n",
      "Epoch 15/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5696 - mse: 0.5630 - val_loss: 0.5182 - val_mse: 0.5116\n",
      "Epoch 16/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5754 - mse: 0.5688 - val_loss: 0.5231 - val_mse: 0.5165\n",
      "Epoch 17/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5687 - mse: 0.5621 - val_loss: 0.5092 - val_mse: 0.5026\n",
      "Epoch 18/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5609 - mse: 0.5543 - val_loss: 0.5378 - val_mse: 0.5312\n",
      "Epoch 19/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5742 - mse: 0.5676 - val_loss: 0.5036 - val_mse: 0.4971\n",
      "Epoch 20/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5599 - mse: 0.5533\n",
      "Epoch 00020: saving model to Regression_Model/mle.linear-0020.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5590 - mse: 0.5524 - val_loss: 0.5058 - val_mse: 0.4992\n",
      "Epoch 21/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5695 - mse: 0.5629 - val_loss: 0.5086 - val_mse: 0.5020\n",
      "Epoch 22/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5569 - mse: 0.5503 - val_loss: 0.4970 - val_mse: 0.4904\n",
      "Epoch 23/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5641 - mse: 0.5575 - val_loss: 0.4965 - val_mse: 0.4899\n",
      "Epoch 24/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5594 - mse: 0.5528 - val_loss: 0.4967 - val_mse: 0.4901\n",
      "Epoch 25/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5619 - mse: 0.5553 - val_loss: 0.5188 - val_mse: 0.5123\n",
      "Epoch 26/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5529 - mse: 0.5464 - val_loss: 0.5083 - val_mse: 0.5017\n",
      "Epoch 27/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5541 - mse: 0.5476 - val_loss: 0.4940 - val_mse: 0.4874\n",
      "Epoch 28/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5606 - mse: 0.5540 - val_loss: 0.4987 - val_mse: 0.4921\n",
      "Epoch 29/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5578 - mse: 0.5513 - val_loss: 0.5139 - val_mse: 0.5073\n",
      "Epoch 30/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5580 - mse: 0.5515\n",
      "Epoch 00030: saving model to Regression_Model/mle.linear-0030.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5585 - mse: 0.5520 - val_loss: 0.4903 - val_mse: 0.4837\n",
      "Epoch 31/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5567 - mse: 0.5502 - val_loss: 0.5269 - val_mse: 0.5203\n",
      "Epoch 32/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5585 - mse: 0.5520 - val_loss: 0.5069 - val_mse: 0.5003\n",
      "Epoch 33/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4906 - val_mse: 0.4841\n",
      "Epoch 34/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5482 - mse: 0.5416 - val_loss: 0.5186 - val_mse: 0.5120\n",
      "Epoch 35/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5547 - mse: 0.5481 - val_loss: 0.5361 - val_mse: 0.5296\n",
      "Epoch 36/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5613 - mse: 0.5547 - val_loss: 0.4986 - val_mse: 0.4921\n",
      "Epoch 37/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5524 - mse: 0.5459 - val_loss: 0.5083 - val_mse: 0.5017\n",
      "Epoch 38/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5413 - mse: 0.5348 - val_loss: 0.5001 - val_mse: 0.4936\n",
      "Epoch 39/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5527 - mse: 0.5461 - val_loss: 0.4915 - val_mse: 0.4849\n",
      "Epoch 40/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5529 - mse: 0.5463\n",
      "Epoch 00040: saving model to Regression_Model/mle.linear-0040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5515 - mse: 0.5449 - val_loss: 0.4893 - val_mse: 0.4828\n",
      "Epoch 41/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5498 - mse: 0.5433 - val_loss: 0.4935 - val_mse: 0.4870\n",
      "Epoch 42/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5584 - mse: 0.5519 - val_loss: 0.5001 - val_mse: 0.4936\n",
      "Epoch 43/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5613 - mse: 0.5548 - val_loss: 0.4860 - val_mse: 0.4795\n",
      "Epoch 44/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5514 - mse: 0.5449 - val_loss: 0.4903 - val_mse: 0.4837\n",
      "Epoch 45/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5389 - mse: 0.5324 - val_loss: 0.5154 - val_mse: 0.5089\n",
      "Epoch 46/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5585 - mse: 0.5520 - val_loss: 0.4963 - val_mse: 0.4898\n",
      "Epoch 47/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5490 - mse: 0.5424 - val_loss: 0.4971 - val_mse: 0.4905\n",
      "Epoch 48/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5551 - mse: 0.5485 - val_loss: 0.4869 - val_mse: 0.4804\n",
      "Epoch 49/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5487 - mse: 0.5422 - val_loss: 0.4836 - val_mse: 0.4771\n",
      "Epoch 50/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5432 - mse: 0.5366\n",
      "Epoch 00050: saving model to Regression_Model/mle.linear-0050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5430 - mse: 0.5365 - val_loss: 0.4864 - val_mse: 0.4799\n",
      "Epoch 51/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5444 - mse: 0.5379 - val_loss: 0.5037 - val_mse: 0.4972\n",
      "Epoch 52/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5435 - mse: 0.5370 - val_loss: 0.5094 - val_mse: 0.5029\n",
      "Epoch 53/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5540 - mse: 0.5475 - val_loss: 0.4869 - val_mse: 0.4804\n",
      "Epoch 54/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5454 - mse: 0.5389 - val_loss: 0.4805 - val_mse: 0.4740\n",
      "Epoch 55/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5478 - mse: 0.5413 - val_loss: 0.4898 - val_mse: 0.4833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5446 - mse: 0.5381 - val_loss: 0.4772 - val_mse: 0.4707\n",
      "Epoch 57/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5434 - mse: 0.5369 - val_loss: 0.4867 - val_mse: 0.4802\n",
      "Epoch 58/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5509 - mse: 0.5444 - val_loss: 0.5008 - val_mse: 0.4943\n",
      "Epoch 59/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5461 - mse: 0.5396 - val_loss: 0.4833 - val_mse: 0.4768\n",
      "Epoch 60/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5377 - mse: 0.5312\n",
      "Epoch 00060: saving model to Regression_Model/mle.linear-0060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5391 - mse: 0.5326 - val_loss: 0.4802 - val_mse: 0.4737\n",
      "Epoch 61/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5457 - mse: 0.5392 - val_loss: 0.4966 - val_mse: 0.4901\n",
      "Epoch 62/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5435 - mse: 0.5370 - val_loss: 0.4801 - val_mse: 0.4736\n",
      "Epoch 63/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5455 - mse: 0.5390 - val_loss: 0.4808 - val_mse: 0.4743\n",
      "Epoch 64/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5416 - mse: 0.5351 - val_loss: 0.4758 - val_mse: 0.4692\n",
      "Epoch 65/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5405 - mse: 0.5340 - val_loss: 0.5261 - val_mse: 0.5196\n",
      "Epoch 66/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5470 - mse: 0.5405 - val_loss: 0.5053 - val_mse: 0.4988\n",
      "Epoch 67/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5347 - mse: 0.5282 - val_loss: 0.4738 - val_mse: 0.4673\n",
      "Epoch 68/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5437 - mse: 0.5372 - val_loss: 0.4841 - val_mse: 0.4776\n",
      "Epoch 69/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5403 - mse: 0.5338 - val_loss: 0.4772 - val_mse: 0.4707\n",
      "Epoch 70/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5485 - mse: 0.5420\n",
      "Epoch 00070: saving model to Regression_Model/mle.linear-0070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5479 - mse: 0.5414 - val_loss: 0.4756 - val_mse: 0.4691\n",
      "Epoch 71/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5330 - mse: 0.5265 - val_loss: 0.4744 - val_mse: 0.4679\n",
      "Epoch 72/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5502 - mse: 0.5437 - val_loss: 0.5272 - val_mse: 0.5207\n",
      "Epoch 73/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5344 - mse: 0.5279 - val_loss: 0.4891 - val_mse: 0.4826\n",
      "Epoch 74/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5316 - mse: 0.5251 - val_loss: 0.5061 - val_mse: 0.4996\n",
      "Epoch 75/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5402 - mse: 0.5337 - val_loss: 0.5072 - val_mse: 0.5007\n",
      "Epoch 76/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5493 - mse: 0.5428 - val_loss: 0.4721 - val_mse: 0.4656\n",
      "Epoch 77/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5326 - mse: 0.5261 - val_loss: 0.4704 - val_mse: 0.4639\n",
      "Epoch 78/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5383 - mse: 0.5318 - val_loss: 0.5036 - val_mse: 0.4971\n",
      "Epoch 79/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5436 - mse: 0.5371 - val_loss: 0.4804 - val_mse: 0.4739\n",
      "Epoch 80/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5446 - mse: 0.5380\n",
      "Epoch 00080: saving model to Regression_Model/mle.linear-0080.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5443 - mse: 0.5378 - val_loss: 0.4809 - val_mse: 0.4744\n",
      "Epoch 81/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5412 - mse: 0.5346 - val_loss: 0.4801 - val_mse: 0.4736\n",
      "Epoch 82/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5357 - mse: 0.5292 - val_loss: 0.4703 - val_mse: 0.4638\n",
      "Epoch 83/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5371 - mse: 0.5306 - val_loss: 0.4986 - val_mse: 0.4921\n",
      "Epoch 84/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5353 - mse: 0.5288 - val_loss: 0.4691 - val_mse: 0.4625\n",
      "Epoch 85/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5399 - mse: 0.5334 - val_loss: 0.4783 - val_mse: 0.4717\n",
      "Epoch 86/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5371 - mse: 0.5306 - val_loss: 0.4770 - val_mse: 0.4704\n",
      "Epoch 87/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5346 - mse: 0.5281 - val_loss: 0.4768 - val_mse: 0.4703\n",
      "Epoch 88/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5398 - mse: 0.5333 - val_loss: 0.4646 - val_mse: 0.4581\n",
      "Epoch 89/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5355 - mse: 0.5290 - val_loss: 0.4868 - val_mse: 0.4803\n",
      "Epoch 90/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5293 - mse: 0.5228\n",
      "Epoch 00090: saving model to Regression_Model/mle.linear-0090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5318 - mse: 0.5253 - val_loss: 0.4843 - val_mse: 0.4778\n",
      "Epoch 91/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5343 - mse: 0.5278 - val_loss: 0.4638 - val_mse: 0.4572\n",
      "Epoch 92/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5327 - mse: 0.5262 - val_loss: 0.4641 - val_mse: 0.4575\n",
      "Epoch 93/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5343 - mse: 0.5277 - val_loss: 0.4796 - val_mse: 0.4731\n",
      "Epoch 94/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5433 - mse: 0.5368 - val_loss: 0.4780 - val_mse: 0.4714\n",
      "Epoch 95/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5412 - mse: 0.5346 - val_loss: 0.4686 - val_mse: 0.4620\n",
      "Epoch 96/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5298 - mse: 0.5233 - val_loss: 0.4713 - val_mse: 0.4648\n",
      "Epoch 97/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5380 - mse: 0.5314 - val_loss: 0.4667 - val_mse: 0.4602\n",
      "Epoch 98/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5308 - mse: 0.5243 - val_loss: 0.4775 - val_mse: 0.4709\n",
      "Epoch 99/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5516 - mse: 0.5451 - val_loss: 0.4687 - val_mse: 0.4622\n",
      "Epoch 100/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5306 - mse: 0.5241\n",
      "Epoch 00100: saving model to Regression_Model/mle.linear-0100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5313 - mse: 0.5247 - val_loss: 0.4695 - val_mse: 0.4630\n",
      "Epoch 101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5333 - mse: 0.5268 - val_loss: 0.4848 - val_mse: 0.4782\n",
      "Epoch 102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5317 - mse: 0.5252 - val_loss: 0.4867 - val_mse: 0.4801\n",
      "Epoch 103/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5264 - mse: 0.5199 - val_loss: 0.4694 - val_mse: 0.4629\n",
      "Epoch 104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5262 - mse: 0.5197 - val_loss: 0.4642 - val_mse: 0.4577\n",
      "Epoch 105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5356 - mse: 0.5290 - val_loss: 0.4847 - val_mse: 0.4782\n",
      "Epoch 106/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5309 - mse: 0.5243 - val_loss: 0.4650 - val_mse: 0.4584\n",
      "Epoch 107/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5297 - mse: 0.5232 - val_loss: 0.4643 - val_mse: 0.4578\n",
      "Epoch 108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5275 - mse: 0.5209 - val_loss: 0.4684 - val_mse: 0.4618\n",
      "Epoch 109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5307 - mse: 0.5242 - val_loss: 0.4711 - val_mse: 0.4646\n",
      "Epoch 110/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5445 - mse: 0.5380\n",
      "Epoch 00110: saving model to Regression_Model/mle.linear-0110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5448 - mse: 0.5383 - val_loss: 0.5017 - val_mse: 0.4951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5301 - mse: 0.5235 - val_loss: 0.4745 - val_mse: 0.4679\n",
      "Epoch 112/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5309 - mse: 0.5243 - val_loss: 0.4620 - val_mse: 0.4555\n",
      "Epoch 113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5305 - mse: 0.5240 - val_loss: 0.4651 - val_mse: 0.4585\n",
      "Epoch 114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5304 - mse: 0.5238 - val_loss: 0.4606 - val_mse: 0.4540\n",
      "Epoch 115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5296 - mse: 0.5230 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 116/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5323 - mse: 0.5258 - val_loss: 0.4614 - val_mse: 0.4549\n",
      "Epoch 117/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5316 - mse: 0.5251 - val_loss: 0.4758 - val_mse: 0.4693\n",
      "Epoch 118/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5368 - mse: 0.5303 - val_loss: 0.4707 - val_mse: 0.4641\n",
      "Epoch 119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5368 - mse: 0.5303 - val_loss: 0.4686 - val_mse: 0.4620\n",
      "Epoch 120/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5246 - mse: 0.5180\n",
      "Epoch 00120: saving model to Regression_Model/mle.linear-0120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5251 - mse: 0.5185 - val_loss: 0.4709 - val_mse: 0.4643\n",
      "Epoch 121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5296 - mse: 0.5230 - val_loss: 0.4522 - val_mse: 0.4456\n",
      "Epoch 122/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5555 - mse: 0.5489 - val_loss: 0.4754 - val_mse: 0.4688\n",
      "Epoch 123/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5308 - mse: 0.5243 - val_loss: 0.4695 - val_mse: 0.4630\n",
      "Epoch 124/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5335 - mse: 0.5269 - val_loss: 0.4675 - val_mse: 0.4609\n",
      "Epoch 125/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5286 - mse: 0.5220 - val_loss: 0.4875 - val_mse: 0.4810\n",
      "Epoch 126/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5370 - mse: 0.5304 - val_loss: 0.5158 - val_mse: 0.5092\n",
      "Epoch 127/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5351 - mse: 0.5285 - val_loss: 0.4718 - val_mse: 0.4652\n",
      "Epoch 128/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5360 - mse: 0.5295 - val_loss: 0.4938 - val_mse: 0.4873\n",
      "Epoch 129/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5269 - mse: 0.5203 - val_loss: 0.4613 - val_mse: 0.4548\n",
      "Epoch 130/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5306 - mse: 0.5240\n",
      "Epoch 00130: saving model to Regression_Model/mle.linear-0130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5328 - mse: 0.5262 - val_loss: 0.4790 - val_mse: 0.4725\n",
      "Epoch 131/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5290 - mse: 0.5224 - val_loss: 0.4627 - val_mse: 0.4561\n",
      "Epoch 132/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5219 - mse: 0.5153 - val_loss: 0.4557 - val_mse: 0.4491\n",
      "Epoch 133/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5256 - mse: 0.5190 - val_loss: 0.4602 - val_mse: 0.4536\n",
      "Epoch 134/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5289 - mse: 0.5223 - val_loss: 0.4648 - val_mse: 0.4582\n",
      "Epoch 135/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5320 - mse: 0.5254 - val_loss: 0.4991 - val_mse: 0.4925\n",
      "Epoch 136/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5241 - mse: 0.5175 - val_loss: 0.4638 - val_mse: 0.4572\n",
      "Epoch 137/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5384 - mse: 0.5318 - val_loss: 0.4720 - val_mse: 0.4654\n",
      "Epoch 138/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5241 - mse: 0.5175 - val_loss: 0.4744 - val_mse: 0.4679\n",
      "Epoch 139/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5301 - mse: 0.5235 - val_loss: 0.4626 - val_mse: 0.4560\n",
      "Epoch 140/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5200 - mse: 0.5134\n",
      "Epoch 00140: saving model to Regression_Model/mle.linear-0140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5182 - mse: 0.5116 - val_loss: 0.4578 - val_mse: 0.4512\n",
      "Epoch 141/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5258 - mse: 0.5192 - val_loss: 0.4530 - val_mse: 0.4464\n",
      "Epoch 142/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5269 - mse: 0.5204 - val_loss: 0.4546 - val_mse: 0.4480\n",
      "Epoch 143/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5234 - mse: 0.5168 - val_loss: 0.4581 - val_mse: 0.4515\n",
      "Epoch 144/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5195 - mse: 0.5129 - val_loss: 0.4532 - val_mse: 0.4466\n",
      "Epoch 145/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5189 - val_loss: 0.4655 - val_mse: 0.4589\n",
      "Epoch 146/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5239 - mse: 0.5173 - val_loss: 0.4565 - val_mse: 0.4499\n",
      "Epoch 147/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5243 - mse: 0.5177 - val_loss: 0.4695 - val_mse: 0.4629\n",
      "Epoch 148/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5204 - mse: 0.5138 - val_loss: 0.4579 - val_mse: 0.4513\n",
      "Epoch 149/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5240 - mse: 0.5174 - val_loss: 0.4584 - val_mse: 0.4517\n",
      "Epoch 150/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5280 - mse: 0.5214\n",
      "Epoch 00150: saving model to Regression_Model/mle.linear-0150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5272 - mse: 0.5206 - val_loss: 0.4530 - val_mse: 0.4464\n",
      "Epoch 151/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5230 - mse: 0.5164 - val_loss: 0.4679 - val_mse: 0.4613\n",
      "Epoch 152/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5266 - mse: 0.5200 - val_loss: 0.4667 - val_mse: 0.4601\n",
      "Epoch 153/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5189 - mse: 0.5123 - val_loss: 0.4506 - val_mse: 0.4440\n",
      "Epoch 154/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5278 - mse: 0.5212 - val_loss: 0.4592 - val_mse: 0.4526\n",
      "Epoch 155/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5213 - mse: 0.5147 - val_loss: 0.4510 - val_mse: 0.4444\n",
      "Epoch 156/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5291 - mse: 0.5225 - val_loss: 0.4599 - val_mse: 0.4533\n",
      "Epoch 157/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5370 - mse: 0.5304 - val_loss: 0.4611 - val_mse: 0.4545\n",
      "Epoch 158/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5253 - mse: 0.5187 - val_loss: 0.4579 - val_mse: 0.4513\n",
      "Epoch 159/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5299 - mse: 0.5233 - val_loss: 0.4611 - val_mse: 0.4545\n",
      "Epoch 160/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5180 - mse: 0.5113\n",
      "Epoch 00160: saving model to Regression_Model/mle.linear-0160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5192 - mse: 0.5126 - val_loss: 0.4546 - val_mse: 0.4480\n",
      "Epoch 161/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5283 - mse: 0.5217 - val_loss: 0.4558 - val_mse: 0.4492\n",
      "Epoch 162/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5166 - mse: 0.5100 - val_loss: 0.4631 - val_mse: 0.4565\n",
      "Epoch 163/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5252 - mse: 0.5186 - val_loss: 0.4508 - val_mse: 0.4441\n",
      "Epoch 164/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5251 - mse: 0.5185 - val_loss: 0.4580 - val_mse: 0.4513\n",
      "Epoch 165/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5243 - mse: 0.5176 - val_loss: 0.4736 - val_mse: 0.4669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5222 - mse: 0.5156 - val_loss: 0.4767 - val_mse: 0.4700\n",
      "Epoch 167/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5187 - mse: 0.5121 - val_loss: 0.4695 - val_mse: 0.4628\n",
      "Epoch 168/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5258 - mse: 0.5191 - val_loss: 0.4500 - val_mse: 0.4433\n",
      "Epoch 169/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5298 - mse: 0.5232 - val_loss: 0.4585 - val_mse: 0.4518\n",
      "Epoch 170/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5196 - mse: 0.5129\n",
      "Epoch 00170: saving model to Regression_Model/mle.linear-0170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5228 - mse: 0.5162 - val_loss: 0.4558 - val_mse: 0.4491\n",
      "Epoch 171/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5234 - mse: 0.5167 - val_loss: 0.4575 - val_mse: 0.4508\n",
      "Epoch 172/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5186 - mse: 0.5120 - val_loss: 0.4525 - val_mse: 0.4458\n",
      "Epoch 173/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5115 - mse: 0.5048 - val_loss: 0.4698 - val_mse: 0.4631\n",
      "Epoch 174/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5243 - mse: 0.5176 - val_loss: 0.4570 - val_mse: 0.4504\n",
      "Epoch 175/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5263 - mse: 0.5196 - val_loss: 0.4578 - val_mse: 0.4512\n",
      "Epoch 176/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5222 - mse: 0.5155 - val_loss: 0.4640 - val_mse: 0.4573\n",
      "Epoch 177/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5197 - mse: 0.5130 - val_loss: 0.4556 - val_mse: 0.4489\n",
      "Epoch 178/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5208 - mse: 0.5141 - val_loss: 0.4569 - val_mse: 0.4502\n",
      "Epoch 179/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5116 - mse: 0.5049 - val_loss: 0.4625 - val_mse: 0.4558\n",
      "Epoch 180/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5220 - mse: 0.5153\n",
      "Epoch 00180: saving model to Regression_Model/mle.linear-0180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5226 - mse: 0.5159 - val_loss: 0.4474 - val_mse: 0.4407\n",
      "Epoch 181/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5175 - mse: 0.5108 - val_loss: 0.4563 - val_mse: 0.4496\n",
      "Epoch 182/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5189 - mse: 0.5123 - val_loss: 0.4485 - val_mse: 0.4419\n",
      "Epoch 183/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5251 - mse: 0.5184 - val_loss: 0.4928 - val_mse: 0.4861\n",
      "Epoch 184/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5220 - mse: 0.5153 - val_loss: 0.4520 - val_mse: 0.4453\n",
      "Epoch 185/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5074 - val_loss: 0.4545 - val_mse: 0.4478\n",
      "Epoch 186/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5212 - mse: 0.5145 - val_loss: 0.4643 - val_mse: 0.4576\n",
      "Epoch 187/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5297 - mse: 0.5230 - val_loss: 0.4546 - val_mse: 0.4479\n",
      "Epoch 188/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5244 - mse: 0.5177 - val_loss: 0.4732 - val_mse: 0.4665\n",
      "Epoch 189/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5225 - mse: 0.5158 - val_loss: 0.4548 - val_mse: 0.4480\n",
      "Epoch 190/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5214 - mse: 0.5147\n",
      "Epoch 00190: saving model to Regression_Model/mle.linear-0190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5204 - mse: 0.5137 - val_loss: 0.4511 - val_mse: 0.4444\n",
      "Epoch 191/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5074 - val_loss: 0.4511 - val_mse: 0.4444\n",
      "Epoch 192/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5145 - mse: 0.5078 - val_loss: 0.4565 - val_mse: 0.4498\n",
      "Epoch 193/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5183 - mse: 0.5116 - val_loss: 0.4564 - val_mse: 0.4497\n",
      "Epoch 194/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5124 - mse: 0.5057 - val_loss: 0.4561 - val_mse: 0.4493\n",
      "Epoch 195/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5235 - mse: 0.5168 - val_loss: 0.4956 - val_mse: 0.4889\n",
      "Epoch 196/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5191 - mse: 0.5124 - val_loss: 0.4523 - val_mse: 0.4456\n",
      "Epoch 197/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5208 - mse: 0.5141 - val_loss: 0.4505 - val_mse: 0.4438\n",
      "Epoch 198/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5150 - mse: 0.5082 - val_loss: 0.4758 - val_mse: 0.4691\n",
      "Epoch 199/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5202 - mse: 0.5135 - val_loss: 0.4524 - val_mse: 0.4456\n",
      "Epoch 200/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5141 - mse: 0.5074\n",
      "Epoch 00200: saving model to Regression_Model/mle.linear-0200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5158 - mse: 0.5091 - val_loss: 0.4507 - val_mse: 0.4439\n",
      "Epoch 201/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5239 - mse: 0.5172 - val_loss: 0.4594 - val_mse: 0.4526\n",
      "Epoch 202/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5158 - mse: 0.5090 - val_loss: 0.4582 - val_mse: 0.4514\n",
      "Epoch 203/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5219 - mse: 0.5151 - val_loss: 0.4596 - val_mse: 0.4528\n",
      "Epoch 204/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5186 - mse: 0.5119 - val_loss: 0.4543 - val_mse: 0.4475\n",
      "Epoch 205/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5182 - mse: 0.5115 - val_loss: 0.4671 - val_mse: 0.4604\n",
      "Epoch 206/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5043 - val_loss: 0.4497 - val_mse: 0.4429\n",
      "Epoch 207/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5320 - mse: 0.5252 - val_loss: 0.4499 - val_mse: 0.4431\n",
      "Epoch 208/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5205 - mse: 0.5138 - val_loss: 0.4460 - val_mse: 0.4393\n",
      "Epoch 209/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5214 - mse: 0.5146 - val_loss: 0.4485 - val_mse: 0.4417\n",
      "Epoch 210/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5176 - mse: 0.5109\n",
      "Epoch 00210: saving model to Regression_Model/mle.linear-0210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5187 - mse: 0.5119 - val_loss: 0.4554 - val_mse: 0.4486\n",
      "Epoch 211/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5185 - mse: 0.5118 - val_loss: 0.4606 - val_mse: 0.4539\n",
      "Epoch 212/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5215 - mse: 0.5147 - val_loss: 0.4586 - val_mse: 0.4519\n",
      "Epoch 213/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5183 - mse: 0.5116 - val_loss: 0.4683 - val_mse: 0.4615\n",
      "Epoch 214/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5231 - mse: 0.5163 - val_loss: 0.4477 - val_mse: 0.4409\n",
      "Epoch 215/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5192 - mse: 0.5124 - val_loss: 0.4490 - val_mse: 0.4423\n",
      "Epoch 216/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5183 - mse: 0.5116 - val_loss: 0.4629 - val_mse: 0.4562\n",
      "Epoch 217/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5171 - mse: 0.5104 - val_loss: 0.4692 - val_mse: 0.4625\n",
      "Epoch 218/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5064 - val_loss: 0.4524 - val_mse: 0.4456\n",
      "Epoch 219/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5248 - mse: 0.5180 - val_loss: 0.4625 - val_mse: 0.4557\n",
      "Epoch 220/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5159 - mse: 0.5091\n",
      "Epoch 00220: saving model to Regression_Model/mle.linear-0220.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5174 - mse: 0.5107 - val_loss: 0.4479 - val_mse: 0.4411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5166 - mse: 0.5098 - val_loss: 0.4462 - val_mse: 0.4394\n",
      "Epoch 222/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5017 - val_loss: 0.4560 - val_mse: 0.4493\n",
      "Epoch 223/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5180 - mse: 0.5113 - val_loss: 0.4529 - val_mse: 0.4461\n",
      "Epoch 224/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5032 - val_loss: 0.4815 - val_mse: 0.4747\n",
      "Epoch 225/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5147 - mse: 0.5079 - val_loss: 0.4485 - val_mse: 0.4418\n",
      "Epoch 226/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5165 - mse: 0.5097 - val_loss: 0.4458 - val_mse: 0.4390\n",
      "Epoch 227/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5219 - mse: 0.5152 - val_loss: 0.4630 - val_mse: 0.4562\n",
      "Epoch 228/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5253 - mse: 0.5185 - val_loss: 0.4679 - val_mse: 0.4611\n",
      "Epoch 229/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5229 - mse: 0.5161 - val_loss: 0.4515 - val_mse: 0.4447\n",
      "Epoch 230/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5173 - mse: 0.5105\n",
      "Epoch 00230: saving model to Regression_Model/mle.linear-0230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5177 - mse: 0.5109 - val_loss: 0.4471 - val_mse: 0.4403\n",
      "Epoch 231/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5216 - mse: 0.5148 - val_loss: 0.4449 - val_mse: 0.4381\n",
      "Epoch 232/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5000 - val_loss: 0.4485 - val_mse: 0.4417\n",
      "Epoch 233/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5120 - mse: 0.5053 - val_loss: 0.4524 - val_mse: 0.4456\n",
      "Epoch 234/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5055 - val_loss: 0.4460 - val_mse: 0.4392\n",
      "Epoch 235/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5004 - val_loss: 0.4514 - val_mse: 0.4446\n",
      "Epoch 236/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.4997 - val_loss: 0.4461 - val_mse: 0.4393\n",
      "Epoch 237/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5186 - mse: 0.5118 - val_loss: 0.4542 - val_mse: 0.4474\n",
      "Epoch 238/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5138 - val_loss: 0.4469 - val_mse: 0.4401\n",
      "Epoch 239/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5139 - mse: 0.5071 - val_loss: 0.4545 - val_mse: 0.4477\n",
      "Epoch 240/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5228 - mse: 0.5160\n",
      "Epoch 00240: saving model to Regression_Model/mle.linear-0240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5223 - mse: 0.5155 - val_loss: 0.4429 - val_mse: 0.4361\n",
      "Epoch 241/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5278 - mse: 0.5210 - val_loss: 0.4488 - val_mse: 0.4420\n",
      "Epoch 242/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5046 - val_loss: 0.4482 - val_mse: 0.4414\n",
      "Epoch 243/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5210 - mse: 0.5142 - val_loss: 0.4869 - val_mse: 0.4800\n",
      "Epoch 244/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5251 - mse: 0.5183 - val_loss: 0.4444 - val_mse: 0.4376\n",
      "Epoch 245/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5121 - mse: 0.5053 - val_loss: 0.4631 - val_mse: 0.4563\n",
      "Epoch 246/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5193 - mse: 0.5125 - val_loss: 0.4538 - val_mse: 0.4470\n",
      "Epoch 247/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5024 - val_loss: 0.4494 - val_mse: 0.4426\n",
      "Epoch 248/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5025 - val_loss: 0.4453 - val_mse: 0.4385\n",
      "Epoch 249/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5034 - val_loss: 0.4515 - val_mse: 0.4447\n",
      "Epoch 250/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5151 - mse: 0.5082\n",
      "Epoch 00250: saving model to Regression_Model/mle.linear-0250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5074 - val_loss: 0.4555 - val_mse: 0.4487\n",
      "Epoch 251/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5064 - val_loss: 0.4448 - val_mse: 0.4379\n",
      "Epoch 252/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5209 - mse: 0.5140 - val_loss: 0.4522 - val_mse: 0.4453\n",
      "Epoch 253/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5186 - mse: 0.5117 - val_loss: 0.4570 - val_mse: 0.4502\n",
      "Epoch 254/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5306 - mse: 0.5238 - val_loss: 0.4467 - val_mse: 0.4398\n",
      "Epoch 255/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5156 - mse: 0.5087 - val_loss: 0.4662 - val_mse: 0.4593\n",
      "Epoch 256/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5149 - mse: 0.5080 - val_loss: 0.4644 - val_mse: 0.4575\n",
      "Epoch 257/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5036 - val_loss: 0.4423 - val_mse: 0.4354\n",
      "Epoch 258/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5102 - mse: 0.5034 - val_loss: 0.4492 - val_mse: 0.4424\n",
      "Epoch 259/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5034 - val_loss: 0.4455 - val_mse: 0.4386\n",
      "Epoch 260/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5145 - mse: 0.5076\n",
      "Epoch 00260: saving model to Regression_Model/mle.linear-0260.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5063 - val_loss: 0.4604 - val_mse: 0.4535\n",
      "Epoch 261/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5172 - mse: 0.5103 - val_loss: 0.4698 - val_mse: 0.4630\n",
      "Epoch 262/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5040 - val_loss: 0.4421 - val_mse: 0.4352\n",
      "Epoch 263/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5230 - mse: 0.5161 - val_loss: 0.4500 - val_mse: 0.4431\n",
      "Epoch 264/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5149 - mse: 0.5080 - val_loss: 0.4545 - val_mse: 0.4477\n",
      "Epoch 265/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5054 - val_loss: 0.4489 - val_mse: 0.4420\n",
      "Epoch 266/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5213 - mse: 0.5144 - val_loss: 0.4466 - val_mse: 0.4397\n",
      "Epoch 267/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5150 - mse: 0.5081 - val_loss: 0.4523 - val_mse: 0.4455\n",
      "Epoch 268/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5151 - mse: 0.5082 - val_loss: 0.4509 - val_mse: 0.4440\n",
      "Epoch 269/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5071 - val_loss: 0.4520 - val_mse: 0.4451\n",
      "Epoch 270/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5138 - mse: 0.5069\n",
      "Epoch 00270: saving model to Regression_Model/mle.linear-0270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5148 - mse: 0.5079 - val_loss: 0.4527 - val_mse: 0.4458\n",
      "Epoch 271/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5021 - val_loss: 0.4426 - val_mse: 0.4356\n",
      "Epoch 272/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5013 - val_loss: 0.4470 - val_mse: 0.4401\n",
      "Epoch 273/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4979 - val_loss: 0.4378 - val_mse: 0.4309\n",
      "Epoch 274/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5037 - val_loss: 0.4472 - val_mse: 0.4403\n",
      "Epoch 275/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5071 - val_loss: 0.4572 - val_mse: 0.4503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5121 - mse: 0.5052 - val_loss: 0.4415 - val_mse: 0.4346\n",
      "Epoch 277/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5167 - mse: 0.5098 - val_loss: 0.4494 - val_mse: 0.4425\n",
      "Epoch 278/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5088 - mse: 0.5019 - val_loss: 0.4472 - val_mse: 0.4402\n",
      "Epoch 279/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5129 - mse: 0.5060 - val_loss: 0.4592 - val_mse: 0.4523\n",
      "Epoch 280/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.5162 - mse: 0.5093\n",
      "Epoch 00280: saving model to Regression_Model/mle.linear-0280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5175 - mse: 0.5106 - val_loss: 0.4464 - val_mse: 0.4395\n",
      "Epoch 281/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5019 - val_loss: 0.4400 - val_mse: 0.4331\n",
      "Epoch 282/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5010 - val_loss: 0.4432 - val_mse: 0.4362\n",
      "Epoch 283/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5134 - mse: 0.5065 - val_loss: 0.4370 - val_mse: 0.4300\n",
      "Epoch 284/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5196 - mse: 0.5127 - val_loss: 0.4427 - val_mse: 0.4358\n",
      "Epoch 285/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5030 - val_loss: 0.4469 - val_mse: 0.4399\n",
      "Epoch 286/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4963 - val_loss: 0.4461 - val_mse: 0.4391\n",
      "Epoch 287/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5148 - mse: 0.5078 - val_loss: 0.4490 - val_mse: 0.4420\n",
      "Epoch 288/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5096 - mse: 0.5026 - val_loss: 0.4507 - val_mse: 0.4437\n",
      "Epoch 289/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5164 - mse: 0.5094 - val_loss: 0.4487 - val_mse: 0.4417\n",
      "Epoch 290/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5121 - mse: 0.5052\n",
      "Epoch 00290: saving model to Regression_Model/mle.linear-0290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5048 - val_loss: 0.4475 - val_mse: 0.4406\n",
      "Epoch 291/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5198 - mse: 0.5128 - val_loss: 0.4478 - val_mse: 0.4409\n",
      "Epoch 292/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5039 - val_loss: 0.4531 - val_mse: 0.4462\n",
      "Epoch 293/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5181 - mse: 0.5112 - val_loss: 0.4432 - val_mse: 0.4362\n",
      "Epoch 294/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5031 - val_loss: 0.4524 - val_mse: 0.4455\n",
      "Epoch 295/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5038 - mse: 0.4969 - val_loss: 0.4388 - val_mse: 0.4319\n",
      "Epoch 296/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5009 - val_loss: 0.4445 - val_mse: 0.4375\n",
      "Epoch 297/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5019 - val_loss: 0.4373 - val_mse: 0.4303\n",
      "Epoch 298/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5020 - val_loss: 0.4367 - val_mse: 0.4298\n",
      "Epoch 299/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5004 - val_loss: 0.4388 - val_mse: 0.4318\n",
      "Epoch 300/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5123 - mse: 0.5053\n",
      "Epoch 00300: saving model to Regression_Model/mle.linear-0300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5063 - val_loss: 0.4526 - val_mse: 0.4457\n",
      "Epoch 301/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5053 - val_loss: 0.4392 - val_mse: 0.4322\n",
      "Epoch 302/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5039 - val_loss: 0.4396 - val_mse: 0.4326\n",
      "Epoch 303/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4982 - val_loss: 0.4701 - val_mse: 0.4631\n",
      "Epoch 304/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5119 - mse: 0.5050 - val_loss: 0.4537 - val_mse: 0.4467\n",
      "Epoch 305/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5031 - val_loss: 0.4380 - val_mse: 0.4310\n",
      "Epoch 306/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5012 - val_loss: 0.4483 - val_mse: 0.4414\n",
      "Epoch 307/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5041 - val_loss: 0.4382 - val_mse: 0.4312\n",
      "Epoch 308/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5034 - val_loss: 0.4343 - val_mse: 0.4273\n",
      "Epoch 309/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5008 - val_loss: 0.4492 - val_mse: 0.4422\n",
      "Epoch 310/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5111 - mse: 0.5041\n",
      "Epoch 00310: saving model to Regression_Model/mle.linear-0310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5025 - val_loss: 0.4443 - val_mse: 0.4373\n",
      "Epoch 311/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4951 - val_loss: 0.4410 - val_mse: 0.4340\n",
      "Epoch 312/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5070 - val_loss: 0.4456 - val_mse: 0.4386\n",
      "Epoch 313/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5126 - mse: 0.5056 - val_loss: 0.4458 - val_mse: 0.4388\n",
      "Epoch 314/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4973 - val_loss: 0.4379 - val_mse: 0.4308\n",
      "Epoch 315/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5172 - mse: 0.5102 - val_loss: 0.4452 - val_mse: 0.4382\n",
      "Epoch 316/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5011 - val_loss: 0.4433 - val_mse: 0.4363\n",
      "Epoch 317/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5121 - mse: 0.5051 - val_loss: 0.4388 - val_mse: 0.4318\n",
      "Epoch 318/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5148 - mse: 0.5078 - val_loss: 0.4409 - val_mse: 0.4338\n",
      "Epoch 319/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5044 - val_loss: 0.4659 - val_mse: 0.4589\n",
      "Epoch 320/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5032 - mse: 0.4962\n",
      "Epoch 00320: saving model to Regression_Model/mle.linear-0320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.4996 - val_loss: 0.4498 - val_mse: 0.4428\n",
      "Epoch 321/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5037 - val_loss: 0.4404 - val_mse: 0.4333\n",
      "Epoch 322/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5097 - mse: 0.5027 - val_loss: 0.4330 - val_mse: 0.4259\n",
      "Epoch 323/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.4988 - val_loss: 0.4406 - val_mse: 0.4335\n",
      "Epoch 324/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5169 - mse: 0.5098 - val_loss: 0.4395 - val_mse: 0.4325\n",
      "Epoch 325/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5044 - val_loss: 0.4408 - val_mse: 0.4338\n",
      "Epoch 326/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5103 - mse: 0.5033 - val_loss: 0.4370 - val_mse: 0.4300\n",
      "Epoch 327/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4979 - val_loss: 0.4439 - val_mse: 0.4369\n",
      "Epoch 328/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5032 - val_loss: 0.4391 - val_mse: 0.4321\n",
      "Epoch 329/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5010 - val_loss: 0.4462 - val_mse: 0.4392\n",
      "Epoch 330/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5169 - mse: 0.5098\n",
      "Epoch 00330: saving model to Regression_Model/mle.linear-0330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5165 - mse: 0.5094 - val_loss: 0.4415 - val_mse: 0.4345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4957 - val_loss: 0.4385 - val_mse: 0.4315\n",
      "Epoch 332/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.4993 - val_loss: 0.4381 - val_mse: 0.4310\n",
      "Epoch 333/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5013 - val_loss: 0.4375 - val_mse: 0.4304\n",
      "Epoch 334/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.4996 - val_loss: 0.4374 - val_mse: 0.4304\n",
      "Epoch 335/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5170 - mse: 0.5100 - val_loss: 0.4781 - val_mse: 0.4710\n",
      "Epoch 336/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5269 - mse: 0.5198 - val_loss: 0.4384 - val_mse: 0.4313\n",
      "Epoch 337/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5022 - val_loss: 0.4517 - val_mse: 0.4446\n",
      "Epoch 338/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5052 - val_loss: 0.4408 - val_mse: 0.4337\n",
      "Epoch 339/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4984 - val_loss: 0.4390 - val_mse: 0.4319\n",
      "Epoch 340/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5082 - mse: 0.5011\n",
      "Epoch 00340: saving model to Regression_Model/mle.linear-0340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.4994 - val_loss: 0.4388 - val_mse: 0.4317\n",
      "Epoch 341/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5020 - val_loss: 0.4373 - val_mse: 0.4302\n",
      "Epoch 342/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4962 - val_loss: 0.4424 - val_mse: 0.4353\n",
      "Epoch 343/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4954 - val_loss: 0.4553 - val_mse: 0.4482\n",
      "Epoch 344/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5028 - val_loss: 0.4435 - val_mse: 0.4364\n",
      "Epoch 345/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5070 - val_loss: 0.4549 - val_mse: 0.4478\n",
      "Epoch 346/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5047 - val_loss: 0.4369 - val_mse: 0.4298\n",
      "Epoch 347/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4981 - val_loss: 0.4465 - val_mse: 0.4394\n",
      "Epoch 348/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5003 - val_loss: 0.4486 - val_mse: 0.4415\n",
      "Epoch 349/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5001 - val_loss: 0.4386 - val_mse: 0.4315\n",
      "Epoch 350/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5033 - mse: 0.4962\n",
      "Epoch 00350: saving model to Regression_Model/mle.linear-0350.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4977 - val_loss: 0.4513 - val_mse: 0.4442\n",
      "Epoch 351/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4981 - val_loss: 0.4550 - val_mse: 0.4479\n",
      "Epoch 352/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5062 - val_loss: 0.4427 - val_mse: 0.4357\n",
      "Epoch 353/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4985 - val_loss: 0.4366 - val_mse: 0.4295\n",
      "Epoch 354/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.4993 - val_loss: 0.4356 - val_mse: 0.4285\n",
      "Epoch 355/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5125 - mse: 0.5054 - val_loss: 0.4344 - val_mse: 0.4273\n",
      "Epoch 356/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5050 - val_loss: 0.4385 - val_mse: 0.4314\n",
      "Epoch 357/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5051 - val_loss: 0.4422 - val_mse: 0.4351\n",
      "Epoch 358/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5001 - val_loss: 0.4410 - val_mse: 0.4339\n",
      "Epoch 359/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5115 - mse: 0.5043 - val_loss: 0.4516 - val_mse: 0.4444\n",
      "Epoch 360/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5029 - mse: 0.4958\n",
      "Epoch 00360: saving model to Regression_Model/mle.linear-0360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4941 - val_loss: 0.4577 - val_mse: 0.4506\n",
      "Epoch 361/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5033 - val_loss: 0.4451 - val_mse: 0.4380\n",
      "Epoch 362/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5032 - val_loss: 0.4501 - val_mse: 0.4429\n",
      "Epoch 363/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4984 - val_loss: 0.4650 - val_mse: 0.4579\n",
      "Epoch 364/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.4993 - val_loss: 0.4410 - val_mse: 0.4339\n",
      "Epoch 365/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4975 - val_loss: 0.4351 - val_mse: 0.4279\n",
      "Epoch 366/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4890 - val_loss: 0.4466 - val_mse: 0.4395\n",
      "Epoch 367/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5028 - val_loss: 0.4366 - val_mse: 0.4294\n",
      "Epoch 368/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4922 - val_loss: 0.4347 - val_mse: 0.4276\n",
      "Epoch 369/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4983 - val_loss: 0.4414 - val_mse: 0.4343\n",
      "Epoch 370/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5078 - mse: 0.5007\n",
      "Epoch 00370: saving model to Regression_Model/mle.linear-0370.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5052 - mse: 0.4980 - val_loss: 0.4385 - val_mse: 0.4313\n",
      "Epoch 371/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4976 - val_loss: 0.4350 - val_mse: 0.4279\n",
      "Epoch 372/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4963 - val_loss: 0.4459 - val_mse: 0.4387\n",
      "Epoch 373/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4957 - val_loss: 0.4478 - val_mse: 0.4407\n",
      "Epoch 374/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5001 - val_loss: 0.4351 - val_mse: 0.4279\n",
      "Epoch 375/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5047 - val_loss: 0.4398 - val_mse: 0.4326\n",
      "Epoch 376/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5156 - mse: 0.5085 - val_loss: 0.4332 - val_mse: 0.4260\n",
      "Epoch 377/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.4986 - val_loss: 0.4349 - val_mse: 0.4277\n",
      "Epoch 378/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5119 - mse: 0.5048 - val_loss: 0.4422 - val_mse: 0.4350\n",
      "Epoch 379/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5017 - val_loss: 0.4387 - val_mse: 0.4316\n",
      "Epoch 380/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5052 - mse: 0.4981\n",
      "Epoch 00380: saving model to Regression_Model/mle.linear-0380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4972 - val_loss: 0.4391 - val_mse: 0.4319\n",
      "Epoch 381/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4960 - val_loss: 0.4456 - val_mse: 0.4384\n",
      "Epoch 382/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5037 - val_loss: 0.4564 - val_mse: 0.4493\n",
      "Epoch 383/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5036 - val_loss: 0.4320 - val_mse: 0.4249\n",
      "Epoch 384/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4952 - val_loss: 0.4389 - val_mse: 0.4318\n",
      "Epoch 385/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4964 - val_loss: 0.4349 - val_mse: 0.4277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5196 - mse: 0.5124 - val_loss: 0.4450 - val_mse: 0.4379\n",
      "Epoch 387/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5120 - mse: 0.5048 - val_loss: 0.4511 - val_mse: 0.4439\n",
      "Epoch 388/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4936 - val_loss: 0.4364 - val_mse: 0.4292\n",
      "Epoch 389/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4973 - val_loss: 0.4380 - val_mse: 0.4308\n",
      "Epoch 390/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5092 - mse: 0.5020\n",
      "Epoch 00390: saving model to Regression_Model/mle.linear-0390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5012 - val_loss: 0.4371 - val_mse: 0.4299\n",
      "Epoch 391/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4968 - val_loss: 0.4342 - val_mse: 0.4270\n",
      "Epoch 392/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4960 - val_loss: 0.4443 - val_mse: 0.4371\n",
      "Epoch 393/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4985 - val_loss: 0.4347 - val_mse: 0.4275\n",
      "Epoch 394/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4959 - val_loss: 0.4512 - val_mse: 0.4440\n",
      "Epoch 395/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5032 - val_loss: 0.4424 - val_mse: 0.4352\n",
      "Epoch 396/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4943 - val_loss: 0.4405 - val_mse: 0.4333\n",
      "Epoch 397/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5063 - val_loss: 0.4336 - val_mse: 0.4264\n",
      "Epoch 398/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5024 - val_loss: 0.4428 - val_mse: 0.4356\n",
      "Epoch 399/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5125 - mse: 0.5053 - val_loss: 0.4403 - val_mse: 0.4331\n",
      "Epoch 400/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5025 - mse: 0.4953\n",
      "Epoch 00400: saving model to Regression_Model/mle.linear-0400.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5016 - mse: 0.4943 - val_loss: 0.4440 - val_mse: 0.4368\n",
      "Epoch 401/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5005 - val_loss: 0.4375 - val_mse: 0.4303\n",
      "Epoch 402/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5068 - val_loss: 0.4476 - val_mse: 0.4404\n",
      "Epoch 403/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4936 - val_loss: 0.4323 - val_mse: 0.4251\n",
      "Epoch 404/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4951 - val_loss: 0.4413 - val_mse: 0.4341\n",
      "Epoch 405/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4963 - val_loss: 0.4354 - val_mse: 0.4282\n",
      "Epoch 406/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4915 - val_loss: 0.4450 - val_mse: 0.4377\n",
      "Epoch 407/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5013 - val_loss: 0.4304 - val_mse: 0.4232\n",
      "Epoch 408/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5019 - val_loss: 0.4404 - val_mse: 0.4332\n",
      "Epoch 409/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4944 - val_loss: 0.4358 - val_mse: 0.4286\n",
      "Epoch 410/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5037 - mse: 0.4965\n",
      "Epoch 00410: saving model to Regression_Model/mle.linear-0410.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4966 - val_loss: 0.4356 - val_mse: 0.4284\n",
      "Epoch 411/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5107 - mse: 0.5035 - val_loss: 0.4558 - val_mse: 0.4486\n",
      "Epoch 412/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4943 - val_loss: 0.4296 - val_mse: 0.4223\n",
      "Epoch 413/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5022 - val_loss: 0.4320 - val_mse: 0.4248\n",
      "Epoch 414/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5042 - val_loss: 0.4509 - val_mse: 0.4437\n",
      "Epoch 415/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5000 - mse: 0.4928 - val_loss: 0.4383 - val_mse: 0.4311\n",
      "Epoch 416/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4956 - val_loss: 0.4344 - val_mse: 0.4272\n",
      "Epoch 417/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4982 - mse: 0.4910 - val_loss: 0.4357 - val_mse: 0.4284\n",
      "Epoch 418/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.4994 - val_loss: 0.4459 - val_mse: 0.4387\n",
      "Epoch 419/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5013 - val_loss: 0.4513 - val_mse: 0.4441\n",
      "Epoch 420/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4991 - mse: 0.4918\n",
      "Epoch 00420: saving model to Regression_Model/mle.linear-0420.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5001 - mse: 0.4928 - val_loss: 0.4385 - val_mse: 0.4312\n",
      "Epoch 421/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4947 - val_loss: 0.4381 - val_mse: 0.4309\n",
      "Epoch 422/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4970 - val_loss: 0.4369 - val_mse: 0.4296\n",
      "Epoch 423/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4952 - val_loss: 0.4378 - val_mse: 0.4306\n",
      "Epoch 424/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5013 - val_loss: 0.4350 - val_mse: 0.4277\n",
      "Epoch 425/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4950 - val_loss: 0.4356 - val_mse: 0.4284\n",
      "Epoch 426/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4973 - val_loss: 0.4411 - val_mse: 0.4339\n",
      "Epoch 427/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4930 - val_loss: 0.4356 - val_mse: 0.4284\n",
      "Epoch 428/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4870 - val_loss: 0.4394 - val_mse: 0.4321\n",
      "Epoch 429/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5058 - mse: 0.4985 - val_loss: 0.4500 - val_mse: 0.4427\n",
      "Epoch 430/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5015 - mse: 0.4942\n",
      "Epoch 00430: saving model to Regression_Model/mle.linear-0430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4959 - val_loss: 0.4548 - val_mse: 0.4476\n",
      "Epoch 431/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.4990 - val_loss: 0.4408 - val_mse: 0.4336\n",
      "Epoch 432/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4958 - val_loss: 0.4417 - val_mse: 0.4344\n",
      "Epoch 433/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5010 - val_loss: 0.4443 - val_mse: 0.4370\n",
      "Epoch 434/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4973 - val_loss: 0.4325 - val_mse: 0.4252\n",
      "Epoch 435/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4949 - mse: 0.4876 - val_loss: 0.4323 - val_mse: 0.4250\n",
      "Epoch 436/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4982 - val_loss: 0.4371 - val_mse: 0.4298\n",
      "Epoch 437/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4959 - val_loss: 0.4343 - val_mse: 0.4270\n",
      "Epoch 438/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5023 - val_loss: 0.4358 - val_mse: 0.4285\n",
      "Epoch 439/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.4999 - val_loss: 0.4383 - val_mse: 0.4310\n",
      "Epoch 440/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5080 - mse: 0.5008\n",
      "Epoch 00440: saving model to Regression_Model/mle.linear-0440.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.4996 - val_loss: 0.4442 - val_mse: 0.4369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4956 - val_loss: 0.4585 - val_mse: 0.4513\n",
      "Epoch 442/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4971 - val_loss: 0.4315 - val_mse: 0.4242\n",
      "Epoch 443/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5019 - val_loss: 0.4445 - val_mse: 0.4372\n",
      "Epoch 444/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4969 - val_loss: 0.4377 - val_mse: 0.4304\n",
      "Epoch 445/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4979 - val_loss: 0.4405 - val_mse: 0.4332\n",
      "Epoch 446/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5025 - val_loss: 0.4380 - val_mse: 0.4307\n",
      "Epoch 447/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4961 - val_loss: 0.4319 - val_mse: 0.4246\n",
      "Epoch 448/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5059 - mse: 0.4986 - val_loss: 0.4416 - val_mse: 0.4343\n",
      "Epoch 449/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5027 - val_loss: 0.4418 - val_mse: 0.4345\n",
      "Epoch 450/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5070 - mse: 0.4997\n",
      "Epoch 00450: saving model to Regression_Model/mle.linear-0450.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5074 - mse: 0.5001 - val_loss: 0.4305 - val_mse: 0.4232\n",
      "Epoch 451/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.4998 - val_loss: 0.4476 - val_mse: 0.4403\n",
      "Epoch 452/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4935 - val_loss: 0.4317 - val_mse: 0.4244\n",
      "Epoch 453/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4968 - val_loss: 0.4306 - val_mse: 0.4233\n",
      "Epoch 454/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4979 - val_loss: 0.4325 - val_mse: 0.4252\n",
      "Epoch 455/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.4990 - val_loss: 0.4416 - val_mse: 0.4343\n",
      "Epoch 456/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5028 - mse: 0.4955 - val_loss: 0.4381 - val_mse: 0.4308\n",
      "Epoch 457/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4977 - val_loss: 0.4372 - val_mse: 0.4299\n",
      "Epoch 458/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4968 - val_loss: 0.4328 - val_mse: 0.4255\n",
      "Epoch 459/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5060 - mse: 0.4987 - val_loss: 0.4464 - val_mse: 0.4391\n",
      "Epoch 460/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.5026 - mse: 0.4953\n",
      "Epoch 00460: saving model to Regression_Model/mle.linear-0460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4964 - val_loss: 0.4299 - val_mse: 0.4226\n",
      "Epoch 461/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4919 - val_loss: 0.4362 - val_mse: 0.4288\n",
      "Epoch 462/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4956 - mse: 0.4883 - val_loss: 0.4502 - val_mse: 0.4429\n",
      "Epoch 463/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5051 - mse: 0.4977 - val_loss: 0.4499 - val_mse: 0.4425\n",
      "Epoch 464/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4953 - val_loss: 0.4307 - val_mse: 0.4234\n",
      "Epoch 465/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5039 - mse: 0.4966 - val_loss: 0.4414 - val_mse: 0.4340\n",
      "Epoch 466/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4985 - mse: 0.4911 - val_loss: 0.4325 - val_mse: 0.4252\n",
      "Epoch 467/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4939 - val_loss: 0.4295 - val_mse: 0.4222\n",
      "Epoch 468/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4965 - val_loss: 0.4360 - val_mse: 0.4287\n",
      "Epoch 469/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4989 - mse: 0.4916 - val_loss: 0.4411 - val_mse: 0.4338\n",
      "Epoch 470/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5080 - mse: 0.5007\n",
      "Epoch 00470: saving model to Regression_Model/mle.linear-0470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.4995 - val_loss: 0.4352 - val_mse: 0.4279\n",
      "Epoch 471/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4914 - val_loss: 0.4382 - val_mse: 0.4309\n",
      "Epoch 472/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5050 - mse: 0.4976 - val_loss: 0.4286 - val_mse: 0.4212\n",
      "Epoch 473/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5001 - val_loss: 0.4415 - val_mse: 0.4342\n",
      "Epoch 474/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4941 - val_loss: 0.4334 - val_mse: 0.4261\n",
      "Epoch 475/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4938 - val_loss: 0.4408 - val_mse: 0.4334\n",
      "Epoch 476/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4934 - val_loss: 0.4442 - val_mse: 0.4369\n",
      "Epoch 477/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5038 - mse: 0.4965 - val_loss: 0.4377 - val_mse: 0.4303\n",
      "Epoch 478/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4955 - val_loss: 0.4477 - val_mse: 0.4404\n",
      "Epoch 479/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4958 - mse: 0.4884 - val_loss: 0.4354 - val_mse: 0.4281\n",
      "Epoch 480/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4926 - mse: 0.4852\n",
      "Epoch 00480: saving model to Regression_Model/mle.linear-0480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4953 - mse: 0.4879 - val_loss: 0.4406 - val_mse: 0.4332\n",
      "Epoch 481/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.4986 - val_loss: 0.4468 - val_mse: 0.4395\n",
      "Epoch 482/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.4994 - val_loss: 0.4347 - val_mse: 0.4274\n",
      "Epoch 483/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4928 - val_loss: 0.4415 - val_mse: 0.4341\n",
      "Epoch 484/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4950 - val_loss: 0.4463 - val_mse: 0.4390\n",
      "Epoch 485/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4926 - val_loss: 0.4438 - val_mse: 0.4364\n",
      "Epoch 486/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4965 - val_loss: 0.4535 - val_mse: 0.4461\n",
      "Epoch 487/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5010 - val_loss: 0.4498 - val_mse: 0.4424\n",
      "Epoch 488/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5083 - mse: 0.5009 - val_loss: 0.4356 - val_mse: 0.4282\n",
      "Epoch 489/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5076 - mse: 0.5002 - val_loss: 0.4511 - val_mse: 0.4437\n",
      "Epoch 490/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.4988 - mse: 0.4914\n",
      "Epoch 00490: saving model to Regression_Model/mle.linear-0490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4940 - val_loss: 0.4283 - val_mse: 0.4210\n",
      "Epoch 491/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4945 - val_loss: 0.4322 - val_mse: 0.4249\n",
      "Epoch 492/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4957 - mse: 0.4883 - val_loss: 0.4312 - val_mse: 0.4238\n",
      "Epoch 493/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5017 - val_loss: 0.4324 - val_mse: 0.4250\n",
      "Epoch 494/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4975 - mse: 0.4901 - val_loss: 0.4384 - val_mse: 0.4311\n",
      "Epoch 495/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4979 - val_loss: 0.4315 - val_mse: 0.4241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4967 - val_loss: 0.4393 - val_mse: 0.4319\n",
      "Epoch 497/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4923 - val_loss: 0.4423 - val_mse: 0.4349\n",
      "Epoch 498/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.4996 - val_loss: 0.4279 - val_mse: 0.4205\n",
      "Epoch 499/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4962 - val_loss: 0.4333 - val_mse: 0.4260\n",
      "Epoch 500/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5047 - mse: 0.4974\n",
      "Epoch 00500: saving model to Regression_Model/mle.linear-0500.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5026 - mse: 0.4953 - val_loss: 0.4355 - val_mse: 0.4281\n",
      "Epoch 501/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.4995 - val_loss: 0.4361 - val_mse: 0.4287\n",
      "Epoch 502/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5010 - mse: 0.4936 - val_loss: 0.4249 - val_mse: 0.4175\n",
      "Epoch 503/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5043 - val_loss: 0.4289 - val_mse: 0.4215\n",
      "Epoch 504/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4963 - val_loss: 0.4375 - val_mse: 0.4302\n",
      "Epoch 505/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5014 - val_loss: 0.4338 - val_mse: 0.4264\n",
      "Epoch 506/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.4985 - val_loss: 0.4321 - val_mse: 0.4247\n",
      "Epoch 507/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5026 - val_loss: 0.4422 - val_mse: 0.4349\n",
      "Epoch 508/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4913 - val_loss: 0.4337 - val_mse: 0.4263\n",
      "Epoch 509/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4966 - val_loss: 0.4357 - val_mse: 0.4283\n",
      "Epoch 510/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5042 - mse: 0.4968\n",
      "Epoch 00510: saving model to Regression_Model/mle.linear-0510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4952 - val_loss: 0.4426 - val_mse: 0.4353\n",
      "Epoch 511/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5009 - val_loss: 0.4317 - val_mse: 0.4243\n",
      "Epoch 512/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4923 - val_loss: 0.4298 - val_mse: 0.4224\n",
      "Epoch 513/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4971 - val_loss: 0.4407 - val_mse: 0.4333\n",
      "Epoch 514/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4903 - val_loss: 0.4277 - val_mse: 0.4203\n",
      "Epoch 515/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4960 - val_loss: 0.4502 - val_mse: 0.4428\n",
      "Epoch 516/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4956 - val_loss: 0.4305 - val_mse: 0.4231\n",
      "Epoch 517/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4981 - mse: 0.4907 - val_loss: 0.4305 - val_mse: 0.4231\n",
      "Epoch 518/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4958 - val_loss: 0.4310 - val_mse: 0.4236\n",
      "Epoch 519/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4943 - mse: 0.4869 - val_loss: 0.4532 - val_mse: 0.4458\n",
      "Epoch 520/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5020 - mse: 0.4946\n",
      "Epoch 00520: saving model to Regression_Model/mle.linear-0520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4937 - val_loss: 0.4442 - val_mse: 0.4368\n",
      "Epoch 521/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4955 - val_loss: 0.4274 - val_mse: 0.4200\n",
      "Epoch 522/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4922 - val_loss: 0.4345 - val_mse: 0.4271\n",
      "Epoch 523/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4978 - mse: 0.4904 - val_loss: 0.4301 - val_mse: 0.4227\n",
      "Epoch 524/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4975 - mse: 0.4901 - val_loss: 0.4362 - val_mse: 0.4288\n",
      "Epoch 525/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4957 - val_loss: 0.4267 - val_mse: 0.4193\n",
      "Epoch 526/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4936 - mse: 0.4862 - val_loss: 0.4332 - val_mse: 0.4258\n",
      "Epoch 527/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5035 - mse: 0.4961 - val_loss: 0.4289 - val_mse: 0.4215\n",
      "Epoch 528/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4932 - val_loss: 0.4303 - val_mse: 0.4229\n",
      "Epoch 529/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4980 - mse: 0.4905 - val_loss: 0.4281 - val_mse: 0.4207\n",
      "Epoch 530/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4986 - mse: 0.4911\n",
      "Epoch 00530: saving model to Regression_Model/mle.linear-0530.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4966 - mse: 0.4892 - val_loss: 0.4292 - val_mse: 0.4218\n",
      "Epoch 531/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4925 - val_loss: 0.4330 - val_mse: 0.4255\n",
      "Epoch 532/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4845 - val_loss: 0.4358 - val_mse: 0.4284\n",
      "Epoch 533/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4959 - mse: 0.4885 - val_loss: 0.4386 - val_mse: 0.4312\n",
      "Epoch 534/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4931 - val_loss: 0.4346 - val_mse: 0.4272\n",
      "Epoch 535/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4894 - val_loss: 0.4364 - val_mse: 0.4290\n",
      "Epoch 536/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4958 - val_loss: 0.4408 - val_mse: 0.4334\n",
      "Epoch 537/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4923 - val_loss: 0.4353 - val_mse: 0.4279\n",
      "Epoch 538/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4844 - val_loss: 0.4299 - val_mse: 0.4224\n",
      "Epoch 539/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4922 - val_loss: 0.4378 - val_mse: 0.4303\n",
      "Epoch 540/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5071 - mse: 0.4997\n",
      "Epoch 00540: saving model to Regression_Model/mle.linear-0540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4979 - val_loss: 0.4275 - val_mse: 0.4201\n",
      "Epoch 541/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4976 - val_loss: 0.4375 - val_mse: 0.4301\n",
      "Epoch 542/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5013 - mse: 0.4939 - val_loss: 0.4461 - val_mse: 0.4387\n",
      "Epoch 543/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5002 - val_loss: 0.4461 - val_mse: 0.4387\n",
      "Epoch 544/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4935 - val_loss: 0.4328 - val_mse: 0.4254\n",
      "Epoch 545/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4994 - mse: 0.4920 - val_loss: 0.4332 - val_mse: 0.4257\n",
      "Epoch 546/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4978 - val_loss: 0.4317 - val_mse: 0.4243\n",
      "Epoch 547/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4929 - val_loss: 0.4303 - val_mse: 0.4228\n",
      "Epoch 548/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4920 - val_loss: 0.4326 - val_mse: 0.4251\n",
      "Epoch 549/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4968 - mse: 0.4894 - val_loss: 0.4316 - val_mse: 0.4241\n",
      "Epoch 550/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5083 - mse: 0.5008\n",
      "Epoch 00550: saving model to Regression_Model/mle.linear-0550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5012 - val_loss: 0.4272 - val_mse: 0.4198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4809 - val_loss: 0.4252 - val_mse: 0.4177\n",
      "Epoch 552/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4947 - val_loss: 0.4238 - val_mse: 0.4163\n",
      "Epoch 553/3000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4985 - mse: 0.4910 - val_loss: 0.4361 - val_mse: 0.4287\n",
      "Epoch 554/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4903 - val_loss: 0.4316 - val_mse: 0.4241\n",
      "Epoch 555/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4887 - val_loss: 0.4369 - val_mse: 0.4294\n",
      "Epoch 556/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4964 - val_loss: 0.4394 - val_mse: 0.4320\n",
      "Epoch 557/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4928 - val_loss: 0.4339 - val_mse: 0.4264\n",
      "Epoch 558/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4989 - mse: 0.4914 - val_loss: 0.4285 - val_mse: 0.4211\n",
      "Epoch 559/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4960 - val_loss: 0.4351 - val_mse: 0.4277\n",
      "Epoch 560/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4999 - mse: 0.4924\n",
      "Epoch 00560: saving model to Regression_Model/mle.linear-0560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4913 - val_loss: 0.4250 - val_mse: 0.4175\n",
      "Epoch 561/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4940 - mse: 0.4865 - val_loss: 0.4354 - val_mse: 0.4280\n",
      "Epoch 562/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4937 - mse: 0.4863 - val_loss: 0.4287 - val_mse: 0.4212\n",
      "Epoch 563/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4932 - val_loss: 0.4273 - val_mse: 0.4199\n",
      "Epoch 564/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4912 - val_loss: 0.4299 - val_mse: 0.4224\n",
      "Epoch 565/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4868 - val_loss: 0.4312 - val_mse: 0.4237\n",
      "Epoch 566/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4971 - val_loss: 0.4276 - val_mse: 0.4201\n",
      "Epoch 567/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5038 - mse: 0.4963 - val_loss: 0.4458 - val_mse: 0.4384\n",
      "Epoch 568/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5070 - mse: 0.4995 - val_loss: 0.4347 - val_mse: 0.4273\n",
      "Epoch 569/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4902 - val_loss: 0.4243 - val_mse: 0.4168\n",
      "Epoch 570/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4965 - mse: 0.4891\n",
      "Epoch 00570: saving model to Regression_Model/mle.linear-0570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4922 - val_loss: 0.4318 - val_mse: 0.4243\n",
      "Epoch 571/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4945 - val_loss: 0.4358 - val_mse: 0.4283\n",
      "Epoch 572/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4949 - val_loss: 0.4287 - val_mse: 0.4212\n",
      "Epoch 573/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4933 - val_loss: 0.4365 - val_mse: 0.4290\n",
      "Epoch 574/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4963 - val_loss: 0.4340 - val_mse: 0.4266\n",
      "Epoch 575/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4930 - val_loss: 0.4468 - val_mse: 0.4393\n",
      "Epoch 576/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4926 - mse: 0.4851 - val_loss: 0.4258 - val_mse: 0.4183\n",
      "Epoch 577/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4902 - val_loss: 0.4332 - val_mse: 0.4257\n",
      "Epoch 578/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5001 - mse: 0.4926 - val_loss: 0.4250 - val_mse: 0.4175\n",
      "Epoch 579/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4964 - val_loss: 0.4301 - val_mse: 0.4227\n",
      "Epoch 580/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4979 - mse: 0.4904\n",
      "Epoch 00580: saving model to Regression_Model/mle.linear-0580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4912 - val_loss: 0.4294 - val_mse: 0.4220\n",
      "Epoch 581/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4814 - val_loss: 0.4267 - val_mse: 0.4193\n",
      "Epoch 582/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4969 - mse: 0.4894 - val_loss: 0.4322 - val_mse: 0.4248\n",
      "Epoch 583/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4956 - mse: 0.4882 - val_loss: 0.4330 - val_mse: 0.4255\n",
      "Epoch 584/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4967 - mse: 0.4892 - val_loss: 0.4278 - val_mse: 0.4204\n",
      "Epoch 585/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4921 - val_loss: 0.4381 - val_mse: 0.4306\n",
      "Epoch 586/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4916 - val_loss: 0.4232 - val_mse: 0.4157\n",
      "Epoch 587/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4968 - mse: 0.4894 - val_loss: 0.4315 - val_mse: 0.4240\n",
      "Epoch 588/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4953 - mse: 0.4878 - val_loss: 0.4325 - val_mse: 0.4250\n",
      "Epoch 589/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4913 - val_loss: 0.4338 - val_mse: 0.4264\n",
      "Epoch 590/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5005 - mse: 0.4930\n",
      "Epoch 00590: saving model to Regression_Model/mle.linear-0590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4946 - val_loss: 0.4322 - val_mse: 0.4247\n",
      "Epoch 591/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4927 - val_loss: 0.4455 - val_mse: 0.4381\n",
      "Epoch 592/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4960 - mse: 0.4886 - val_loss: 0.4279 - val_mse: 0.4205\n",
      "Epoch 593/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4959 - val_loss: 0.4297 - val_mse: 0.4222\n",
      "Epoch 594/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4923 - val_loss: 0.4332 - val_mse: 0.4257\n",
      "Epoch 595/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4894 - val_loss: 0.4268 - val_mse: 0.4194\n",
      "Epoch 596/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4894 - val_loss: 0.4418 - val_mse: 0.4343\n",
      "Epoch 597/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4929 - val_loss: 0.4252 - val_mse: 0.4177\n",
      "Epoch 598/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4978 - val_loss: 0.4264 - val_mse: 0.4189\n",
      "Epoch 599/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4974 - val_loss: 0.4312 - val_mse: 0.4237\n",
      "Epoch 600/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4979 - mse: 0.4904\n",
      "Epoch 00600: saving model to Regression_Model/mle.linear-0600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4981 - mse: 0.4906 - val_loss: 0.4256 - val_mse: 0.4181\n",
      "Epoch 601/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4930 - val_loss: 0.4248 - val_mse: 0.4174\n",
      "Epoch 602/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4911 - val_loss: 0.4214 - val_mse: 0.4139\n",
      "Epoch 603/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4934 - mse: 0.4859 - val_loss: 0.4262 - val_mse: 0.4187\n",
      "Epoch 604/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4941 - val_loss: 0.4252 - val_mse: 0.4177\n",
      "Epoch 605/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4980 - mse: 0.4906 - val_loss: 0.4294 - val_mse: 0.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4832 - val_loss: 0.4302 - val_mse: 0.4227\n",
      "Epoch 607/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4929 - val_loss: 0.4340 - val_mse: 0.4265\n",
      "Epoch 608/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4920 - val_loss: 0.4301 - val_mse: 0.4226\n",
      "Epoch 609/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4994 - mse: 0.4919 - val_loss: 0.4326 - val_mse: 0.4252\n",
      "Epoch 610/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5012 - mse: 0.4937\n",
      "Epoch 00610: saving model to Regression_Model/mle.linear-0610.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4936 - val_loss: 0.4297 - val_mse: 0.4222\n",
      "Epoch 611/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4942 - mse: 0.4867 - val_loss: 0.4314 - val_mse: 0.4239\n",
      "Epoch 612/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4928 - val_loss: 0.4395 - val_mse: 0.4320\n",
      "Epoch 613/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4958 - mse: 0.4883 - val_loss: 0.4305 - val_mse: 0.4230\n",
      "Epoch 614/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4926 - mse: 0.4851 - val_loss: 0.4310 - val_mse: 0.4235\n",
      "Epoch 615/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4909 - val_loss: 0.4274 - val_mse: 0.4199\n",
      "Epoch 616/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4975 - mse: 0.4901 - val_loss: 0.4314 - val_mse: 0.4239\n",
      "Epoch 617/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4909 - val_loss: 0.4277 - val_mse: 0.4203\n",
      "Epoch 618/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4907 - mse: 0.4833 - val_loss: 0.4216 - val_mse: 0.4142\n",
      "Epoch 619/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4947 - mse: 0.4872 - val_loss: 0.4242 - val_mse: 0.4167\n",
      "Epoch 620/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4975 - mse: 0.4900\n",
      "Epoch 00620: saving model to Regression_Model/mle.linear-0620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4979 - mse: 0.4904 - val_loss: 0.4363 - val_mse: 0.4288\n",
      "Epoch 621/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4909 - val_loss: 0.4356 - val_mse: 0.4281\n",
      "Epoch 622/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4950 - mse: 0.4875 - val_loss: 0.4372 - val_mse: 0.4298\n",
      "Epoch 623/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4918 - val_loss: 0.4262 - val_mse: 0.4187\n",
      "Epoch 624/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4901 - mse: 0.4826 - val_loss: 0.4325 - val_mse: 0.4250\n",
      "Epoch 625/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4945 - mse: 0.4871 - val_loss: 0.4260 - val_mse: 0.4185\n",
      "Epoch 626/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4926 - mse: 0.4851 - val_loss: 0.4340 - val_mse: 0.4265\n",
      "Epoch 627/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4886 - val_loss: 0.4276 - val_mse: 0.4201\n",
      "Epoch 628/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4858 - val_loss: 0.4269 - val_mse: 0.4194\n",
      "Epoch 629/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4835 - val_loss: 0.4248 - val_mse: 0.4173\n",
      "Epoch 630/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5006 - mse: 0.4931\n",
      "Epoch 00630: saving model to Regression_Model/mle.linear-0630.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5007 - mse: 0.4932 - val_loss: 0.4310 - val_mse: 0.4235\n",
      "Epoch 631/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4937 - val_loss: 0.4316 - val_mse: 0.4241\n",
      "Epoch 632/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4917 - val_loss: 0.4287 - val_mse: 0.4212\n",
      "Epoch 633/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5038 - mse: 0.4963 - val_loss: 0.4399 - val_mse: 0.4324\n",
      "Epoch 634/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4916 - val_loss: 0.4279 - val_mse: 0.4204\n",
      "Epoch 635/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4841 - val_loss: 0.4284 - val_mse: 0.4209\n",
      "Epoch 636/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4857 - mse: 0.4782 - val_loss: 0.4297 - val_mse: 0.4222\n",
      "Epoch 637/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4962 - val_loss: 0.4231 - val_mse: 0.4156\n",
      "Epoch 638/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4979 - mse: 0.4904 - val_loss: 0.4443 - val_mse: 0.4368\n",
      "Epoch 639/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4911 - val_loss: 0.4255 - val_mse: 0.4180\n",
      "Epoch 640/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5022 - mse: 0.4947\n",
      "Epoch 00640: saving model to Regression_Model/mle.linear-0640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4945 - val_loss: 0.4281 - val_mse: 0.4206\n",
      "Epoch 641/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4940 - mse: 0.4865 - val_loss: 0.4265 - val_mse: 0.4190\n",
      "Epoch 642/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4862 - val_loss: 0.4261 - val_mse: 0.4186\n",
      "Epoch 643/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4899 - mse: 0.4824 - val_loss: 0.4281 - val_mse: 0.4206\n",
      "Epoch 644/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4954 - val_loss: 0.4263 - val_mse: 0.4188\n",
      "Epoch 645/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4909 - val_loss: 0.4233 - val_mse: 0.4158\n",
      "Epoch 646/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5026 - mse: 0.4951 - val_loss: 0.4317 - val_mse: 0.4242\n",
      "Epoch 647/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4893 - val_loss: 0.4308 - val_mse: 0.4233\n",
      "Epoch 648/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4935 - mse: 0.4860 - val_loss: 0.4285 - val_mse: 0.4210\n",
      "Epoch 649/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4911 - val_loss: 0.4298 - val_mse: 0.4222\n",
      "Epoch 650/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4910 - mse: 0.4835\n",
      "Epoch 00650: saving model to Regression_Model/mle.linear-0650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4927 - mse: 0.4852 - val_loss: 0.4303 - val_mse: 0.4227\n",
      "Epoch 651/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4901 - mse: 0.4825 - val_loss: 0.4217 - val_mse: 0.4142\n",
      "Epoch 652/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4937 - mse: 0.4862 - val_loss: 0.4219 - val_mse: 0.4144\n",
      "Epoch 653/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4922 - mse: 0.4847 - val_loss: 0.4319 - val_mse: 0.4244\n",
      "Epoch 654/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4931 - val_loss: 0.4276 - val_mse: 0.4201\n",
      "Epoch 655/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4857 - val_loss: 0.4210 - val_mse: 0.4135\n",
      "Epoch 656/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4955 - mse: 0.4879 - val_loss: 0.4246 - val_mse: 0.4171\n",
      "Epoch 657/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4934 - mse: 0.4859 - val_loss: 0.4324 - val_mse: 0.4249\n",
      "Epoch 658/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4989 - mse: 0.4914 - val_loss: 0.4356 - val_mse: 0.4281\n",
      "Epoch 659/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4968 - mse: 0.4893 - val_loss: 0.4222 - val_mse: 0.4147\n",
      "Epoch 660/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5032 - mse: 0.4957\n",
      "Epoch 00660: saving model to Regression_Model/mle.linear-0660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4942 - val_loss: 0.4391 - val_mse: 0.4316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4817 - val_loss: 0.4277 - val_mse: 0.4202\n",
      "Epoch 662/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4955 - mse: 0.4880 - val_loss: 0.4206 - val_mse: 0.4131\n",
      "Epoch 663/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4971 - mse: 0.4896 - val_loss: 0.4333 - val_mse: 0.4258\n",
      "Epoch 664/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4971 - val_loss: 0.4320 - val_mse: 0.4245\n",
      "Epoch 665/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4952 - mse: 0.4877 - val_loss: 0.4244 - val_mse: 0.4169\n",
      "Epoch 666/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4925 - mse: 0.4849 - val_loss: 0.4362 - val_mse: 0.4287\n",
      "Epoch 667/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4982 - mse: 0.4907 - val_loss: 0.4268 - val_mse: 0.4192\n",
      "Epoch 668/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4951 - mse: 0.4876 - val_loss: 0.4369 - val_mse: 0.4293\n",
      "Epoch 669/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4911 - mse: 0.4836 - val_loss: 0.4243 - val_mse: 0.4167\n",
      "Epoch 670/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5027 - mse: 0.4951\n",
      "Epoch 00670: saving model to Regression_Model/mle.linear-0670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4952 - val_loss: 0.4292 - val_mse: 0.4217\n",
      "Epoch 671/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5000 - mse: 0.4924 - val_loss: 0.4337 - val_mse: 0.4261\n",
      "Epoch 672/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4924 - val_loss: 0.4306 - val_mse: 0.4231\n",
      "Epoch 673/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4886 - val_loss: 0.4224 - val_mse: 0.4148\n",
      "Epoch 674/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4924 - mse: 0.4849 - val_loss: 0.4353 - val_mse: 0.4278\n",
      "Epoch 675/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4936 - mse: 0.4861 - val_loss: 0.4272 - val_mse: 0.4197\n",
      "Epoch 676/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4962 - mse: 0.4886 - val_loss: 0.4274 - val_mse: 0.4198\n",
      "Epoch 677/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4973 - mse: 0.4898 - val_loss: 0.4337 - val_mse: 0.4262\n",
      "Epoch 678/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4902 - val_loss: 0.4358 - val_mse: 0.4283\n",
      "Epoch 679/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4937 - mse: 0.4862 - val_loss: 0.4306 - val_mse: 0.4230\n",
      "Epoch 680/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4915 - mse: 0.4840\n",
      "Epoch 00680: saving model to Regression_Model/mle.linear-0680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4951 - mse: 0.4876 - val_loss: 0.4274 - val_mse: 0.4199\n",
      "Epoch 681/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4903 - mse: 0.4828 - val_loss: 0.4284 - val_mse: 0.4209\n",
      "Epoch 682/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4934 - val_loss: 0.4275 - val_mse: 0.4199\n",
      "Epoch 683/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4946 - mse: 0.4871 - val_loss: 0.4295 - val_mse: 0.4220\n",
      "Epoch 684/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4927 - mse: 0.4852 - val_loss: 0.4236 - val_mse: 0.4161\n",
      "Epoch 685/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4881 - mse: 0.4805 - val_loss: 0.4268 - val_mse: 0.4193\n",
      "Epoch 686/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4949 - val_loss: 0.4301 - val_mse: 0.4226\n",
      "Epoch 687/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4929 - mse: 0.4853 - val_loss: 0.4296 - val_mse: 0.4221\n",
      "Epoch 688/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4956 - mse: 0.4881 - val_loss: 0.4253 - val_mse: 0.4178\n",
      "Epoch 689/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4815 - val_loss: 0.4252 - val_mse: 0.4177\n",
      "Epoch 690/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4997 - mse: 0.4922\n",
      "Epoch 00690: saving model to Regression_Model/mle.linear-0690.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4996 - mse: 0.4920 - val_loss: 0.4286 - val_mse: 0.4211\n",
      "Epoch 691/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4841 - val_loss: 0.4273 - val_mse: 0.4197\n",
      "Epoch 692/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4934 - mse: 0.4859 - val_loss: 0.4197 - val_mse: 0.4121\n",
      "Epoch 693/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4902 - val_loss: 0.4340 - val_mse: 0.4264\n",
      "Epoch 694/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4771 - val_loss: 0.4257 - val_mse: 0.4182\n",
      "Epoch 695/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4971 - mse: 0.4896 - val_loss: 0.4234 - val_mse: 0.4158\n",
      "Epoch 696/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4985 - mse: 0.4910 - val_loss: 0.4390 - val_mse: 0.4314\n",
      "Epoch 697/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4902 - mse: 0.4827 - val_loss: 0.4220 - val_mse: 0.4145\n",
      "Epoch 698/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4826 - val_loss: 0.4344 - val_mse: 0.4269\n",
      "Epoch 699/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4951 - mse: 0.4875 - val_loss: 0.4233 - val_mse: 0.4157\n",
      "Epoch 700/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4970 - mse: 0.4895\n",
      "Epoch 00700: saving model to Regression_Model/mle.linear-0700.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4967 - mse: 0.4891 - val_loss: 0.4219 - val_mse: 0.4143\n",
      "Epoch 701/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4970 - mse: 0.4894 - val_loss: 0.4367 - val_mse: 0.4291\n",
      "Epoch 702/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4917 - mse: 0.4841 - val_loss: 0.4265 - val_mse: 0.4190\n",
      "Epoch 703/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4924 - mse: 0.4849 - val_loss: 0.4321 - val_mse: 0.4245\n",
      "Epoch 704/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4800 - val_loss: 0.4200 - val_mse: 0.4124\n",
      "Epoch 705/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4930 - mse: 0.4854 - val_loss: 0.4265 - val_mse: 0.4189\n",
      "Epoch 706/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4978 - val_loss: 0.4391 - val_mse: 0.4315\n",
      "Epoch 707/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4975 - mse: 0.4900 - val_loss: 0.4306 - val_mse: 0.4230\n",
      "Epoch 708/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4921 - val_loss: 0.4271 - val_mse: 0.4195\n",
      "Epoch 709/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4963 - mse: 0.4888 - val_loss: 0.4216 - val_mse: 0.4140\n",
      "Epoch 710/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4970 - mse: 0.4895\n",
      "Epoch 00710: saving model to Regression_Model/mle.linear-0710.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4967 - mse: 0.4891 - val_loss: 0.4195 - val_mse: 0.4119\n",
      "Epoch 711/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4905 - mse: 0.4829 - val_loss: 0.4215 - val_mse: 0.4139\n",
      "Epoch 712/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4945 - mse: 0.4869 - val_loss: 0.4258 - val_mse: 0.4183\n",
      "Epoch 713/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4951 - mse: 0.4875 - val_loss: 0.4210 - val_mse: 0.4134\n",
      "Epoch 714/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4901 - mse: 0.4826 - val_loss: 0.4319 - val_mse: 0.4243\n",
      "Epoch 715/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4901 - mse: 0.4826 - val_loss: 0.4210 - val_mse: 0.4134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4950 - mse: 0.4874 - val_loss: 0.4235 - val_mse: 0.4159\n",
      "Epoch 717/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4971 - mse: 0.4895 - val_loss: 0.4235 - val_mse: 0.4159\n",
      "Epoch 718/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4934 - mse: 0.4859 - val_loss: 0.4292 - val_mse: 0.4216\n",
      "Epoch 719/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4921 - mse: 0.4845 - val_loss: 0.4258 - val_mse: 0.4182\n",
      "Epoch 720/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4955 - mse: 0.4879\n",
      "Epoch 00720: saving model to Regression_Model/mle.linear-0720.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4965 - mse: 0.4890 - val_loss: 0.4246 - val_mse: 0.4171\n",
      "Epoch 721/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4818 - val_loss: 0.4249 - val_mse: 0.4173\n",
      "Epoch 722/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4936 - mse: 0.4860 - val_loss: 0.4286 - val_mse: 0.4210\n",
      "Epoch 723/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4843 - val_loss: 0.4267 - val_mse: 0.4191\n",
      "Epoch 724/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4826 - val_loss: 0.4270 - val_mse: 0.4194\n",
      "Epoch 725/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4857 - val_loss: 0.4305 - val_mse: 0.4230\n",
      "Epoch 726/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4937 - mse: 0.4861 - val_loss: 0.4289 - val_mse: 0.4213\n",
      "Epoch 727/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4923 - mse: 0.4847 - val_loss: 0.4275 - val_mse: 0.4200\n",
      "Epoch 728/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4943 - mse: 0.4867 - val_loss: 0.4309 - val_mse: 0.4233\n",
      "Epoch 729/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4953 - mse: 0.4877 - val_loss: 0.4272 - val_mse: 0.4196\n",
      "Epoch 730/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4982 - mse: 0.4906\n",
      "Epoch 00730: saving model to Regression_Model/mle.linear-0730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4958 - mse: 0.4882 - val_loss: 0.4178 - val_mse: 0.4103\n",
      "Epoch 731/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4956 - mse: 0.4880 - val_loss: 0.4272 - val_mse: 0.4196\n",
      "Epoch 732/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4799 - val_loss: 0.4256 - val_mse: 0.4180\n",
      "Epoch 733/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4909 - mse: 0.4833 - val_loss: 0.4276 - val_mse: 0.4200\n",
      "Epoch 734/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4935 - mse: 0.4859 - val_loss: 0.4231 - val_mse: 0.4155\n",
      "Epoch 735/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4934 - mse: 0.4858 - val_loss: 0.4250 - val_mse: 0.4174\n",
      "Epoch 736/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4967 - mse: 0.4891 - val_loss: 0.4220 - val_mse: 0.4144\n",
      "Epoch 737/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4906 - mse: 0.4831 - val_loss: 0.4229 - val_mse: 0.4153\n",
      "Epoch 738/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4954 - mse: 0.4878 - val_loss: 0.4231 - val_mse: 0.4155\n",
      "Epoch 739/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4920 - mse: 0.4844 - val_loss: 0.4190 - val_mse: 0.4115\n",
      "Epoch 740/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4963 - mse: 0.4887\n",
      "Epoch 00740: saving model to Regression_Model/mle.linear-0740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4968 - mse: 0.4893 - val_loss: 0.4290 - val_mse: 0.4214\n",
      "Epoch 741/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4890 - mse: 0.4814 - val_loss: 0.4234 - val_mse: 0.4158\n",
      "Epoch 742/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4826 - val_loss: 0.4396 - val_mse: 0.4320\n",
      "Epoch 743/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4933 - val_loss: 0.4225 - val_mse: 0.4149\n",
      "Epoch 744/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4946 - mse: 0.4870 - val_loss: 0.4243 - val_mse: 0.4167\n",
      "Epoch 745/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4927 - mse: 0.4851 - val_loss: 0.4229 - val_mse: 0.4153\n",
      "Epoch 746/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4971 - mse: 0.4895 - val_loss: 0.4201 - val_mse: 0.4125\n",
      "Epoch 747/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4780 - val_loss: 0.4266 - val_mse: 0.4191\n",
      "Epoch 748/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4857 - val_loss: 0.4220 - val_mse: 0.4144\n",
      "Epoch 749/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4928 - mse: 0.4852 - val_loss: 0.4263 - val_mse: 0.4187\n",
      "Epoch 750/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5016 - mse: 0.4940\n",
      "Epoch 00750: saving model to Regression_Model/mle.linear-0750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4946 - val_loss: 0.4219 - val_mse: 0.4143\n",
      "Epoch 751/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4893 - val_loss: 0.4300 - val_mse: 0.4224\n",
      "Epoch 752/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4917 - mse: 0.4841 - val_loss: 0.4240 - val_mse: 0.4164\n",
      "Epoch 753/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4842 - val_loss: 0.4306 - val_mse: 0.4230\n",
      "Epoch 754/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4815 - val_loss: 0.4234 - val_mse: 0.4158\n",
      "Epoch 755/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4857 - val_loss: 0.4405 - val_mse: 0.4329\n",
      "Epoch 756/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4966 - mse: 0.4890 - val_loss: 0.4303 - val_mse: 0.4227\n",
      "Epoch 757/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4941 - val_loss: 0.4367 - val_mse: 0.4291\n",
      "Epoch 758/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4923 - mse: 0.4847 - val_loss: 0.4207 - val_mse: 0.4131\n",
      "Epoch 759/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4811 - val_loss: 0.4217 - val_mse: 0.4141\n",
      "Epoch 760/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4948 - mse: 0.4872\n",
      "Epoch 00760: saving model to Regression_Model/mle.linear-0760.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4931 - mse: 0.4855 - val_loss: 0.4305 - val_mse: 0.4229\n",
      "Epoch 761/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4966 - mse: 0.4890 - val_loss: 0.4196 - val_mse: 0.4120\n",
      "Epoch 762/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4956 - mse: 0.4880 - val_loss: 0.4243 - val_mse: 0.4168\n",
      "Epoch 763/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4929 - mse: 0.4853 - val_loss: 0.4221 - val_mse: 0.4145\n",
      "Epoch 764/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4955 - mse: 0.4879 - val_loss: 0.4273 - val_mse: 0.4197\n",
      "Epoch 765/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4840 - val_loss: 0.4228 - val_mse: 0.4152\n",
      "Epoch 766/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4937 - mse: 0.4861 - val_loss: 0.4200 - val_mse: 0.4124\n",
      "Epoch 767/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4929 - mse: 0.4853 - val_loss: 0.4319 - val_mse: 0.4243\n",
      "Epoch 768/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4939 - val_loss: 0.4234 - val_mse: 0.4158\n",
      "Epoch 769/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4908 - val_loss: 0.4250 - val_mse: 0.4174\n",
      "Epoch 770/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4931 - mse: 0.4855\n",
      "Epoch 00770: saving model to Regression_Model/mle.linear-0770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4930 - mse: 0.4854 - val_loss: 0.4234 - val_mse: 0.4158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4964 - mse: 0.4888 - val_loss: 0.4323 - val_mse: 0.4247\n",
      "Epoch 772/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4917 - mse: 0.4841 - val_loss: 0.4236 - val_mse: 0.4160\n",
      "Epoch 773/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4910 - val_loss: 0.4297 - val_mse: 0.4221\n",
      "Epoch 774/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4926 - mse: 0.4850 - val_loss: 0.4178 - val_mse: 0.4102\n",
      "Epoch 775/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4930 - mse: 0.4853 - val_loss: 0.4330 - val_mse: 0.4254\n",
      "Epoch 776/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4914 - val_loss: 0.4295 - val_mse: 0.4219\n",
      "Epoch 777/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4823 - val_loss: 0.4298 - val_mse: 0.4221\n",
      "Epoch 778/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4818 - val_loss: 0.4262 - val_mse: 0.4186\n",
      "Epoch 779/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4867 - val_loss: 0.4219 - val_mse: 0.4143\n",
      "Epoch 780/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4903 - mse: 0.4827\n",
      "Epoch 00780: saving model to Regression_Model/mle.linear-0780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4904 - mse: 0.4828 - val_loss: 0.4255 - val_mse: 0.4179\n",
      "Epoch 781/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4843 - val_loss: 0.4349 - val_mse: 0.4273\n",
      "Epoch 782/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4846 - mse: 0.4770 - val_loss: 0.4196 - val_mse: 0.4119\n",
      "Epoch 783/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4898 - mse: 0.4821 - val_loss: 0.4208 - val_mse: 0.4132\n",
      "Epoch 784/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4983 - mse: 0.4907 - val_loss: 0.4333 - val_mse: 0.4257\n",
      "Epoch 785/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4836 - val_loss: 0.4242 - val_mse: 0.4166\n",
      "Epoch 786/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4982 - mse: 0.4906 - val_loss: 0.4237 - val_mse: 0.4161\n",
      "Epoch 787/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4909 - mse: 0.4833 - val_loss: 0.4185 - val_mse: 0.4109\n",
      "Epoch 788/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4970 - mse: 0.4894 - val_loss: 0.4207 - val_mse: 0.4131\n",
      "Epoch 789/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4815 - val_loss: 0.4239 - val_mse: 0.4163\n",
      "Epoch 790/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4894 - mse: 0.4818\n",
      "Epoch 00790: saving model to Regression_Model/mle.linear-0790.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4840 - val_loss: 0.4225 - val_mse: 0.4149\n",
      "Epoch 791/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4936 - mse: 0.4860 - val_loss: 0.4246 - val_mse: 0.4170\n",
      "Epoch 792/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4885 - val_loss: 0.4258 - val_mse: 0.4181\n",
      "Epoch 793/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4959 - mse: 0.4883 - val_loss: 0.4272 - val_mse: 0.4196\n",
      "Epoch 794/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4929 - val_loss: 0.4486 - val_mse: 0.4410\n",
      "Epoch 795/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4924 - mse: 0.4848 - val_loss: 0.4262 - val_mse: 0.4186\n",
      "Epoch 796/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4842 - mse: 0.4765 - val_loss: 0.4187 - val_mse: 0.4111\n",
      "Epoch 797/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4941 - mse: 0.4865 - val_loss: 0.4182 - val_mse: 0.4106\n",
      "Epoch 798/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4924 - mse: 0.4848 - val_loss: 0.4194 - val_mse: 0.4118\n",
      "Epoch 799/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4951 - mse: 0.4875 - val_loss: 0.4221 - val_mse: 0.4145\n",
      "Epoch 800/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4889 - mse: 0.4813\n",
      "Epoch 00800: saving model to Regression_Model/mle.linear-0800.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4802 - val_loss: 0.4286 - val_mse: 0.4210\n",
      "Epoch 801/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4806 - val_loss: 0.4298 - val_mse: 0.4222\n",
      "Epoch 802/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4968 - mse: 0.4892 - val_loss: 0.4279 - val_mse: 0.4203\n",
      "Epoch 803/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4903 - mse: 0.4826 - val_loss: 0.4332 - val_mse: 0.4256\n",
      "Epoch 804/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4834 - val_loss: 0.4196 - val_mse: 0.4120\n",
      "Epoch 805/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4936 - mse: 0.4860 - val_loss: 0.4191 - val_mse: 0.4115\n",
      "Epoch 806/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4964 - mse: 0.4888 - val_loss: 0.4207 - val_mse: 0.4131\n",
      "Epoch 807/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4904 - mse: 0.4828 - val_loss: 0.4267 - val_mse: 0.4191\n",
      "Epoch 808/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4826 - val_loss: 0.4183 - val_mse: 0.4107\n",
      "Epoch 809/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4939 - mse: 0.4863 - val_loss: 0.4251 - val_mse: 0.4175\n",
      "Epoch 810/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4948 - mse: 0.4872\n",
      "Epoch 00810: saving model to Regression_Model/mle.linear-0810.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4947 - mse: 0.4871 - val_loss: 0.4295 - val_mse: 0.4219\n",
      "Epoch 811/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4967 - mse: 0.4891 - val_loss: 0.4201 - val_mse: 0.4125\n",
      "Epoch 812/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4973 - mse: 0.4897 - val_loss: 0.4253 - val_mse: 0.4177\n",
      "Epoch 813/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4798 - val_loss: 0.4185 - val_mse: 0.4109\n",
      "Epoch 814/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4930 - mse: 0.4854 - val_loss: 0.4301 - val_mse: 0.4225\n",
      "Epoch 815/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4930 - mse: 0.4854 - val_loss: 0.4243 - val_mse: 0.4167\n",
      "Epoch 816/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4881 - mse: 0.4805 - val_loss: 0.4211 - val_mse: 0.4135\n",
      "Epoch 817/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4898 - mse: 0.4821 - val_loss: 0.4204 - val_mse: 0.4128\n",
      "Epoch 818/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4918 - mse: 0.4841 - val_loss: 0.4200 - val_mse: 0.4124\n",
      "Epoch 819/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4929 - mse: 0.4853 - val_loss: 0.4346 - val_mse: 0.4269\n",
      "Epoch 820/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4938 - mse: 0.4862\n",
      "Epoch 00820: saving model to Regression_Model/mle.linear-0820.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4908 - mse: 0.4832 - val_loss: 0.4165 - val_mse: 0.4089\n",
      "Epoch 821/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4787 - val_loss: 0.4183 - val_mse: 0.4107\n",
      "Epoch 822/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4830 - val_loss: 0.4181 - val_mse: 0.4104\n",
      "Epoch 823/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4864 - mse: 0.4788 - val_loss: 0.4179 - val_mse: 0.4102\n",
      "Epoch 824/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4885 - val_loss: 0.4181 - val_mse: 0.4105\n",
      "Epoch 825/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4904 - mse: 0.4827 - val_loss: 0.4242 - val_mse: 0.4166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4844 - mse: 0.4768 - val_loss: 0.4315 - val_mse: 0.4238\n",
      "Epoch 827/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4890 - mse: 0.4814 - val_loss: 0.4336 - val_mse: 0.4260\n",
      "Epoch 828/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4911 - mse: 0.4834 - val_loss: 0.4164 - val_mse: 0.4088\n",
      "Epoch 829/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4869 - mse: 0.4793 - val_loss: 0.4234 - val_mse: 0.4158\n",
      "Epoch 830/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4888 - mse: 0.4812\n",
      "Epoch 00830: saving model to Regression_Model/mle.linear-0830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4812 - val_loss: 0.4220 - val_mse: 0.4143\n",
      "Epoch 831/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4836 - val_loss: 0.4260 - val_mse: 0.4184\n",
      "Epoch 832/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4810 - val_loss: 0.4232 - val_mse: 0.4156\n",
      "Epoch 833/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4909 - mse: 0.4833 - val_loss: 0.4323 - val_mse: 0.4246\n",
      "Epoch 834/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4778 - val_loss: 0.4206 - val_mse: 0.4130\n",
      "Epoch 835/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4915 - mse: 0.4839 - val_loss: 0.4269 - val_mse: 0.4193\n",
      "Epoch 836/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4922 - mse: 0.4845 - val_loss: 0.4274 - val_mse: 0.4198\n",
      "Epoch 837/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4929 - mse: 0.4853 - val_loss: 0.4179 - val_mse: 0.4103\n",
      "Epoch 838/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4830 - mse: 0.4753 - val_loss: 0.4192 - val_mse: 0.4116\n",
      "Epoch 839/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4867 - mse: 0.4790 - val_loss: 0.4271 - val_mse: 0.4195\n",
      "Epoch 840/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4881 - mse: 0.4805\n",
      "Epoch 00840: saving model to Regression_Model/mle.linear-0840.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4800 - val_loss: 0.4187 - val_mse: 0.4110\n",
      "Epoch 841/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4923 - mse: 0.4847 - val_loss: 0.4220 - val_mse: 0.4144\n",
      "Epoch 842/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4953 - mse: 0.4877 - val_loss: 0.4228 - val_mse: 0.4152\n",
      "Epoch 843/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4920 - mse: 0.4843 - val_loss: 0.4245 - val_mse: 0.4169\n",
      "Epoch 844/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4949 - mse: 0.4872 - val_loss: 0.4180 - val_mse: 0.4104\n",
      "Epoch 845/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4750 - val_loss: 0.4139 - val_mse: 0.4063\n",
      "Epoch 846/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4780 - val_loss: 0.4207 - val_mse: 0.4131\n",
      "Epoch 847/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4856 - val_loss: 0.4221 - val_mse: 0.4145\n",
      "Epoch 848/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4946 - mse: 0.4870 - val_loss: 0.4153 - val_mse: 0.4077\n",
      "Epoch 849/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4918 - val_loss: 0.4193 - val_mse: 0.4117\n",
      "Epoch 850/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4907 - mse: 0.4831\n",
      "Epoch 00850: saving model to Regression_Model/mle.linear-0850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4820 - val_loss: 0.4166 - val_mse: 0.4090\n",
      "Epoch 851/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4906 - mse: 0.4830 - val_loss: 0.4235 - val_mse: 0.4159\n",
      "Epoch 852/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4876 - mse: 0.4800 - val_loss: 0.4192 - val_mse: 0.4116\n",
      "Epoch 853/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4734 - val_loss: 0.4266 - val_mse: 0.4190\n",
      "Epoch 854/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4862 - val_loss: 0.4315 - val_mse: 0.4239\n",
      "Epoch 855/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4807 - val_loss: 0.4319 - val_mse: 0.4242\n",
      "Epoch 856/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4935 - mse: 0.4859 - val_loss: 0.4334 - val_mse: 0.4258\n",
      "Epoch 857/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4920 - mse: 0.4844 - val_loss: 0.4188 - val_mse: 0.4112\n",
      "Epoch 858/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4802 - val_loss: 0.4225 - val_mse: 0.4149\n",
      "Epoch 859/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4928 - mse: 0.4852 - val_loss: 0.4239 - val_mse: 0.4163\n",
      "Epoch 860/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4939 - mse: 0.4863\n",
      "Epoch 00860: saving model to Regression_Model/mle.linear-0860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4940 - mse: 0.4864 - val_loss: 0.4338 - val_mse: 0.4262\n",
      "Epoch 861/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4953 - mse: 0.4877 - val_loss: 0.4236 - val_mse: 0.4160\n",
      "Epoch 862/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4818 - val_loss: 0.4211 - val_mse: 0.4135\n",
      "Epoch 863/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4900 - mse: 0.4824 - val_loss: 0.4176 - val_mse: 0.4100\n",
      "Epoch 864/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4815 - val_loss: 0.4192 - val_mse: 0.4116\n",
      "Epoch 865/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4985 - mse: 0.4909 - val_loss: 0.4377 - val_mse: 0.4301\n",
      "Epoch 866/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4967 - mse: 0.4891 - val_loss: 0.4296 - val_mse: 0.4220\n",
      "Epoch 867/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4836 - val_loss: 0.4309 - val_mse: 0.4233\n",
      "Epoch 868/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4873 - mse: 0.4797 - val_loss: 0.4214 - val_mse: 0.4137\n",
      "Epoch 869/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4901 - mse: 0.4825 - val_loss: 0.4260 - val_mse: 0.4184\n",
      "Epoch 870/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4897 - mse: 0.4821\n",
      "Epoch 00870: saving model to Regression_Model/mle.linear-0870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4811 - val_loss: 0.4264 - val_mse: 0.4188\n",
      "Epoch 871/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4869 - mse: 0.4792 - val_loss: 0.4214 - val_mse: 0.4138\n",
      "Epoch 872/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4802 - val_loss: 0.4202 - val_mse: 0.4126\n",
      "Epoch 873/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4971 - mse: 0.4895 - val_loss: 0.4156 - val_mse: 0.4080\n",
      "Epoch 874/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4950 - mse: 0.4873 - val_loss: 0.4147 - val_mse: 0.4071\n",
      "Epoch 875/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4893 - mse: 0.4816 - val_loss: 0.4210 - val_mse: 0.4133\n",
      "Epoch 876/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4890 - mse: 0.4813 - val_loss: 0.4177 - val_mse: 0.4101\n",
      "Epoch 877/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4987 - mse: 0.4911 - val_loss: 0.4157 - val_mse: 0.4081\n",
      "Epoch 878/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4831 - val_loss: 0.4212 - val_mse: 0.4136\n",
      "Epoch 879/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4867 - val_loss: 0.4188 - val_mse: 0.4112\n",
      "Epoch 880/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4903 - mse: 0.4827\n",
      "Epoch 00880: saving model to Regression_Model/mle.linear-0880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4840 - val_loss: 0.4158 - val_mse: 0.4082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4798 - val_loss: 0.4239 - val_mse: 0.4162\n",
      "Epoch 882/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4812 - val_loss: 0.4253 - val_mse: 0.4177\n",
      "Epoch 883/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4921 - mse: 0.4845 - val_loss: 0.4158 - val_mse: 0.4082\n",
      "Epoch 884/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4819 - val_loss: 0.4187 - val_mse: 0.4111\n",
      "Epoch 885/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4904 - mse: 0.4828 - val_loss: 0.4175 - val_mse: 0.4099\n",
      "Epoch 886/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4804 - val_loss: 0.4187 - val_mse: 0.4111\n",
      "Epoch 887/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4757 - val_loss: 0.4260 - val_mse: 0.4184\n",
      "Epoch 888/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4930 - mse: 0.4854 - val_loss: 0.4171 - val_mse: 0.4094\n",
      "Epoch 889/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4764 - val_loss: 0.4217 - val_mse: 0.4141\n",
      "Epoch 890/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4885 - mse: 0.4809\n",
      "Epoch 00890: saving model to Regression_Model/mle.linear-0890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4906 - mse: 0.4830 - val_loss: 0.4176 - val_mse: 0.4100\n",
      "Epoch 891/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4831 - val_loss: 0.4256 - val_mse: 0.4180\n",
      "Epoch 892/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4826 - val_loss: 0.4320 - val_mse: 0.4244\n",
      "Epoch 893/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4805 - val_loss: 0.4175 - val_mse: 0.4098\n",
      "Epoch 894/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4911 - val_loss: 0.4186 - val_mse: 0.4110\n",
      "Epoch 895/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4871 - mse: 0.4795 - val_loss: 0.4146 - val_mse: 0.4070\n",
      "Epoch 896/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4816 - val_loss: 0.4155 - val_mse: 0.4079\n",
      "Epoch 897/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4857 - val_loss: 0.4198 - val_mse: 0.4122\n",
      "Epoch 898/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4919 - mse: 0.4843 - val_loss: 0.4195 - val_mse: 0.4119\n",
      "Epoch 899/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4852 - mse: 0.4776 - val_loss: 0.4183 - val_mse: 0.4106\n",
      "Epoch 900/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4891 - mse: 0.4815\n",
      "Epoch 00900: saving model to Regression_Model/mle.linear-0900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4883 - mse: 0.4807 - val_loss: 0.4219 - val_mse: 0.4143\n",
      "Epoch 901/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4840 - val_loss: 0.4156 - val_mse: 0.4080\n",
      "Epoch 902/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4975 - mse: 0.4899 - val_loss: 0.4219 - val_mse: 0.4143\n",
      "Epoch 903/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4893 - mse: 0.4817 - val_loss: 0.4209 - val_mse: 0.4133\n",
      "Epoch 904/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4820 - val_loss: 0.4160 - val_mse: 0.4084\n",
      "Epoch 905/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4909 - mse: 0.4833 - val_loss: 0.4208 - val_mse: 0.4132\n",
      "Epoch 906/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4860 - mse: 0.4783 - val_loss: 0.4159 - val_mse: 0.4083\n",
      "Epoch 907/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4920 - mse: 0.4844 - val_loss: 0.4273 - val_mse: 0.4197\n",
      "Epoch 908/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4861 - mse: 0.4785 - val_loss: 0.4154 - val_mse: 0.4077\n",
      "Epoch 909/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4890 - mse: 0.4814 - val_loss: 0.4247 - val_mse: 0.4171\n",
      "Epoch 910/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4837 - mse: 0.4761\n",
      "Epoch 00910: saving model to Regression_Model/mle.linear-0910.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4843 - mse: 0.4767 - val_loss: 0.4178 - val_mse: 0.4102\n",
      "Epoch 911/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4839 - val_loss: 0.4193 - val_mse: 0.4117\n",
      "Epoch 912/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4911 - mse: 0.4835 - val_loss: 0.4170 - val_mse: 0.4093\n",
      "Epoch 913/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4954 - mse: 0.4877 - val_loss: 0.4215 - val_mse: 0.4138\n",
      "Epoch 914/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4843 - val_loss: 0.4235 - val_mse: 0.4159\n",
      "Epoch 915/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4872 - mse: 0.4796 - val_loss: 0.4177 - val_mse: 0.4101\n",
      "Epoch 916/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4811 - val_loss: 0.4221 - val_mse: 0.4145\n",
      "Epoch 917/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4760 - val_loss: 0.4195 - val_mse: 0.4119\n",
      "Epoch 918/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4798 - val_loss: 0.4227 - val_mse: 0.4150\n",
      "Epoch 919/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4849 - mse: 0.4773 - val_loss: 0.4176 - val_mse: 0.4100\n",
      "Epoch 920/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.4867 - mse: 0.4790\n",
      "Epoch 00920: saving model to Regression_Model/mle.linear-0920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4790 - val_loss: 0.4284 - val_mse: 0.4208\n",
      "Epoch 921/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4836 - val_loss: 0.4210 - val_mse: 0.4134\n",
      "Epoch 922/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4898 - mse: 0.4822 - val_loss: 0.4180 - val_mse: 0.4104\n",
      "Epoch 923/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4897 - mse: 0.4821 - val_loss: 0.4260 - val_mse: 0.4184\n",
      "Epoch 924/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4816 - val_loss: 0.4256 - val_mse: 0.4180\n",
      "Epoch 925/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4879 - mse: 0.4803 - val_loss: 0.4187 - val_mse: 0.4111\n",
      "Epoch 926/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4818 - val_loss: 0.4099 - val_mse: 0.4023\n",
      "Epoch 927/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4755 - val_loss: 0.4173 - val_mse: 0.4097\n",
      "Epoch 928/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4759 - val_loss: 0.4170 - val_mse: 0.4094\n",
      "Epoch 929/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4758 - val_loss: 0.4170 - val_mse: 0.4094\n",
      "Epoch 930/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4821 - mse: 0.4745\n",
      "Epoch 00930: saving model to Regression_Model/mle.linear-0930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4786 - val_loss: 0.4224 - val_mse: 0.4148\n",
      "Epoch 931/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4759 - val_loss: 0.4172 - val_mse: 0.4096\n",
      "Epoch 932/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4870 - mse: 0.4794 - val_loss: 0.4191 - val_mse: 0.4115\n",
      "Epoch 933/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4786 - val_loss: 0.4256 - val_mse: 0.4180\n",
      "Epoch 934/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4964 - mse: 0.4888 - val_loss: 0.4241 - val_mse: 0.4165\n",
      "Epoch 935/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4890 - mse: 0.4814 - val_loss: 0.4160 - val_mse: 0.4084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4778 - val_loss: 0.4234 - val_mse: 0.4158\n",
      "Epoch 937/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4952 - mse: 0.4876 - val_loss: 0.4196 - val_mse: 0.4120\n",
      "Epoch 938/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4786 - val_loss: 0.4315 - val_mse: 0.4239\n",
      "Epoch 939/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4883 - mse: 0.4807 - val_loss: 0.4261 - val_mse: 0.4185\n",
      "Epoch 940/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4924 - mse: 0.4848\n",
      "Epoch 00940: saving model to Regression_Model/mle.linear-0940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4925 - mse: 0.4848 - val_loss: 0.4221 - val_mse: 0.4145\n",
      "Epoch 941/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4790 - val_loss: 0.4202 - val_mse: 0.4126\n",
      "Epoch 942/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4881 - mse: 0.4804 - val_loss: 0.4200 - val_mse: 0.4124\n",
      "Epoch 943/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4893 - mse: 0.4816 - val_loss: 0.4309 - val_mse: 0.4232\n",
      "Epoch 944/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4979 - mse: 0.4902 - val_loss: 0.4266 - val_mse: 0.4190\n",
      "Epoch 945/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4864 - mse: 0.4788 - val_loss: 0.4232 - val_mse: 0.4156\n",
      "Epoch 946/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4922 - mse: 0.4846 - val_loss: 0.4226 - val_mse: 0.4149\n",
      "Epoch 947/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4789 - val_loss: 0.4145 - val_mse: 0.4069\n",
      "Epoch 948/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4831 - val_loss: 0.4275 - val_mse: 0.4199\n",
      "Epoch 949/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4769 - val_loss: 0.4215 - val_mse: 0.4138\n",
      "Epoch 950/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4839 - mse: 0.4763\n",
      "Epoch 00950: saving model to Regression_Model/mle.linear-0950.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4773 - val_loss: 0.4154 - val_mse: 0.4078\n",
      "Epoch 951/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4904 - mse: 0.4827 - val_loss: 0.4165 - val_mse: 0.4089\n",
      "Epoch 952/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4789 - val_loss: 0.4199 - val_mse: 0.4123\n",
      "Epoch 953/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4699 - val_loss: 0.4182 - val_mse: 0.4106\n",
      "Epoch 954/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4741 - val_loss: 0.4198 - val_mse: 0.4122\n",
      "Epoch 955/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4777 - val_loss: 0.4269 - val_mse: 0.4193\n",
      "Epoch 956/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4897 - mse: 0.4821 - val_loss: 0.4178 - val_mse: 0.4102\n",
      "Epoch 957/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4812 - val_loss: 0.4188 - val_mse: 0.4112\n",
      "Epoch 958/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4922 - mse: 0.4846 - val_loss: 0.4190 - val_mse: 0.4114\n",
      "Epoch 959/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4795 - val_loss: 0.4109 - val_mse: 0.4032\n",
      "Epoch 960/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4854 - mse: 0.4778\n",
      "Epoch 00960: saving model to Regression_Model/mle.linear-0960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4777 - val_loss: 0.4213 - val_mse: 0.4137\n",
      "Epoch 961/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4897 - mse: 0.4821 - val_loss: 0.4142 - val_mse: 0.4066\n",
      "Epoch 962/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4775 - val_loss: 0.4197 - val_mse: 0.4121\n",
      "Epoch 963/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4801 - val_loss: 0.4208 - val_mse: 0.4132\n",
      "Epoch 964/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4763 - val_loss: 0.4230 - val_mse: 0.4154\n",
      "Epoch 965/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4934 - mse: 0.4857 - val_loss: 0.4240 - val_mse: 0.4164\n",
      "Epoch 966/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4801 - val_loss: 0.4175 - val_mse: 0.4099\n",
      "Epoch 967/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4728 - val_loss: 0.4137 - val_mse: 0.4061\n",
      "Epoch 968/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4924 - mse: 0.4848 - val_loss: 0.4147 - val_mse: 0.4071\n",
      "Epoch 969/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4795 - val_loss: 0.4197 - val_mse: 0.4121\n",
      "Epoch 970/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4883 - mse: 0.4807\n",
      "Epoch 00970: saving model to Regression_Model/mle.linear-0970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4780 - val_loss: 0.4128 - val_mse: 0.4052\n",
      "Epoch 971/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4812 - val_loss: 0.4184 - val_mse: 0.4108\n",
      "Epoch 972/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4886 - mse: 0.4810 - val_loss: 0.4372 - val_mse: 0.4296\n",
      "Epoch 973/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4856 - val_loss: 0.4186 - val_mse: 0.4109\n",
      "Epoch 974/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4788 - val_loss: 0.4186 - val_mse: 0.4109\n",
      "Epoch 975/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4898 - mse: 0.4822 - val_loss: 0.4287 - val_mse: 0.4211\n",
      "Epoch 976/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4945 - mse: 0.4869 - val_loss: 0.4241 - val_mse: 0.4165\n",
      "Epoch 977/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4730 - val_loss: 0.4174 - val_mse: 0.4097\n",
      "Epoch 978/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4816 - val_loss: 0.4138 - val_mse: 0.4061\n",
      "Epoch 979/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4802 - val_loss: 0.4354 - val_mse: 0.4278\n",
      "Epoch 980/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4945 - mse: 0.4868\n",
      "Epoch 00980: saving model to Regression_Model/mle.linear-0980.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4862 - val_loss: 0.4207 - val_mse: 0.4130\n",
      "Epoch 981/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4733 - val_loss: 0.4162 - val_mse: 0.4085\n",
      "Epoch 982/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4759 - val_loss: 0.4255 - val_mse: 0.4179\n",
      "Epoch 983/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4795 - val_loss: 0.4162 - val_mse: 0.4085\n",
      "Epoch 984/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4802 - val_loss: 0.4205 - val_mse: 0.4129\n",
      "Epoch 985/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4825 - val_loss: 0.4116 - val_mse: 0.4040\n",
      "Epoch 986/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4756 - val_loss: 0.4175 - val_mse: 0.4098\n",
      "Epoch 987/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4878 - mse: 0.4802 - val_loss: 0.4156 - val_mse: 0.4080\n",
      "Epoch 988/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4894 - mse: 0.4818 - val_loss: 0.4185 - val_mse: 0.4108\n",
      "Epoch 989/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4806 - val_loss: 0.4144 - val_mse: 0.4068\n",
      "Epoch 990/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4876 - mse: 0.4800\n",
      "Epoch 00990: saving model to Regression_Model/mle.linear-0990.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 7ms/step - loss: 0.4892 - mse: 0.4816 - val_loss: 0.4178 - val_mse: 0.4101\n",
      "Epoch 991/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4761 - val_loss: 0.4249 - val_mse: 0.4173\n",
      "Epoch 992/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4820 - val_loss: 0.4205 - val_mse: 0.4129\n",
      "Epoch 993/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4924 - mse: 0.4848 - val_loss: 0.4193 - val_mse: 0.4117\n",
      "Epoch 994/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4766 - val_loss: 0.4152 - val_mse: 0.4075\n",
      "Epoch 995/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4819 - val_loss: 0.4153 - val_mse: 0.4077\n",
      "Epoch 996/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4753 - val_loss: 0.4113 - val_mse: 0.4037\n",
      "Epoch 997/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4751 - val_loss: 0.4156 - val_mse: 0.4080\n",
      "Epoch 998/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4786 - val_loss: 0.4165 - val_mse: 0.4089\n",
      "Epoch 999/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4746 - val_loss: 0.4281 - val_mse: 0.4205\n",
      "Epoch 1000/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4821 - mse: 0.4745\n",
      "Epoch 01000: saving model to Regression_Model/mle.linear-1000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4762 - val_loss: 0.4168 - val_mse: 0.4092\n",
      "Epoch 1001/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4857 - val_loss: 0.4179 - val_mse: 0.4103\n",
      "Epoch 1002/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4794 - val_loss: 0.4181 - val_mse: 0.4105\n",
      "Epoch 1003/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4773 - val_loss: 0.4189 - val_mse: 0.4112\n",
      "Epoch 1004/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4762 - val_loss: 0.4203 - val_mse: 0.4127\n",
      "Epoch 1005/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4798 - val_loss: 0.4146 - val_mse: 0.4070\n",
      "Epoch 1006/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4836 - val_loss: 0.4184 - val_mse: 0.4108\n",
      "Epoch 1007/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4876 - mse: 0.4800 - val_loss: 0.4144 - val_mse: 0.4068\n",
      "Epoch 1008/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4799 - val_loss: 0.4168 - val_mse: 0.4092\n",
      "Epoch 1009/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4766 - val_loss: 0.4102 - val_mse: 0.4026\n",
      "Epoch 1010/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4908 - mse: 0.4832\n",
      "Epoch 01010: saving model to Regression_Model/mle.linear-1010.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4897 - mse: 0.4821 - val_loss: 0.4159 - val_mse: 0.4083\n",
      "Epoch 1011/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4774 - val_loss: 0.4178 - val_mse: 0.4102\n",
      "Epoch 1012/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4799 - val_loss: 0.4125 - val_mse: 0.4048\n",
      "Epoch 1013/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4867 - val_loss: 0.4212 - val_mse: 0.4136\n",
      "Epoch 1014/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4945 - mse: 0.4869 - val_loss: 0.4156 - val_mse: 0.4079\n",
      "Epoch 1015/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4758 - val_loss: 0.4139 - val_mse: 0.4063\n",
      "Epoch 1016/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4729 - val_loss: 0.4125 - val_mse: 0.4049\n",
      "Epoch 1017/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4786 - val_loss: 0.4217 - val_mse: 0.4141\n",
      "Epoch 1018/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4836 - val_loss: 0.4176 - val_mse: 0.4099\n",
      "Epoch 1019/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4872 - mse: 0.4796 - val_loss: 0.4194 - val_mse: 0.4118\n",
      "Epoch 1020/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4890 - mse: 0.4814\n",
      "Epoch 01020: saving model to Regression_Model/mle.linear-1020.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4900 - mse: 0.4824 - val_loss: 0.4219 - val_mse: 0.4143\n",
      "Epoch 1021/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4911 - mse: 0.4835 - val_loss: 0.4155 - val_mse: 0.4079\n",
      "Epoch 1022/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4799 - val_loss: 0.4235 - val_mse: 0.4159\n",
      "Epoch 1023/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4797 - val_loss: 0.4154 - val_mse: 0.4078\n",
      "Epoch 1024/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4924 - mse: 0.4848 - val_loss: 0.4186 - val_mse: 0.4110\n",
      "Epoch 1025/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4773 - val_loss: 0.4117 - val_mse: 0.4040\n",
      "Epoch 1026/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4797 - val_loss: 0.4134 - val_mse: 0.4057\n",
      "Epoch 1027/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4820 - val_loss: 0.4280 - val_mse: 0.4204\n",
      "Epoch 1028/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4887 - mse: 0.4811 - val_loss: 0.4201 - val_mse: 0.4125\n",
      "Epoch 1029/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4801 - val_loss: 0.4120 - val_mse: 0.4044\n",
      "Epoch 1030/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4906 - mse: 0.4830\n",
      "Epoch 01030: saving model to Regression_Model/mle.linear-1030.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4893 - mse: 0.4817 - val_loss: 0.4170 - val_mse: 0.4094\n",
      "Epoch 1031/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4777 - val_loss: 0.4211 - val_mse: 0.4135\n",
      "Epoch 1032/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4808 - val_loss: 0.4125 - val_mse: 0.4049\n",
      "Epoch 1033/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4743 - val_loss: 0.4134 - val_mse: 0.4058\n",
      "Epoch 1034/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4699 - val_loss: 0.4142 - val_mse: 0.4065\n",
      "Epoch 1035/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4840 - mse: 0.4764 - val_loss: 0.4167 - val_mse: 0.4091\n",
      "Epoch 1036/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4765 - val_loss: 0.4145 - val_mse: 0.4069\n",
      "Epoch 1037/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4782 - val_loss: 0.4161 - val_mse: 0.4085\n",
      "Epoch 1038/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4792 - val_loss: 0.4154 - val_mse: 0.4077\n",
      "Epoch 1039/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4786 - val_loss: 0.4166 - val_mse: 0.4090\n",
      "Epoch 1040/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4846 - mse: 0.4770\n",
      "Epoch 01040: saving model to Regression_Model/mle.linear-1040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4778 - val_loss: 0.4172 - val_mse: 0.4096\n",
      "Epoch 1041/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4920 - mse: 0.4844 - val_loss: 0.4203 - val_mse: 0.4127\n",
      "Epoch 1042/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4818 - val_loss: 0.4133 - val_mse: 0.4057\n",
      "Epoch 1043/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4707 - val_loss: 0.4152 - val_mse: 0.4076\n",
      "Epoch 1044/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4746 - val_loss: 0.4271 - val_mse: 0.4195\n",
      "Epoch 1045/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4823 - val_loss: 0.4145 - val_mse: 0.4068\n",
      "Epoch 1046/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4749 - val_loss: 0.4195 - val_mse: 0.4119\n",
      "Epoch 1047/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4915 - mse: 0.4839 - val_loss: 0.4146 - val_mse: 0.4070\n",
      "Epoch 1048/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4771 - val_loss: 0.4150 - val_mse: 0.4074\n",
      "Epoch 1049/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4945 - mse: 0.4869 - val_loss: 0.4197 - val_mse: 0.4121\n",
      "Epoch 1050/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4868 - mse: 0.4792\n",
      "Epoch 01050: saving model to Regression_Model/mle.linear-1050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4830 - val_loss: 0.4181 - val_mse: 0.4104\n",
      "Epoch 1051/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4841 - val_loss: 0.4176 - val_mse: 0.4100\n",
      "Epoch 1052/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4765 - val_loss: 0.4134 - val_mse: 0.4058\n",
      "Epoch 1053/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4795 - val_loss: 0.4102 - val_mse: 0.4026\n",
      "Epoch 1054/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4795 - val_loss: 0.4212 - val_mse: 0.4136\n",
      "Epoch 1055/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4742 - val_loss: 0.4200 - val_mse: 0.4123\n",
      "Epoch 1056/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4806 - val_loss: 0.4180 - val_mse: 0.4104\n",
      "Epoch 1057/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4760 - val_loss: 0.4102 - val_mse: 0.4026\n",
      "Epoch 1058/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4771 - val_loss: 0.4161 - val_mse: 0.4085\n",
      "Epoch 1059/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4815 - val_loss: 0.4167 - val_mse: 0.4091\n",
      "Epoch 1060/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4825 - mse: 0.4748\n",
      "Epoch 01060: saving model to Regression_Model/mle.linear-1060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4769 - val_loss: 0.4157 - val_mse: 0.4081\n",
      "Epoch 1061/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4802 - val_loss: 0.4170 - val_mse: 0.4094\n",
      "Epoch 1062/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4756 - val_loss: 0.4143 - val_mse: 0.4067\n",
      "Epoch 1063/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4811 - val_loss: 0.4156 - val_mse: 0.4080\n",
      "Epoch 1064/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4879 - mse: 0.4803 - val_loss: 0.4226 - val_mse: 0.4150\n",
      "Epoch 1065/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4861 - mse: 0.4785 - val_loss: 0.4168 - val_mse: 0.4092\n",
      "Epoch 1066/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4788 - val_loss: 0.4129 - val_mse: 0.4053\n",
      "Epoch 1067/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4795 - val_loss: 0.4126 - val_mse: 0.4050\n",
      "Epoch 1068/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4857 - val_loss: 0.4099 - val_mse: 0.4023\n",
      "Epoch 1069/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4715 - val_loss: 0.4163 - val_mse: 0.4087\n",
      "Epoch 1070/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4872 - mse: 0.4795\n",
      "Epoch 01070: saving model to Regression_Model/mle.linear-1070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4860 - mse: 0.4784 - val_loss: 0.4171 - val_mse: 0.4095\n",
      "Epoch 1071/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4775 - val_loss: 0.4178 - val_mse: 0.4101\n",
      "Epoch 1072/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4860 - mse: 0.4784 - val_loss: 0.4189 - val_mse: 0.4112\n",
      "Epoch 1073/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4848 - mse: 0.4772 - val_loss: 0.4162 - val_mse: 0.4086\n",
      "Epoch 1074/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4780 - val_loss: 0.4218 - val_mse: 0.4142\n",
      "Epoch 1075/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4823 - val_loss: 0.4129 - val_mse: 0.4053\n",
      "Epoch 1076/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4721 - val_loss: 0.4159 - val_mse: 0.4083\n",
      "Epoch 1077/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4870 - mse: 0.4794 - val_loss: 0.4177 - val_mse: 0.4100\n",
      "Epoch 1078/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4885 - mse: 0.4809 - val_loss: 0.4133 - val_mse: 0.4057\n",
      "Epoch 1079/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4824 - mse: 0.4748 - val_loss: 0.4197 - val_mse: 0.4121\n",
      "Epoch 1080/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4847 - mse: 0.4771\n",
      "Epoch 01080: saving model to Regression_Model/mle.linear-1080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4757 - val_loss: 0.4190 - val_mse: 0.4113\n",
      "Epoch 1081/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4799 - val_loss: 0.4079 - val_mse: 0.4003\n",
      "Epoch 1082/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4905 - mse: 0.4828 - val_loss: 0.4191 - val_mse: 0.4115\n",
      "Epoch 1083/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4775 - val_loss: 0.4124 - val_mse: 0.4047\n",
      "Epoch 1084/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4815 - val_loss: 0.4154 - val_mse: 0.4078\n",
      "Epoch 1085/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4909 - mse: 0.4833 - val_loss: 0.4165 - val_mse: 0.4089\n",
      "Epoch 1086/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4798 - val_loss: 0.4129 - val_mse: 0.4053\n",
      "Epoch 1087/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4911 - mse: 0.4835 - val_loss: 0.4190 - val_mse: 0.4114\n",
      "Epoch 1088/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4848 - mse: 0.4772 - val_loss: 0.4165 - val_mse: 0.4089\n",
      "Epoch 1089/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4805 - val_loss: 0.4161 - val_mse: 0.4085\n",
      "Epoch 1090/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4830 - mse: 0.4754\n",
      "Epoch 01090: saving model to Regression_Model/mle.linear-1090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4751 - val_loss: 0.4154 - val_mse: 0.4078\n",
      "Epoch 1091/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4777 - val_loss: 0.4144 - val_mse: 0.4068\n",
      "Epoch 1092/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4759 - val_loss: 0.4159 - val_mse: 0.4083\n",
      "Epoch 1093/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4749 - val_loss: 0.4152 - val_mse: 0.4075\n",
      "Epoch 1094/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4870 - mse: 0.4794 - val_loss: 0.4116 - val_mse: 0.4040\n",
      "Epoch 1095/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4777 - val_loss: 0.4219 - val_mse: 0.4143\n",
      "Epoch 1096/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4778 - val_loss: 0.4169 - val_mse: 0.4093\n",
      "Epoch 1097/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4913 - mse: 0.4837 - val_loss: 0.4129 - val_mse: 0.4053\n",
      "Epoch 1098/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4777 - val_loss: 0.4214 - val_mse: 0.4138\n",
      "Epoch 1099/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4797 - val_loss: 0.4149 - val_mse: 0.4073\n",
      "Epoch 1100/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4842 - mse: 0.4766\n",
      "Epoch 01100: saving model to Regression_Model/mle.linear-1100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4754 - val_loss: 0.4159 - val_mse: 0.4083\n",
      "Epoch 1101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4815 - val_loss: 0.4136 - val_mse: 0.4060\n",
      "Epoch 1102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4774 - val_loss: 0.4143 - val_mse: 0.4067\n",
      "Epoch 1103/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4737 - val_loss: 0.4160 - val_mse: 0.4084\n",
      "Epoch 1104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4754 - val_loss: 0.4172 - val_mse: 0.4096\n",
      "Epoch 1105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4886 - mse: 0.4810 - val_loss: 0.4172 - val_mse: 0.4096\n",
      "Epoch 1106/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4789 - val_loss: 0.4129 - val_mse: 0.4053\n",
      "Epoch 1107/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4722 - val_loss: 0.4188 - val_mse: 0.4112\n",
      "Epoch 1108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4881 - mse: 0.4805 - val_loss: 0.4176 - val_mse: 0.4100\n",
      "Epoch 1109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4913 - mse: 0.4837 - val_loss: 0.4107 - val_mse: 0.4031\n",
      "Epoch 1110/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4872 - mse: 0.4796\n",
      "Epoch 01110: saving model to Regression_Model/mle.linear-1110.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4845 - mse: 0.4769 - val_loss: 0.4231 - val_mse: 0.4155\n",
      "Epoch 1111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4885 - mse: 0.4809 - val_loss: 0.4140 - val_mse: 0.4064\n",
      "Epoch 1112/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4878 - mse: 0.4802 - val_loss: 0.4182 - val_mse: 0.4106\n",
      "Epoch 1113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4749 - val_loss: 0.4178 - val_mse: 0.4102\n",
      "Epoch 1114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4752 - val_loss: 0.4116 - val_mse: 0.4040\n",
      "Epoch 1115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4765 - val_loss: 0.4127 - val_mse: 0.4051\n",
      "Epoch 1116/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4803 - mse: 0.4727 - val_loss: 0.4121 - val_mse: 0.4045\n",
      "Epoch 1117/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4817 - mse: 0.4741 - val_loss: 0.4104 - val_mse: 0.4028\n",
      "Epoch 1118/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4906 - mse: 0.4830 - val_loss: 0.4133 - val_mse: 0.4057\n",
      "Epoch 1119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4780 - val_loss: 0.4084 - val_mse: 0.4008\n",
      "Epoch 1120/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.4922 - mse: 0.4846\n",
      "Epoch 01120: saving model to Regression_Model/mle.linear-1120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4806 - val_loss: 0.4247 - val_mse: 0.4171\n",
      "Epoch 1121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4761 - val_loss: 0.4161 - val_mse: 0.4084\n",
      "Epoch 1122/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4780 - val_loss: 0.4173 - val_mse: 0.4097\n",
      "Epoch 1123/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4759 - val_loss: 0.4156 - val_mse: 0.4080\n",
      "Epoch 1124/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4767 - val_loss: 0.4090 - val_mse: 0.4014\n",
      "Epoch 1125/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4867 - mse: 0.4791 - val_loss: 0.4137 - val_mse: 0.4061\n",
      "Epoch 1126/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4765 - val_loss: 0.4110 - val_mse: 0.4034\n",
      "Epoch 1127/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4812 - mse: 0.4736 - val_loss: 0.4163 - val_mse: 0.4087\n",
      "Epoch 1128/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4781 - val_loss: 0.4154 - val_mse: 0.4078\n",
      "Epoch 1129/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4819 - val_loss: 0.4156 - val_mse: 0.4080\n",
      "Epoch 1130/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4792 - mse: 0.4716\n",
      "Epoch 01130: saving model to Regression_Model/mle.linear-1130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4707 - val_loss: 0.4118 - val_mse: 0.4042\n",
      "Epoch 1131/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4790 - val_loss: 0.4114 - val_mse: 0.4038\n",
      "Epoch 1132/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4761 - val_loss: 0.4095 - val_mse: 0.4019\n",
      "Epoch 1133/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4735 - val_loss: 0.4180 - val_mse: 0.4104\n",
      "Epoch 1134/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4733 - val_loss: 0.4123 - val_mse: 0.4047\n",
      "Epoch 1135/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4901 - mse: 0.4825 - val_loss: 0.4137 - val_mse: 0.4061\n",
      "Epoch 1136/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4727 - val_loss: 0.4120 - val_mse: 0.4044\n",
      "Epoch 1137/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4883 - mse: 0.4807 - val_loss: 0.4145 - val_mse: 0.4069\n",
      "Epoch 1138/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4798 - val_loss: 0.4150 - val_mse: 0.4074\n",
      "Epoch 1139/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4774 - val_loss: 0.4124 - val_mse: 0.4048\n",
      "Epoch 1140/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4711 - mse: 0.4635\n",
      "Epoch 01140: saving model to Regression_Model/mle.linear-1140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4725 - mse: 0.4649 - val_loss: 0.4183 - val_mse: 0.4107\n",
      "Epoch 1141/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4702 - val_loss: 0.4155 - val_mse: 0.4079\n",
      "Epoch 1142/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4763 - val_loss: 0.4104 - val_mse: 0.4027\n",
      "Epoch 1143/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4798 - val_loss: 0.4174 - val_mse: 0.4098\n",
      "Epoch 1144/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4914 - mse: 0.4838 - val_loss: 0.4154 - val_mse: 0.4078\n",
      "Epoch 1145/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4771 - val_loss: 0.4225 - val_mse: 0.4149\n",
      "Epoch 1146/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4735 - val_loss: 0.4107 - val_mse: 0.4031\n",
      "Epoch 1147/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4775 - val_loss: 0.4156 - val_mse: 0.4080\n",
      "Epoch 1148/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4805 - mse: 0.4729 - val_loss: 0.4138 - val_mse: 0.4062\n",
      "Epoch 1149/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4897 - mse: 0.4821 - val_loss: 0.4230 - val_mse: 0.4154\n",
      "Epoch 1150/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4836 - mse: 0.4760\n",
      "Epoch 01150: saving model to Regression_Model/mle.linear-1150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4761 - val_loss: 0.4154 - val_mse: 0.4078\n",
      "Epoch 1151/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4737 - val_loss: 0.4152 - val_mse: 0.4076\n",
      "Epoch 1152/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4763 - val_loss: 0.4180 - val_mse: 0.4104\n",
      "Epoch 1153/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4748 - val_loss: 0.4274 - val_mse: 0.4198\n",
      "Epoch 1154/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4781 - val_loss: 0.4135 - val_mse: 0.4059\n",
      "Epoch 1155/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4765 - val_loss: 0.4136 - val_mse: 0.4060\n",
      "Epoch 1156/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4771 - val_loss: 0.4136 - val_mse: 0.4060\n",
      "Epoch 1157/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4839 - mse: 0.4763 - val_loss: 0.4157 - val_mse: 0.4081\n",
      "Epoch 1158/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4799 - val_loss: 0.4127 - val_mse: 0.4051\n",
      "Epoch 1159/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4869 - mse: 0.4793 - val_loss: 0.4151 - val_mse: 0.4075\n",
      "Epoch 1160/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4798 - mse: 0.4722\n",
      "Epoch 01160: saving model to Regression_Model/mle.linear-1160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4721 - val_loss: 0.4198 - val_mse: 0.4122\n",
      "Epoch 1161/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4869 - mse: 0.4793 - val_loss: 0.4128 - val_mse: 0.4052\n",
      "Epoch 1162/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4951 - mse: 0.4875 - val_loss: 0.4154 - val_mse: 0.4078\n",
      "Epoch 1163/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4839 - mse: 0.4763 - val_loss: 0.4118 - val_mse: 0.4042\n",
      "Epoch 1164/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4744 - val_loss: 0.4108 - val_mse: 0.4032\n",
      "Epoch 1165/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4721 - val_loss: 0.4078 - val_mse: 0.4002\n",
      "Epoch 1166/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4761 - mse: 0.4686 - val_loss: 0.4137 - val_mse: 0.4061\n",
      "Epoch 1167/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4718 - val_loss: 0.4121 - val_mse: 0.4045\n",
      "Epoch 1168/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4780 - val_loss: 0.4102 - val_mse: 0.4026\n",
      "Epoch 1169/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4767 - mse: 0.4691 - val_loss: 0.4134 - val_mse: 0.4058\n",
      "Epoch 1170/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4883 - mse: 0.4807\n",
      "Epoch 01170: saving model to Regression_Model/mle.linear-1170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4813 - val_loss: 0.4157 - val_mse: 0.4082\n",
      "Epoch 1171/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4789 - mse: 0.4713 - val_loss: 0.4131 - val_mse: 0.4055\n",
      "Epoch 1172/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4773 - val_loss: 0.4154 - val_mse: 0.4078\n",
      "Epoch 1173/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4752 - mse: 0.4676 - val_loss: 0.4132 - val_mse: 0.4056\n",
      "Epoch 1174/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4931 - mse: 0.4855 - val_loss: 0.4131 - val_mse: 0.4055\n",
      "Epoch 1175/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4729 - val_loss: 0.4183 - val_mse: 0.4107\n",
      "Epoch 1176/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4818 - val_loss: 0.4147 - val_mse: 0.4072\n",
      "Epoch 1177/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4798 - val_loss: 0.4144 - val_mse: 0.4069\n",
      "Epoch 1178/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4737 - val_loss: 0.4124 - val_mse: 0.4048\n",
      "Epoch 1179/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4731 - val_loss: 0.4115 - val_mse: 0.4039\n",
      "Epoch 1180/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4792 - mse: 0.4716\n",
      "Epoch 01180: saving model to Regression_Model/mle.linear-1180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4709 - val_loss: 0.4092 - val_mse: 0.4016\n",
      "Epoch 1181/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4763 - val_loss: 0.4153 - val_mse: 0.4078\n",
      "Epoch 1182/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4811 - val_loss: 0.4208 - val_mse: 0.4132\n",
      "Epoch 1183/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4753 - val_loss: 0.4126 - val_mse: 0.4050\n",
      "Epoch 1184/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4766 - val_loss: 0.4140 - val_mse: 0.4064\n",
      "Epoch 1185/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4795 - val_loss: 0.4106 - val_mse: 0.4030\n",
      "Epoch 1186/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4791 - val_loss: 0.4165 - val_mse: 0.4089\n",
      "Epoch 1187/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4859 - mse: 0.4784 - val_loss: 0.4110 - val_mse: 0.4034\n",
      "Epoch 1188/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4765 - val_loss: 0.4121 - val_mse: 0.4045\n",
      "Epoch 1189/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4808 - mse: 0.4733 - val_loss: 0.4119 - val_mse: 0.4043\n",
      "Epoch 1190/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.4784 - mse: 0.4708\n",
      "Epoch 01190: saving model to Regression_Model/mle.linear-1190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4721 - val_loss: 0.4119 - val_mse: 0.4044\n",
      "Epoch 1191/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4777 - val_loss: 0.4117 - val_mse: 0.4041\n",
      "Epoch 1192/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4861 - mse: 0.4785 - val_loss: 0.4090 - val_mse: 0.4014\n",
      "Epoch 1193/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4743 - val_loss: 0.4149 - val_mse: 0.4074\n",
      "Epoch 1194/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4767 - val_loss: 0.4114 - val_mse: 0.4039\n",
      "Epoch 1195/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4790 - val_loss: 0.4153 - val_mse: 0.4077\n",
      "Epoch 1196/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4801 - val_loss: 0.4169 - val_mse: 0.4094\n",
      "Epoch 1197/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4743 - val_loss: 0.4120 - val_mse: 0.4044\n",
      "Epoch 1198/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4745 - val_loss: 0.4109 - val_mse: 0.4033\n",
      "Epoch 1199/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4813 - val_loss: 0.4129 - val_mse: 0.4053\n",
      "Epoch 1200/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4817 - mse: 0.4741\n",
      "Epoch 01200: saving model to Regression_Model/mle.linear-1200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4751 - val_loss: 0.4128 - val_mse: 0.4053\n",
      "Epoch 1201/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4749 - val_loss: 0.4113 - val_mse: 0.4037\n",
      "Epoch 1202/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4799 - val_loss: 0.4124 - val_mse: 0.4048\n",
      "Epoch 1203/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4855 - mse: 0.4779 - val_loss: 0.4116 - val_mse: 0.4040\n",
      "Epoch 1204/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4748 - val_loss: 0.4132 - val_mse: 0.4056\n",
      "Epoch 1205/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4781 - val_loss: 0.4106 - val_mse: 0.4030\n",
      "Epoch 1206/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4789 - mse: 0.4713 - val_loss: 0.4142 - val_mse: 0.4066\n",
      "Epoch 1207/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4788 - val_loss: 0.4131 - val_mse: 0.4055\n",
      "Epoch 1208/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4745 - val_loss: 0.4127 - val_mse: 0.4051\n",
      "Epoch 1209/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4818 - val_loss: 0.4198 - val_mse: 0.4123\n",
      "Epoch 1210/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4824 - mse: 0.4748\n",
      "Epoch 01210: saving model to Regression_Model/mle.linear-1210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4745 - val_loss: 0.4095 - val_mse: 0.4020\n",
      "Epoch 1211/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4730 - val_loss: 0.4094 - val_mse: 0.4019\n",
      "Epoch 1212/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4844 - mse: 0.4768 - val_loss: 0.4118 - val_mse: 0.4042\n",
      "Epoch 1213/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4734 - val_loss: 0.4118 - val_mse: 0.4042\n",
      "Epoch 1214/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4691 - val_loss: 0.4090 - val_mse: 0.4014\n",
      "Epoch 1215/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4754 - val_loss: 0.4192 - val_mse: 0.4116\n",
      "Epoch 1216/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4747 - val_loss: 0.4130 - val_mse: 0.4054\n",
      "Epoch 1217/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4708 - val_loss: 0.4079 - val_mse: 0.4003\n",
      "Epoch 1218/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4760 - val_loss: 0.4142 - val_mse: 0.4066\n",
      "Epoch 1219/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4801 - val_loss: 0.4178 - val_mse: 0.4102\n",
      "Epoch 1220/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4826 - mse: 0.4750\n",
      "Epoch 01220: saving model to Regression_Model/mle.linear-1220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4758 - val_loss: 0.4129 - val_mse: 0.4053\n",
      "Epoch 1221/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4905 - mse: 0.4829 - val_loss: 0.4121 - val_mse: 0.4046\n",
      "Epoch 1222/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4744 - val_loss: 0.4131 - val_mse: 0.4055\n",
      "Epoch 1223/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4720 - val_loss: 0.4143 - val_mse: 0.4067\n",
      "Epoch 1224/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4757 - val_loss: 0.4208 - val_mse: 0.4133\n",
      "Epoch 1225/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4753 - val_loss: 0.4145 - val_mse: 0.4070\n",
      "Epoch 1226/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4757 - val_loss: 0.4169 - val_mse: 0.4093\n",
      "Epoch 1227/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4856 - val_loss: 0.4177 - val_mse: 0.4102\n",
      "Epoch 1228/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4793 - mse: 0.4718 - val_loss: 0.4075 - val_mse: 0.3999\n",
      "Epoch 1229/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4766 - val_loss: 0.4138 - val_mse: 0.4062\n",
      "Epoch 1230/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4918 - mse: 0.4842\n",
      "Epoch 01230: saving model to Regression_Model/mle.linear-1230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4927 - mse: 0.4851 - val_loss: 0.4134 - val_mse: 0.4058\n",
      "Epoch 1231/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4726 - val_loss: 0.4093 - val_mse: 0.4017\n",
      "Epoch 1232/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4719 - val_loss: 0.4119 - val_mse: 0.4043\n",
      "Epoch 1233/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4761 - val_loss: 0.4185 - val_mse: 0.4110\n",
      "Epoch 1234/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4855 - mse: 0.4779 - val_loss: 0.4101 - val_mse: 0.4026\n",
      "Epoch 1235/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4777 - mse: 0.4701 - val_loss: 0.4068 - val_mse: 0.3992\n",
      "Epoch 1236/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4735 - val_loss: 0.4124 - val_mse: 0.4048\n",
      "Epoch 1237/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4887 - mse: 0.4811 - val_loss: 0.4192 - val_mse: 0.4116\n",
      "Epoch 1238/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4763 - val_loss: 0.4121 - val_mse: 0.4046\n",
      "Epoch 1239/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4817 - mse: 0.4741 - val_loss: 0.4120 - val_mse: 0.4044\n",
      "Epoch 1240/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4754 - mse: 0.4679\n",
      "Epoch 01240: saving model to Regression_Model/mle.linear-1240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4679 - val_loss: 0.4068 - val_mse: 0.3992\n",
      "Epoch 1241/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4855 - mse: 0.4779 - val_loss: 0.4125 - val_mse: 0.4049\n",
      "Epoch 1242/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4719 - val_loss: 0.4122 - val_mse: 0.4046\n",
      "Epoch 1243/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4754 - val_loss: 0.4130 - val_mse: 0.4055\n",
      "Epoch 1244/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4729 - val_loss: 0.4081 - val_mse: 0.4005\n",
      "Epoch 1245/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4756 - val_loss: 0.4148 - val_mse: 0.4073\n",
      "Epoch 1246/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4717 - val_loss: 0.4137 - val_mse: 0.4061\n",
      "Epoch 1247/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4808 - val_loss: 0.4131 - val_mse: 0.4055\n",
      "Epoch 1248/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4767 - val_loss: 0.4139 - val_mse: 0.4063\n",
      "Epoch 1249/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4737 - val_loss: 0.4098 - val_mse: 0.4023\n",
      "Epoch 1250/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4808 - mse: 0.4732\n",
      "Epoch 01250: saving model to Regression_Model/mle.linear-1250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4801 - mse: 0.4726 - val_loss: 0.4077 - val_mse: 0.4001\n",
      "Epoch 1251/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4722 - val_loss: 0.4152 - val_mse: 0.4077\n",
      "Epoch 1252/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4708 - val_loss: 0.4115 - val_mse: 0.4040\n",
      "Epoch 1253/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4781 - val_loss: 0.4130 - val_mse: 0.4055\n",
      "Epoch 1254/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4803 - mse: 0.4728 - val_loss: 0.4086 - val_mse: 0.4011\n",
      "Epoch 1255/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4738 - val_loss: 0.4159 - val_mse: 0.4084\n",
      "Epoch 1256/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4708 - val_loss: 0.4163 - val_mse: 0.4087\n",
      "Epoch 1257/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4740 - val_loss: 0.4109 - val_mse: 0.4034\n",
      "Epoch 1258/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4694 - val_loss: 0.4074 - val_mse: 0.3998\n",
      "Epoch 1259/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4801 - mse: 0.4726 - val_loss: 0.4105 - val_mse: 0.4029\n",
      "Epoch 1260/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4763 - mse: 0.4688\n",
      "Epoch 01260: saving model to Regression_Model/mle.linear-1260.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4687 - val_loss: 0.4121 - val_mse: 0.4046\n",
      "Epoch 1261/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4885 - mse: 0.4809 - val_loss: 0.4118 - val_mse: 0.4043\n",
      "Epoch 1262/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4712 - val_loss: 0.4117 - val_mse: 0.4042\n",
      "Epoch 1263/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4714 - val_loss: 0.4136 - val_mse: 0.4061\n",
      "Epoch 1264/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4739 - val_loss: 0.4081 - val_mse: 0.4005\n",
      "Epoch 1265/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4714 - val_loss: 0.4089 - val_mse: 0.4014\n",
      "Epoch 1266/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4767 - val_loss: 0.4177 - val_mse: 0.4101\n",
      "Epoch 1267/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4762 - mse: 0.4687 - val_loss: 0.4126 - val_mse: 0.4050\n",
      "Epoch 1268/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4769 - val_loss: 0.4216 - val_mse: 0.4141\n",
      "Epoch 1269/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4723 - val_loss: 0.4048 - val_mse: 0.3973\n",
      "Epoch 1270/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4826 - mse: 0.4750\n",
      "Epoch 01270: saving model to Regression_Model/mle.linear-1270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4846 - mse: 0.4770 - val_loss: 0.4121 - val_mse: 0.4045\n",
      "Epoch 1271/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4796 - mse: 0.4721 - val_loss: 0.4146 - val_mse: 0.4071\n",
      "Epoch 1272/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4731 - val_loss: 0.4203 - val_mse: 0.4128\n",
      "Epoch 1273/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4725 - val_loss: 0.4070 - val_mse: 0.3994\n",
      "Epoch 1274/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4727 - val_loss: 0.4157 - val_mse: 0.4081\n",
      "Epoch 1275/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4932 - mse: 0.4856 - val_loss: 0.4109 - val_mse: 0.4033\n",
      "Epoch 1276/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4867 - mse: 0.4792 - val_loss: 0.4140 - val_mse: 0.4064\n",
      "Epoch 1277/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4736 - val_loss: 0.4108 - val_mse: 0.4033\n",
      "Epoch 1278/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4763 - val_loss: 0.4390 - val_mse: 0.4315\n",
      "Epoch 1279/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4792 - val_loss: 0.4114 - val_mse: 0.4038\n",
      "Epoch 1280/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4840 - mse: 0.4764\n",
      "Epoch 01280: saving model to Regression_Model/mle.linear-1280.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4840 - mse: 0.4765 - val_loss: 0.4155 - val_mse: 0.4079\n",
      "Epoch 1281/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4722 - val_loss: 0.4101 - val_mse: 0.4025\n",
      "Epoch 1282/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4708 - val_loss: 0.4123 - val_mse: 0.4048\n",
      "Epoch 1283/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4870 - mse: 0.4794 - val_loss: 0.4192 - val_mse: 0.4116\n",
      "Epoch 1284/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4818 - val_loss: 0.4114 - val_mse: 0.4038\n",
      "Epoch 1285/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4740 - val_loss: 0.4136 - val_mse: 0.4061\n",
      "Epoch 1286/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4734 - val_loss: 0.4092 - val_mse: 0.4017\n",
      "Epoch 1287/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4812 - val_loss: 0.4198 - val_mse: 0.4123\n",
      "Epoch 1288/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4702 - val_loss: 0.4117 - val_mse: 0.4041\n",
      "Epoch 1289/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4753 - val_loss: 0.4119 - val_mse: 0.4044\n",
      "Epoch 1290/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4800 - mse: 0.4725\n",
      "Epoch 01290: saving model to Regression_Model/mle.linear-1290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4727 - val_loss: 0.4108 - val_mse: 0.4033\n",
      "Epoch 1291/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4861 - mse: 0.4785 - val_loss: 0.4144 - val_mse: 0.4068\n",
      "Epoch 1292/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4747 - val_loss: 0.4150 - val_mse: 0.4075\n",
      "Epoch 1293/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4737 - val_loss: 0.4109 - val_mse: 0.4034\n",
      "Epoch 1294/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4859 - mse: 0.4783 - val_loss: 0.4117 - val_mse: 0.4042\n",
      "Epoch 1295/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4736 - mse: 0.4661 - val_loss: 0.4100 - val_mse: 0.4025\n",
      "Epoch 1296/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4757 - val_loss: 0.4115 - val_mse: 0.4040\n",
      "Epoch 1297/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4842 - val_loss: 0.4133 - val_mse: 0.4057\n",
      "Epoch 1298/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4805 - val_loss: 0.4104 - val_mse: 0.4028\n",
      "Epoch 1299/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4782 - val_loss: 0.4154 - val_mse: 0.4079\n",
      "Epoch 1300/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4809 - mse: 0.4734\n",
      "Epoch 01300: saving model to Regression_Model/mle.linear-1300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4738 - val_loss: 0.4100 - val_mse: 0.4025\n",
      "Epoch 1301/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4779 - val_loss: 0.4131 - val_mse: 0.4056\n",
      "Epoch 1302/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4759 - val_loss: 0.4110 - val_mse: 0.4034\n",
      "Epoch 1303/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4753 - val_loss: 0.4133 - val_mse: 0.4058\n",
      "Epoch 1304/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4716 - val_loss: 0.4241 - val_mse: 0.4166\n",
      "Epoch 1305/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4793 - val_loss: 0.4149 - val_mse: 0.4074\n",
      "Epoch 1306/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4753 - val_loss: 0.4138 - val_mse: 0.4063\n",
      "Epoch 1307/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4743 - mse: 0.4668 - val_loss: 0.4103 - val_mse: 0.4028\n",
      "Epoch 1308/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4851 - mse: 0.4775 - val_loss: 0.4204 - val_mse: 0.4129\n",
      "Epoch 1309/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4703 - val_loss: 0.4082 - val_mse: 0.4007\n",
      "Epoch 1310/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4783 - mse: 0.4708\n",
      "Epoch 01310: saving model to Regression_Model/mle.linear-1310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4777 - mse: 0.4701 - val_loss: 0.4195 - val_mse: 0.4119\n",
      "Epoch 1311/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4760 - val_loss: 0.4063 - val_mse: 0.3987\n",
      "Epoch 1312/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4796 - val_loss: 0.4106 - val_mse: 0.4030\n",
      "Epoch 1313/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4712 - val_loss: 0.4109 - val_mse: 0.4034\n",
      "Epoch 1314/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4732 - val_loss: 0.4119 - val_mse: 0.4044\n",
      "Epoch 1315/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4813 - val_loss: 0.4167 - val_mse: 0.4092\n",
      "Epoch 1316/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4734 - val_loss: 0.4115 - val_mse: 0.4040\n",
      "Epoch 1317/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4819 - val_loss: 0.4127 - val_mse: 0.4052\n",
      "Epoch 1318/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4729 - val_loss: 0.4137 - val_mse: 0.4062\n",
      "Epoch 1319/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4728 - val_loss: 0.4079 - val_mse: 0.4004\n",
      "Epoch 1320/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4788 - mse: 0.4713\n",
      "Epoch 01320: saving model to Regression_Model/mle.linear-1320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4796 - mse: 0.4721 - val_loss: 0.4093 - val_mse: 0.4017\n",
      "Epoch 1321/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4754 - val_loss: 0.4100 - val_mse: 0.4025\n",
      "Epoch 1322/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4747 - val_loss: 0.4139 - val_mse: 0.4064\n",
      "Epoch 1323/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4738 - val_loss: 0.4082 - val_mse: 0.4007\n",
      "Epoch 1324/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4780 - mse: 0.4705 - val_loss: 0.4098 - val_mse: 0.4023\n",
      "Epoch 1325/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4809 - val_loss: 0.4119 - val_mse: 0.4044\n",
      "Epoch 1326/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4727 - val_loss: 0.4127 - val_mse: 0.4052\n",
      "Epoch 1327/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4838 - mse: 0.4763 - val_loss: 0.4109 - val_mse: 0.4034\n",
      "Epoch 1328/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4751 - val_loss: 0.4143 - val_mse: 0.4068\n",
      "Epoch 1329/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4728 - val_loss: 0.4109 - val_mse: 0.4034\n",
      "Epoch 1330/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4811 - mse: 0.4736\n",
      "Epoch 01330: saving model to Regression_Model/mle.linear-1330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4732 - val_loss: 0.4088 - val_mse: 0.4013\n",
      "Epoch 1331/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4917 - mse: 0.4842 - val_loss: 0.4096 - val_mse: 0.4021\n",
      "Epoch 1332/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4729 - val_loss: 0.4127 - val_mse: 0.4052\n",
      "Epoch 1333/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4728 - val_loss: 0.4133 - val_mse: 0.4058\n",
      "Epoch 1334/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4776 - val_loss: 0.4087 - val_mse: 0.4012\n",
      "Epoch 1335/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4830 - mse: 0.4755 - val_loss: 0.4094 - val_mse: 0.4019\n",
      "Epoch 1336/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4749 - val_loss: 0.4071 - val_mse: 0.3996\n",
      "Epoch 1337/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4713 - val_loss: 0.4098 - val_mse: 0.4023\n",
      "Epoch 1338/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4720 - val_loss: 0.4164 - val_mse: 0.4089\n",
      "Epoch 1339/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4713 - val_loss: 0.4120 - val_mse: 0.4045\n",
      "Epoch 1340/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4807 - mse: 0.4732\n",
      "Epoch 01340: saving model to Regression_Model/mle.linear-1340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4737 - val_loss: 0.4118 - val_mse: 0.4043\n",
      "Epoch 1341/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4763 - val_loss: 0.4129 - val_mse: 0.4053\n",
      "Epoch 1342/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4680 - val_loss: 0.4227 - val_mse: 0.4152\n",
      "Epoch 1343/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4767 - val_loss: 0.4140 - val_mse: 0.4064\n",
      "Epoch 1344/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4789 - val_loss: 0.4097 - val_mse: 0.4022\n",
      "Epoch 1345/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4790 - val_loss: 0.4058 - val_mse: 0.3983\n",
      "Epoch 1346/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4756 - val_loss: 0.4092 - val_mse: 0.4016\n",
      "Epoch 1347/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4741 - val_loss: 0.4136 - val_mse: 0.4061\n",
      "Epoch 1348/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4869 - mse: 0.4794 - val_loss: 0.4088 - val_mse: 0.4012\n",
      "Epoch 1349/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4706 - val_loss: 0.4123 - val_mse: 0.4048\n",
      "Epoch 1350/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4853 - mse: 0.4777\n",
      "Epoch 01350: saving model to Regression_Model/mle.linear-1350.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4778 - val_loss: 0.4069 - val_mse: 0.3994\n",
      "Epoch 1351/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4841 - val_loss: 0.4097 - val_mse: 0.4022\n",
      "Epoch 1352/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4740 - val_loss: 0.4194 - val_mse: 0.4119\n",
      "Epoch 1353/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4752 - val_loss: 0.4084 - val_mse: 0.4009\n",
      "Epoch 1354/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4751 - val_loss: 0.4177 - val_mse: 0.4102\n",
      "Epoch 1355/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4743 - val_loss: 0.4092 - val_mse: 0.4017\n",
      "Epoch 1356/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4723 - val_loss: 0.4119 - val_mse: 0.4044\n",
      "Epoch 1357/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4719 - val_loss: 0.4122 - val_mse: 0.4047\n",
      "Epoch 1358/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4756 - val_loss: 0.4072 - val_mse: 0.3997\n",
      "Epoch 1359/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4807 - val_loss: 0.4060 - val_mse: 0.3985\n",
      "Epoch 1360/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4831 - mse: 0.4756\n",
      "Epoch 01360: saving model to Regression_Model/mle.linear-1360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4767 - val_loss: 0.4181 - val_mse: 0.4106\n",
      "Epoch 1361/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4762 - val_loss: 0.4129 - val_mse: 0.4054\n",
      "Epoch 1362/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4732 - val_loss: 0.4129 - val_mse: 0.4054\n",
      "Epoch 1363/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4745 - val_loss: 0.4079 - val_mse: 0.4004\n",
      "Epoch 1364/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4743 - val_loss: 0.4083 - val_mse: 0.4008\n",
      "Epoch 1365/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4743 - val_loss: 0.4126 - val_mse: 0.4051\n",
      "Epoch 1366/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4724 - val_loss: 0.4082 - val_mse: 0.4007\n",
      "Epoch 1367/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4730 - val_loss: 0.4096 - val_mse: 0.4021\n",
      "Epoch 1368/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4762 - val_loss: 0.4090 - val_mse: 0.4015\n",
      "Epoch 1369/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4753 - val_loss: 0.4138 - val_mse: 0.4063\n",
      "Epoch 1370/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4770 - mse: 0.4695\n",
      "Epoch 01370: saving model to Regression_Model/mle.linear-1370.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4717 - val_loss: 0.4053 - val_mse: 0.3978\n",
      "Epoch 1371/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4762 - val_loss: 0.4114 - val_mse: 0.4039\n",
      "Epoch 1372/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4867 - mse: 0.4792 - val_loss: 0.4118 - val_mse: 0.4043\n",
      "Epoch 1373/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4734 - val_loss: 0.4087 - val_mse: 0.4012\n",
      "Epoch 1374/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4766 - val_loss: 0.4086 - val_mse: 0.4011\n",
      "Epoch 1375/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4732 - mse: 0.4657 - val_loss: 0.4094 - val_mse: 0.4019\n",
      "Epoch 1376/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4732 - val_loss: 0.4091 - val_mse: 0.4016\n",
      "Epoch 1377/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4710 - val_loss: 0.4140 - val_mse: 0.4065\n",
      "Epoch 1378/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4724 - val_loss: 0.4108 - val_mse: 0.4033\n",
      "Epoch 1379/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4737 - mse: 0.4662 - val_loss: 0.4063 - val_mse: 0.3988\n",
      "Epoch 1380/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4808 - mse: 0.4733\n",
      "Epoch 01380: saving model to Regression_Model/mle.linear-1380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4736 - val_loss: 0.4081 - val_mse: 0.4006\n",
      "Epoch 1381/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4692 - val_loss: 0.4066 - val_mse: 0.3991\n",
      "Epoch 1382/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4764 - val_loss: 0.4158 - val_mse: 0.4083\n",
      "Epoch 1383/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4738 - val_loss: 0.4076 - val_mse: 0.4001\n",
      "Epoch 1384/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4754 - val_loss: 0.4043 - val_mse: 0.3968\n",
      "Epoch 1385/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4716 - val_loss: 0.4055 - val_mse: 0.3980\n",
      "Epoch 1386/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4744 - val_loss: 0.4076 - val_mse: 0.4001\n",
      "Epoch 1387/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4740 - val_loss: 0.4158 - val_mse: 0.4083\n",
      "Epoch 1388/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4692 - val_loss: 0.4078 - val_mse: 0.4003\n",
      "Epoch 1389/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4749 - val_loss: 0.4081 - val_mse: 0.4006\n",
      "Epoch 1390/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4727 - mse: 0.4652\n",
      "Epoch 01390: saving model to Regression_Model/mle.linear-1390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4687 - val_loss: 0.4118 - val_mse: 0.4043\n",
      "Epoch 1391/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4719 - val_loss: 0.4127 - val_mse: 0.4052\n",
      "Epoch 1392/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4766 - val_loss: 0.4106 - val_mse: 0.4031\n",
      "Epoch 1393/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4787 - val_loss: 0.4081 - val_mse: 0.4006\n",
      "Epoch 1394/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4793 - val_loss: 0.4110 - val_mse: 0.4035\n",
      "Epoch 1395/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4922 - mse: 0.4847 - val_loss: 0.4150 - val_mse: 0.4075\n",
      "Epoch 1396/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4771 - mse: 0.4696 - val_loss: 0.4089 - val_mse: 0.4014\n",
      "Epoch 1397/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4774 - mse: 0.4699 - val_loss: 0.4114 - val_mse: 0.4039\n",
      "Epoch 1398/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4790 - mse: 0.4716 - val_loss: 0.4100 - val_mse: 0.4025\n",
      "Epoch 1399/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4756 - val_loss: 0.4134 - val_mse: 0.4059\n",
      "Epoch 1400/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4773 - mse: 0.4698\n",
      "Epoch 01400: saving model to Regression_Model/mle.linear-1400.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4703 - val_loss: 0.4073 - val_mse: 0.3999\n",
      "Epoch 1401/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4720 - val_loss: 0.4086 - val_mse: 0.4011\n",
      "Epoch 1402/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4729 - val_loss: 0.4052 - val_mse: 0.3977\n",
      "Epoch 1403/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4727 - val_loss: 0.4160 - val_mse: 0.4085\n",
      "Epoch 1404/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4694 - val_loss: 0.4095 - val_mse: 0.4020\n",
      "Epoch 1405/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4709 - val_loss: 0.4079 - val_mse: 0.4004\n",
      "Epoch 1406/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4774 - val_loss: 0.4096 - val_mse: 0.4022\n",
      "Epoch 1407/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4777 - val_loss: 0.4137 - val_mse: 0.4062\n",
      "Epoch 1408/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4722 - val_loss: 0.4116 - val_mse: 0.4042\n",
      "Epoch 1409/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4694 - mse: 0.4619 - val_loss: 0.4129 - val_mse: 0.4054\n",
      "Epoch 1410/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4774 - mse: 0.4699\n",
      "Epoch 01410: saving model to Regression_Model/mle.linear-1410.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4716 - val_loss: 0.4126 - val_mse: 0.4051\n",
      "Epoch 1411/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4727 - val_loss: 0.4071 - val_mse: 0.3996\n",
      "Epoch 1412/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4776 - mse: 0.4702 - val_loss: 0.4092 - val_mse: 0.4017\n",
      "Epoch 1413/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4736 - val_loss: 0.4081 - val_mse: 0.4006\n",
      "Epoch 1414/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4731 - val_loss: 0.4097 - val_mse: 0.4023\n",
      "Epoch 1415/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4747 - val_loss: 0.4106 - val_mse: 0.4031\n",
      "Epoch 1416/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4680 - val_loss: 0.4160 - val_mse: 0.4086\n",
      "Epoch 1417/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4840 - mse: 0.4765 - val_loss: 0.4048 - val_mse: 0.3973\n",
      "Epoch 1418/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4735 - val_loss: 0.4049 - val_mse: 0.3974\n",
      "Epoch 1419/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4730 - mse: 0.4655 - val_loss: 0.4079 - val_mse: 0.4004\n",
      "Epoch 1420/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/368 [============================>.] - ETA: 0s - loss: 0.4837 - mse: 0.4762\n",
      "Epoch 01420: saving model to Regression_Model/mle.linear-1420.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4829 - mse: 0.4754 - val_loss: 0.4111 - val_mse: 0.4036\n",
      "Epoch 1421/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4820 - val_loss: 0.4124 - val_mse: 0.4049\n",
      "Epoch 1422/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4756 - val_loss: 0.4097 - val_mse: 0.4022\n",
      "Epoch 1423/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4810 - mse: 0.4735 - val_loss: 0.4061 - val_mse: 0.3986\n",
      "Epoch 1424/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4738 - val_loss: 0.4066 - val_mse: 0.3991\n",
      "Epoch 1425/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4766 - val_loss: 0.4137 - val_mse: 0.4062\n",
      "Epoch 1426/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4745 - mse: 0.4670 - val_loss: 0.4078 - val_mse: 0.4003\n",
      "Epoch 1427/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4722 - val_loss: 0.4115 - val_mse: 0.4040\n",
      "Epoch 1428/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4789 - val_loss: 0.4032 - val_mse: 0.3957\n",
      "Epoch 1429/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4793 - val_loss: 0.4063 - val_mse: 0.3989\n",
      "Epoch 1430/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4751 - mse: 0.4676\n",
      "Epoch 01430: saving model to Regression_Model/mle.linear-1430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4685 - val_loss: 0.4072 - val_mse: 0.3997\n",
      "Epoch 1431/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4746 - mse: 0.4671 - val_loss: 0.4070 - val_mse: 0.3995\n",
      "Epoch 1432/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4780 - mse: 0.4705 - val_loss: 0.4068 - val_mse: 0.3993\n",
      "Epoch 1433/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4786 - mse: 0.4711 - val_loss: 0.4095 - val_mse: 0.4020\n",
      "Epoch 1434/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4734 - val_loss: 0.4108 - val_mse: 0.4033\n",
      "Epoch 1435/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4693 - val_loss: 0.4056 - val_mse: 0.3982\n",
      "Epoch 1436/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4724 - mse: 0.4650 - val_loss: 0.4064 - val_mse: 0.3989\n",
      "Epoch 1437/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4749 - mse: 0.4674 - val_loss: 0.4132 - val_mse: 0.4057\n",
      "Epoch 1438/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4765 - mse: 0.4690 - val_loss: 0.4054 - val_mse: 0.3979\n",
      "Epoch 1439/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4717 - val_loss: 0.4063 - val_mse: 0.3989\n",
      "Epoch 1440/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4802 - mse: 0.4727\n",
      "Epoch 01440: saving model to Regression_Model/mle.linear-1440.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4727 - val_loss: 0.4075 - val_mse: 0.4000\n",
      "Epoch 1441/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4758 - val_loss: 0.4064 - val_mse: 0.3989\n",
      "Epoch 1442/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4716 - val_loss: 0.4121 - val_mse: 0.4047\n",
      "Epoch 1443/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4739 - val_loss: 0.4074 - val_mse: 0.3999\n",
      "Epoch 1444/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4817 - mse: 0.4742 - val_loss: 0.4058 - val_mse: 0.3983\n",
      "Epoch 1445/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4775 - mse: 0.4700 - val_loss: 0.4106 - val_mse: 0.4031\n",
      "Epoch 1446/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4717 - val_loss: 0.4095 - val_mse: 0.4020\n",
      "Epoch 1447/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4756 - val_loss: 0.4064 - val_mse: 0.3989\n",
      "Epoch 1448/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4777 - mse: 0.4702 - val_loss: 0.4072 - val_mse: 0.3997\n",
      "Epoch 1449/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4719 - val_loss: 0.4042 - val_mse: 0.3967\n",
      "Epoch 1450/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4822 - mse: 0.4747\n",
      "Epoch 01450: saving model to Regression_Model/mle.linear-1450.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4848 - mse: 0.4773 - val_loss: 0.4066 - val_mse: 0.3991\n",
      "Epoch 1451/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4731 - val_loss: 0.4156 - val_mse: 0.4082\n",
      "Epoch 1452/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4772 - val_loss: 0.4072 - val_mse: 0.3997\n",
      "Epoch 1453/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4746 - val_loss: 0.4041 - val_mse: 0.3966\n",
      "Epoch 1454/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4774 - mse: 0.4699 - val_loss: 0.4128 - val_mse: 0.4053\n",
      "Epoch 1455/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4691 - val_loss: 0.4099 - val_mse: 0.4024\n",
      "Epoch 1456/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4709 - val_loss: 0.4083 - val_mse: 0.4009\n",
      "Epoch 1457/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4691 - val_loss: 0.4056 - val_mse: 0.3981\n",
      "Epoch 1458/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4716 - val_loss: 0.4130 - val_mse: 0.4055\n",
      "Epoch 1459/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4787 - val_loss: 0.4120 - val_mse: 0.4045\n",
      "Epoch 1460/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4740 - mse: 0.4665\n",
      "Epoch 01460: saving model to Regression_Model/mle.linear-1460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4744 - mse: 0.4669 - val_loss: 0.4080 - val_mse: 0.4005\n",
      "Epoch 1461/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4759 - val_loss: 0.4082 - val_mse: 0.4007\n",
      "Epoch 1462/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4774 - mse: 0.4700 - val_loss: 0.4088 - val_mse: 0.4013\n",
      "Epoch 1463/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4744 - mse: 0.4669 - val_loss: 0.4118 - val_mse: 0.4044\n",
      "Epoch 1464/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4779 - mse: 0.4704 - val_loss: 0.4131 - val_mse: 0.4056\n",
      "Epoch 1465/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4770 - val_loss: 0.4115 - val_mse: 0.4040\n",
      "Epoch 1466/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4714 - val_loss: 0.4069 - val_mse: 0.3994\n",
      "Epoch 1467/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4728 - mse: 0.4654 - val_loss: 0.4098 - val_mse: 0.4023\n",
      "Epoch 1468/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4718 - val_loss: 0.4135 - val_mse: 0.4060\n",
      "Epoch 1469/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4740 - val_loss: 0.4120 - val_mse: 0.4045\n",
      "Epoch 1470/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4837 - mse: 0.4763\n",
      "Epoch 01470: saving model to Regression_Model/mle.linear-1470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4846 - mse: 0.4771 - val_loss: 0.4077 - val_mse: 0.4003\n",
      "Epoch 1471/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4796 - mse: 0.4721 - val_loss: 0.4112 - val_mse: 0.4038\n",
      "Epoch 1472/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4786 - mse: 0.4712 - val_loss: 0.4064 - val_mse: 0.3989\n",
      "Epoch 1473/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4774 - val_loss: 0.4099 - val_mse: 0.4025\n",
      "Epoch 1474/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4768 - val_loss: 0.4087 - val_mse: 0.4013\n",
      "Epoch 1475/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4747 - mse: 0.4672 - val_loss: 0.4063 - val_mse: 0.3988\n",
      "Epoch 1476/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4737 - val_loss: 0.4093 - val_mse: 0.4018\n",
      "Epoch 1477/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4779 - mse: 0.4704 - val_loss: 0.4204 - val_mse: 0.4129\n",
      "Epoch 1478/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4872 - mse: 0.4798 - val_loss: 0.4100 - val_mse: 0.4026\n",
      "Epoch 1479/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4727 - val_loss: 0.4117 - val_mse: 0.4043\n",
      "Epoch 1480/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4752 - mse: 0.4678\n",
      "Epoch 01480: saving model to Regression_Model/mle.linear-1480.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4743 - mse: 0.4669 - val_loss: 0.4138 - val_mse: 0.4064\n",
      "Epoch 1481/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4735 - val_loss: 0.4056 - val_mse: 0.3981\n",
      "Epoch 1482/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4701 - val_loss: 0.4110 - val_mse: 0.4035\n",
      "Epoch 1483/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4746 - mse: 0.4671 - val_loss: 0.4079 - val_mse: 0.4004\n",
      "Epoch 1484/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4753 - mse: 0.4679 - val_loss: 0.4100 - val_mse: 0.4026\n",
      "Epoch 1485/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4687 - val_loss: 0.4098 - val_mse: 0.4023\n",
      "Epoch 1486/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4893 - mse: 0.4818 - val_loss: 0.4111 - val_mse: 0.4036\n",
      "Epoch 1487/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4761 - mse: 0.4686 - val_loss: 0.4077 - val_mse: 0.4003\n",
      "Epoch 1488/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4777 - val_loss: 0.4080 - val_mse: 0.4006\n",
      "Epoch 1489/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4694 - val_loss: 0.4082 - val_mse: 0.4008\n",
      "Epoch 1490/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4830 - mse: 0.4755\n",
      "Epoch 01490: saving model to Regression_Model/mle.linear-1490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4748 - val_loss: 0.4088 - val_mse: 0.4014\n",
      "Epoch 1491/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4766 - val_loss: 0.4113 - val_mse: 0.4039\n",
      "Epoch 1492/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4704 - val_loss: 0.4150 - val_mse: 0.4076\n",
      "Epoch 1493/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4748 - mse: 0.4674 - val_loss: 0.4108 - val_mse: 0.4034\n",
      "Epoch 1494/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4872 - mse: 0.4797 - val_loss: 0.4045 - val_mse: 0.3971\n",
      "Epoch 1495/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4698 - val_loss: 0.4060 - val_mse: 0.3985\n",
      "Epoch 1496/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4761 - mse: 0.4686 - val_loss: 0.4110 - val_mse: 0.4035\n",
      "Epoch 1497/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4879 - mse: 0.4805 - val_loss: 0.4049 - val_mse: 0.3974\n",
      "Epoch 1498/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4693 - val_loss: 0.4083 - val_mse: 0.4009\n",
      "Epoch 1499/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4789 - mse: 0.4715 - val_loss: 0.4090 - val_mse: 0.4015\n",
      "Epoch 1500/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4782 - mse: 0.4707\n",
      "Epoch 01500: saving model to Regression_Model/mle.linear-1500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4724 - val_loss: 0.4064 - val_mse: 0.3989\n",
      "Epoch 1501/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4799 - val_loss: 0.4135 - val_mse: 0.4061\n",
      "Epoch 1502/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4737 - val_loss: 0.4111 - val_mse: 0.4036\n",
      "Epoch 1503/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4746 - mse: 0.4671 - val_loss: 0.4065 - val_mse: 0.3991\n",
      "Epoch 1504/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4786 - mse: 0.4712 - val_loss: 0.4084 - val_mse: 0.4009\n",
      "Epoch 1505/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4704 - val_loss: 0.4041 - val_mse: 0.3967\n",
      "Epoch 1506/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4706 - val_loss: 0.4058 - val_mse: 0.3983\n",
      "Epoch 1507/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4752 - val_loss: 0.4066 - val_mse: 0.3992\n",
      "Epoch 1508/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4739 - mse: 0.4664 - val_loss: 0.4061 - val_mse: 0.3987\n",
      "Epoch 1509/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4743 - mse: 0.4668 - val_loss: 0.4079 - val_mse: 0.4004\n",
      "Epoch 1510/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4791 - mse: 0.4716\n",
      "Epoch 01510: saving model to Regression_Model/mle.linear-1510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4692 - val_loss: 0.4053 - val_mse: 0.3978\n",
      "Epoch 1511/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4731 - val_loss: 0.4067 - val_mse: 0.3993\n",
      "Epoch 1512/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4769 - val_loss: 0.4078 - val_mse: 0.4003\n",
      "Epoch 1513/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4771 - mse: 0.4697 - val_loss: 0.4111 - val_mse: 0.4037\n",
      "Epoch 1514/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4736 - val_loss: 0.4072 - val_mse: 0.3997\n",
      "Epoch 1515/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4739 - mse: 0.4664 - val_loss: 0.4108 - val_mse: 0.4034\n",
      "Epoch 1516/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4782 - mse: 0.4708 - val_loss: 0.4114 - val_mse: 0.4040\n",
      "Epoch 1517/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4738 - val_loss: 0.4118 - val_mse: 0.4044\n",
      "Epoch 1518/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4728 - mse: 0.4653 - val_loss: 0.4057 - val_mse: 0.3983\n",
      "Epoch 1519/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4739 - val_loss: 0.4039 - val_mse: 0.3965\n",
      "Epoch 1520/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4712 - mse: 0.4637\n",
      "Epoch 01520: saving model to Regression_Model/mle.linear-1520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4743 - mse: 0.4669 - val_loss: 0.4022 - val_mse: 0.3948\n",
      "Epoch 1521/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4796 - mse: 0.4722 - val_loss: 0.4045 - val_mse: 0.3970\n",
      "Epoch 1522/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4708 - val_loss: 0.4073 - val_mse: 0.3999\n",
      "Epoch 1523/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4748 - val_loss: 0.4084 - val_mse: 0.4010\n",
      "Epoch 1524/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4718 - val_loss: 0.4080 - val_mse: 0.4006\n",
      "Epoch 1525/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4746 - val_loss: 0.4068 - val_mse: 0.3993\n",
      "Epoch 1526/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4716 - val_loss: 0.4068 - val_mse: 0.3994\n",
      "Epoch 1527/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4780 - val_loss: 0.4055 - val_mse: 0.3980\n",
      "Epoch 1528/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4738 - val_loss: 0.4072 - val_mse: 0.3998\n",
      "Epoch 1529/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4754 - val_loss: 0.4145 - val_mse: 0.4070\n",
      "Epoch 1530/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4709 - mse: 0.4635\n",
      "Epoch 01530: saving model to Regression_Model/mle.linear-1530.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4708 - mse: 0.4633 - val_loss: 0.4047 - val_mse: 0.3973\n",
      "Epoch 1531/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4731 - mse: 0.4657 - val_loss: 0.4051 - val_mse: 0.3976\n",
      "Epoch 1532/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4759 - val_loss: 0.4117 - val_mse: 0.4043\n",
      "Epoch 1533/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4764 - val_loss: 0.4113 - val_mse: 0.4038\n",
      "Epoch 1534/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4729 - val_loss: 0.4084 - val_mse: 0.4010\n",
      "Epoch 1535/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4744 - val_loss: 0.4034 - val_mse: 0.3960\n",
      "Epoch 1536/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4749 - val_loss: 0.4068 - val_mse: 0.3994\n",
      "Epoch 1537/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4698 - val_loss: 0.4047 - val_mse: 0.3972\n",
      "Epoch 1538/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4739 - val_loss: 0.4089 - val_mse: 0.4014\n",
      "Epoch 1539/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4752 - mse: 0.4678 - val_loss: 0.4068 - val_mse: 0.3994\n",
      "Epoch 1540/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4747 - mse: 0.4673\n",
      "Epoch 01540: saving model to Regression_Model/mle.linear-1540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4695 - val_loss: 0.4051 - val_mse: 0.3977\n",
      "Epoch 1541/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4752 - mse: 0.4678 - val_loss: 0.4021 - val_mse: 0.3947\n",
      "Epoch 1542/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4691 - val_loss: 0.4051 - val_mse: 0.3976\n",
      "Epoch 1543/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4686 - val_loss: 0.4114 - val_mse: 0.4040\n",
      "Epoch 1544/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4729 - val_loss: 0.4094 - val_mse: 0.4019\n",
      "Epoch 1545/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4751 - val_loss: 0.4054 - val_mse: 0.3980\n",
      "Epoch 1546/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4709 - val_loss: 0.4123 - val_mse: 0.4049\n",
      "Epoch 1547/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4763 - val_loss: 0.4073 - val_mse: 0.3999\n",
      "Epoch 1548/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4728 - val_loss: 0.4037 - val_mse: 0.3963\n",
      "Epoch 1549/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4786 - mse: 0.4712 - val_loss: 0.4058 - val_mse: 0.3984\n",
      "Epoch 1550/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.4737 - mse: 0.4663\n",
      "Epoch 01550: saving model to Regression_Model/mle.linear-1550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4739 - mse: 0.4665 - val_loss: 0.4039 - val_mse: 0.3965\n",
      "Epoch 1551/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4763 - mse: 0.4689 - val_loss: 0.4060 - val_mse: 0.3986\n",
      "Epoch 1552/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4699 - mse: 0.4625 - val_loss: 0.4073 - val_mse: 0.3999\n",
      "Epoch 1553/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4768 - mse: 0.4694 - val_loss: 0.4081 - val_mse: 0.4007\n",
      "Epoch 1554/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4775 - mse: 0.4700 - val_loss: 0.4049 - val_mse: 0.3975\n",
      "Epoch 1555/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4713 - val_loss: 0.4101 - val_mse: 0.4027\n",
      "Epoch 1556/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4786 - mse: 0.4712 - val_loss: 0.4070 - val_mse: 0.3996\n",
      "Epoch 1557/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4742 - mse: 0.4668 - val_loss: 0.4095 - val_mse: 0.4021\n",
      "Epoch 1558/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4745 - val_loss: 0.4159 - val_mse: 0.4085\n",
      "Epoch 1559/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4742 - val_loss: 0.4098 - val_mse: 0.4024\n",
      "Epoch 1560/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4812 - mse: 0.4738\n",
      "Epoch 01560: saving model to Regression_Model/mle.linear-1560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4737 - val_loss: 0.4044 - val_mse: 0.3969\n",
      "Epoch 1561/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4774 - mse: 0.4700 - val_loss: 0.4079 - val_mse: 0.4005\n",
      "Epoch 1562/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4730 - val_loss: 0.4111 - val_mse: 0.4037\n",
      "Epoch 1563/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4688 - val_loss: 0.4061 - val_mse: 0.3987\n",
      "Epoch 1564/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4745 - val_loss: 0.4063 - val_mse: 0.3989\n",
      "Epoch 1565/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4734 - mse: 0.4660 - val_loss: 0.4097 - val_mse: 0.4023\n",
      "Epoch 1566/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4696 - mse: 0.4622 - val_loss: 0.4041 - val_mse: 0.3967\n",
      "Epoch 1567/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4753 - mse: 0.4679 - val_loss: 0.4107 - val_mse: 0.4033\n",
      "Epoch 1568/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4692 - val_loss: 0.4087 - val_mse: 0.4013\n",
      "Epoch 1569/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4707 - val_loss: 0.4083 - val_mse: 0.4009\n",
      "Epoch 1570/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4835 - mse: 0.4761\n",
      "Epoch 01570: saving model to Regression_Model/mle.linear-1570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4764 - val_loss: 0.4064 - val_mse: 0.3989\n",
      "Epoch 1571/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4713 - val_loss: 0.4078 - val_mse: 0.4004\n",
      "Epoch 1572/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4728 - val_loss: 0.4091 - val_mse: 0.4016\n",
      "Epoch 1573/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4761 - mse: 0.4687 - val_loss: 0.4063 - val_mse: 0.3989\n",
      "Epoch 1574/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4757 - val_loss: 0.4103 - val_mse: 0.4029\n",
      "Epoch 1575/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4741 - mse: 0.4667 - val_loss: 0.4121 - val_mse: 0.4047\n",
      "Epoch 1576/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4761 - mse: 0.4687 - val_loss: 0.4069 - val_mse: 0.3995\n",
      "Epoch 1577/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4761 - mse: 0.4687 - val_loss: 0.4047 - val_mse: 0.3973\n",
      "Epoch 1578/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4696 - val_loss: 0.4082 - val_mse: 0.4008\n",
      "Epoch 1579/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4737 - val_loss: 0.4080 - val_mse: 0.4006\n",
      "Epoch 1580/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4868 - mse: 0.4794\n",
      "Epoch 01580: saving model to Regression_Model/mle.linear-1580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4792 - val_loss: 0.4037 - val_mse: 0.3963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1581/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4745 - val_loss: 0.4089 - val_mse: 0.4015\n",
      "Epoch 1582/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4696 - val_loss: 0.4036 - val_mse: 0.3962\n",
      "Epoch 1583/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4711 - val_loss: 0.4054 - val_mse: 0.3980\n",
      "Epoch 1584/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4779 - mse: 0.4705 - val_loss: 0.4100 - val_mse: 0.4026\n",
      "Epoch 1585/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4742 - mse: 0.4668 - val_loss: 0.4029 - val_mse: 0.3955\n",
      "Epoch 1586/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4736 - val_loss: 0.4031 - val_mse: 0.3957\n",
      "Epoch 1587/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4803 - mse: 0.4729 - val_loss: 0.4057 - val_mse: 0.3982\n",
      "Epoch 1588/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4780 - mse: 0.4706 - val_loss: 0.4035 - val_mse: 0.3961\n",
      "Epoch 1589/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4728 - val_loss: 0.4080 - val_mse: 0.4006\n",
      "Epoch 1590/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4779 - mse: 0.4705\n",
      "Epoch 01590: saving model to Regression_Model/mle.linear-1590.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4762 - mse: 0.4688 - val_loss: 0.4062 - val_mse: 0.3988\n",
      "Epoch 1591/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4742 - val_loss: 0.4099 - val_mse: 0.4025\n",
      "Epoch 1592/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4710 - val_loss: 0.4047 - val_mse: 0.3973\n",
      "Epoch 1593/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4698 - val_loss: 0.4075 - val_mse: 0.4001\n",
      "Epoch 1594/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4692 - val_loss: 0.4056 - val_mse: 0.3982\n",
      "Epoch 1595/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4711 - val_loss: 0.4112 - val_mse: 0.4039\n",
      "Epoch 1596/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4728 - val_loss: 0.4130 - val_mse: 0.4056\n",
      "Epoch 1597/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4745 - mse: 0.4671 - val_loss: 0.4074 - val_mse: 0.4000\n",
      "Epoch 1598/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4710 - val_loss: 0.4062 - val_mse: 0.3988\n",
      "Epoch 1599/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4681 - val_loss: 0.4056 - val_mse: 0.3982\n",
      "Epoch 1600/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4710 - mse: 0.4636\n",
      "Epoch 01600: saving model to Regression_Model/mle.linear-1600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4699 - mse: 0.4625 - val_loss: 0.4105 - val_mse: 0.4031\n",
      "Epoch 1601/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4708 - val_loss: 0.4044 - val_mse: 0.3970\n",
      "Epoch 1602/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4722 - mse: 0.4649 - val_loss: 0.4057 - val_mse: 0.3983\n",
      "Epoch 1603/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4770 - mse: 0.4696 - val_loss: 0.4096 - val_mse: 0.4022\n",
      "Epoch 1604/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4753 - mse: 0.4679 - val_loss: 0.4116 - val_mse: 0.4042\n",
      "Epoch 1605/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4753 - val_loss: 0.4122 - val_mse: 0.4048\n",
      "Epoch 1606/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4777 - val_loss: 0.4107 - val_mse: 0.4033\n",
      "Epoch 1607/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4701 - val_loss: 0.4048 - val_mse: 0.3974\n",
      "Epoch 1608/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4681 - val_loss: 0.4075 - val_mse: 0.4002\n",
      "Epoch 1609/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4741 - val_loss: 0.4037 - val_mse: 0.3963\n",
      "Epoch 1610/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4813 - mse: 0.4739\n",
      "Epoch 01610: saving model to Regression_Model/mle.linear-1610.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4817 - mse: 0.4743 - val_loss: 0.4080 - val_mse: 0.4007\n",
      "Epoch 1611/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4747 - val_loss: 0.4041 - val_mse: 0.3967\n",
      "Epoch 1612/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4731 - mse: 0.4658 - val_loss: 0.4080 - val_mse: 0.4006\n",
      "Epoch 1613/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4698 - val_loss: 0.4087 - val_mse: 0.4013\n",
      "Epoch 1614/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4708 - val_loss: 0.4071 - val_mse: 0.3997\n",
      "Epoch 1615/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4764 - mse: 0.4690 - val_loss: 0.4034 - val_mse: 0.3960\n",
      "Epoch 1616/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4693 - val_loss: 0.4099 - val_mse: 0.4025\n",
      "Epoch 1617/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4791 - mse: 0.4718 - val_loss: 0.4146 - val_mse: 0.4072\n",
      "Epoch 1618/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4749 - mse: 0.4675 - val_loss: 0.4055 - val_mse: 0.3981\n",
      "Epoch 1619/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4744 - val_loss: 0.4051 - val_mse: 0.3977\n",
      "Epoch 1620/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4819 - mse: 0.4745\n",
      "Epoch 01620: saving model to Regression_Model/mle.linear-1620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4739 - val_loss: 0.4175 - val_mse: 0.4101\n",
      "Epoch 1621/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4697 - val_loss: 0.4074 - val_mse: 0.4001\n",
      "Epoch 1622/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4701 - val_loss: 0.4056 - val_mse: 0.3982\n",
      "Epoch 1623/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4779 - mse: 0.4706 - val_loss: 0.4082 - val_mse: 0.4008\n",
      "Epoch 1624/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4727 - val_loss: 0.4095 - val_mse: 0.4022\n",
      "Epoch 1625/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4739 - val_loss: 0.4054 - val_mse: 0.3981\n",
      "Epoch 1626/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4733 - mse: 0.4659 - val_loss: 0.4089 - val_mse: 0.4015\n",
      "Epoch 1627/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4748 - mse: 0.4675 - val_loss: 0.4032 - val_mse: 0.3958\n",
      "Epoch 1628/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4764 - mse: 0.4690 - val_loss: 0.4062 - val_mse: 0.3988\n",
      "Epoch 1629/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4774 - mse: 0.4700 - val_loss: 0.4117 - val_mse: 0.4043\n",
      "Epoch 1630/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.4775 - mse: 0.4701\n",
      "Epoch 01630: saving model to Regression_Model/mle.linear-1630.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4747 - mse: 0.4673 - val_loss: 0.4072 - val_mse: 0.3998\n",
      "Epoch 1631/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4730 - val_loss: 0.4062 - val_mse: 0.3989\n",
      "Epoch 1632/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4686 - val_loss: 0.4034 - val_mse: 0.3960\n",
      "Epoch 1633/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4686 - mse: 0.4612 - val_loss: 0.4049 - val_mse: 0.3975\n",
      "Epoch 1634/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4739 - mse: 0.4665 - val_loss: 0.4071 - val_mse: 0.3997\n",
      "Epoch 1635/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4777 - mse: 0.4704 - val_loss: 0.4047 - val_mse: 0.3973\n",
      "Epoch 1636/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4737 - val_loss: 0.4052 - val_mse: 0.3978\n",
      "Epoch 1637/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4753 - val_loss: 0.4049 - val_mse: 0.3975\n",
      "Epoch 1638/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4757 - mse: 0.4683 - val_loss: 0.4064 - val_mse: 0.3990\n",
      "Epoch 1639/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4687 - val_loss: 0.4035 - val_mse: 0.3962\n",
      "Epoch 1640/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4775 - mse: 0.4702\n",
      "Epoch 01640: saving model to Regression_Model/mle.linear-1640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4704\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b4e9cc64ece9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                       total_epochs=1)\n\u001b[0m\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=3000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0f2ccce95ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3ca79f84b74a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss of training data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss of validation data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-2550.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA_read\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        truth = y[i]\n",
    "        OUT.write('%s\\t%s\\t%s\\n'%(pasid[i],predict,truth))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "trainid='mle.linear'\n",
    "evaluate(train_x,train_y,train_id,trainid,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "evaluate(valid_x,valid_y,train_id,trainid,'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
