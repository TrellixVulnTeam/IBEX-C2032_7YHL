{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 14753\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.predict.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    #train_data = (train_data-data_mean)/data_std\n",
    "    train_data = train_data/data_max\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #valid_data  = (valid_data-data_mean)/data_std\n",
    "    valid_data    = valid_data/data_max\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.47435 2.5292199\n",
      "5.729239 1.606415\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd8b2889940>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxU1Z338c+vqjfohbVZm01ABRcQexCVqIxL0BgxicmYRbM5xEl8jMmT8WX2xSyTZTIzmTFhcMkkGRPjYyQhils0BhNFAUVkF1mbtdmEZun19/xxbzdFUw23oZvquvV9v1796rrLqT6H5dunzj33HnN3REQkvhKZroCIiHQuBb2ISMwp6EVEYk5BLyIScwp6EZGYy8t0BdLp27evDx8+PNPVEBHJGgsXLtzh7uXpjnXJoB8+fDgLFizIdDVERLKGma1v65iGbkREYk5BLyIScwp6EZGYU9CLiMScgl5EJOYU9CIiMaegFxGJOQV9J5m3ZifLNu/tsPdbvX0ff1lV3WHv15U9s2wbm/YczHQ1RGKjS94wlc121NTy2/kb+eFTKwFY9y/vOub5z6/cTl1DE1edNeCY513x47kAvPXda0gmrGMq2wW9uW0f//jL4Ga5vITxickj+NI1YzJcK5HsFqse/TnfeIqP/fwVMrWYysd//gqV3/5TS8in2neonscXbzmibg2NTXzs5/OZ/quFNDQ2cdP9L/OvTx9d9lB9Y8vrt6prOqfyXcRrG/YAcP34QTS5M3PuGvYeqs9wrUSyW6x69GMGlvH8ymrW7zzA8L7Fp/Rn79pfx59XVnPJ6eV89vJRPPC3dSzd9HbL8Z88+yb3vrCW+26u5Iqx/dny9kEu/N5zLcdHffkJAF54cwf/Oy+4k7msWz63TB7Bqm2Hw/29P32RBV+5gqL85Clq2am1qGoPJYV5/PgD45lyZj8++9Aitr19iLKi/ExXTSRrxapH3/wRf+W2fR32nks2vR3pE8KasKf9iYuHc/6w3vQpLmBnTR0Pz9/IlB89z70vrAVoGWdfsG43AGbw7nGDjniv3sUF/N3w3qzfeYCv/mEpvwqD//xhvaipbeDMrz7J8LseZ8vb2T2Ovb+2gT+v2M66Hftb9r26fjfnD+tFImEMKCsC4HevbspUFUViIVY9+qG9uwOwaXfHBOCijXu4/p6/kTC49PRyHLjh/AquPXfQUedu3H0AgIpeQR0mndaHX760nq/NXsKh+qaW85qHXv7zuTcBmPfFy+lfVsSYgaXc98Jadu2v4x2jy/nGdWexa38dh+ob+c7jy3n8jS388hMTOevrT7W816OvbuIzU0Z1SFtPtaYm530/e5EVW4NfytPGD+Kuq89k/c4DXDSyLwDjhvQEgvAXkRMXqUdvZlPNbKWZrTazu9Icn2Zmi81skZktMLPJKcfWmdkbzcc6svKt9eyWT37SqK6ppbHJqW1oPH6hY1i7IwjlJoc/r6zm+ZXVfOnRN9L28N+o2kthXoIhvbsBMPWsAbz//ArOHdyTn354Ai998e+5btwgqsJfQs3DMX1LCgH49GWj+Na0s4Cg5w5Bz35Qz2785wfP45UvX05xYR4/ev84rhjTHzhy7D7bbNx9gBVb99EtP8ngnt34w6LNXPi95zhY38jwvsEvy6L8JB+9cBiLN+3J2HUXkTg4bo/ezJLAPcCVQBUw38xmu/uylNOeBWa7u5vZucDDwJkpx6e4+44OrHdaiYTRt6SQLXsO8s5/n8vq7TX8+APjeO+EihN6v/U7D2AGy745lXlrd/LHRZt59LVNVO0+yJDw00OztTtqGN2/hMK8ZEtdfvj+cUecM7K8hD8u3szeQ/V0y09y9uCyI2bQvOucgQz5THfOrehxVLv6lQbDGDecX8EN51cw5qtPZnXQ//fcNQA8+I8XML6iJ4+8WsWdjywGYGCPbi3nnT6glEP1wUXri0b24T+efZM733kGH7t4REbqLZKNovToJwKr3X2Nu9cBDwHTUk9w9xo/3OUqBjLW/SovLeT3izazenvQY/7NKxvaVd7dWVy1h4N1jWzYeYCBZUV0K0gy5Yx+TDtvMADb9h46qtzB+ka65x/792bl8F64w8L1u6ltaGTSaX2OOG5mjBvSE7PjT58syk9Q29B03PMyxd1Zvb2G+sYmXtuwm8amI/9JzFuzE4DxFT1JJIwPVA7h3psrATh7cFnLedeNG0RFr278ZVU133tiBQfqGvnGH5d16D0KInEXZYx+MLAxZbsKuKD1SWb2HuB7QD8gdfK4A0+bmQP/7e4z0/0QM5sOTAcYOnRopMqnUx4OhUAwfPLciu3srKmlT8r+1hoam2hocu7/61qWbdnL44u3tBy7eNThMO7dvQAIZtg0e3H1Dp5cupW3DzZQXtr2zwAYP6Qn+UnjCw+/TpNDn+KCdrevWWFektr6rhn0jU3OvS+s4V+eWMG08YP4w6LNfOVdY7jlHacBwVz5NdXBBdhEyieaK8f2P+q+g9KifOb+8xRq6ho49xtPt+y/5icv8Nj/mczZg4/89CMiR4sS9Om6l0f12N19FjDLzC4B7gauCA9d7O6bzawf8IyZrXD3uWnKzwRmAlRWVp7wJ4Ie3Q5Pw7v1spE8uXQrv3hxHZ+/6oy0589ft4sP3TuP+sb0P/KG8w8P+/QqDt574frdLTc4/fiZVSwILxYO6dX/mHUrLszjvedV8NsFwe/Ncyp6RmzV0QrzEyd9DaIzNDY5l/zgzy13tv5h0WYAXlm7i3eeNYC5b1bz5JKtANz+99EuJCcSRllRPh+/eDgjy0voU1zAPz34KvPW7FTQi0QQJeirgCEp2xXA5rZOdve5ZjbSzPq6+w533xzu325mswiGgo4K+o5yxxWnc97Qnnxw4uFPBU8t3cbnrjydbz22jDEDy/hA5eHmfGP2UuobnVsmj+DxN7aw5e3DwzKfvmwk706ZYdN84fS/567hk5NH0K+siJ0pvfuCvOOPhH33vedwdkUPkmZMGHriQV+UlzxiNk9Xsaa65ojHF9w59Qx+8ORKnl62jaeXbWvZP2FoTz535enteu+vvzu4WO3uFOUnWKrhG5FIogT9fGC0mY0ANgE3Ah9KPcHMRgFvhRdjJwAFwE4zKwYS7r4vfH0V8K0ObUErQ/t056YLh7ds33B+BX9avo2V2/bx87+tA6CkMI9rzhnIgboGlm7ey6cvG8mdU8/kpguH8Z3Hl/O5K09nVL8S8pNHBndRfpKvvGsM3358Oa9Xvc2qbVWs3bGfgT2K2PL2oUhj5smEcdOkYSfdzpraBp5cuvWY57g7j766idH9Szj3JD49RLX3UD1X/lvwO/zvhvfiM1NGcdkZ/fjBk0fe7fvKly6nZ/eCSNci0jEzKnp1Z9Zrm7h4VN8jPnWJyNGO2wV19wbgNuApYDnwsLsvNbNbzezW8LT3AUvMbBHBDJ1/CC/O9gf+amavA68Aj7v7k53RkLYM692dPQfqWbLpcO9vSXjH6vqdwdz3MQODi3/D+hQz8+ZKxgwsOyrkmzVPbXxtw25++NRKzGiZy36grqHT2tFac695z4E6tu87xNaUTyKH6hup3lfLfz23mv/7/17nw/e93On1uXfuGiZ86xkASovyePhTF3LZGf0AuG3KKEoL8+hdXMBnpoykX1lRpE8/x/LDG84F4Bcvrjup9xHJBZFumHL3OcCcVvtmpLz+PvD9NOXWAONa7z+V+od3Vy5cvwsIZuVs2BUE/PItQfiP7l8S+f1Ki4I/sp8+/xYAc/95SstwT0XP7m2W62jXjRvE7Nc3M+eNrXxp1hsAXHhaHy4f048Zf3mLHTWHh5T2HWpg1mtVvOe8ju/57t5fxxNLtvKdOctb9v3xtslH9Na/8M4z+MI7018jOVHnDe3F+8+v4M8rt3fo+4rEUawegZBO/x5B0K/cuo/CvARnDihtCfpV22rITxqjytsT9Icv9paXFlLRqxuVw3ox86bzuevqM49RsmN9Phzfbg55gJfW7OTbjy8/IuTfG04J/dxvX2dVBz4aotl9f11zRB2AU/acoYE9u7Fzfx11XXiaqUhXEP+gLwsuoL65rYbSojyG9u7eEvTb9x2ivKSQvDaGadJJHXJ4/guXYWYkEsZVZw2g10lMl2yv4X2L+eTkwzcN3XHFaH70/nFMHNH7iPPelzJ+/djrwTX0vYfqeXLJliOeMXOitu2tPWL7zqkd23M/lnMH98Ad/vZWp9+LJ5LVYvWsm3SG9ykmmTD21TbQp6Q75aWF7DlQT0NjE9X7aikPh3ba48FbLmBkeQnFhZn94/vqtWOZfslprNq2j3eMLgdg/JAevPDmDsYOLKNbQZKxA8u4+/qz+ervl/Creev5/FVncN8La/nJs29y5oBSnrzjkhP++Y8t3swjC6tath+/fTJnDTp10x0vCu9x+PKjbzD3zint+oUtkktiH/RF+UnOGdyDRRv3UNvQRK/wpqeP3P8y89bs4n0n8HiEi0f17ehqnrD+ZUUt1yEARvUrZVS/0iPOuWnSMN7aXsP/vLiOpiZn1/6gF75i6z627zvU8niF9mp+7v7d15/NlDPKWx7odqp0L8jj9P4lrNpWw5LNexk/pPNnFolko5zoAt16aXBHZp+SAnp2D8bY560JLs5eO25gxup1Kg3uGTw/Zvbrm3n74OHZQRO/8ywbw6EsgPrGJp5eupXXN+457nvu2FfLxy8ezk2Thp3ykG/2HzeeB8D8tbsy8vNFskHse/QAU88eyM8//ncM6dWdfSmrFf3ghnO57PTyDNbs1CnrFvxV3/HbRbReiXDZlr0M6d2deWt28s0/LmP5lr0kE8aqb1+ddtnCv6yq5pllW9lf19hyE1mmND+a+jtzljPlzPKjPs2ISI4EPcCUcE43wAt3TqEwL0G/Exifz1apd9E2OYzuV8KGXQeobWhiQ3g/wb88saJlZk5jk7O/ruGolZ027jrARx94pWV7xCleyau14sI8vnbtWL712DJ+8eJ67r7+7IzWR6Qryomhm9aG9O6eUyEPcM05A5k2/vDjHAb17MbKb19Nj275LN+yl5vuf5lFG/dw06RhfP995wDB+q2V336Gy//1efbXBsM99/81WCnrQxcM5V3nDDziF2imfGLyCMYMLMv6FbdEOkvO9OhzXXlpIf9x43n8bfUOdtTUtazeNLK8mEdfC5bqG96nOx+9aHjLI4Cbz91RU8dZX3+KBV+5gv95cR0Thvbku+85J2NtSWdwzyJeemsn9Y1Nbd7VLJKrFPQ55t6bK1m7Y3/L0zd/cMM4Xt2wm/ykcdXYARQX5rVcnG19g1Vzb37a+MGnttIRTB7Vlz8t3843Zi/lO13sl5BIpqnrk2POG9qL906ooCS8B2BUvxI+UDmE95xX0XJfQPNz9Z9fWU3/skIeufVCIHieDcCZA7reBc+bLhxOftJ48OUNrNza8XcAi2QzBb0c5Yz+h4P8stP7UTm8N5edUU5DuEpUWbf8topmTDJhPHLrRQA8EH7yEJGAgl6OkkgYX7t2LBNH9Obr140FDk9jhK4Z9ADjhvTk2nMH8tsFG4+4N0Ak1ynoJa1PTB7Bw5+6kO4FwXDO5JS7gQd04RlLHwoXnJkVXmAWEQW9RHTVWQP4/JWn8+inL0p7E1VXcdGovowf0pPnVujxxSLNFPQS2e2Xj2bC0F6ZrsZxnT+sFyu27iVY+0ZEFPQSO8P7dOdQfRPfTVkMRSSXKegldqaePZCi/AT3vrCWJ97YkunqiGRcpKA3s6lmttLMVpvZXWmOTzOzxWa2yMwWmNnkqGVFOlp5aSG/+6dgquWLb+3McG1EMu+4QW9mSYIFv68GxgIfNLOxrU57Fhjn7uOBTwD3taOsSIc7a1APRpYXs6Om9vgni8RclB79RGC1u69x9zrgIWBa6gnuXuOHr3wVAx61rEhn6VtSyMtrd3HLL+YfsRKWSK6JEvSDgY0p21XhviOY2XvMbAXwOEGvPnLZsPz0cNhnQXV1dZS6ixzTu8cNYmCPIl7dsId/e2ZVpqsjkjFRgj7dpOmj5q25+yx3PxO4Hri7PWXD8jPdvdLdK8vLc2MxEOlcH5k0jMdvfwefuuQ0Nu05yNsH649fSCSGogR9FTAkZbsC2NzWye4+FxhpZn3bW1akMzQvc7h6e02GayKSGVGCfj4w2sxGmFkBcCMwO/UEMxtlZha+ngAUADujlBXpbKeVB6tgPbJw43HOFImn4z6P3t0bzOw24CkgCTzg7kvN7Nbw+AzgfcDNZlYPHAT+Ibw4m7ZsJ7VFJK0xA8swg7oG3SkruSnSwiPuPgeY02rfjJTX3we+H7WsyKl2er9Samo1Ri+5SXfGSk4oKcqjJlz3ViTXKOglJ5QU5rFuh55RL7lJQS85Y9Oeg+zUnbKSgxT0khMuH9MPgN0HNE4vuUdBLzlhYI9uAByqb8xwTUROPQW95IRu+UkADiroJQcp6CUndCsI/qkfrFPQS+5R0EtOKAp79Bq6kVykoJecUKShG8lhCnrJCd0LgqD/3aubMlwTkVMv0iMQRLLdgLIiSgrz2LBzP7Nf30xewrj09HKKC/VfQOJPPXrJCWbGJyePYN3OA9z+m9f49IOv8uDL6zNdLZFTQt0ZyRm3Xz6a68YPwh0+fN88vjtnBROG9qJyeO9MV02kU6lHLzkjmTBGlpcwql8JH5o4DIDfvKJn1Ev8qUcvOemzV4zm5bU7eataq05J/KlHLzlrZHkJb1XXEKyRIxJfCnrJWSP6FrPvUAO79tdluioinUpBLzmrrFs+APtrdROVxFukoDezqWa20sxWm9ldaY5/2MwWh18vmtm4lGPrzOwNM1tkZgs6svIiJ6MoP/jnf6hBQS/xdtyLsWaWBO4BrgSqgPlmNtvdl6Wctha41N13m9nVwEzggpTjU9x9RwfWW+SkFeXp+TeSG6L06CcCq919jbvXAQ8B01JPcPcX3X13uDkPqOjYaop0vMMPOmvKcE1EOleUoB8MpE42rgr3teWTwBMp2w48bWYLzWx6W4XMbLqZLTCzBdXV1RGqJXJyWoZu1KOXmIsyj97S7Es7H83MphAE/eSU3Re7+2Yz6wc8Y2Yr3H3uUW/oPpNgyIfKykrNd5NOp0cXS66I0qOvAoakbFcAm1ufZGbnAvcB09x9Z/N+d98cft8OzCIYChLJuMMXYzV0I/EWJejnA6PNbISZFQA3ArNTTzCzocCjwE3uviplf7GZlTa/Bq4ClnRU5UVORqEuxkqOOO7Qjbs3mNltwFNAEnjA3Zea2a3h8RnA14A+wE/NDKDB3SuB/sCscF8e8Gt3f7JTWiLSTs1DN7UKeom5SM+6cfc5wJxW+2akvL4FuCVNuTXAuNb7RbqCwxdjNXQj8aY7YyVn6WKs5AoFveSs/GSCZMJ0Z6zEnoJeclpRXkJDNxJ7CnrJaYX5SQ3dSOwp6CWnFeUlqNU8eok5Bb3ktCL16CUHKOglpwVDN+rRS7wp6CWnFeUnqNWsG4k5Bb3ktKI8Dd1I/CnoJacV5Wt6pcSfgl5ymi7GSi5Q0EtOK8pP6s5YiT0FveQ0Dd1ILlDQS04rzEvqMcUSewp6yWl5CaOhSStXSrwp6CWn5SUTNDQq6CXeFPSS0/KTRn2Txugl3hT0ktPyEgncoUnDNxJjkYLezKaa2UozW21md6U5/mEzWxx+vWhm46KWFcmkvKQBqFcvsXbcoDezJHAPcDUwFvigmY1tddpa4FJ3Pxe4G5jZjrIiGZOXCIJe4/QSZ1F69BOB1e6+xt3rgIeAaaknuPuL7r473JwHVEQtK5JJecngv4CCXuIsStAPBjambFeF+9rySeCJEywrckrlh0M3DRq6kRjLi3COpdmXtvtjZlMIgn7yCZSdDkwHGDp0aIRqiZy8vETYo9fFWImxKD36KmBIynYFsLn1SWZ2LnAfMM3dd7anLIC7z3T3SnevLC8vj1J3kZPWPEZf36gevcRXlKCfD4w2sxFmVgDcCMxOPcHMhgKPAje5+6r2lBXJpOZZNxqjlzg77tCNuzeY2W3AU0ASeMDdl5rZreHxGcDXgD7AT80MoCHsnact20ltEWm3louxGrqRGIsyRo+7zwHmtNo3I+X1LcAtUcuKdBX5CV2MlfiLFPQicZUMg/5XL62nX2nREcfecXpfJgztlYlqiXQoBb3ktKF9ulOUn+DBlzccdezFt3bw209dmIFaiXQsBb3ktDMHlLHsm1OP2j/9VwvZtOdgBmok0vH0UDPJeYmEHfVVVpTHvkP1ma6aSIdQ0IukUVKUR01tQ6arIdIhFPQiaZQW5VFzqAF3TbuU7KegF0mjpDCfhibXwuESCwp6kTRKi4J5CvtqNU4v2U9BL5JGS9Af0ji9ZD8FvUgaJYVB0Nco6CUGFPQiaZQW5QPw8tqdxzlTpOtT0IukMapfCQAbdh3IcE1ETp6CXiSN3sUF9Cst1OOLJRYU9CJtyE8mqFfQSwwo6EXakJ80rTwlsaCgF2lDfjKh59RLLCjoRdqQl0xQ16ChG8l+CnqRNhRo6EZiIlLQm9lUM1tpZqvN7K40x880s5fMrNbMvtDq2Doze8PMFpnZgo6quEhn09CNxMVxFx4xsyRwD3AlUAXMN7PZ7r4s5bRdwO3A9W28zRR333GylRU5lfKSRr2GbiQGovToJwKr3X2Nu9cBDwHTUk9w9+3uPh/QE6AkNvKTCerVo5cYiBL0g4GNKdtV4b6oHHjazBaa2fT2VE4kk4J59Ap6yX5R1oy1NPva83n2YnffbGb9gGfMbIW7zz3qhwS/BKYDDB06tB1vL9I58pOmO2MlFqL06KuAISnbFcDmqD/A3TeH37cDswiGgtKdN9PdK929sry8POrbi3SaZMJYsXUf+7WkoGS5KEE/HxhtZiPMrAC4EZgd5c3NrNjMSptfA1cBS060siKn0sAe3QDYUVOb4ZqInJzjDt24e4OZ3QY8BSSBB9x9qZndGh6fYWYDgAVAGdBkZncAY4G+wCwza/5Zv3b3JzunKSId69yKHgA0NGn4RrJblDF63H0OMKfVvhkpr7cSDOm0thcYdzIVFMmUvETwgbdRQS9ZTnfGirQhmQjmIeiCrGQ7Bb1IG/LCoFePXrKdgl6kDclk2KPXTVOS5RT0Im1Qj17iQkEv0oaWMXoFvWQ5Bb1IGzTrRuJCQS/SBvXoJS4U9CJtODxGr4uxkt0U9CJt0Dx6iQsFvUgb8pKadSPxoKAXaUOexuglJhT0Im1IataNxISCXqQN6tFLXCjoRdpw+GKsZt1IdlPQi7ShIC/47/H7RZsyXBORk6OgF2lD35JCAEoKIy3bINJlKehFjmHckJ7UaR69ZDkFvcgxFCRNY/SS9RT0IseQl0hQr6CXLBcp6M1sqpmtNLPVZnZXmuNnmtlLZlZrZl9oT1mRriw/L6GhG8l6xw16M0sC9wBXA2OBD5rZ2Fan7QJuB350AmVFuiwN3UgcROnRTwRWu/sad68DHgKmpZ7g7tvdfT5Q396yIl2Zhm4kDqIE/WBgY8p2VbgvishlzWy6mS0wswXV1dUR316kc+XnJfT0Ssl6UYLe0uyL+i8/cll3n+nule5eWV5eHvHtRTpXfsKoU49eslyUoK8ChqRsVwCbI77/yZQVybj8pIZuJPtFCfr5wGgzG2FmBcCNwOyI738yZUUyLj/PNHQjWe+493a7e4OZ3QY8BSSBB9x9qZndGh6fYWYDgAVAGdBkZncAY919b7qyndUYkY6Wl0hwoK6RxxZvZtJpfVoeiyCSTSI9xMPd5wBzWu2bkfJ6K8GwTKSyItmivLSQg/WN3Pbr17hp0jDuvv7sTFdJpN10Z6zIMfzTpSP50+cvpV8Y+CLZSEEvcgyJhDGqXwn5yQRNrrF6yU4KepEIEgmiTyoW6WIU9CIRGKYevWQtBb1IBAlTh16yl4JeJAIzQ2uES7ZS0ItEYAauoRvJUgp6kQgMUM5LtlLQi0RgZrhG6SVLKehFIkgYNOnZZpKlFPQiERjq0Uv2UtCLRBBcjM10LUROjIJeJAJNr5RspqAXiSBhoFumJFsp6EUiMEM9eslaCnqRCBJmumFKspaCXiQCQz16yV4KepEIghumRLJTpKA3s6lmttLMVpvZXWmOm5n9JDy+2MwmpBxbZ2ZvmNkiM1vQkZUXOVX0rBvJZsddM9bMksA9wJVAFTDfzGa7+7KU064GRodfFwA/C783m+LuOzqs1iKnWDBGn+laiJyYKD36icBqd1/j7nXAQ8C0VudMA37pgXlATzMb2MF1FcmYYIxeSS/ZKUrQDwY2pmxXhfuinuPA02a20Mymt/VDzGy6mS0wswXV1dURqiVy6qhHL9ksStBbmn2t/8kf65yL3X0CwfDOZ8zsknQ/xN1nunulu1eWl5dHqJbIKWTq0Uv2ihL0VcCQlO0KYHPUc9y9+ft2YBbBUJBIVjF0X6xkryhBPx8YbWYjzKwAuBGY3eqc2cDN4eybScDb7r7FzIrNrBTAzIqBq4AlHVh/kVNCN0xJNjvurBt3bzCz24CngCTwgLsvNbNbw+MzgDnANcBq4ADw8bB4f2CWmTX/rF+7+5Md3gqRTqanV0o2O27QA7j7HIIwT903I+W1A59JU24NMO4k6yiScQndMCVZTHfGikRguhgrWUxBLxKBaXqlZDEFvUgEhh6BINlLQS8SQcI0vVKyl4JeJIJgKUFFvWQnBb1IBAlNr5QspqAXiUSLg0v2UtCLRJDQ8+gliynoRSLQnbGSzRT0IhEYhmvejWQpBb1IBImEFgeX7KWgF4nA0NMrJXsp6EUi0Bi9ZDMFvUgEpqdXShZT0ItEoOmVks0U9CIRGLoYK9lLQS8SQbDwiJJespOCXiQKg6amTFdC5MRECnozm2pmK81stZndlea4mdlPwuOLzWxC1LIi2SARrHsskpWOG/RmlgTuAa4GxgIfNLOxrU67Ghgdfk0HftaOsiJdXjBGr6EbyU5RFgefCKwOF/rGzB4CpgHLUs6ZBvwyXCR8npn1NLOBwPAIZUW6vIQZ2/fVcuWP/5LpqkiM9epewMO3Xtjh7xsl6AcDG1O2q4ALIpwzOGJZAMxsOsGnAYYOHRqhWiKnznsmDKamtkEXZETzfhAAAASaSURBVKVTlRXld8r7Rgn6dIOTrf+1t3VOlLLBTveZwEyAyspK/W+SLmXSaX2YdFqfTFdD5IRECfoqYEjKdgWwOeI5BRHKiohIJ4oy62Y+MNrMRphZAXAjMLvVObOBm8PZN5OAt919S8SyIiLSiY7bo3f3BjO7DXgKSAIPuPtSM7s1PD4DmANcA6wGDgAfP1bZTmmJiIikZV3x+R2VlZW+YMGCTFdDRCRrmNlCd69Md0x3xoqIxJyCXkQk5hT0IiIxp6AXEYm5Lnkx1syqgfUnWLwvsKMDq9OVqG3ZK87tU9u6hmHuXp7uQJcM+pNhZgvauvKc7dS27BXn9qltXZ+GbkREYk5BLyISc3EM+pmZrkAnUtuyV5zbp7Z1cbEboxcRkSPFsUcvIiIpFPQiIjEXm6DP9kXIzWyImf3ZzJab2VIz+2y4v7eZPWNmb4bfe6WU+WLY3pVm9s7M1T4aM0ua2Wtm9li4Hae29TSzR8xsRfh3eGFc2mdmnwv/TS4xs9+YWVE2t83MHjCz7Wa2JGVfu9tjZueb2RvhsZ+YdeEV5N09678IHoH8FnAawWInrwNjM12vdrZhIDAhfF0KrCJYUP0HwF3h/ruA74evx4btLARGhO1PZrodx2nj54FfA4+F23Fq2y+AW8LXBUDPOLSPYDnQtUC3cPth4GPZ3DbgEmACsCRlX7vbA7wCXEiwkt4TwNWZbltbX3Hp0bcsYO7udUDzIuRZw923uPur4et9wHKC/2TTCEKE8Pv14etpwEPuXuvuawnWAph4amsdnZlVAO8C7kvZHZe2lRGEx/0A7l7n7nuISfsI1q3oZmZ5QHeCVeKytm3uPhfY1Wp3u9pjZgOBMnd/yYPU/2VKmS4nLkHf1uLkWcnMhgPnAS8D/T1YrYvwe7/wtGxr878DdwJNKfvi0rbTgGrg5+HQ1H1mVkwM2ufum4AfARuALQSrxz1NDNrWSnvbMzh83Xp/lxSXoI+8CHlXZ2YlwO+AO9x977FOTbOvS7bZzK4Ftrv7wqhF0uzrkm0L5REMBfzM3c8D9hN8/G9L1rQvHKueRjBsMQgoNrOPHKtImn1dsm0RtdWerGpnXII+ygLmXZ6Z5ROE/IPu/mi4e1v4MZHw+/Zwfza1+WLgOjNbRzCs9vdm9r/Eo20Q1LfK3V8Otx8hCP44tO8KYK27V7t7PfAocBHxaFuq9ranKnzden+XFJegz/pFyMMr9vcDy939xymHZgMfDV9/FPhDyv4bzazQzEYAowkuDnU57v5Fd69w9+EEfzfPuftHiEHbANx9K7DRzM4Id10OLCMe7dsATDKz7uG/0csJrh/FoW2p2tWecHhnn5lNCv9cbk4p0/Vk+mpwR30RLE6+iuCq+JczXZ8TqP9kgo9+i4FF4dc1QB/gWeDN8HvvlDJfDtu7ki58xb9VOy/j8Kyb2LQNGA8sCP/+fg/0ikv7gG8CK4AlwK8IZqBkbduA3xBcb6gn6Jl/8kTaA1SGfyZvAf9F+KSBrvilRyCIiMRcXIZuRESkDQp6EZGYU9CLiMScgl5EJOYU9CIiMaegFxGJOQW9iEjM/X8iE5/ZUaRpLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd8b2828438>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfZyVdZ3/8dfn3Mz9DLfD3QACMoCgeDeirqaiqHizYTdbWG1b2brsZqa2v9bK2n6/erRrtbvlL4vIXCsrsyxjlaTUTM1UhkQU5E5AGARmAJn7mXP33T/OmfEwDHAGznBxruv9fDx4cM51vufw+R7OvOd7vtf3ui5zziEiIoUv5HUBIiKSHwp0ERGfUKCLiPiEAl1ExCcU6CIiPhHx6h8eOXKkmzRpklf/vIhIQVq5cuUe51x1f495FuiTJk2ivr7eq39eRKQgmdkbh3pMUy4iIj6hQBcR8QkFuoiITyjQRUR8QoEuIuITCnQREZ9QoIuI+IRn69ALVXt3gude38vuli5mjKlk1fb9zD91DOOHlXldmogEnAJ9AL7/9Ga++tvX6HsK+TsfW8c7T69heHmUSDjE379jCvFkijf2dnD2ScMIh6y3bUcsQThkFEfCx7l6EfE7BfoA/PTFbYyqLOY/33cGQ0qjvN7URnEkzD3PbOaPG5p4qyNGMuX47lOv9z7nA+dO5KvvOo1kyvHG3nY+dM8LlBSFefLTl3jXERHxJQX6EWxqbOP5zXtZu7OFLXva+cz86VwwdSQAp9YMAWD+qWMAcM7x8xXbufdPW5g6qoJIKMRPX9jGT1/YdtDrdsWTlETDpFKOUNYI/kTXGUtyx8OvMqW6nH+8+OSCql3E7xToh9EVT/Ke7z5Hc2e8d9u5k0ccsr2ZsXDORBbOmQhAMuUYO7SE7/1xMwBfvHYmLV1xvvn4Ru56YiO/XNlAc2eceaeMpmZYKTVDSwF479njKS/29r8mlXJsbGzjrY4Y504ejlk6uBf/8XUe+ksDACXRMDdcONnLMkUkS0EGemtXnMqS6KD/O39Y10hzZ5yvvWc2IyuLOHXcEEZVleT8/HDIuH3+DM6cMIxpoyuYUl3BMxubAPhO1rTMo6/sPOB5v1zZwP988sL8dOIoOOf4h/tX8vu1uwF4R+1IZoyppGZoKT94dgvjh5VycnUFX3l0LZNGlHHZKaM9q1VE3mZeXSS6rq7OHc3ZFp9a38ii+1dSXVlMeVGEf75iOvNmjubR1TuJhI0rZo7uHU0ei71t3Zz9lccZUhpl5R3ziITzs8Izlkjxw+e2Mm1MJbPGVTG8rIh9HTHqt+5jdFUJn/7Fy2xuaucTc0/mn6+Yfkx92b6vg+c37+Xa2eMoLQqzblcL/7ZsHWbw7rPGM3d6NVv3dNAZT7KzuZPXG9vY3xnnZy9uI550fOSvJrFtXwdPrmvsfc2yojC//qcLmDC8lGvvepbNe9q5ZvZY/t87ZzGkNMrXf7eecycP59IZo+mKJ1ny9Gb2tce47YppVB2HX8IifmdmK51zdf0+VmiBvnVPO19d9hqxZIqn1jcRCRm1oyt5bWcLAHdccwrvP2cCTa3dTKmuANIjzo5Yki172imOhKgdXdnva7d1J6gojtDWneCy/3iK3S3d3DKvllvmTTv6jg5Qc2ecm3/2En/c0MTX3zubv6mbMKDn79jfSTRkfO7Xr/L4a7t7t7/wuct493eeY8f+zsM+Pxo2IqEQE4aXsvSmCymJhkmmHF3xJM9u2kPdScMYUVEMwOtNbXzr8Y0sX7OLMUNK+OxVp7Do/pUADCmN0toVJ5X5eF04dSQ/vmFOXn7ZigSZrwI9W2NLF3c+tp7nXt9DaTRMVzzJm81dAJjBP18xnYriCN/43XpauxK9z7v/hnO5sDa9Y9M5x5Y97Xz+16/y5817uWR6NaMqi3mwvoHvfPAsrj5t7DHVeDTiyRRnf/n3nDFxGD/62Jycn/dg/XY+88vVvfc/fuFklr2ys/c9Abhp7lTOmzKCL/zmVfa1x7jslFGs2LqPRRefzOyaoYweUsyQ0ighM6I5fit5ccs+rv/+8yRTb3+WRlYUMbKimFvm1bK7pZt/XbqGKdXlfPLSqbzz9JoDlnKKSO58G+h97WuPcftDq9nU2MbmPe0HPf6Rv5rEfc9t5ZOXTmXD7lZe3t7MnrZuEilHaTRMZzzZ2/aiadXc95FzPFvF8dVlr3Hvs1t45UtX0hVPsv2tDmaPH9pv27buBI+v3c1tD64i5aA0Gub6ORP5wrWnYGasfbOFB+u388qOZr7/4TqGlxcB5HWFzUvb3uLOx9ZxwckjuenSqQC9o/GueJIZX3ist+0pY6v44rUzmTm2iob9HcwaNyQvNYgEQWACPduetm5e3r6fCcPLmDSinGTKUVoUZu43nmJLJux7plcAvrXwDC6ZPoqnNzTx0rb93Hp57XHZ8XooT7y2mxt+WE9RJEQskQJg5R3zeqc7ejS81cE1dz1Lc2ecqaMq+MU/nM+wTGCfSJ5ctxvDeL2pjSVPb6axtbv3sbnTq/n+h+vytp9CxM8CGeiHsnzNLv7hx+l53rs/cBZXnzaG3S3djBmS++qV46ErnuQrj66lqbWbzU3tbGxs478/eg5zp486oN2Xlq7hR3/eyuIPnc07aqspLTrxj0Ddvq+Df3loNUWREGVFYZa9sosPnjuRT18xvffbg4j075gD3czmA98CwsA9zrl/76fNJcA3gSiwxzl38eFe06tAB7jt56v41Us7+N2tFzHtEDtITyRt3QlO+9JyLpsxmlnjqmjujDOlupytezq4909beNeZNfzX+8/wusyj4pzjjodf5ScvbCMaNm6+tJZPzJ2qA5ZEDuGYAt3MwsAG4HKgAVgBXO+cW5vVZijwHDDfObfNzEY55xr7fcEMLwM9lXLsauliXOZAnkJw3d1/YtX2/Qdtnza6gm++/0xmjqvyoKr8Wb+rlW89sYFlr+zi5kunctsV070uSeSEdKyBfj7wJefclZn7nwVwzv1bVpt/AsY55+7ItSgvA70QdcWTPLp6J6/saOYz86ez461OYskUM8dW+WYpoHOORfev5MUt+6i/43KthBHpx+ECPZe9UDXA9qz7DZlt2aYBw8zsKTNbaWYfPkQhN5pZvZnVNzU15VK7ZJREw7zn7PF86Z2zKCuKUDu6klnjhvgmzCG9Kuadp9fwVkecpzfq8yEyULkEen+J0XdYHwHOBq4BrgS+YGYHHY3jnFvinKtzztVVV1cPuFjxv4unVzNuSAn/5xereX7zXq/LESkouQR6A5B9uOJ44M1+2jzmnGt3zu0BngZOz0+JEiQVxRHu+9gczGDhkue57eereKs95nVZIgUhl0BfAdSa2WQzKwIWAkv7tPkN8A4zi5hZGXAu8Fp+S5WgmDa6ksdvvZgPnTeRX720g0uyjh0QkUM7YqA75xLATcBy0iH9oHNujZktMrNFmTavAY8Bq4EXSS9tfHXwyha/G1IW5SvXncaPb5hDIpni5p+9RCrlzTETIoUicAcWSeF5aGUDn/7Fyyw8ZwL//p7ZXpcj4qljXeUi4ql3n1XDu8+s4cH67QdcbEREDqRAlxOemXHdmTWkHKx9s8XrckROWAp0KQgnj0qf235jY6vHlYicuBToUhDGVpUwcXgZj7y888iNRQJKgS4FIRQyzpsynDf2afmiyKEo0KVgjBlSSmNrN/FkyutSRE5ICnQpGDPGVOIcvO97f+aHz231uhyRE44CXQrG/FljuHXeNJo74/zr0jV88TevHnAdU5GgU6BLwQiFjE/Nq+V3t1zEe88ez4/+/AbX3PUMv31lp44iFUGBLgUoEg7xjb85nW8tPINYIsU//uQvfHWZTh0kokCXgrXgjBp+f9vFXH3aGH764rbei2mLBJUCXQpaOGQsOKOGjliSl7a95XU5Ip5SoEvBO//kEYRDxjMb93hdioinFOhS8KpKosweP4QXt+zzuhQRTynQxRdGV5boTIwSeAp08YWy4jDtsYTXZYh4SoEuvlBRHKG9W4EuwaZAF18oK4rQHkt6XYaIpxTo4gvlRWFiiZRO3CWBpkAXXygrjgDQ1NrtcSUi3lGgiy+cO3k44ZDxtcfW4dWFz0W8pkAXXzi1Zgh/e95JPLzqTZ54rdHrckQ8kVOgm9l8M1tvZpvM7PZ+Hr/EzJrNbFXmzxfzX6rI4d12xTQANui6oxJQkSM1MLMwcDdwOdAArDCzpc65tX2aPuOcu3YQahTJSVVJlGFlUb722HoumTaKmeOqvC5J5LjKZYQ+B9jknNvsnIsBDwALBrcskaPzH+87naFlUT523woSWvEiAZNLoNcA27PuN2S29XW+mb1sZr81s1n9vZCZ3Whm9WZW39TUdBTlihzepTNG8/mrT2FXSxdb9+qC0hIsuQS69bOt7zKCvwAnOedOB/4/8HB/L+ScW+Kcq3PO1VVXVw+sUpEc1QwrBaBRSxglYHIJ9AZgQtb98cCb2Q2ccy3OubbM7WVA1MxG5q1KkQEYVVkCaE26BE8ugb4CqDWzyWZWBCwElmY3MLMxZmaZ23Myr7s338WK5GLMkHSgv7G3w+NKRI6vI65ycc4lzOwmYDkQBu51zq0xs0WZxxcD7wX+0cwSQCew0OnoDvFIRXGEGWMqeWHLXqDW63JEjpsjBjr0TqMs67NtcdbtbwPfzm9pIkfv/JNH8NMXttGdSFIcCXtdjshxoSNFxZfOPmkY3YkU63fpICMJDgW6+NLZJw3DDL739GZau3QlIwkGBbr40tghpXz8wsk8unonN/yw3utyRI6LnObQRQrR56+ZSUtngt+8vAPnHJmFWCK+pRG6+Frt6Aq64ildQFoCQYEuvjZ5ZDkAy9fs8rgSkcGnQBdfmzt9FAANb3V6XInI4FOgi6+FQkZ5UZhOXUBaAkCBLr5XWhSmI65AF/9ToIvvlRaF6dIIXQJAgS6+VxoN06kRugSAAl18rzQapkMjdAkABbr4XmmRRugSDAp08b1xQ0rZuLuVWELXGBV/U6CL7117+lje6ojr4CLxPQW6+N5FtdXMGFPJlx9ZSyKpUbr4lwJdfC8SDvGJuVNpbO3m3367Dl1MS/xKgS6BMHfGKOZMHs4Pnt3Cr1/a4XU5IoNCgS6BUFEc4YG/P49Z46q477mtXpcjMigU6BIYoZBx/pQRbNjdSiqlaRfxHwW6BMrk6nK64il2tXR5XYpI3uUU6GY238zWm9kmM7v9MO3OMbOkmb03fyWK5E/P+dG37Gn3uBKR/DtioJtZGLgbuAqYCVxvZjMP0e5OYHm+ixTJl5OrKwD406Y9Hlcikn+5jNDnAJucc5udczHgAWBBP+0+CTwENOaxPpG8Gl1VwhkThvLMRgW6+E8ugV4DbM+635DZ1svMaoB3AYvzV5rI4DhlbBU79usKRuI/uQR6f5dK77tE4JvAvzjnDnsGJDO70czqzay+qakp1xpF8qpmaAn72mN06YRd4jORHNo0ABOy7o8H3uzTpg54wMwARgJXm1nCOfdwdiPn3BJgCUBdXZ3WjYknhpRGAWjrTlASDXtcjUj+5BLoK4BaM5sM7AAWAh/IbuCcm9xz28zuAx7pG+YiJ4qyovTHvr07wciKYo+rEcmfIwa6cy5hZjeRXr0SBu51zq0xs0WZxzVvLgWlvLgn0DXlIv6Sywgd59wyYFmfbf0GuXPuI8delsjgKS9OT7N0xBIeVyKSXzpSVAKnZ8qlrVuBLv6iQJfAqdCUi/iUAl0CpyiS/tjHdbEL8RkFugROOL28lqTOuCg+o0CXwAllPvVJXblIfEaBLoETDqVH6DonuviNAl0Cp3fKRSN08RkFugROSCN08SkFugSOdoqKXynQJXB6RuhJ5bn4jAJdAkc7RcWvFOgSONopKn6lQJfA6V2HrhG6+IwCXQKnZ4SuKRfxGwW6BE44pCkX8ScFugSOmWGmEbr4jwJdAilsphG6+I4CXQIpFDJ09lzxGwW6BFLYjJRG6OIzCnQJpHDItGxRfEeBLoEUMq1DF/9RoEsgaYQufpRToJvZfDNbb2abzOz2fh5fYGarzWyVmdWb2YX5L1Ukf8IhrXIR/4kcqYGZhYG7gcuBBmCFmS11zq3NavYEsNQ558xsNvAgMGMwChbJh5CZ1qGL7+QyQp8DbHLObXbOxYAHgAXZDZxzbc71DnfKAf2kyAlNUy7iR7kEeg2wPet+Q2bbAczsXWa2DngU+Fh/L2RmN2amZOqbmpqOpl6RvAjpwCLxoVwC3frZdtBPgnPu1865GcB1wJf7eyHn3BLnXJ1zrq66unpglYrkUTikKRfxn1wCvQGYkHV/PPDmoRo7554GTjazkcdYm8igiYSMhAJdfCaXQF8B1JrZZDMrAhYCS7MbmNlUs/Q5Sc3sLKAI2JvvYkXypbw4Qnt3wusyRPLqiKtcnHMJM7sJWA6EgXudc2vMbFHm8cXAe4APm1kc6ATen7WTVOSEU1kSobVLgS7+csRAB3DOLQOW9dm2OOv2ncCd+S1NZPBUlUTZvKfN6zJE8kpHikogaYQufqRAl0CqKo3S0hn3ugyRvFKgSyBVlkRojyVJ6KTo4iMKdAmkqpIoAG1a6SI+okCXQKosSa8H0Dy6+IkCXQKpqjQ9Qm/WPLr4iAJdAkkjdPEjBboEUnlROtA7Ygp08Q8FugRSWVEYgI5Y0uNKRPJHgS6BVJoJ9E4FuviIAl0CqTSaCfS4Al38Q4EugVTWO4euQBf/UKBLIJVEQ5hBp3aKio8o0CWQzIxoOMRdT26iuUNr0cUfFOgSWPNOGQXAul0tHlcikh8KdAmsW+dNA2BXS5fHlYjkhwJdAmv0kBIAPvXAKlZs3edxNSLHToEugVVVEuVTl9UC8EpDs8fViBw7BboE2icvnQronC7iDwp0CbRIOERZUZjWLq10kcKnQJfAqyyJ0KJAFx9QoEvgVZZENeUivpBToJvZfDNbb2abzOz2fh7/oJmtzvx5zsxOz3+pIoOjJBqiO6Fri0rhO2Kgm1kYuBu4CpgJXG9mM/s02wJc7JybDXwZWJLvQkUGS9iMZMp5XYbIMctlhD4H2OSc2+yciwEPAAuyGzjnnnPOvZW5+zwwPr9ligyeUMhIOQW6FL5cAr0G2J51vyGz7VBuAH7b3wNmdqOZ1ZtZfVNTU+5VigyikCnQxR9yCXTrZ1u/n34zm0s60P+lv8edc0ucc3XOubrq6urcqxQZRJpyEb+I5NCmAZiQdX888GbfRmY2G7gHuMo5tzc/5YkMvlAIUtonKj6Qywh9BVBrZpPNrAhYCCzNbmBmE4FfAX/rnNuQ/zJFBo+mXMQvjjhCd84lzOwmYDkQBu51zq0xs0WZxxcDXwRGAN8xM4CEc65u8MoWyZ9wyEgq0MUHcplywTm3DFjWZ9virNsfBz6e39JEjo/0CN3rKkSOnY4UlcALGaSU6OIDCnQJvHBIq1zEHxToEnjaKSp+oUCXwFOgi18o0CXwNOUifqFAl8ALhQwN0MUPFOgSeCFD69DFFxToEng6l4v4hQJdAk9TLuIXCnQJvJChEbr4ggJdAk/nchG/UKBL4IXMcAp08QEFugReSDtFxScU6BJ4OrBI/CKn0+eK+Fl6ysXrKvzjc79+hf9ZddBFzQBYcOY4vnLdace5ouBQoEvg6cCi/Hph816qK4u5ZPqoA7b/YX0jL27Z51FVwaBAl8DTlEt+tXUnuGTaKL741zMP2N7SFee5TXs8qioYNIcugacDi/KrrStBRcnBY8WK4git3QkPKgoOBboEnqZc8ieZcrTHklQUHxzolSUR2roTWiI6iDTlIoHXcy6XB1dsB6A4GuLKWWMoiYY9ruz429vWzZPrGnP+xnLRtGrKi8P8bs1ukilHdyIJpMO7r4riCM7BT17YRlH44LFkNGJcOWsMZUXexdKu5i6e3tCUc/twyLhi1mgqS6KHbdcRS7B8zS7iifQbO31MJadPGHpMtfZHgS6BN6qqBIDPPLS6d9vdHziLa2aP9aokz9zz7Ba++9TrObe/fs5Epo6q4MuPrD1g+/hhZQe1nTg8ve2Oh1895Ot97T2O950zIed/P9/+6/cb+Hn99gE951+7ZvLRCyYfts3SVW9y+69e6b2/6OKTvQt0M5sPfAsIA/c45/69z+MzgP8GzgI+75z7Rr4LFRksHzx3IvNOGU3SOfa0drPg7j/R3Bn3uixPNHfGGVYW5ZGb33HEth/4/vO0dMZ736tnPjOXUMiIho1RlSUHtb/qtLG8+LnLiPezA7qjO8Hl//W05+97c2ecySPLuf/j5x6xbSrleMfX/pBTzT1tHr/tIkqLIv1OSeXDEV/VzMLA3cDlQAOwwsyWOueyfyXvA24GrhuUKkUGkZkxZkg6gHp+0DrjSS9L8kxXLEl5cYSaoaVHbFtZEqEznqQrnqQkGmLC8INH5X31fBvqK5FMAd6/753xJFUlufUfoCgSyqnmnjaTR1YQDtkx1Xg4uewUnQNscs5tds7FgAeABdkNnHONzrkVQDCHNeIbZUXpefPOWDBXY3TEkr3vwZGURSN0xBJ0xBLHPO8dCYcoCofoiHkc6LEkpTn2H9Kfl84cau6MJSmOhAY1zCG3QK8BsieVGjLbBszMbjSzejOrb2rKfceDyPESDYeIhs3zYPFKRzxJaY7hXJoJs45YktI87EBOv563v0g74gP75VQWDef0WRnIL8pjkUug9/cr5ajWHTnnljjn6pxzddXV1UfzEiKDrjTHH1I/6owlKMsxnMuK0u9TZ57Cquf1vNQxwBF6aY4j9HSgD/4alFz+hQYge7fzeKD/EzWI+EBJNMyrO5pxzmE2uF+Rj7eWrjibm9p770fDRnEkTFvmgJ997TFOGlGe02uVRsM0d8ZpbO0eUAge7vV2Nnexavv+nJ8TNqN2dAUbd7eRdI6hpVEmjcyt/mw970tLZ2JA3zZKi8LsbjlyzbtaOimJDv5hP7kE+gqg1swmAzuAhcAHBrUqEQ+FzKh/4y1e2dHM7PH5X1rmpVseWMWT6xoP2+bMicNyeq3h5UU0tnbT2NrNJdOP/Rv38PIint20h2cHeHqACcNL2b6vEwAzeOFzl/W7yuZwbn1gFU9k3pcR5UU5P294eTFPb2jiurv/dMS2cyYNH1BNR+OIge6cS5jZTcBy0ssW73XOrTGzRZnHF5vZGKAeqAJSZnYLMNM51zKItYsMituvmsEtP1/F/g7/7ePf2x7jtJoh3Hb5NFq7E9z8s5cAuO3yaZxWMwSAM3JcH/2pebVcUDsSHMwaV3XMtd11/Zms39U6oOfc8MMVbN/XSThk3HjRFL771Os0d8QHHOh722OcWlPFp6+YTt1Juf1CA/jGe2ez5s3cYm7G2MoB1XQ0cprUcc4tA5b12bY46/Yu0lMxIgVv4oj08js/ng6gO55k4vAy5s4YRXvWeVXOmTSc808eMaDXqiyJMrfPGRWPxbihpYzLcblgj+JImM54eqfsWZlvFt2J1ID/7e5EivHDSgfcn1FVJYdciukFnctFpI9QZt7cj+cciSVSFEXSP/bFkbd//IuPw/zuYOjpS1Ek1Hu75/QDA9GdSB7wfhSqwu+BSJ6FM4GeHPhA74TXnUhRHEnv9ItknU+lv3OrFILirF9OPbe740cxQo+//YuukBV+D0TyLJT5qfDjOdK7E6l+R+PHYwXGYOjpywGBfhS/iWPJt3/RFbLC/F8UGUQ9R/OlfDjl0p1I9jsaL9Qw6+nLAVMuRzVC15SLiC+9PeXix0Dvf4ReqGHW84uoOBLuvX10c+j9vy+FpvB7IJJnIZ+O0J1zxBL9Ty0U6gi93ymXAa5ycc4dsG+hkOl86CJ9FNoIfV97LKdRaSwTdP2Nxgt1h2D2lEtPv5pau9nZ3Jnza/RcdKJQv6VkU6CL9NGzbLEQ8nzF1n38zeI/D+g55VmH6RdHQnQnCneFR8+VkcqLI5QVRzCDry9fz9eXrx/wa5Ufh5NnDTYFukgfPatcUgWQ6Luau4D0kZ6jKouP2D4SDnHlrNG9939z0wXsa4sN+mldB8sd18xk3imjOW/KCCqKI9z30Tns3J/76LxHOGRceeqYQajw+FKgi/TRE26FcKRoz7TQX58+jslHcVKqGWOO/ZB9L00aWX7Aybgunhbss7gW5vcskUFUSHPo8cya60iBjrAlvxToIn0U0iqXnl86kbACXRToIgcpqBF6T6CH9KMsCnSRg7w9Qve4kBwkNeUiWRToIn30ZGMhrHJJaMpFsijQRfoopFUuCU25SBZ9CkT6CBXQHHqiZ8pFI3RBgS5ykN6zLRZAoMeT6RrDPruYtRwdBbpIH72rXApgyiWZcoTs7R25EmwKdJE+QoU0Qk+lDrjykASbPgki/QhZoSxbdFqyKL0U6CL9CIesIKZcEikFurwtp0A3s/lmtt7MNpnZ7f08bmZ2V+bx1WZ2Vv5LFTl+QmYFMeWS0JSLZDniJ8HMwsDdwFXATOB6M5vZp9lVQG3mz43Ad/Ncp8hxFQ5ZgSxb1Ahd3pbL6XPnAJucc5sBzOwBYAGwNqvNAuBHzjkHPG9mQ81srHNuZ94rFjkOwmb88i8N/HFDk9elHNauli4qi3UWbEnL5ZNQA2zPut8AnJtDmxrggEA3sxtJj+CZOHHiQGsVOW4+celUVjfs97qMI6odXcG5k0d4XYacIHIJ9P6+z/X9LppLG5xzS4AlAHV1dSf+91kJrEUXn+x1CSIDlsvelAZgQtb98cCbR9FGREQGUS6BvgKoNbPJZlYELASW9mmzFPhwZrXLeUCz5s9FRI6vI065OOcSZnYTsBwIA/c659aY2aLM44uBZcDVwCagA/jo4JUsIiL9yWn3uHNuGenQzt62OOu2Az6R39JERGQgdESCiIhPKNBFRHxCgS4i4hMKdBERnzDn0RnlzKwJeOMonz4S2JPHcgqB+hwM6nMwHEufT3LOVff3gGeBfizMrN45V+d1HceT+hwM6nMwDFafNeUiIuITCnQREZ8o1EBf4nUBHlCfg0F9DoZB6XNBzqGLiMjBCnWELiIifSjQRUR8ouAC/UgXrC5EZjbBzP5gZq+Z2Roz+1Rm+3Az+72Zbcz8PSzrOZ/NvAfrzR/6mdQAAANZSURBVOxK76o/NmYWNrOXzOyRzH1f9zlzecZfmtm6zP/3+QHo862Zz/WrZvYzMyvxW5/N7F4zazSzV7O2DbiPZna2mb2SeewuMxvYBWOdcwXzh/Tpe18HpgBFwMvATK/rykO/xgJnZW5XAhtIX5D7a8Dtme23A3dmbs/M9L0YmJx5T8Je9+Mo+34b8FPgkcx9X/cZ+CHw8cztImCon/tM+lKUW4DSzP0HgY/4rc/ARcBZwKtZ2wbcR+BF4HzSV4H7LXDVQOootBF67wWrnXMxoOeC1QXNObfTOfeXzO1W4DXSPwgLSAcAmb+vy9xeADzgnOt2zm0hfR76Oce36mNnZuOBa4B7sjb7ts9mVkX6B/8HAM65mHNuPz7uc0YEKDWzCFBG+mpmvuqzc+5pYF+fzQPqo5mNBaqcc3926XT/UdZzclJogX6oi1H7hplNAs4EXgBGu8yVnzJ/j8o088v78E3gM0Aqa5uf+zwFaAL+OzPNdI+ZlePjPjvndgDfALaRvmh8s3Pud/i4z1kG2seazO2+23NWaIGe08WoC5WZVQAPAbc451oO17SfbQX1PpjZtUCjc25lrk/pZ1tB9Zn0SPUs4LvOuTOBdtJfxQ+l4PucmTdeQHpqYRxQbmYfOtxT+tlWUH3OwaH6eMx9L7RA9+3FqM0sSjrMf+Kc+1Vm8+7M1zAyfzdmtvvhfbgAeKeZbSU9dXapmd2Pv/vcADQ4517I3P8l6YD3c5/nAVucc03OuTjwK+Cv8Hefewy0jw2Z232356zQAj2XC1YXnMye7B8Arznn/jProaXA32Vu/x3wm6ztC82s2MwmA7Wkd6YUDOfcZ51z451zk0j/Pz7pnPsQ/u7zLmC7mU3PbLoMWIuP+0x6quU8MyvLfM4vI72PyM997jGgPmamZVrN7LzMe/XhrOfkxuu9w0exN/lq0qtAXgc+73U9eerThaS/Wq0GVmX+XA2MAJ4ANmb+Hp71nM9n3oP1DHBP+In2B7iEt1e5+LrPwBlAfeb/+mFgWAD6/H+BdcCrwI9Jr+7wVZ+Bn5HeRxAnPdK+4Wj6CNRl3qfXgW+TOZo/1z869F9ExCcKbcpFREQOQYEuIuITCnQREZ9QoIuI+IQCXUTEJxToIiI+oUAXEfGJ/wUvUUElJ+aYmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 368 steps, validate for 368 steps\n",
      "Epoch 1/3000\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.7701 - mse: 0.7635 - val_loss: 0.5654 - val_mse: 0.5588\n",
      "Epoch 2/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.6141 - mse: 0.6074 - val_loss: 0.5435 - val_mse: 0.5368\n",
      "Epoch 3/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5966 - mse: 0.5900 - val_loss: 0.5336 - val_mse: 0.5269\n",
      "Epoch 4/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5949 - mse: 0.5882 - val_loss: 0.5277 - val_mse: 0.5210\n",
      "Epoch 5/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5798 - mse: 0.5730 - val_loss: 0.5282 - val_mse: 0.5215\n",
      "Epoch 6/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5940 - mse: 0.5872 - val_loss: 0.5281 - val_mse: 0.5213\n",
      "Epoch 7/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5751 - mse: 0.5683 - val_loss: 0.5271 - val_mse: 0.5203\n",
      "Epoch 8/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5758 - mse: 0.5690 - val_loss: 0.5317 - val_mse: 0.5249\n",
      "Epoch 9/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5816 - mse: 0.5749 - val_loss: 0.5516 - val_mse: 0.5448\n",
      "Epoch 10/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5711 - mse: 0.5643\n",
      "Epoch 00010: saving model to Regression_Model/mle.linear-0010.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5708 - mse: 0.5640 - val_loss: 0.5424 - val_mse: 0.5356\n",
      "Epoch 11/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5695 - mse: 0.5628 - val_loss: 0.5255 - val_mse: 0.5187\n",
      "Epoch 12/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5732 - mse: 0.5664 - val_loss: 0.5174 - val_mse: 0.5106\n",
      "Epoch 13/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5699 - mse: 0.5631 - val_loss: 0.5387 - val_mse: 0.5319\n",
      "Epoch 14/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5718 - mse: 0.5650 - val_loss: 0.5224 - val_mse: 0.5156\n",
      "Epoch 15/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5816 - mse: 0.5748 - val_loss: 0.5254 - val_mse: 0.5186\n",
      "Epoch 16/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5646 - mse: 0.5578 - val_loss: 0.5190 - val_mse: 0.5122\n",
      "Epoch 17/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5713 - mse: 0.5645 - val_loss: 0.5305 - val_mse: 0.5237\n",
      "Epoch 18/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5732 - mse: 0.5664 - val_loss: 0.5435 - val_mse: 0.5367\n",
      "Epoch 19/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5687 - mse: 0.5619 - val_loss: 0.5120 - val_mse: 0.5052\n",
      "Epoch 20/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5677 - mse: 0.5609\n",
      "Epoch 00020: saving model to Regression_Model/mle.linear-0020.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5679 - mse: 0.5611 - val_loss: 0.5237 - val_mse: 0.5169\n",
      "Epoch 21/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5625 - mse: 0.5558 - val_loss: 0.5077 - val_mse: 0.5009\n",
      "Epoch 22/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5695 - mse: 0.5628 - val_loss: 0.5553 - val_mse: 0.5485\n",
      "Epoch 23/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5702 - mse: 0.5635 - val_loss: 0.5064 - val_mse: 0.4996\n",
      "Epoch 24/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5582 - mse: 0.5515 - val_loss: 0.5203 - val_mse: 0.5135\n",
      "Epoch 25/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5617 - mse: 0.5549 - val_loss: 0.5096 - val_mse: 0.5028\n",
      "Epoch 26/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5567 - mse: 0.5500 - val_loss: 0.5087 - val_mse: 0.5020\n",
      "Epoch 27/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5705 - mse: 0.5638 - val_loss: 0.5055 - val_mse: 0.4988\n",
      "Epoch 28/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5543 - mse: 0.5475 - val_loss: 0.5207 - val_mse: 0.5139\n",
      "Epoch 29/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5625 - mse: 0.5558 - val_loss: 0.5035 - val_mse: 0.4967\n",
      "Epoch 30/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5596 - mse: 0.5529\n",
      "Epoch 00030: saving model to Regression_Model/mle.linear-0030.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5610 - mse: 0.5543 - val_loss: 0.5046 - val_mse: 0.4978\n",
      "Epoch 31/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5642 - mse: 0.5575 - val_loss: 0.5473 - val_mse: 0.5406\n",
      "Epoch 32/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5663 - mse: 0.5596 - val_loss: 0.5141 - val_mse: 0.5074\n",
      "Epoch 33/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5724 - mse: 0.5657 - val_loss: 0.5137 - val_mse: 0.5070\n",
      "Epoch 34/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5593 - mse: 0.5526 - val_loss: 0.5075 - val_mse: 0.5008\n",
      "Epoch 35/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5701 - mse: 0.5634 - val_loss: 0.5130 - val_mse: 0.5063\n",
      "Epoch 36/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5575 - mse: 0.5508 - val_loss: 0.5037 - val_mse: 0.4970\n",
      "Epoch 37/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5613 - mse: 0.5546 - val_loss: 0.5027 - val_mse: 0.4960\n",
      "Epoch 38/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5510 - mse: 0.5443 - val_loss: 0.5128 - val_mse: 0.5061\n",
      "Epoch 39/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5673 - mse: 0.5606 - val_loss: 0.5494 - val_mse: 0.5427\n",
      "Epoch 40/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5618 - mse: 0.5551\n",
      "Epoch 00040: saving model to Regression_Model/mle.linear-0040.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5600 - mse: 0.5533 - val_loss: 0.5134 - val_mse: 0.5067\n",
      "Epoch 41/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5508 - mse: 0.5441 - val_loss: 0.4990 - val_mse: 0.4923\n",
      "Epoch 42/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5563 - mse: 0.5496 - val_loss: 0.5006 - val_mse: 0.4939\n",
      "Epoch 43/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5547 - mse: 0.5481 - val_loss: 0.4998 - val_mse: 0.4931\n",
      "Epoch 44/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5556 - mse: 0.5489 - val_loss: 0.5040 - val_mse: 0.4973\n",
      "Epoch 45/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5566 - mse: 0.5500 - val_loss: 0.5278 - val_mse: 0.5212\n",
      "Epoch 46/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5546 - mse: 0.5479 - val_loss: 0.5018 - val_mse: 0.4951\n",
      "Epoch 47/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5551 - mse: 0.5484 - val_loss: 0.5176 - val_mse: 0.5109\n",
      "Epoch 48/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5618 - mse: 0.5552 - val_loss: 0.5046 - val_mse: 0.4980\n",
      "Epoch 49/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5675 - mse: 0.5608 - val_loss: 0.5075 - val_mse: 0.5009\n",
      "Epoch 50/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5510 - mse: 0.5443\n",
      "Epoch 00050: saving model to Regression_Model/mle.linear-0050.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5517 - mse: 0.5451 - val_loss: 0.5089 - val_mse: 0.5023\n",
      "Epoch 51/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5567 - mse: 0.5501 - val_loss: 0.5054 - val_mse: 0.4988\n",
      "Epoch 52/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5588 - mse: 0.5522 - val_loss: 0.4999 - val_mse: 0.4932\n",
      "Epoch 53/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5490 - mse: 0.5424 - val_loss: 0.4970 - val_mse: 0.4904\n",
      "Epoch 54/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5500 - mse: 0.5434 - val_loss: 0.4988 - val_mse: 0.4922\n",
      "Epoch 55/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5560 - mse: 0.5493 - val_loss: 0.5201 - val_mse: 0.5135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5512 - mse: 0.5446 - val_loss: 0.4989 - val_mse: 0.4923\n",
      "Epoch 57/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5496 - mse: 0.5430 - val_loss: 0.5065 - val_mse: 0.4999\n",
      "Epoch 58/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5507 - mse: 0.5441 - val_loss: 0.5008 - val_mse: 0.4942\n",
      "Epoch 59/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5553 - mse: 0.5487 - val_loss: 0.5064 - val_mse: 0.4998\n",
      "Epoch 60/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5558 - mse: 0.5492\n",
      "Epoch 00060: saving model to Regression_Model/mle.linear-0060.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5574 - mse: 0.5508 - val_loss: 0.5101 - val_mse: 0.5035\n",
      "Epoch 61/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5512 - mse: 0.5446 - val_loss: 0.4974 - val_mse: 0.4908\n",
      "Epoch 62/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5510 - mse: 0.5444 - val_loss: 0.5139 - val_mse: 0.5074\n",
      "Epoch 63/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5541 - mse: 0.5476 - val_loss: 0.4959 - val_mse: 0.4894\n",
      "Epoch 64/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5525 - mse: 0.5460 - val_loss: 0.5410 - val_mse: 0.5345\n",
      "Epoch 65/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5568 - mse: 0.5503 - val_loss: 0.5047 - val_mse: 0.4981\n",
      "Epoch 66/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5500 - mse: 0.5435 - val_loss: 0.4969 - val_mse: 0.4904\n",
      "Epoch 67/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5496 - mse: 0.5430 - val_loss: 0.5001 - val_mse: 0.4936\n",
      "Epoch 68/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5471 - mse: 0.5406 - val_loss: 0.4959 - val_mse: 0.4893\n",
      "Epoch 69/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5527 - mse: 0.5462 - val_loss: 0.4955 - val_mse: 0.4890\n",
      "Epoch 70/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5480 - mse: 0.5415\n",
      "Epoch 00070: saving model to Regression_Model/mle.linear-0070.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5476 - mse: 0.5411 - val_loss: 0.4940 - val_mse: 0.4875\n",
      "Epoch 71/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5538 - mse: 0.5472 - val_loss: 0.5114 - val_mse: 0.5049\n",
      "Epoch 72/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5486 - mse: 0.5421 - val_loss: 0.5100 - val_mse: 0.5035\n",
      "Epoch 73/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5496 - mse: 0.5431 - val_loss: 0.4953 - val_mse: 0.4888\n",
      "Epoch 74/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5517 - mse: 0.5452 - val_loss: 0.4995 - val_mse: 0.4930\n",
      "Epoch 75/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5553 - mse: 0.5488 - val_loss: 0.4923 - val_mse: 0.4858\n",
      "Epoch 76/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5541 - mse: 0.5476 - val_loss: 0.4978 - val_mse: 0.4912\n",
      "Epoch 77/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5569 - mse: 0.5504 - val_loss: 0.5138 - val_mse: 0.5073\n",
      "Epoch 78/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5627 - mse: 0.5562 - val_loss: 0.4989 - val_mse: 0.4924\n",
      "Epoch 79/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5479 - mse: 0.5414 - val_loss: 0.5055 - val_mse: 0.4990\n",
      "Epoch 80/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5464 - mse: 0.5399\n",
      "Epoch 00080: saving model to Regression_Model/mle.linear-0080.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5455 - mse: 0.5390 - val_loss: 0.5002 - val_mse: 0.4937\n",
      "Epoch 81/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5537 - mse: 0.5472 - val_loss: 0.5005 - val_mse: 0.4941\n",
      "Epoch 82/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5405 - mse: 0.5340 - val_loss: 0.5003 - val_mse: 0.4938\n",
      "Epoch 83/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5502 - mse: 0.5438 - val_loss: 0.4936 - val_mse: 0.4872\n",
      "Epoch 84/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5469 - mse: 0.5404 - val_loss: 0.4995 - val_mse: 0.4931\n",
      "Epoch 85/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5489 - mse: 0.5424 - val_loss: 0.5043 - val_mse: 0.4978\n",
      "Epoch 86/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5415 - mse: 0.5351 - val_loss: 0.4971 - val_mse: 0.4906\n",
      "Epoch 87/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5470 - mse: 0.5406 - val_loss: 0.4885 - val_mse: 0.4820\n",
      "Epoch 88/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5471 - mse: 0.5407 - val_loss: 0.4943 - val_mse: 0.4879\n",
      "Epoch 89/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5455 - mse: 0.5391 - val_loss: 0.4925 - val_mse: 0.4860\n",
      "Epoch 90/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5527 - mse: 0.5463\n",
      "Epoch 00090: saving model to Regression_Model/mle.linear-0090.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5539 - mse: 0.5474 - val_loss: 0.4919 - val_mse: 0.4855\n",
      "Epoch 91/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5471 - mse: 0.5407 - val_loss: 0.4878 - val_mse: 0.4813\n",
      "Epoch 92/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5390 - mse: 0.5326 - val_loss: 0.4965 - val_mse: 0.4901\n",
      "Epoch 93/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5503 - mse: 0.5438 - val_loss: 0.5080 - val_mse: 0.5016\n",
      "Epoch 94/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5524 - mse: 0.5460 - val_loss: 0.4916 - val_mse: 0.4852\n",
      "Epoch 95/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5515 - mse: 0.5451 - val_loss: 0.4880 - val_mse: 0.4815\n",
      "Epoch 96/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5483 - mse: 0.5418 - val_loss: 0.4898 - val_mse: 0.4834\n",
      "Epoch 97/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5421 - mse: 0.5357 - val_loss: 0.4995 - val_mse: 0.4930\n",
      "Epoch 98/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5464 - mse: 0.5400 - val_loss: 0.4899 - val_mse: 0.4835\n",
      "Epoch 99/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5455 - mse: 0.5392 - val_loss: 0.5064 - val_mse: 0.5000\n",
      "Epoch 100/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5500 - mse: 0.5436\n",
      "Epoch 00100: saving model to Regression_Model/mle.linear-0100.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5477 - mse: 0.5414 - val_loss: 0.4852 - val_mse: 0.4788\n",
      "Epoch 101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5442 - mse: 0.5378 - val_loss: 0.5085 - val_mse: 0.5022\n",
      "Epoch 102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5512 - mse: 0.5448 - val_loss: 0.4912 - val_mse: 0.4848\n",
      "Epoch 103/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5491 - mse: 0.5427 - val_loss: 0.4914 - val_mse: 0.4850\n",
      "Epoch 104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5411 - mse: 0.5348 - val_loss: 0.4957 - val_mse: 0.4893\n",
      "Epoch 105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5454 - mse: 0.5391 - val_loss: 0.4975 - val_mse: 0.4912\n",
      "Epoch 106/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5406 - mse: 0.5342 - val_loss: 0.4874 - val_mse: 0.4810\n",
      "Epoch 107/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5519 - mse: 0.5456 - val_loss: 0.4903 - val_mse: 0.4840\n",
      "Epoch 108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5395 - mse: 0.5331 - val_loss: 0.4971 - val_mse: 0.4908\n",
      "Epoch 109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5418 - mse: 0.5355 - val_loss: 0.4854 - val_mse: 0.4790\n",
      "Epoch 110/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5399 - mse: 0.5336\n",
      "Epoch 00110: saving model to Regression_Model/mle.linear-0110.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5411 - mse: 0.5348 - val_loss: 0.4915 - val_mse: 0.4851\n",
      "Epoch 111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5540 - mse: 0.5476 - val_loss: 0.4867 - val_mse: 0.4804\n",
      "Epoch 112/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5458 - mse: 0.5394 - val_loss: 0.4895 - val_mse: 0.4832\n",
      "Epoch 113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5515 - mse: 0.5452 - val_loss: 0.4945 - val_mse: 0.4882\n",
      "Epoch 114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5367 - mse: 0.5304 - val_loss: 0.4915 - val_mse: 0.4852\n",
      "Epoch 115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5446 - mse: 0.5383 - val_loss: 0.5011 - val_mse: 0.4948\n",
      "Epoch 116/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5421 - mse: 0.5357 - val_loss: 0.4941 - val_mse: 0.4877\n",
      "Epoch 117/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5456 - mse: 0.5393 - val_loss: 0.4915 - val_mse: 0.4852\n",
      "Epoch 118/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5377 - mse: 0.5314 - val_loss: 0.4872 - val_mse: 0.4808\n",
      "Epoch 119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5392 - mse: 0.5329 - val_loss: 0.5010 - val_mse: 0.4947\n",
      "Epoch 120/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5428 - mse: 0.5365\n",
      "Epoch 00120: saving model to Regression_Model/mle.linear-0120.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5407 - mse: 0.5344 - val_loss: 0.4912 - val_mse: 0.4849\n",
      "Epoch 121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5469 - mse: 0.5406 - val_loss: 0.4846 - val_mse: 0.4783\n",
      "Epoch 122/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5446 - mse: 0.5383 - val_loss: 0.5234 - val_mse: 0.5171\n",
      "Epoch 123/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5417 - mse: 0.5354 - val_loss: 0.4891 - val_mse: 0.4828\n",
      "Epoch 124/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5382 - mse: 0.5319 - val_loss: 0.4839 - val_mse: 0.4776\n",
      "Epoch 125/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5364 - mse: 0.5301 - val_loss: 0.4809 - val_mse: 0.4746\n",
      "Epoch 126/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5401 - mse: 0.5338 - val_loss: 0.4923 - val_mse: 0.4860\n",
      "Epoch 127/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5375 - mse: 0.5312 - val_loss: 0.4945 - val_mse: 0.4882\n",
      "Epoch 128/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5434 - mse: 0.5371 - val_loss: 0.4909 - val_mse: 0.4846\n",
      "Epoch 129/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5415 - mse: 0.5352 - val_loss: 0.4865 - val_mse: 0.4802\n",
      "Epoch 130/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5424 - mse: 0.5361\n",
      "Epoch 00130: saving model to Regression_Model/mle.linear-0130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5440 - mse: 0.5377 - val_loss: 0.5164 - val_mse: 0.5101\n",
      "Epoch 131/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5402 - mse: 0.5339 - val_loss: 0.4898 - val_mse: 0.4836\n",
      "Epoch 132/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5413 - mse: 0.5350 - val_loss: 0.4922 - val_mse: 0.4859\n",
      "Epoch 133/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5372 - mse: 0.5310 - val_loss: 0.4922 - val_mse: 0.4859\n",
      "Epoch 134/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5344 - mse: 0.5282 - val_loss: 0.4869 - val_mse: 0.4806\n",
      "Epoch 135/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5418 - mse: 0.5356 - val_loss: 0.5003 - val_mse: 0.4940\n",
      "Epoch 136/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5473 - mse: 0.5411 - val_loss: 0.4899 - val_mse: 0.4836\n",
      "Epoch 137/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5451 - mse: 0.5388 - val_loss: 0.4841 - val_mse: 0.4778\n",
      "Epoch 138/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5424 - mse: 0.5361 - val_loss: 0.4824 - val_mse: 0.4761\n",
      "Epoch 139/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5324 - mse: 0.5262 - val_loss: 0.4978 - val_mse: 0.4916\n",
      "Epoch 140/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5435 - mse: 0.5372\n",
      "Epoch 00140: saving model to Regression_Model/mle.linear-0140.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5409 - mse: 0.5346 - val_loss: 0.4842 - val_mse: 0.4779\n",
      "Epoch 141/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5387 - mse: 0.5324 - val_loss: 0.4790 - val_mse: 0.4727\n",
      "Epoch 142/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5305 - mse: 0.5242 - val_loss: 0.4804 - val_mse: 0.4741\n",
      "Epoch 143/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5380 - mse: 0.5318 - val_loss: 0.4809 - val_mse: 0.4746\n",
      "Epoch 144/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5373 - mse: 0.5310 - val_loss: 0.4910 - val_mse: 0.4847\n",
      "Epoch 145/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5363 - mse: 0.5301 - val_loss: 0.4815 - val_mse: 0.4753\n",
      "Epoch 146/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5416 - mse: 0.5353 - val_loss: 0.4846 - val_mse: 0.4784\n",
      "Epoch 147/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5317 - mse: 0.5254 - val_loss: 0.4782 - val_mse: 0.4720\n",
      "Epoch 148/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5413 - mse: 0.5350 - val_loss: 0.4857 - val_mse: 0.4794\n",
      "Epoch 149/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5436 - mse: 0.5374 - val_loss: 0.4803 - val_mse: 0.4740\n",
      "Epoch 150/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5342 - mse: 0.5279\n",
      "Epoch 00150: saving model to Regression_Model/mle.linear-0150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5333 - mse: 0.5270 - val_loss: 0.4892 - val_mse: 0.4829\n",
      "Epoch 151/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5420 - mse: 0.5357 - val_loss: 0.4774 - val_mse: 0.4712\n",
      "Epoch 152/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5319 - mse: 0.5256 - val_loss: 0.4881 - val_mse: 0.4818\n",
      "Epoch 153/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5413 - mse: 0.5351 - val_loss: 0.4881 - val_mse: 0.4818\n",
      "Epoch 154/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5320 - mse: 0.5258 - val_loss: 0.4849 - val_mse: 0.4787\n",
      "Epoch 155/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5370 - mse: 0.5308 - val_loss: 0.4829 - val_mse: 0.4767\n",
      "Epoch 156/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5419 - mse: 0.5356 - val_loss: 0.4945 - val_mse: 0.4882\n",
      "Epoch 157/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5345 - mse: 0.5283 - val_loss: 0.4817 - val_mse: 0.4755\n",
      "Epoch 158/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5391 - mse: 0.5329 - val_loss: 0.4821 - val_mse: 0.4759\n",
      "Epoch 159/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5396 - mse: 0.5334 - val_loss: 0.4863 - val_mse: 0.4800\n",
      "Epoch 160/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5335 - mse: 0.5273\n",
      "Epoch 00160: saving model to Regression_Model/mle.linear-0160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5340 - mse: 0.5277 - val_loss: 0.4823 - val_mse: 0.4761\n",
      "Epoch 161/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5313 - mse: 0.5250 - val_loss: 0.4848 - val_mse: 0.4786\n",
      "Epoch 162/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5321 - mse: 0.5259 - val_loss: 0.4858 - val_mse: 0.4796\n",
      "Epoch 163/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5325 - mse: 0.5263 - val_loss: 0.4885 - val_mse: 0.4823\n",
      "Epoch 164/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5385 - mse: 0.5322 - val_loss: 0.4877 - val_mse: 0.4815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5350 - mse: 0.5288 - val_loss: 0.4778 - val_mse: 0.4716\n",
      "Epoch 166/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5375 - mse: 0.5313 - val_loss: 0.4861 - val_mse: 0.4799\n",
      "Epoch 167/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5330 - mse: 0.5268 - val_loss: 0.4811 - val_mse: 0.4749\n",
      "Epoch 168/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5323 - mse: 0.5261 - val_loss: 0.4916 - val_mse: 0.4854\n",
      "Epoch 169/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5428 - mse: 0.5366 - val_loss: 0.4854 - val_mse: 0.4792\n",
      "Epoch 170/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5408 - mse: 0.5346\n",
      "Epoch 00170: saving model to Regression_Model/mle.linear-0170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5394 - mse: 0.5332 - val_loss: 0.4811 - val_mse: 0.4749\n",
      "Epoch 171/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5357 - mse: 0.5295 - val_loss: 0.4885 - val_mse: 0.4823\n",
      "Epoch 172/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5407 - mse: 0.5345 - val_loss: 0.4882 - val_mse: 0.4820\n",
      "Epoch 173/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5340 - mse: 0.5278 - val_loss: 0.4802 - val_mse: 0.4740\n",
      "Epoch 174/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5373 - mse: 0.5311 - val_loss: 0.4841 - val_mse: 0.4779\n",
      "Epoch 175/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5411 - mse: 0.5349 - val_loss: 0.4771 - val_mse: 0.4709\n",
      "Epoch 176/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5342 - mse: 0.5280 - val_loss: 0.5019 - val_mse: 0.4957\n",
      "Epoch 177/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5309 - mse: 0.5247 - val_loss: 0.4797 - val_mse: 0.4735\n",
      "Epoch 178/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5324 - mse: 0.5262 - val_loss: 0.4781 - val_mse: 0.4719\n",
      "Epoch 179/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5324 - mse: 0.5262 - val_loss: 0.4870 - val_mse: 0.4808\n",
      "Epoch 180/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5358 - mse: 0.5296\n",
      "Epoch 00180: saving model to Regression_Model/mle.linear-0180.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5345 - mse: 0.5283 - val_loss: 0.4834 - val_mse: 0.4772\n",
      "Epoch 181/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5321 - mse: 0.5259 - val_loss: 0.4841 - val_mse: 0.4779\n",
      "Epoch 182/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5342 - mse: 0.5280 - val_loss: 0.4875 - val_mse: 0.4814\n",
      "Epoch 183/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5376 - mse: 0.5315 - val_loss: 0.4770 - val_mse: 0.4708\n",
      "Epoch 184/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5385 - mse: 0.5323 - val_loss: 0.4807 - val_mse: 0.4745\n",
      "Epoch 185/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5385 - mse: 0.5323 - val_loss: 0.4816 - val_mse: 0.4754\n",
      "Epoch 186/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5398 - mse: 0.5336 - val_loss: 0.4847 - val_mse: 0.4785\n",
      "Epoch 187/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5312 - mse: 0.5250 - val_loss: 0.4779 - val_mse: 0.4717\n",
      "Epoch 188/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5385 - mse: 0.5324 - val_loss: 0.4933 - val_mse: 0.4872\n",
      "Epoch 189/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5345 - mse: 0.5283 - val_loss: 0.4824 - val_mse: 0.4762\n",
      "Epoch 190/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5363 - mse: 0.5301\n",
      "Epoch 00190: saving model to Regression_Model/mle.linear-0190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5357 - mse: 0.5295 - val_loss: 0.4825 - val_mse: 0.4763\n",
      "Epoch 191/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5359 - mse: 0.5297 - val_loss: 0.4809 - val_mse: 0.4747\n",
      "Epoch 192/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5312 - mse: 0.5250 - val_loss: 0.4820 - val_mse: 0.4758\n",
      "Epoch 193/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5394 - mse: 0.5332 - val_loss: 0.4802 - val_mse: 0.4740\n",
      "Epoch 194/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5341 - mse: 0.5279 - val_loss: 0.4730 - val_mse: 0.4668\n",
      "Epoch 195/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5308 - mse: 0.5246 - val_loss: 0.4745 - val_mse: 0.4683\n",
      "Epoch 196/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5349 - mse: 0.5287 - val_loss: 0.4765 - val_mse: 0.4704\n",
      "Epoch 197/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5378 - mse: 0.5316 - val_loss: 0.4848 - val_mse: 0.4786\n",
      "Epoch 198/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5353 - mse: 0.5291 - val_loss: 0.5131 - val_mse: 0.5069\n",
      "Epoch 199/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5358 - mse: 0.5296 - val_loss: 0.4788 - val_mse: 0.4726\n",
      "Epoch 200/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5321 - mse: 0.5259\n",
      "Epoch 00200: saving model to Regression_Model/mle.linear-0200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5319 - mse: 0.5257 - val_loss: 0.4772 - val_mse: 0.4710\n",
      "Epoch 201/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5298 - mse: 0.5237 - val_loss: 0.4735 - val_mse: 0.4673\n",
      "Epoch 202/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5319 - mse: 0.5257 - val_loss: 0.4889 - val_mse: 0.4827\n",
      "Epoch 203/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5316 - mse: 0.5254 - val_loss: 0.4744 - val_mse: 0.4682\n",
      "Epoch 204/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5386 - mse: 0.5324 - val_loss: 0.4800 - val_mse: 0.4738\n",
      "Epoch 205/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5386 - mse: 0.5324 - val_loss: 0.4777 - val_mse: 0.4715\n",
      "Epoch 206/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5337 - mse: 0.5275 - val_loss: 0.4796 - val_mse: 0.4734\n",
      "Epoch 207/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5372 - mse: 0.5310 - val_loss: 0.4788 - val_mse: 0.4726\n",
      "Epoch 208/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5280 - mse: 0.5218 - val_loss: 0.4789 - val_mse: 0.4727\n",
      "Epoch 209/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5301 - mse: 0.5239 - val_loss: 0.4848 - val_mse: 0.4786\n",
      "Epoch 210/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5406 - mse: 0.5345\n",
      "Epoch 00210: saving model to Regression_Model/mle.linear-0210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5404 - mse: 0.5342 - val_loss: 0.4744 - val_mse: 0.4683\n",
      "Epoch 211/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5283 - mse: 0.5221 - val_loss: 0.4783 - val_mse: 0.4721\n",
      "Epoch 212/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5363 - mse: 0.5301 - val_loss: 0.4851 - val_mse: 0.4789\n",
      "Epoch 213/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5343 - mse: 0.5282 - val_loss: 0.4770 - val_mse: 0.4708\n",
      "Epoch 214/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5282 - mse: 0.5220 - val_loss: 0.4712 - val_mse: 0.4650\n",
      "Epoch 215/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5289 - mse: 0.5227 - val_loss: 0.4722 - val_mse: 0.4661\n",
      "Epoch 216/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5324 - mse: 0.5262 - val_loss: 0.4735 - val_mse: 0.4673\n",
      "Epoch 217/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5311 - mse: 0.5249 - val_loss: 0.4778 - val_mse: 0.4717\n",
      "Epoch 218/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5339 - mse: 0.5278 - val_loss: 0.4774 - val_mse: 0.4713\n",
      "Epoch 219/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5295 - mse: 0.5234 - val_loss: 0.4757 - val_mse: 0.4695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5297 - mse: 0.5236\n",
      "Epoch 00220: saving model to Regression_Model/mle.linear-0220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5295 - mse: 0.5233 - val_loss: 0.4733 - val_mse: 0.4671\n",
      "Epoch 221/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5265 - mse: 0.5204 - val_loss: 0.4789 - val_mse: 0.4727\n",
      "Epoch 222/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5247 - mse: 0.5186 - val_loss: 0.4823 - val_mse: 0.4761\n",
      "Epoch 223/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5342 - mse: 0.5281 - val_loss: 0.4750 - val_mse: 0.4688\n",
      "Epoch 224/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5315 - mse: 0.5253 - val_loss: 0.4773 - val_mse: 0.4711\n",
      "Epoch 225/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5293 - mse: 0.5232 - val_loss: 0.4735 - val_mse: 0.4673\n",
      "Epoch 226/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5326 - mse: 0.5265 - val_loss: 0.4785 - val_mse: 0.4724\n",
      "Epoch 227/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5317 - mse: 0.5255 - val_loss: 0.4761 - val_mse: 0.4699\n",
      "Epoch 228/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5303 - mse: 0.5242 - val_loss: 0.4743 - val_mse: 0.4682\n",
      "Epoch 229/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5245 - mse: 0.5183 - val_loss: 0.4799 - val_mse: 0.4738\n",
      "Epoch 230/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5247 - mse: 0.5186\n",
      "Epoch 00230: saving model to Regression_Model/mle.linear-0230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5274 - mse: 0.5212 - val_loss: 0.4717 - val_mse: 0.4656\n",
      "Epoch 231/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5280 - mse: 0.5219 - val_loss: 0.4782 - val_mse: 0.4721\n",
      "Epoch 232/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5334 - mse: 0.5273 - val_loss: 0.4702 - val_mse: 0.4641\n",
      "Epoch 233/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5280 - mse: 0.5219 - val_loss: 0.4754 - val_mse: 0.4693\n",
      "Epoch 234/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5347 - mse: 0.5286 - val_loss: 0.4732 - val_mse: 0.4670\n",
      "Epoch 235/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5321 - mse: 0.5259 - val_loss: 0.4871 - val_mse: 0.4809\n",
      "Epoch 236/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5333 - mse: 0.5272 - val_loss: 0.4806 - val_mse: 0.4744\n",
      "Epoch 237/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5364 - mse: 0.5303 - val_loss: 0.4699 - val_mse: 0.4637\n",
      "Epoch 238/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5266 - mse: 0.5205 - val_loss: 0.4736 - val_mse: 0.4675\n",
      "Epoch 239/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5304 - mse: 0.5243 - val_loss: 0.4712 - val_mse: 0.4650\n",
      "Epoch 240/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5336 - mse: 0.5275\n",
      "Epoch 00240: saving model to Regression_Model/mle.linear-0240.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5309 - mse: 0.5248 - val_loss: 0.4723 - val_mse: 0.4662\n",
      "Epoch 241/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5334 - mse: 0.5272 - val_loss: 0.4849 - val_mse: 0.4788\n",
      "Epoch 242/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5272 - mse: 0.5210 - val_loss: 0.4799 - val_mse: 0.4738\n",
      "Epoch 243/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5295 - mse: 0.5234 - val_loss: 0.4798 - val_mse: 0.4736\n",
      "Epoch 244/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5310 - mse: 0.5248 - val_loss: 0.4775 - val_mse: 0.4714\n",
      "Epoch 245/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5303 - mse: 0.5242 - val_loss: 0.4787 - val_mse: 0.4726\n",
      "Epoch 246/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5253 - mse: 0.5192 - val_loss: 0.4741 - val_mse: 0.4680\n",
      "Epoch 247/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5345 - mse: 0.5284 - val_loss: 0.4940 - val_mse: 0.4879\n",
      "Epoch 248/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5346 - mse: 0.5285 - val_loss: 0.4804 - val_mse: 0.4742\n",
      "Epoch 249/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5341 - mse: 0.5280 - val_loss: 0.4751 - val_mse: 0.4689\n",
      "Epoch 250/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5297 - mse: 0.5236\n",
      "Epoch 00250: saving model to Regression_Model/mle.linear-0250.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5304 - mse: 0.5242 - val_loss: 0.4739 - val_mse: 0.4678\n",
      "Epoch 251/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5273 - mse: 0.5212 - val_loss: 0.4732 - val_mse: 0.4670\n",
      "Epoch 252/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5260 - mse: 0.5199 - val_loss: 0.4819 - val_mse: 0.4758\n",
      "Epoch 253/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5301 - mse: 0.5239 - val_loss: 0.4769 - val_mse: 0.4707\n",
      "Epoch 254/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5349 - mse: 0.5288 - val_loss: 0.4744 - val_mse: 0.4683\n",
      "Epoch 255/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5285 - mse: 0.5223 - val_loss: 0.4756 - val_mse: 0.4695\n",
      "Epoch 256/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5261 - mse: 0.5199 - val_loss: 0.4764 - val_mse: 0.4703\n",
      "Epoch 257/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5318 - mse: 0.5257 - val_loss: 0.4735 - val_mse: 0.4673\n",
      "Epoch 258/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5237 - mse: 0.5175 - val_loss: 0.4708 - val_mse: 0.4647\n",
      "Epoch 259/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5297 - mse: 0.5236 - val_loss: 0.4758 - val_mse: 0.4697\n",
      "Epoch 260/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5275 - mse: 0.5214\n",
      "Epoch 00260: saving model to Regression_Model/mle.linear-0260.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5263 - mse: 0.5201 - val_loss: 0.4715 - val_mse: 0.4653\n",
      "Epoch 261/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5249 - mse: 0.5188 - val_loss: 0.4686 - val_mse: 0.4624\n",
      "Epoch 262/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5285 - mse: 0.5224 - val_loss: 0.4816 - val_mse: 0.4755\n",
      "Epoch 263/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5210 - mse: 0.5148 - val_loss: 0.4679 - val_mse: 0.4618\n",
      "Epoch 264/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5284 - mse: 0.5223 - val_loss: 0.4704 - val_mse: 0.4642\n",
      "Epoch 265/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5276 - mse: 0.5214 - val_loss: 0.4687 - val_mse: 0.4626\n",
      "Epoch 266/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5302 - mse: 0.5241 - val_loss: 0.4727 - val_mse: 0.4666\n",
      "Epoch 267/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5251 - mse: 0.5190 - val_loss: 0.4707 - val_mse: 0.4646\n",
      "Epoch 268/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5287 - mse: 0.5225 - val_loss: 0.4726 - val_mse: 0.4665\n",
      "Epoch 269/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5234 - mse: 0.5172 - val_loss: 0.4700 - val_mse: 0.4638\n",
      "Epoch 270/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5274 - mse: 0.5212\n",
      "Epoch 00270: saving model to Regression_Model/mle.linear-0270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5268 - mse: 0.5207 - val_loss: 0.4846 - val_mse: 0.4785\n",
      "Epoch 271/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5326 - mse: 0.5264 - val_loss: 0.4806 - val_mse: 0.4745\n",
      "Epoch 272/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5244 - mse: 0.5182 - val_loss: 0.4672 - val_mse: 0.4611\n",
      "Epoch 273/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5283 - mse: 0.5222 - val_loss: 0.4734 - val_mse: 0.4672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5194 - val_loss: 0.4713 - val_mse: 0.4651\n",
      "Epoch 275/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5222 - mse: 0.5160 - val_loss: 0.4694 - val_mse: 0.4633\n",
      "Epoch 276/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5267 - mse: 0.5206 - val_loss: 0.4696 - val_mse: 0.4635\n",
      "Epoch 277/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5276 - mse: 0.5215 - val_loss: 0.4691 - val_mse: 0.4630\n",
      "Epoch 278/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5276 - mse: 0.5215 - val_loss: 0.4744 - val_mse: 0.4682\n",
      "Epoch 279/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5257 - mse: 0.5196 - val_loss: 0.4743 - val_mse: 0.4681\n",
      "Epoch 280/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5184 - mse: 0.5122\n",
      "Epoch 00280: saving model to Regression_Model/mle.linear-0280.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5202 - mse: 0.5140 - val_loss: 0.4660 - val_mse: 0.4599\n",
      "Epoch 281/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5282 - mse: 0.5221 - val_loss: 0.4728 - val_mse: 0.4666\n",
      "Epoch 282/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5326 - mse: 0.5264 - val_loss: 0.4762 - val_mse: 0.4701\n",
      "Epoch 283/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5308 - mse: 0.5247 - val_loss: 0.4723 - val_mse: 0.4662\n",
      "Epoch 284/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5246 - mse: 0.5185 - val_loss: 0.4673 - val_mse: 0.4611\n",
      "Epoch 285/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5274 - mse: 0.5213 - val_loss: 0.4792 - val_mse: 0.4730\n",
      "Epoch 286/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5174 - mse: 0.5112 - val_loss: 0.4677 - val_mse: 0.4615\n",
      "Epoch 287/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5224 - mse: 0.5162 - val_loss: 0.4656 - val_mse: 0.4595\n",
      "Epoch 288/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5237 - mse: 0.5175 - val_loss: 0.4715 - val_mse: 0.4654\n",
      "Epoch 289/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5167 - mse: 0.5106 - val_loss: 0.4748 - val_mse: 0.4687\n",
      "Epoch 290/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5248 - mse: 0.5186\n",
      "Epoch 00290: saving model to Regression_Model/mle.linear-0290.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5251 - mse: 0.5190 - val_loss: 0.4689 - val_mse: 0.4628\n",
      "Epoch 291/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5248 - mse: 0.5186 - val_loss: 0.4718 - val_mse: 0.4656\n",
      "Epoch 292/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5275 - mse: 0.5214 - val_loss: 0.4766 - val_mse: 0.4705\n",
      "Epoch 293/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5244 - mse: 0.5183 - val_loss: 0.4724 - val_mse: 0.4662\n",
      "Epoch 294/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5318 - mse: 0.5256 - val_loss: 0.4782 - val_mse: 0.4721\n",
      "Epoch 295/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5317 - mse: 0.5255 - val_loss: 0.4713 - val_mse: 0.4652\n",
      "Epoch 296/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5240 - mse: 0.5178 - val_loss: 0.4716 - val_mse: 0.4655\n",
      "Epoch 297/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5210 - mse: 0.5148 - val_loss: 0.4687 - val_mse: 0.4625\n",
      "Epoch 298/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5261 - mse: 0.5200 - val_loss: 0.4693 - val_mse: 0.4632\n",
      "Epoch 299/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5258 - mse: 0.5197 - val_loss: 0.4760 - val_mse: 0.4699\n",
      "Epoch 300/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5250 - mse: 0.5189\n",
      "Epoch 00300: saving model to Regression_Model/mle.linear-0300.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5262 - mse: 0.5201 - val_loss: 0.4798 - val_mse: 0.4736\n",
      "Epoch 301/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5184 - mse: 0.5122 - val_loss: 0.4680 - val_mse: 0.4619\n",
      "Epoch 302/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5289 - mse: 0.5228 - val_loss: 0.4705 - val_mse: 0.4644\n",
      "Epoch 303/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5301 - mse: 0.5240 - val_loss: 0.4781 - val_mse: 0.4720\n",
      "Epoch 304/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5311 - mse: 0.5250 - val_loss: 0.4846 - val_mse: 0.4785\n",
      "Epoch 305/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5276 - mse: 0.5215 - val_loss: 0.4695 - val_mse: 0.4634\n",
      "Epoch 306/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5243 - mse: 0.5181 - val_loss: 0.4683 - val_mse: 0.4622\n",
      "Epoch 307/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5203 - mse: 0.5142 - val_loss: 0.4665 - val_mse: 0.4604\n",
      "Epoch 308/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5271 - mse: 0.5209 - val_loss: 0.4695 - val_mse: 0.4633\n",
      "Epoch 309/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5258 - mse: 0.5197 - val_loss: 0.4676 - val_mse: 0.4615\n",
      "Epoch 310/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5214 - mse: 0.5153\n",
      "Epoch 00310: saving model to Regression_Model/mle.linear-0310.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5207 - mse: 0.5146 - val_loss: 0.4723 - val_mse: 0.4662\n",
      "Epoch 311/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5321 - mse: 0.5260 - val_loss: 0.4743 - val_mse: 0.4681\n",
      "Epoch 312/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5229 - mse: 0.5168 - val_loss: 0.4668 - val_mse: 0.4606\n",
      "Epoch 313/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5318 - mse: 0.5257 - val_loss: 0.4729 - val_mse: 0.4667\n",
      "Epoch 314/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5235 - mse: 0.5174 - val_loss: 0.4662 - val_mse: 0.4600\n",
      "Epoch 315/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5256 - mse: 0.5194 - val_loss: 0.4693 - val_mse: 0.4631\n",
      "Epoch 316/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5237 - mse: 0.5175 - val_loss: 0.4763 - val_mse: 0.4702\n",
      "Epoch 317/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5165 - mse: 0.5104 - val_loss: 0.4653 - val_mse: 0.4592\n",
      "Epoch 318/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5270 - mse: 0.5208 - val_loss: 0.4666 - val_mse: 0.4604\n",
      "Epoch 319/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5183 - mse: 0.5121 - val_loss: 0.4680 - val_mse: 0.4619\n",
      "Epoch 320/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5229 - mse: 0.5168\n",
      "Epoch 00320: saving model to Regression_Model/mle.linear-0320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5251 - mse: 0.5190 - val_loss: 0.4676 - val_mse: 0.4615\n",
      "Epoch 321/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5243 - mse: 0.5182 - val_loss: 0.4658 - val_mse: 0.4597\n",
      "Epoch 322/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5251 - mse: 0.5190 - val_loss: 0.4639 - val_mse: 0.4578\n",
      "Epoch 323/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5293 - mse: 0.5232 - val_loss: 0.4671 - val_mse: 0.4610\n",
      "Epoch 324/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5295 - mse: 0.5234 - val_loss: 0.4781 - val_mse: 0.4720\n",
      "Epoch 325/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5249 - mse: 0.5188 - val_loss: 0.4689 - val_mse: 0.4627\n",
      "Epoch 326/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5216 - mse: 0.5154 - val_loss: 0.4678 - val_mse: 0.4617\n",
      "Epoch 327/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5236 - mse: 0.5175 - val_loss: 0.4710 - val_mse: 0.4649\n",
      "Epoch 328/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5197 - mse: 0.5136 - val_loss: 0.4696 - val_mse: 0.4634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5270 - mse: 0.5209 - val_loss: 0.4691 - val_mse: 0.4630\n",
      "Epoch 330/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5268 - mse: 0.5207\n",
      "Epoch 00330: saving model to Regression_Model/mle.linear-0330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5305 - mse: 0.5243 - val_loss: 0.4634 - val_mse: 0.4573\n",
      "Epoch 331/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5207 - mse: 0.5146 - val_loss: 0.4677 - val_mse: 0.4615\n",
      "Epoch 332/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5219 - mse: 0.5158 - val_loss: 0.4654 - val_mse: 0.4592\n",
      "Epoch 333/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5262 - mse: 0.5200 - val_loss: 0.4720 - val_mse: 0.4659\n",
      "Epoch 334/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5194 - val_loss: 0.4641 - val_mse: 0.4580\n",
      "Epoch 335/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5222 - mse: 0.5160 - val_loss: 0.4647 - val_mse: 0.4585\n",
      "Epoch 336/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5247 - mse: 0.5186 - val_loss: 0.4711 - val_mse: 0.4649\n",
      "Epoch 337/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5254 - mse: 0.5192 - val_loss: 0.4702 - val_mse: 0.4641\n",
      "Epoch 338/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5245 - mse: 0.5184 - val_loss: 0.4705 - val_mse: 0.4643\n",
      "Epoch 339/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5198 - mse: 0.5137 - val_loss: 0.4662 - val_mse: 0.4601\n",
      "Epoch 340/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5241 - mse: 0.5180\n",
      "Epoch 00340: saving model to Regression_Model/mle.linear-0340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5250 - mse: 0.5189 - val_loss: 0.4691 - val_mse: 0.4630\n",
      "Epoch 341/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5275 - mse: 0.5214 - val_loss: 0.4732 - val_mse: 0.4670\n",
      "Epoch 342/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5237 - mse: 0.5175 - val_loss: 0.4647 - val_mse: 0.4586\n",
      "Epoch 343/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5244 - mse: 0.5183 - val_loss: 0.4662 - val_mse: 0.4601\n",
      "Epoch 344/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5316 - mse: 0.5255 - val_loss: 0.4792 - val_mse: 0.4731\n",
      "Epoch 345/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5195 - mse: 0.5134 - val_loss: 0.4686 - val_mse: 0.4624\n",
      "Epoch 346/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5289 - mse: 0.5228 - val_loss: 0.4727 - val_mse: 0.4666\n",
      "Epoch 347/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5189 - mse: 0.5128 - val_loss: 0.4737 - val_mse: 0.4676\n",
      "Epoch 348/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5259 - mse: 0.5198 - val_loss: 0.4658 - val_mse: 0.4597\n",
      "Epoch 349/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5277 - mse: 0.5216 - val_loss: 0.4740 - val_mse: 0.4679\n",
      "Epoch 350/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5249 - mse: 0.5187\n",
      "Epoch 00350: saving model to Regression_Model/mle.linear-0350.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5219 - mse: 0.5158 - val_loss: 0.4660 - val_mse: 0.4599\n",
      "Epoch 351/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5181 - mse: 0.5119 - val_loss: 0.4628 - val_mse: 0.4567\n",
      "Epoch 352/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5229 - mse: 0.5168 - val_loss: 0.4665 - val_mse: 0.4603\n",
      "Epoch 353/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5194 - mse: 0.5132 - val_loss: 0.4662 - val_mse: 0.4600\n",
      "Epoch 354/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5245 - mse: 0.5184 - val_loss: 0.4685 - val_mse: 0.4624\n",
      "Epoch 355/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5244 - mse: 0.5183 - val_loss: 0.4657 - val_mse: 0.4596\n",
      "Epoch 356/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5259 - mse: 0.5198 - val_loss: 0.4734 - val_mse: 0.4672\n",
      "Epoch 357/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5205 - mse: 0.5144 - val_loss: 0.4666 - val_mse: 0.4605\n",
      "Epoch 358/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5209 - mse: 0.5148 - val_loss: 0.4674 - val_mse: 0.4612\n",
      "Epoch 359/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5261 - mse: 0.5200 - val_loss: 0.4671 - val_mse: 0.4610\n",
      "Epoch 360/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5179 - mse: 0.5117\n",
      "Epoch 00360: saving model to Regression_Model/mle.linear-0360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5191 - mse: 0.5130 - val_loss: 0.4643 - val_mse: 0.4582\n",
      "Epoch 361/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5244 - mse: 0.5183 - val_loss: 0.4664 - val_mse: 0.4603\n",
      "Epoch 362/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5134 - mse: 0.5073 - val_loss: 0.4673 - val_mse: 0.4612\n",
      "Epoch 363/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5202 - mse: 0.5141 - val_loss: 0.4781 - val_mse: 0.4720\n",
      "Epoch 364/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5269 - mse: 0.5207 - val_loss: 0.4712 - val_mse: 0.4651\n",
      "Epoch 365/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5224 - mse: 0.5163 - val_loss: 0.4671 - val_mse: 0.4610\n",
      "Epoch 366/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5262 - mse: 0.5201 - val_loss: 0.4706 - val_mse: 0.4645\n",
      "Epoch 367/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5204 - mse: 0.5142 - val_loss: 0.4707 - val_mse: 0.4646\n",
      "Epoch 368/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5223 - mse: 0.5161 - val_loss: 0.4708 - val_mse: 0.4647\n",
      "Epoch 369/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5267 - mse: 0.5206 - val_loss: 0.4767 - val_mse: 0.4706\n",
      "Epoch 370/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5245 - mse: 0.5184\n",
      "Epoch 00370: saving model to Regression_Model/mle.linear-0370.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5194 - val_loss: 0.4679 - val_mse: 0.4618\n",
      "Epoch 371/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5155 - mse: 0.5094 - val_loss: 0.4664 - val_mse: 0.4603\n",
      "Epoch 372/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5226 - mse: 0.5165 - val_loss: 0.4664 - val_mse: 0.4603\n",
      "Epoch 373/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5194 - mse: 0.5133 - val_loss: 0.4708 - val_mse: 0.4646\n",
      "Epoch 374/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5209 - mse: 0.5148 - val_loss: 0.4726 - val_mse: 0.4665\n",
      "Epoch 375/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5235 - mse: 0.5174 - val_loss: 0.4655 - val_mse: 0.4594\n",
      "Epoch 376/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5069 - val_loss: 0.4637 - val_mse: 0.4576\n",
      "Epoch 377/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5203 - mse: 0.5142 - val_loss: 0.4692 - val_mse: 0.4631\n",
      "Epoch 378/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5240 - mse: 0.5179 - val_loss: 0.4640 - val_mse: 0.4578\n",
      "Epoch 379/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5214 - mse: 0.5152 - val_loss: 0.4671 - val_mse: 0.4610\n",
      "Epoch 380/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5239 - mse: 0.5178\n",
      "Epoch 00380: saving model to Regression_Model/mle.linear-0380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5251 - mse: 0.5190 - val_loss: 0.4678 - val_mse: 0.4616\n",
      "Epoch 381/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5225 - mse: 0.5164 - val_loss: 0.4611 - val_mse: 0.4549\n",
      "Epoch 382/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5176 - mse: 0.5115 - val_loss: 0.4681 - val_mse: 0.4620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5169 - mse: 0.5108 - val_loss: 0.4711 - val_mse: 0.4650\n",
      "Epoch 384/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5191 - mse: 0.5129 - val_loss: 0.4664 - val_mse: 0.4603\n",
      "Epoch 385/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5189 - mse: 0.5127 - val_loss: 0.4697 - val_mse: 0.4636\n",
      "Epoch 386/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5243 - mse: 0.5182 - val_loss: 0.4671 - val_mse: 0.4609\n",
      "Epoch 387/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5207 - mse: 0.5146 - val_loss: 0.4615 - val_mse: 0.4554\n",
      "Epoch 388/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5162 - mse: 0.5100 - val_loss: 0.4677 - val_mse: 0.4616\n",
      "Epoch 389/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5220 - mse: 0.5158 - val_loss: 0.4620 - val_mse: 0.4558\n",
      "Epoch 390/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5129 - mse: 0.5068\n",
      "Epoch 00390: saving model to Regression_Model/mle.linear-0390.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5141 - mse: 0.5079 - val_loss: 0.4707 - val_mse: 0.4646\n",
      "Epoch 391/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5208 - mse: 0.5147 - val_loss: 0.4637 - val_mse: 0.4576\n",
      "Epoch 392/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5249 - mse: 0.5187 - val_loss: 0.4663 - val_mse: 0.4601\n",
      "Epoch 393/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5216 - mse: 0.5155 - val_loss: 0.4737 - val_mse: 0.4676\n",
      "Epoch 394/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5244 - mse: 0.5183 - val_loss: 0.4640 - val_mse: 0.4579\n",
      "Epoch 395/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5239 - mse: 0.5177 - val_loss: 0.4627 - val_mse: 0.4566\n",
      "Epoch 396/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5193 - mse: 0.5131 - val_loss: 0.4679 - val_mse: 0.4618\n",
      "Epoch 397/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5144 - val_loss: 0.4669 - val_mse: 0.4607\n",
      "Epoch 398/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5072 - val_loss: 0.4628 - val_mse: 0.4567\n",
      "Epoch 399/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5154 - mse: 0.5093 - val_loss: 0.4690 - val_mse: 0.4628\n",
      "Epoch 400/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5197 - mse: 0.5136\n",
      "Epoch 00400: saving model to Regression_Model/mle.linear-0400.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5201 - mse: 0.5139 - val_loss: 0.4640 - val_mse: 0.4579\n",
      "Epoch 401/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5240 - mse: 0.5179 - val_loss: 0.4654 - val_mse: 0.4593\n",
      "Epoch 402/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5193 - mse: 0.5132 - val_loss: 0.4646 - val_mse: 0.4584\n",
      "Epoch 403/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5263 - mse: 0.5201 - val_loss: 0.4640 - val_mse: 0.4578\n",
      "Epoch 404/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5180 - mse: 0.5118 - val_loss: 0.4640 - val_mse: 0.4579\n",
      "Epoch 405/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5207 - mse: 0.5146 - val_loss: 0.4626 - val_mse: 0.4565\n",
      "Epoch 406/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5173 - mse: 0.5111 - val_loss: 0.4616 - val_mse: 0.4554\n",
      "Epoch 407/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5062 - val_loss: 0.4612 - val_mse: 0.4550\n",
      "Epoch 408/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5205 - mse: 0.5143 - val_loss: 0.4651 - val_mse: 0.4590\n",
      "Epoch 409/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5161 - mse: 0.5099 - val_loss: 0.4656 - val_mse: 0.4595\n",
      "Epoch 410/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5208 - mse: 0.5147\n",
      "Epoch 00410: saving model to Regression_Model/mle.linear-0410.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5221 - mse: 0.5160 - val_loss: 0.4629 - val_mse: 0.4567\n",
      "Epoch 411/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5212 - mse: 0.5151 - val_loss: 0.4688 - val_mse: 0.4627\n",
      "Epoch 412/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5202 - mse: 0.5140 - val_loss: 0.4631 - val_mse: 0.4570\n",
      "Epoch 413/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5185 - mse: 0.5124 - val_loss: 0.4620 - val_mse: 0.4558\n",
      "Epoch 414/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5145 - val_loss: 0.4601 - val_mse: 0.4540\n",
      "Epoch 415/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5170 - mse: 0.5109 - val_loss: 0.4653 - val_mse: 0.4591\n",
      "Epoch 416/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5204 - mse: 0.5143 - val_loss: 0.4617 - val_mse: 0.4555\n",
      "Epoch 417/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5215 - mse: 0.5153 - val_loss: 0.4648 - val_mse: 0.4587\n",
      "Epoch 418/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5198 - mse: 0.5137 - val_loss: 0.4624 - val_mse: 0.4562\n",
      "Epoch 419/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5208 - mse: 0.5147 - val_loss: 0.4628 - val_mse: 0.4567\n",
      "Epoch 420/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5146 - mse: 0.5085\n",
      "Epoch 00420: saving model to Regression_Model/mle.linear-0420.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5181 - mse: 0.5120 - val_loss: 0.4708 - val_mse: 0.4647\n",
      "Epoch 421/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5159 - mse: 0.5097 - val_loss: 0.4697 - val_mse: 0.4636\n",
      "Epoch 422/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5209 - mse: 0.5148 - val_loss: 0.4616 - val_mse: 0.4555\n",
      "Epoch 423/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5212 - mse: 0.5151 - val_loss: 0.4629 - val_mse: 0.4568\n",
      "Epoch 424/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5203 - mse: 0.5142 - val_loss: 0.4619 - val_mse: 0.4558\n",
      "Epoch 425/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5152 - mse: 0.5091 - val_loss: 0.4644 - val_mse: 0.4583\n",
      "Epoch 426/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5145 - val_loss: 0.4714 - val_mse: 0.4653\n",
      "Epoch 427/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5174 - mse: 0.5113 - val_loss: 0.4636 - val_mse: 0.4575\n",
      "Epoch 428/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5147 - mse: 0.5086 - val_loss: 0.4584 - val_mse: 0.4523\n",
      "Epoch 429/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5257 - mse: 0.5196 - val_loss: 0.4653 - val_mse: 0.4592\n",
      "Epoch 430/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5206 - mse: 0.5145\n",
      "Epoch 00430: saving model to Regression_Model/mle.linear-0430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5144 - val_loss: 0.4625 - val_mse: 0.4564\n",
      "Epoch 431/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5196 - mse: 0.5135 - val_loss: 0.4650 - val_mse: 0.4589\n",
      "Epoch 432/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5209 - mse: 0.5148 - val_loss: 0.4654 - val_mse: 0.4593\n",
      "Epoch 433/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5167 - mse: 0.5106 - val_loss: 0.4603 - val_mse: 0.4541\n",
      "Epoch 434/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5265 - mse: 0.5203 - val_loss: 0.4624 - val_mse: 0.4563\n",
      "Epoch 435/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5251 - mse: 0.5189 - val_loss: 0.4616 - val_mse: 0.4555\n",
      "Epoch 436/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5199 - mse: 0.5138 - val_loss: 0.4638 - val_mse: 0.4577\n",
      "Epoch 437/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5184 - mse: 0.5123 - val_loss: 0.4677 - val_mse: 0.4616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5200 - mse: 0.5139 - val_loss: 0.4612 - val_mse: 0.4550\n",
      "Epoch 439/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5148 - mse: 0.5087 - val_loss: 0.4643 - val_mse: 0.4582\n",
      "Epoch 440/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5156 - mse: 0.5095\n",
      "Epoch 00440: saving model to Regression_Model/mle.linear-0440.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5194 - mse: 0.5133 - val_loss: 0.4637 - val_mse: 0.4576\n",
      "Epoch 441/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5181 - mse: 0.5120 - val_loss: 0.4628 - val_mse: 0.4567\n",
      "Epoch 442/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5199 - mse: 0.5138 - val_loss: 0.4619 - val_mse: 0.4558\n",
      "Epoch 443/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5081 - val_loss: 0.4610 - val_mse: 0.4549\n",
      "Epoch 444/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5199 - mse: 0.5138 - val_loss: 0.4686 - val_mse: 0.4625\n",
      "Epoch 445/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5107 - mse: 0.5046 - val_loss: 0.4584 - val_mse: 0.4523\n",
      "Epoch 446/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5062 - val_loss: 0.4618 - val_mse: 0.4556\n",
      "Epoch 447/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5165 - mse: 0.5104 - val_loss: 0.4643 - val_mse: 0.4582\n",
      "Epoch 448/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5202 - mse: 0.5141 - val_loss: 0.4677 - val_mse: 0.4616\n",
      "Epoch 449/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5211 - mse: 0.5150 - val_loss: 0.4628 - val_mse: 0.4567\n",
      "Epoch 450/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5225 - mse: 0.5164\n",
      "Epoch 00450: saving model to Regression_Model/mle.linear-0450.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5221 - mse: 0.5160 - val_loss: 0.4607 - val_mse: 0.4546\n",
      "Epoch 451/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5184 - mse: 0.5123 - val_loss: 0.4583 - val_mse: 0.4521\n",
      "Epoch 452/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5182 - mse: 0.5121 - val_loss: 0.4631 - val_mse: 0.4570\n",
      "Epoch 453/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5178 - mse: 0.5117 - val_loss: 0.4634 - val_mse: 0.4573\n",
      "Epoch 454/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5162 - mse: 0.5101 - val_loss: 0.4607 - val_mse: 0.4546\n",
      "Epoch 455/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5039 - val_loss: 0.4602 - val_mse: 0.4540\n",
      "Epoch 456/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5145 - val_loss: 0.4636 - val_mse: 0.4575\n",
      "Epoch 457/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5169 - mse: 0.5108 - val_loss: 0.4600 - val_mse: 0.4539\n",
      "Epoch 458/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5231 - mse: 0.5170 - val_loss: 0.4640 - val_mse: 0.4579\n",
      "Epoch 459/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5210 - mse: 0.5149 - val_loss: 0.4657 - val_mse: 0.4596\n",
      "Epoch 460/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5189 - mse: 0.5128\n",
      "Epoch 00460: saving model to Regression_Model/mle.linear-0460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5192 - mse: 0.5131 - val_loss: 0.4574 - val_mse: 0.4513\n",
      "Epoch 461/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5179 - mse: 0.5118 - val_loss: 0.4573 - val_mse: 0.4512\n",
      "Epoch 462/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5156 - mse: 0.5095 - val_loss: 0.4614 - val_mse: 0.4553\n",
      "Epoch 463/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5165 - mse: 0.5104 - val_loss: 0.4594 - val_mse: 0.4532\n",
      "Epoch 464/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5024 - val_loss: 0.4592 - val_mse: 0.4531\n",
      "Epoch 465/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5172 - mse: 0.5111 - val_loss: 0.4585 - val_mse: 0.4524\n",
      "Epoch 466/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5158 - mse: 0.5097 - val_loss: 0.4599 - val_mse: 0.4538\n",
      "Epoch 467/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5161 - mse: 0.5100 - val_loss: 0.4645 - val_mse: 0.4584\n",
      "Epoch 468/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5099 - val_loss: 0.4635 - val_mse: 0.4574\n",
      "Epoch 469/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5162 - mse: 0.5101 - val_loss: 0.4577 - val_mse: 0.4516\n",
      "Epoch 470/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5198 - mse: 0.5137\n",
      "Epoch 00470: saving model to Regression_Model/mle.linear-0470.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5194 - mse: 0.5133 - val_loss: 0.4602 - val_mse: 0.4541\n",
      "Epoch 471/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5223 - mse: 0.5162 - val_loss: 0.4608 - val_mse: 0.4547\n",
      "Epoch 472/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5052 - val_loss: 0.4590 - val_mse: 0.4529\n",
      "Epoch 473/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5147 - mse: 0.5086 - val_loss: 0.4622 - val_mse: 0.4561\n",
      "Epoch 474/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5146 - mse: 0.5084 - val_loss: 0.4639 - val_mse: 0.4578\n",
      "Epoch 475/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5150 - mse: 0.5089 - val_loss: 0.4605 - val_mse: 0.4544\n",
      "Epoch 476/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5195 - mse: 0.5134 - val_loss: 0.4679 - val_mse: 0.4618\n",
      "Epoch 477/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5170 - mse: 0.5109 - val_loss: 0.4586 - val_mse: 0.4525\n",
      "Epoch 478/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5125 - mse: 0.5064 - val_loss: 0.4588 - val_mse: 0.4527\n",
      "Epoch 479/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5202 - mse: 0.5141 - val_loss: 0.4608 - val_mse: 0.4547\n",
      "Epoch 480/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5246 - mse: 0.5185\n",
      "Epoch 00480: saving model to Regression_Model/mle.linear-0480.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5221 - mse: 0.5160 - val_loss: 0.4613 - val_mse: 0.4552\n",
      "Epoch 481/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5079 - val_loss: 0.4624 - val_mse: 0.4563\n",
      "Epoch 482/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5186 - mse: 0.5125 - val_loss: 0.4587 - val_mse: 0.4526\n",
      "Epoch 483/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5167 - mse: 0.5106 - val_loss: 0.4587 - val_mse: 0.4526\n",
      "Epoch 484/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5130 - mse: 0.5069 - val_loss: 0.4562 - val_mse: 0.4501\n",
      "Epoch 485/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5016 - val_loss: 0.4574 - val_mse: 0.4513\n",
      "Epoch 486/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5212 - mse: 0.5151 - val_loss: 0.4583 - val_mse: 0.4522\n",
      "Epoch 487/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5147 - mse: 0.5086 - val_loss: 0.4595 - val_mse: 0.4534\n",
      "Epoch 488/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5183 - mse: 0.5122 - val_loss: 0.4566 - val_mse: 0.4505\n",
      "Epoch 489/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5002 - val_loss: 0.4608 - val_mse: 0.4547\n",
      "Epoch 490/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5189 - mse: 0.5128\n",
      "Epoch 00490: saving model to Regression_Model/mle.linear-0490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5184 - mse: 0.5123 - val_loss: 0.4564 - val_mse: 0.4503\n",
      "Epoch 491/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5037 - val_loss: 0.4551 - val_mse: 0.4490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5192 - mse: 0.5131 - val_loss: 0.4588 - val_mse: 0.4527\n",
      "Epoch 493/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5181 - mse: 0.5120 - val_loss: 0.4584 - val_mse: 0.4523\n",
      "Epoch 494/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5107 - mse: 0.5046 - val_loss: 0.4581 - val_mse: 0.4521\n",
      "Epoch 495/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5128 - mse: 0.5067 - val_loss: 0.4604 - val_mse: 0.4543\n",
      "Epoch 496/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5129 - mse: 0.5068 - val_loss: 0.4584 - val_mse: 0.4523\n",
      "Epoch 497/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5166 - mse: 0.5105 - val_loss: 0.4668 - val_mse: 0.4607\n",
      "Epoch 498/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5171 - mse: 0.5110 - val_loss: 0.4611 - val_mse: 0.4550\n",
      "Epoch 499/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5203 - mse: 0.5142 - val_loss: 0.4592 - val_mse: 0.4531\n",
      "Epoch 500/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5206 - mse: 0.5145\n",
      "Epoch 00500: saving model to Regression_Model/mle.linear-0500.ckpt\n",
      "368/368 [==============================] - 5s 12ms/step - loss: 0.5201 - mse: 0.5140 - val_loss: 0.4609 - val_mse: 0.4548\n",
      "Epoch 501/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5200 - mse: 0.5139 - val_loss: 0.4608 - val_mse: 0.4547\n",
      "Epoch 502/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5016 - val_loss: 0.4629 - val_mse: 0.4569\n",
      "Epoch 503/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5187 - mse: 0.5126 - val_loss: 0.4595 - val_mse: 0.4534\n",
      "Epoch 504/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5002 - val_loss: 0.4600 - val_mse: 0.4539\n",
      "Epoch 505/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5134 - mse: 0.5073 - val_loss: 0.4603 - val_mse: 0.4542\n",
      "Epoch 506/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5062 - val_loss: 0.4665 - val_mse: 0.4604\n",
      "Epoch 507/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5072 - val_loss: 0.4617 - val_mse: 0.4556\n",
      "Epoch 508/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5180 - mse: 0.5119 - val_loss: 0.4587 - val_mse: 0.4526\n",
      "Epoch 509/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5062 - val_loss: 0.4625 - val_mse: 0.4564\n",
      "Epoch 510/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5168 - mse: 0.5108\n",
      "Epoch 00510: saving model to Regression_Model/mle.linear-0510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5161 - mse: 0.5100 - val_loss: 0.4581 - val_mse: 0.4520\n",
      "Epoch 511/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5215 - mse: 0.5154 - val_loss: 0.4584 - val_mse: 0.4523\n",
      "Epoch 512/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5168 - mse: 0.5107 - val_loss: 0.4586 - val_mse: 0.4526\n",
      "Epoch 513/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5197 - mse: 0.5136 - val_loss: 0.4601 - val_mse: 0.4540\n",
      "Epoch 514/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5138 - mse: 0.5078 - val_loss: 0.4628 - val_mse: 0.4567\n",
      "Epoch 515/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5023 - val_loss: 0.4557 - val_mse: 0.4496\n",
      "Epoch 516/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5248 - mse: 0.5187 - val_loss: 0.4605 - val_mse: 0.4544\n",
      "Epoch 517/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5137 - mse: 0.5076 - val_loss: 0.4600 - val_mse: 0.4539\n",
      "Epoch 518/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5213 - mse: 0.5152 - val_loss: 0.4601 - val_mse: 0.4540\n",
      "Epoch 519/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5173 - mse: 0.5112 - val_loss: 0.4579 - val_mse: 0.4518\n",
      "Epoch 520/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5102 - mse: 0.5041\n",
      "Epoch 00520: saving model to Regression_Model/mle.linear-0520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5072 - val_loss: 0.4587 - val_mse: 0.4526\n",
      "Epoch 521/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5232 - mse: 0.5171 - val_loss: 0.4621 - val_mse: 0.4560\n",
      "Epoch 522/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5099 - val_loss: 0.4623 - val_mse: 0.4562\n",
      "Epoch 523/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5205 - mse: 0.5144 - val_loss: 0.4649 - val_mse: 0.4588\n",
      "Epoch 524/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5127 - mse: 0.5066 - val_loss: 0.4590 - val_mse: 0.4529\n",
      "Epoch 525/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5194 - mse: 0.5133 - val_loss: 0.4600 - val_mse: 0.4539\n",
      "Epoch 526/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5148 - mse: 0.5088 - val_loss: 0.4584 - val_mse: 0.4523\n",
      "Epoch 527/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5183 - mse: 0.5122 - val_loss: 0.4605 - val_mse: 0.4545\n",
      "Epoch 528/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5063 - val_loss: 0.4656 - val_mse: 0.4596\n",
      "Epoch 529/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5177 - mse: 0.5116 - val_loss: 0.4576 - val_mse: 0.4515\n",
      "Epoch 530/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5184 - mse: 0.5123\n",
      "Epoch 00530: saving model to Regression_Model/mle.linear-0530.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5166 - mse: 0.5105 - val_loss: 0.4648 - val_mse: 0.4587\n",
      "Epoch 531/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5191 - mse: 0.5130 - val_loss: 0.4576 - val_mse: 0.4515\n",
      "Epoch 532/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5048 - val_loss: 0.4574 - val_mse: 0.4513\n",
      "Epoch 533/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5125 - mse: 0.5064 - val_loss: 0.4565 - val_mse: 0.4504\n",
      "Epoch 534/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5230 - mse: 0.5170 - val_loss: 0.4587 - val_mse: 0.4526\n",
      "Epoch 535/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5200 - mse: 0.5139 - val_loss: 0.4602 - val_mse: 0.4541\n",
      "Epoch 536/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5070 - val_loss: 0.4573 - val_mse: 0.4512\n",
      "Epoch 537/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5155 - mse: 0.5094 - val_loss: 0.4568 - val_mse: 0.4507\n",
      "Epoch 538/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5056 - val_loss: 0.4597 - val_mse: 0.4537\n",
      "Epoch 539/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5081 - val_loss: 0.4597 - val_mse: 0.4536\n",
      "Epoch 540/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5166 - mse: 0.5105\n",
      "Epoch 00540: saving model to Regression_Model/mle.linear-0540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5163 - mse: 0.5102 - val_loss: 0.4555 - val_mse: 0.4494\n",
      "Epoch 541/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5152 - mse: 0.5091 - val_loss: 0.4597 - val_mse: 0.4536\n",
      "Epoch 542/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5145 - val_loss: 0.4576 - val_mse: 0.4515\n",
      "Epoch 543/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5022 - val_loss: 0.4632 - val_mse: 0.4571\n",
      "Epoch 544/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5234 - mse: 0.5173 - val_loss: 0.4601 - val_mse: 0.4540\n",
      "Epoch 545/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5147 - mse: 0.5086 - val_loss: 0.4556 - val_mse: 0.4495\n",
      "Epoch 546/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5175 - mse: 0.5114 - val_loss: 0.4608 - val_mse: 0.4547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5154 - mse: 0.5093 - val_loss: 0.4573 - val_mse: 0.4512\n",
      "Epoch 548/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5080 - val_loss: 0.4601 - val_mse: 0.4541\n",
      "Epoch 549/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5155 - mse: 0.5094 - val_loss: 0.4603 - val_mse: 0.4543\n",
      "Epoch 550/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5159 - mse: 0.5098\n",
      "Epoch 00550: saving model to Regression_Model/mle.linear-0550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5147 - mse: 0.5086 - val_loss: 0.4590 - val_mse: 0.4529\n",
      "Epoch 551/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5070 - val_loss: 0.4589 - val_mse: 0.4529\n",
      "Epoch 552/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5081 - val_loss: 0.4565 - val_mse: 0.4504\n",
      "Epoch 553/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5194 - mse: 0.5133 - val_loss: 0.4712 - val_mse: 0.4651\n",
      "Epoch 554/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5024 - val_loss: 0.4555 - val_mse: 0.4494\n",
      "Epoch 555/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5021 - val_loss: 0.4571 - val_mse: 0.4510\n",
      "Epoch 556/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5074 - val_loss: 0.4567 - val_mse: 0.4506\n",
      "Epoch 557/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5024 - val_loss: 0.4574 - val_mse: 0.4514\n",
      "Epoch 558/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5145 - mse: 0.5084 - val_loss: 0.4560 - val_mse: 0.4500\n",
      "Epoch 559/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5168 - mse: 0.5107 - val_loss: 0.4550 - val_mse: 0.4489\n",
      "Epoch 560/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5097 - mse: 0.5036\n",
      "Epoch 00560: saving model to Regression_Model/mle.linear-0560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5037 - val_loss: 0.4540 - val_mse: 0.4480\n",
      "Epoch 561/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5048 - val_loss: 0.4565 - val_mse: 0.4504\n",
      "Epoch 562/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5010 - val_loss: 0.4562 - val_mse: 0.4501\n",
      "Epoch 563/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5074 - val_loss: 0.4596 - val_mse: 0.4535\n",
      "Epoch 564/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5169 - mse: 0.5108 - val_loss: 0.4591 - val_mse: 0.4531\n",
      "Epoch 565/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5052 - val_loss: 0.4571 - val_mse: 0.4510\n",
      "Epoch 566/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5176 - mse: 0.5115 - val_loss: 0.4587 - val_mse: 0.4527\n",
      "Epoch 567/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5126 - mse: 0.5065 - val_loss: 0.4584 - val_mse: 0.4523\n",
      "Epoch 568/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5182 - mse: 0.5121 - val_loss: 0.4560 - val_mse: 0.4500\n",
      "Epoch 569/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5200 - mse: 0.5139 - val_loss: 0.4567 - val_mse: 0.4506\n",
      "Epoch 570/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5126 - mse: 0.5066\n",
      "Epoch 00570: saving model to Regression_Model/mle.linear-0570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5075 - val_loss: 0.4562 - val_mse: 0.4502\n",
      "Epoch 571/3000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5116 - mse: 0.5056 - val_loss: 0.4581 - val_mse: 0.4521\n",
      "Epoch 572/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5048 - val_loss: 0.4577 - val_mse: 0.4516\n",
      "Epoch 573/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5159 - mse: 0.5099 - val_loss: 0.4555 - val_mse: 0.4494\n",
      "Epoch 574/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5074 - val_loss: 0.4563 - val_mse: 0.4503\n",
      "Epoch 575/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5138 - mse: 0.5077 - val_loss: 0.4564 - val_mse: 0.4503\n",
      "Epoch 576/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5215 - mse: 0.5154 - val_loss: 0.4585 - val_mse: 0.4524\n",
      "Epoch 577/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5012 - val_loss: 0.4561 - val_mse: 0.4500\n",
      "Epoch 578/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5025 - val_loss: 0.4579 - val_mse: 0.4519\n",
      "Epoch 579/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5100 - val_loss: 0.4616 - val_mse: 0.4555\n",
      "Epoch 580/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5174 - mse: 0.5113\n",
      "Epoch 00580: saving model to Regression_Model/mle.linear-0580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5151 - mse: 0.5090 - val_loss: 0.4564 - val_mse: 0.4504\n",
      "Epoch 581/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5053 - val_loss: 0.4584 - val_mse: 0.4524\n",
      "Epoch 582/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5230 - mse: 0.5170 - val_loss: 0.4585 - val_mse: 0.4525\n",
      "Epoch 583/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5176 - mse: 0.5115 - val_loss: 0.4589 - val_mse: 0.4528\n",
      "Epoch 584/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5053 - val_loss: 0.4584 - val_mse: 0.4523\n",
      "Epoch 585/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5211 - mse: 0.5151 - val_loss: 0.4580 - val_mse: 0.4519\n",
      "Epoch 586/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5209 - mse: 0.5148 - val_loss: 0.4590 - val_mse: 0.4529\n",
      "Epoch 587/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5175 - mse: 0.5115 - val_loss: 0.4607 - val_mse: 0.4546\n",
      "Epoch 588/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5207 - mse: 0.5147 - val_loss: 0.4558 - val_mse: 0.4497\n",
      "Epoch 589/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5071 - val_loss: 0.4606 - val_mse: 0.4546\n",
      "Epoch 590/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5066 - mse: 0.5006\n",
      "Epoch 00590: saving model to Regression_Model/mle.linear-0590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5017 - val_loss: 0.4550 - val_mse: 0.4489\n",
      "Epoch 591/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5128 - mse: 0.5067 - val_loss: 0.4562 - val_mse: 0.4501\n",
      "Epoch 592/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5064 - val_loss: 0.4561 - val_mse: 0.4500\n",
      "Epoch 593/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5178 - mse: 0.5117 - val_loss: 0.4590 - val_mse: 0.4529\n",
      "Epoch 594/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5061 - val_loss: 0.4653 - val_mse: 0.4593\n",
      "Epoch 595/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5199 - mse: 0.5138 - val_loss: 0.4602 - val_mse: 0.4541\n",
      "Epoch 596/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5162 - mse: 0.5102 - val_loss: 0.4582 - val_mse: 0.4521\n",
      "Epoch 597/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5099 - val_loss: 0.4557 - val_mse: 0.4497\n",
      "Epoch 598/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5181 - mse: 0.5120 - val_loss: 0.4567 - val_mse: 0.4507\n",
      "Epoch 599/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5121 - mse: 0.5060 - val_loss: 0.4648 - val_mse: 0.4587\n",
      "Epoch 600/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5207 - mse: 0.5146\n",
      "Epoch 00600: saving model to Regression_Model/mle.linear-0600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5201 - mse: 0.5141 - val_loss: 0.4635 - val_mse: 0.4575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5080 - val_loss: 0.4564 - val_mse: 0.4503\n",
      "Epoch 602/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5164 - mse: 0.5104 - val_loss: 0.4593 - val_mse: 0.4533\n",
      "Epoch 603/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5022 - val_loss: 0.4542 - val_mse: 0.4482\n",
      "Epoch 604/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5137 - mse: 0.5076 - val_loss: 0.4535 - val_mse: 0.4474\n",
      "Epoch 605/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5018 - val_loss: 0.4539 - val_mse: 0.4478\n",
      "Epoch 606/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5191 - mse: 0.5131 - val_loss: 0.4614 - val_mse: 0.4553\n",
      "Epoch 607/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5176 - mse: 0.5115 - val_loss: 0.4595 - val_mse: 0.4534\n",
      "Epoch 608/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5041 - val_loss: 0.4536 - val_mse: 0.4475\n",
      "Epoch 609/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5080 - val_loss: 0.4584 - val_mse: 0.4524\n",
      "Epoch 610/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5099 - mse: 0.5039\n",
      "Epoch 00610: saving model to Regression_Model/mle.linear-0610.ckpt\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.5105 - mse: 0.5045 - val_loss: 0.4630 - val_mse: 0.4570\n",
      "Epoch 611/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5162 - mse: 0.5102 - val_loss: 0.4532 - val_mse: 0.4472\n",
      "Epoch 612/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5037 - val_loss: 0.4598 - val_mse: 0.4537\n",
      "Epoch 613/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5063 - val_loss: 0.4545 - val_mse: 0.4485\n",
      "Epoch 614/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5041 - val_loss: 0.4576 - val_mse: 0.4516\n",
      "Epoch 615/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5153 - mse: 0.5093 - val_loss: 0.4589 - val_mse: 0.4528\n",
      "Epoch 616/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5145 - mse: 0.5084 - val_loss: 0.4540 - val_mse: 0.4480\n",
      "Epoch 617/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5161 - mse: 0.5101 - val_loss: 0.4595 - val_mse: 0.4535\n",
      "Epoch 618/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5130 - mse: 0.5069 - val_loss: 0.4593 - val_mse: 0.4532\n",
      "Epoch 619/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5072 - val_loss: 0.4549 - val_mse: 0.4488\n",
      "Epoch 620/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5090 - mse: 0.5029\n",
      "Epoch 00620: saving model to Regression_Model/mle.linear-0620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5045 - val_loss: 0.4556 - val_mse: 0.4495\n",
      "Epoch 621/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5188 - mse: 0.5128 - val_loss: 0.4567 - val_mse: 0.4506\n",
      "Epoch 622/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4986 - val_loss: 0.4535 - val_mse: 0.4475\n",
      "Epoch 623/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5014 - val_loss: 0.4563 - val_mse: 0.4503\n",
      "Epoch 624/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5153 - mse: 0.5092 - val_loss: 0.4617 - val_mse: 0.4556\n",
      "Epoch 625/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5179 - mse: 0.5119 - val_loss: 0.4604 - val_mse: 0.4544\n",
      "Epoch 626/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5159 - mse: 0.5099 - val_loss: 0.4554 - val_mse: 0.4493\n",
      "Epoch 627/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5162 - mse: 0.5102 - val_loss: 0.4620 - val_mse: 0.4560\n",
      "Epoch 628/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5159 - mse: 0.5099 - val_loss: 0.4594 - val_mse: 0.4534\n",
      "Epoch 629/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5156 - mse: 0.5096 - val_loss: 0.4551 - val_mse: 0.4490\n",
      "Epoch 630/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5100 - mse: 0.5040\n",
      "Epoch 00630: saving model to Regression_Model/mle.linear-0630.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5030 - val_loss: 0.4572 - val_mse: 0.4511\n",
      "Epoch 631/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5150 - mse: 0.5090 - val_loss: 0.4608 - val_mse: 0.4548\n",
      "Epoch 632/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5054 - val_loss: 0.4548 - val_mse: 0.4488\n",
      "Epoch 633/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5136 - mse: 0.5075 - val_loss: 0.4551 - val_mse: 0.4491\n",
      "Epoch 634/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5144 - mse: 0.5084 - val_loss: 0.4602 - val_mse: 0.4542\n",
      "Epoch 635/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5062 - val_loss: 0.4590 - val_mse: 0.4530\n",
      "Epoch 636/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5017 - val_loss: 0.4553 - val_mse: 0.4493\n",
      "Epoch 637/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5043 - val_loss: 0.4542 - val_mse: 0.4482\n",
      "Epoch 638/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5129 - mse: 0.5069 - val_loss: 0.4599 - val_mse: 0.4539\n",
      "Epoch 639/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5099 - val_loss: 0.4559 - val_mse: 0.4499\n",
      "Epoch 640/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5172 - mse: 0.5112\n",
      "Epoch 00640: saving model to Regression_Model/mle.linear-0640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5183 - mse: 0.5123 - val_loss: 0.4584 - val_mse: 0.4524\n",
      "Epoch 641/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5045 - val_loss: 0.4576 - val_mse: 0.4516\n",
      "Epoch 642/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5062 - val_loss: 0.4571 - val_mse: 0.4510\n",
      "Epoch 643/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5071 - val_loss: 0.4562 - val_mse: 0.4502\n",
      "Epoch 644/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5167 - mse: 0.5107 - val_loss: 0.4541 - val_mse: 0.4481\n",
      "Epoch 645/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5150 - mse: 0.5090 - val_loss: 0.4577 - val_mse: 0.4517\n",
      "Epoch 646/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4991 - val_loss: 0.4581 - val_mse: 0.4521\n",
      "Epoch 647/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5181 - mse: 0.5121 - val_loss: 0.4566 - val_mse: 0.4506\n",
      "Epoch 648/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5024 - val_loss: 0.4581 - val_mse: 0.4521\n",
      "Epoch 649/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5032 - val_loss: 0.4545 - val_mse: 0.4485\n",
      "Epoch 650/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5145 - mse: 0.5085\n",
      "Epoch 00650: saving model to Regression_Model/mle.linear-0650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5129 - mse: 0.5069 - val_loss: 0.4551 - val_mse: 0.4491\n",
      "Epoch 651/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5129 - mse: 0.5068 - val_loss: 0.4543 - val_mse: 0.4483\n",
      "Epoch 652/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5035 - val_loss: 0.4588 - val_mse: 0.4528\n",
      "Epoch 653/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5137 - mse: 0.5077 - val_loss: 0.4584 - val_mse: 0.4524\n",
      "Epoch 654/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5121 - mse: 0.5061 - val_loss: 0.4557 - val_mse: 0.4497\n",
      "Epoch 655/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5184 - mse: 0.5124 - val_loss: 0.4608 - val_mse: 0.4548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5169 - mse: 0.5109 - val_loss: 0.4602 - val_mse: 0.4542\n",
      "Epoch 657/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5054 - val_loss: 0.4580 - val_mse: 0.4520\n",
      "Epoch 658/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5045 - val_loss: 0.4566 - val_mse: 0.4506\n",
      "Epoch 659/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5145 - mse: 0.5085 - val_loss: 0.4578 - val_mse: 0.4518\n",
      "Epoch 660/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5222 - mse: 0.5162\n",
      "Epoch 00660: saving model to Regression_Model/mle.linear-0660.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5189 - mse: 0.5129 - val_loss: 0.4541 - val_mse: 0.4481\n",
      "Epoch 661/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5134 - mse: 0.5074 - val_loss: 0.4535 - val_mse: 0.4475\n",
      "Epoch 662/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5110 - mse: 0.5050 - val_loss: 0.4582 - val_mse: 0.4522\n",
      "Epoch 663/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5071 - val_loss: 0.4520 - val_mse: 0.4460\n",
      "Epoch 664/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5043 - val_loss: 0.4555 - val_mse: 0.4495\n",
      "Epoch 665/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5151 - mse: 0.5091 - val_loss: 0.4550 - val_mse: 0.4490\n",
      "Epoch 666/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5075 - val_loss: 0.4588 - val_mse: 0.4528\n",
      "Epoch 667/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5072 - val_loss: 0.4559 - val_mse: 0.4499\n",
      "Epoch 668/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5139 - mse: 0.5079 - val_loss: 0.4554 - val_mse: 0.4494\n",
      "Epoch 669/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5172 - mse: 0.5112 - val_loss: 0.4563 - val_mse: 0.4503\n",
      "Epoch 670/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5129 - mse: 0.5069\n",
      "Epoch 00670: saving model to Regression_Model/mle.linear-0670.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5128 - mse: 0.5068 - val_loss: 0.4566 - val_mse: 0.4506\n",
      "Epoch 671/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5151 - mse: 0.5091 - val_loss: 0.4577 - val_mse: 0.4517\n",
      "Epoch 672/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5005 - val_loss: 0.4559 - val_mse: 0.4499\n",
      "Epoch 673/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5198 - mse: 0.5137 - val_loss: 0.4578 - val_mse: 0.4518\n",
      "Epoch 674/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5209 - mse: 0.5149 - val_loss: 0.4553 - val_mse: 0.4493\n",
      "Epoch 675/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5107 - mse: 0.5047 - val_loss: 0.4551 - val_mse: 0.4491\n",
      "Epoch 676/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5152 - mse: 0.5092 - val_loss: 0.4569 - val_mse: 0.4509\n",
      "Epoch 677/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5023 - val_loss: 0.4541 - val_mse: 0.4481\n",
      "Epoch 678/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5116 - mse: 0.5056 - val_loss: 0.4568 - val_mse: 0.4508\n",
      "Epoch 679/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5181 - mse: 0.5121 - val_loss: 0.4550 - val_mse: 0.4490\n",
      "Epoch 680/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5111 - mse: 0.5051\n",
      "Epoch 00680: saving model to Regression_Model/mle.linear-0680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5043 - val_loss: 0.4591 - val_mse: 0.4531\n",
      "Epoch 681/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5072 - val_loss: 0.4598 - val_mse: 0.4538\n",
      "Epoch 682/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5125 - mse: 0.5065 - val_loss: 0.4544 - val_mse: 0.4484\n",
      "Epoch 683/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4985 - val_loss: 0.4550 - val_mse: 0.4490\n",
      "Epoch 684/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5125 - mse: 0.5065 - val_loss: 0.4542 - val_mse: 0.4482\n",
      "Epoch 685/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5148 - mse: 0.5088 - val_loss: 0.4545 - val_mse: 0.4485\n",
      "Epoch 686/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5051 - val_loss: 0.4544 - val_mse: 0.4484\n",
      "Epoch 687/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5153 - mse: 0.5093 - val_loss: 0.4557 - val_mse: 0.4497\n",
      "Epoch 688/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5022 - val_loss: 0.4548 - val_mse: 0.4488\n",
      "Epoch 689/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5025 - val_loss: 0.4558 - val_mse: 0.4499\n",
      "Epoch 690/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5188 - mse: 0.5128\n",
      "Epoch 00690: saving model to Regression_Model/mle.linear-0690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5192 - mse: 0.5132 - val_loss: 0.4552 - val_mse: 0.4492\n",
      "Epoch 691/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5127 - mse: 0.5067 - val_loss: 0.4535 - val_mse: 0.4475\n",
      "Epoch 692/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5179 - mse: 0.5119 - val_loss: 0.4555 - val_mse: 0.4495\n",
      "Epoch 693/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5075 - val_loss: 0.4588 - val_mse: 0.4529\n",
      "Epoch 694/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5027 - val_loss: 0.4566 - val_mse: 0.4506\n",
      "Epoch 695/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5019 - val_loss: 0.4558 - val_mse: 0.4498\n",
      "Epoch 696/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5053 - val_loss: 0.4574 - val_mse: 0.4514\n",
      "Epoch 697/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5143 - mse: 0.5084 - val_loss: 0.4577 - val_mse: 0.4517\n",
      "Epoch 698/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5064 - val_loss: 0.4553 - val_mse: 0.4494\n",
      "Epoch 699/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5153 - mse: 0.5093 - val_loss: 0.4558 - val_mse: 0.4499\n",
      "Epoch 700/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5084 - mse: 0.5024\n",
      "Epoch 00700: saving model to Regression_Model/mle.linear-0700.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5079 - mse: 0.5019 - val_loss: 0.4530 - val_mse: 0.4470\n",
      "Epoch 701/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5058 - val_loss: 0.4553 - val_mse: 0.4493\n",
      "Epoch 702/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5031 - val_loss: 0.4518 - val_mse: 0.4458\n",
      "Epoch 703/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5004 - val_loss: 0.4525 - val_mse: 0.4465\n",
      "Epoch 704/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4975 - val_loss: 0.4520 - val_mse: 0.4460\n",
      "Epoch 705/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5052 - val_loss: 0.4564 - val_mse: 0.4504\n",
      "Epoch 706/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5062 - val_loss: 0.4541 - val_mse: 0.4481\n",
      "Epoch 707/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5029 - val_loss: 0.4528 - val_mse: 0.4468\n",
      "Epoch 708/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5037 - val_loss: 0.4553 - val_mse: 0.4493\n",
      "Epoch 709/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5146 - mse: 0.5087 - val_loss: 0.4534 - val_mse: 0.4474\n",
      "Epoch 710/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5079 - mse: 0.5019\n",
      "Epoch 00710: saving model to Regression_Model/mle.linear-0710.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5011 - val_loss: 0.4543 - val_mse: 0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 711/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5038 - val_loss: 0.4527 - val_mse: 0.4467\n",
      "Epoch 712/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5169 - mse: 0.5109 - val_loss: 0.4544 - val_mse: 0.4484\n",
      "Epoch 713/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5186 - mse: 0.5126 - val_loss: 0.4534 - val_mse: 0.4474\n",
      "Epoch 714/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5040 - val_loss: 0.4559 - val_mse: 0.4499\n",
      "Epoch 715/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5171 - mse: 0.5111 - val_loss: 0.4534 - val_mse: 0.4474\n",
      "Epoch 716/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5120 - mse: 0.5060 - val_loss: 0.4525 - val_mse: 0.4465\n",
      "Epoch 717/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5042 - val_loss: 0.4542 - val_mse: 0.4483\n",
      "Epoch 718/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5058 - val_loss: 0.4547 - val_mse: 0.4487\n",
      "Epoch 719/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4982 - val_loss: 0.4525 - val_mse: 0.4465\n",
      "Epoch 720/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5092 - mse: 0.5033\n",
      "Epoch 00720: saving model to Regression_Model/mle.linear-0720.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5042 - val_loss: 0.4539 - val_mse: 0.4480\n",
      "Epoch 721/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5016 - val_loss: 0.4541 - val_mse: 0.4481\n",
      "Epoch 722/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5036 - val_loss: 0.4533 - val_mse: 0.4474\n",
      "Epoch 723/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5152 - mse: 0.5093 - val_loss: 0.4527 - val_mse: 0.4468\n",
      "Epoch 724/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5046 - val_loss: 0.4560 - val_mse: 0.4500\n",
      "Epoch 725/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5044 - val_loss: 0.4578 - val_mse: 0.4518\n",
      "Epoch 726/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5081 - val_loss: 0.4548 - val_mse: 0.4488\n",
      "Epoch 727/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5027 - val_loss: 0.4534 - val_mse: 0.4474\n",
      "Epoch 728/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5137 - mse: 0.5077 - val_loss: 0.4533 - val_mse: 0.4474\n",
      "Epoch 729/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5120 - mse: 0.5060 - val_loss: 0.4512 - val_mse: 0.4453\n",
      "Epoch 730/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5158 - mse: 0.5098\n",
      "Epoch 00730: saving model to Regression_Model/mle.linear-0730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5158 - mse: 0.5098 - val_loss: 0.4563 - val_mse: 0.4503\n",
      "Epoch 731/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5044 - val_loss: 0.4537 - val_mse: 0.4477\n",
      "Epoch 732/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5018 - val_loss: 0.4522 - val_mse: 0.4462\n",
      "Epoch 733/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5038 - val_loss: 0.4541 - val_mse: 0.4482\n",
      "Epoch 734/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5040 - val_loss: 0.4566 - val_mse: 0.4507\n",
      "Epoch 735/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5172 - mse: 0.5112 - val_loss: 0.4543 - val_mse: 0.4483\n",
      "Epoch 736/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4993 - val_loss: 0.4506 - val_mse: 0.4446\n",
      "Epoch 737/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5001 - val_loss: 0.4526 - val_mse: 0.4467\n",
      "Epoch 738/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5170 - mse: 0.5110 - val_loss: 0.4552 - val_mse: 0.4492\n",
      "Epoch 739/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5027 - val_loss: 0.4544 - val_mse: 0.4484\n",
      "Epoch 740/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5030 - mse: 0.4971\n",
      "Epoch 00740: saving model to Regression_Model/mle.linear-0740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4985 - val_loss: 0.4537 - val_mse: 0.4477\n",
      "Epoch 741/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5127 - mse: 0.5068 - val_loss: 0.4543 - val_mse: 0.4483\n",
      "Epoch 742/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5025 - val_loss: 0.4569 - val_mse: 0.4510\n",
      "Epoch 743/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5138 - mse: 0.5079 - val_loss: 0.4533 - val_mse: 0.4473\n",
      "Epoch 744/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5027 - val_loss: 0.4537 - val_mse: 0.4477\n",
      "Epoch 745/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5050 - val_loss: 0.4578 - val_mse: 0.4518\n",
      "Epoch 746/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5076 - val_loss: 0.4549 - val_mse: 0.4489\n",
      "Epoch 747/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5041 - val_loss: 0.4517 - val_mse: 0.4457\n",
      "Epoch 748/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5152 - mse: 0.5092 - val_loss: 0.4548 - val_mse: 0.4489\n",
      "Epoch 749/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5045 - val_loss: 0.4526 - val_mse: 0.4466\n",
      "Epoch 750/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5068 - mse: 0.5009\n",
      "Epoch 00750: saving model to Regression_Model/mle.linear-0750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5030 - val_loss: 0.4529 - val_mse: 0.4469\n",
      "Epoch 751/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4973 - val_loss: 0.4515 - val_mse: 0.4455\n",
      "Epoch 752/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5166 - mse: 0.5107 - val_loss: 0.4573 - val_mse: 0.4513\n",
      "Epoch 753/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5035 - val_loss: 0.4526 - val_mse: 0.4466\n",
      "Epoch 754/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5139 - mse: 0.5079 - val_loss: 0.4562 - val_mse: 0.4503\n",
      "Epoch 755/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5119 - mse: 0.5060 - val_loss: 0.4534 - val_mse: 0.4474\n",
      "Epoch 756/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.4999 - val_loss: 0.4558 - val_mse: 0.4499\n",
      "Epoch 757/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5144 - mse: 0.5084 - val_loss: 0.4565 - val_mse: 0.4506\n",
      "Epoch 758/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5020 - val_loss: 0.4530 - val_mse: 0.4471\n",
      "Epoch 759/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5049 - val_loss: 0.4576 - val_mse: 0.4516\n",
      "Epoch 760/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5121 - mse: 0.5061\n",
      "Epoch 00760: saving model to Regression_Model/mle.linear-0760.ckpt\n",
      "368/368 [==============================] - 4s 11ms/step - loss: 0.5113 - mse: 0.5054 - val_loss: 0.4525 - val_mse: 0.4465\n",
      "Epoch 761/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5055 - val_loss: 0.4534 - val_mse: 0.4474\n",
      "Epoch 762/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5049 - val_loss: 0.4535 - val_mse: 0.4476\n",
      "Epoch 763/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5052 - val_loss: 0.4542 - val_mse: 0.4482\n",
      "Epoch 764/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5188 - mse: 0.5129 - val_loss: 0.4549 - val_mse: 0.4489\n",
      "Epoch 765/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5129 - mse: 0.5070 - val_loss: 0.4546 - val_mse: 0.4487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 766/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5020 - val_loss: 0.4528 - val_mse: 0.4469\n",
      "Epoch 767/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5138 - mse: 0.5078 - val_loss: 0.4529 - val_mse: 0.4470\n",
      "Epoch 768/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5044 - val_loss: 0.4537 - val_mse: 0.4477\n",
      "Epoch 769/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5144 - mse: 0.5085 - val_loss: 0.4534 - val_mse: 0.4474\n",
      "Epoch 770/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5105 - mse: 0.5045\n",
      "Epoch 00770: saving model to Regression_Model/mle.linear-0770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5115 - mse: 0.5056 - val_loss: 0.4516 - val_mse: 0.4457\n",
      "Epoch 771/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5019 - val_loss: 0.4561 - val_mse: 0.4502\n",
      "Epoch 772/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4986 - val_loss: 0.4503 - val_mse: 0.4444\n",
      "Epoch 773/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5149 - mse: 0.5090 - val_loss: 0.4530 - val_mse: 0.4471\n",
      "Epoch 774/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5043 - val_loss: 0.4538 - val_mse: 0.4478\n",
      "Epoch 775/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5038 - val_loss: 0.4533 - val_mse: 0.4474\n",
      "Epoch 776/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5062 - val_loss: 0.4546 - val_mse: 0.4487\n",
      "Epoch 777/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5052 - val_loss: 0.4555 - val_mse: 0.4495\n",
      "Epoch 778/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5046 - val_loss: 0.4540 - val_mse: 0.4480\n",
      "Epoch 779/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5129 - mse: 0.5069 - val_loss: 0.4536 - val_mse: 0.4476\n",
      "Epoch 780/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5116 - mse: 0.5057\n",
      "Epoch 00780: saving model to Regression_Model/mle.linear-0780.ckpt\n",
      "368/368 [==============================] - 6s 15ms/step - loss: 0.5111 - mse: 0.5052 - val_loss: 0.4535 - val_mse: 0.4476\n",
      "Epoch 781/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5129 - mse: 0.5070 - val_loss: 0.4567 - val_mse: 0.4507\n",
      "Epoch 782/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5011 - val_loss: 0.4548 - val_mse: 0.4489\n",
      "Epoch 783/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4986 - val_loss: 0.4524 - val_mse: 0.4464\n",
      "Epoch 784/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4986 - val_loss: 0.4534 - val_mse: 0.4475\n",
      "Epoch 785/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5126 - mse: 0.5066 - val_loss: 0.4542 - val_mse: 0.4483\n",
      "Epoch 786/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5115 - mse: 0.5055 - val_loss: 0.4537 - val_mse: 0.4478\n",
      "Epoch 787/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5146 - mse: 0.5086 - val_loss: 0.4536 - val_mse: 0.4477\n",
      "Epoch 788/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5009 - val_loss: 0.4522 - val_mse: 0.4463\n",
      "Epoch 789/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5026 - val_loss: 0.4523 - val_mse: 0.4463\n",
      "Epoch 790/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5137 - mse: 0.5078\n",
      "Epoch 00790: saving model to Regression_Model/mle.linear-0790.ckpt\n",
      "368/368 [==============================] - 5s 15ms/step - loss: 0.5138 - mse: 0.5079 - val_loss: 0.4519 - val_mse: 0.4459\n",
      "Epoch 791/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5100 - val_loss: 0.4542 - val_mse: 0.4482\n",
      "Epoch 792/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5009 - val_loss: 0.4517 - val_mse: 0.4458\n",
      "Epoch 793/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5028 - val_loss: 0.4544 - val_mse: 0.4485\n",
      "Epoch 794/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5039 - val_loss: 0.4515 - val_mse: 0.4455\n",
      "Epoch 795/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4942 - val_loss: 0.4508 - val_mse: 0.4449\n",
      "Epoch 796/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5200 - mse: 0.5140 - val_loss: 0.4560 - val_mse: 0.4501\n",
      "Epoch 797/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5016 - val_loss: 0.4530 - val_mse: 0.4470\n",
      "Epoch 798/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5040 - val_loss: 0.4526 - val_mse: 0.4467\n",
      "Epoch 799/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5036 - val_loss: 0.4562 - val_mse: 0.4502\n",
      "Epoch 800/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5137 - mse: 0.5078\n",
      "Epoch 00800: saving model to Regression_Model/mle.linear-0800.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5107 - mse: 0.5047 - val_loss: 0.4529 - val_mse: 0.4470\n",
      "Epoch 801/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5003 - val_loss: 0.4510 - val_mse: 0.4451\n",
      "Epoch 802/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5022 - val_loss: 0.4532 - val_mse: 0.4472\n",
      "Epoch 803/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5015 - val_loss: 0.4534 - val_mse: 0.4475\n",
      "Epoch 804/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4961 - val_loss: 0.4548 - val_mse: 0.4488\n",
      "Epoch 805/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5137 - mse: 0.5078 - val_loss: 0.4516 - val_mse: 0.4456\n",
      "Epoch 806/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5081 - val_loss: 0.4548 - val_mse: 0.4489\n",
      "Epoch 807/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4992 - val_loss: 0.4520 - val_mse: 0.4460\n",
      "Epoch 808/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4996 - val_loss: 0.4521 - val_mse: 0.4462\n",
      "Epoch 809/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5007 - val_loss: 0.4511 - val_mse: 0.4451\n",
      "Epoch 810/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5130 - mse: 0.5070\n",
      "Epoch 00810: saving model to Regression_Model/mle.linear-0810.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5135 - mse: 0.5075 - val_loss: 0.4527 - val_mse: 0.4467\n",
      "Epoch 811/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4979 - val_loss: 0.4551 - val_mse: 0.4491\n",
      "Epoch 812/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5083 - val_loss: 0.4522 - val_mse: 0.4462\n",
      "Epoch 813/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5055 - val_loss: 0.4559 - val_mse: 0.4500\n",
      "Epoch 814/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5074 - val_loss: 0.4540 - val_mse: 0.4481\n",
      "Epoch 815/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4968 - val_loss: 0.4553 - val_mse: 0.4494\n",
      "Epoch 816/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4987 - val_loss: 0.4509 - val_mse: 0.4449\n",
      "Epoch 817/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5041 - val_loss: 0.4530 - val_mse: 0.4471\n",
      "Epoch 818/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5025 - val_loss: 0.4542 - val_mse: 0.4483\n",
      "Epoch 819/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5055 - val_loss: 0.4535 - val_mse: 0.4476\n",
      "Epoch 820/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.5014 - mse: 0.4954\n",
      "Epoch 00820: saving model to Regression_Model/mle.linear-0820.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4971 - val_loss: 0.4511 - val_mse: 0.4452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4989 - val_loss: 0.4539 - val_mse: 0.4480\n",
      "Epoch 822/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5031 - val_loss: 0.4509 - val_mse: 0.4449\n",
      "Epoch 823/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5136 - mse: 0.5077 - val_loss: 0.4521 - val_mse: 0.4462\n",
      "Epoch 824/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5130 - mse: 0.5071 - val_loss: 0.4540 - val_mse: 0.4481\n",
      "Epoch 825/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5116 - mse: 0.5057 - val_loss: 0.4526 - val_mse: 0.4466\n",
      "Epoch 826/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5032 - val_loss: 0.4520 - val_mse: 0.4461\n",
      "Epoch 827/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4990 - val_loss: 0.4529 - val_mse: 0.4470\n",
      "Epoch 828/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5027 - val_loss: 0.4508 - val_mse: 0.4449\n",
      "Epoch 829/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5007 - val_loss: 0.4534 - val_mse: 0.4475\n",
      "Epoch 830/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5075 - mse: 0.5015\n",
      "Epoch 00830: saving model to Regression_Model/mle.linear-0830.ckpt\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.5106 - mse: 0.5046 - val_loss: 0.4532 - val_mse: 0.4473\n",
      "Epoch 831/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5027 - val_loss: 0.4535 - val_mse: 0.4476\n",
      "Epoch 832/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5163 - mse: 0.5103 - val_loss: 0.4533 - val_mse: 0.4474\n",
      "Epoch 833/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5005 - val_loss: 0.4529 - val_mse: 0.4470\n",
      "Epoch 834/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5034 - val_loss: 0.4526 - val_mse: 0.4466\n",
      "Epoch 835/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5033 - val_loss: 0.4524 - val_mse: 0.4464\n",
      "Epoch 836/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5022 - val_loss: 0.4523 - val_mse: 0.4464\n",
      "Epoch 837/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5002 - val_loss: 0.4522 - val_mse: 0.4463\n",
      "Epoch 838/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5050 - val_loss: 0.4512 - val_mse: 0.4453\n",
      "Epoch 839/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4993 - val_loss: 0.4516 - val_mse: 0.4457\n",
      "Epoch 840/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5140 - mse: 0.5081\n",
      "Epoch 00840: saving model to Regression_Model/mle.linear-0840.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5139 - mse: 0.5080 - val_loss: 0.4505 - val_mse: 0.4445\n",
      "Epoch 841/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5035 - val_loss: 0.4513 - val_mse: 0.4453\n",
      "Epoch 842/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5065 - val_loss: 0.4526 - val_mse: 0.4467\n",
      "Epoch 843/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5030 - val_loss: 0.4520 - val_mse: 0.4461\n",
      "Epoch 844/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5121 - mse: 0.5062 - val_loss: 0.4524 - val_mse: 0.4465\n",
      "Epoch 845/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5166 - mse: 0.5107 - val_loss: 0.4546 - val_mse: 0.4487\n",
      "Epoch 846/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4993 - val_loss: 0.4513 - val_mse: 0.4454\n",
      "Epoch 847/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5030 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 848/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4985 - val_loss: 0.4517 - val_mse: 0.4458\n",
      "Epoch 849/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4985 - val_loss: 0.4513 - val_mse: 0.4454\n",
      "Epoch 850/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.5059 - mse: 0.5000\n",
      "Epoch 00850: saving model to Regression_Model/mle.linear-0850.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5080 - mse: 0.5021 - val_loss: 0.4511 - val_mse: 0.4451\n",
      "Epoch 851/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5035 - val_loss: 0.4536 - val_mse: 0.4477\n",
      "Epoch 852/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4994 - val_loss: 0.4501 - val_mse: 0.4442\n",
      "Epoch 853/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5148 - mse: 0.5088 - val_loss: 0.4540 - val_mse: 0.4481\n",
      "Epoch 854/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5028 - val_loss: 0.4528 - val_mse: 0.4469\n",
      "Epoch 855/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5029 - val_loss: 0.4539 - val_mse: 0.4480\n",
      "Epoch 856/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5027 - val_loss: 0.4501 - val_mse: 0.4442\n",
      "Epoch 857/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4985 - val_loss: 0.4522 - val_mse: 0.4463\n",
      "Epoch 858/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5019 - val_loss: 0.4521 - val_mse: 0.4462\n",
      "Epoch 859/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5001 - val_loss: 0.4533 - val_mse: 0.4473\n",
      "Epoch 860/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5083 - mse: 0.5024\n",
      "Epoch 00860: saving model to Regression_Model/mle.linear-0860.ckpt\n",
      "368/368 [==============================] - 5s 13ms/step - loss: 0.5099 - mse: 0.5040 - val_loss: 0.4519 - val_mse: 0.4460\n",
      "Epoch 861/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4965 - val_loss: 0.4511 - val_mse: 0.4452\n",
      "Epoch 862/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5175 - mse: 0.5116 - val_loss: 0.4513 - val_mse: 0.4454\n",
      "Epoch 863/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5017 - val_loss: 0.4515 - val_mse: 0.4456\n",
      "Epoch 864/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5059 - val_loss: 0.4521 - val_mse: 0.4462\n",
      "Epoch 865/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5119 - mse: 0.5060 - val_loss: 0.4521 - val_mse: 0.4462\n",
      "Epoch 866/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5024 - val_loss: 0.4535 - val_mse: 0.4476\n",
      "Epoch 867/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5024 - val_loss: 0.4498 - val_mse: 0.4439\n",
      "Epoch 868/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4988 - val_loss: 0.4533 - val_mse: 0.4474\n",
      "Epoch 869/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5003 - val_loss: 0.4518 - val_mse: 0.4459\n",
      "Epoch 870/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5147 - mse: 0.5088\n",
      "Epoch 00870: saving model to Regression_Model/mle.linear-0870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5139 - mse: 0.5079 - val_loss: 0.4525 - val_mse: 0.4466\n",
      "Epoch 871/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5042 - val_loss: 0.4526 - val_mse: 0.4467\n",
      "Epoch 872/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4983 - val_loss: 0.4521 - val_mse: 0.4462\n",
      "Epoch 873/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4985 - val_loss: 0.4518 - val_mse: 0.4459\n",
      "Epoch 874/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5022 - val_loss: 0.4529 - val_mse: 0.4470\n",
      "Epoch 875/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5041 - val_loss: 0.4528 - val_mse: 0.4469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 876/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5027 - val_loss: 0.4526 - val_mse: 0.4467\n",
      "Epoch 877/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5034 - val_loss: 0.4511 - val_mse: 0.4452\n",
      "Epoch 878/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4970 - val_loss: 0.4502 - val_mse: 0.4443\n",
      "Epoch 879/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4982 - val_loss: 0.4515 - val_mse: 0.4456\n",
      "Epoch 880/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5071 - mse: 0.5012\n",
      "Epoch 00880: saving model to Regression_Model/mle.linear-0880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5021 - val_loss: 0.4525 - val_mse: 0.4466\n",
      "Epoch 881/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5018 - val_loss: 0.4537 - val_mse: 0.4478\n",
      "Epoch 882/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5059 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 883/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5012 - val_loss: 0.4524 - val_mse: 0.4465\n",
      "Epoch 884/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5006 - val_loss: 0.4502 - val_mse: 0.4443\n",
      "Epoch 885/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5019 - val_loss: 0.4524 - val_mse: 0.4465\n",
      "Epoch 886/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4968 - val_loss: 0.4504 - val_mse: 0.4445\n",
      "Epoch 887/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5020 - val_loss: 0.4511 - val_mse: 0.4452\n",
      "Epoch 888/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5065 - val_loss: 0.4511 - val_mse: 0.4452\n",
      "Epoch 889/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4982 - val_loss: 0.4516 - val_mse: 0.4457\n",
      "Epoch 890/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5153 - mse: 0.5094\n",
      "Epoch 00890: saving model to Regression_Model/mle.linear-0890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5082 - val_loss: 0.4516 - val_mse: 0.4457\n",
      "Epoch 891/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4975 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 892/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5035 - val_loss: 0.4547 - val_mse: 0.4488\n",
      "Epoch 893/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5037 - val_loss: 0.4519 - val_mse: 0.4460\n",
      "Epoch 894/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5030 - val_loss: 0.4486 - val_mse: 0.4427\n",
      "Epoch 895/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5043 - val_loss: 0.4501 - val_mse: 0.4442\n",
      "Epoch 896/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5119 - mse: 0.5060 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 897/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4978 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 898/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5012 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 899/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4995 - val_loss: 0.4526 - val_mse: 0.4467\n",
      "Epoch 900/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5050 - mse: 0.4991\n",
      "Epoch 00900: saving model to Regression_Model/mle.linear-0900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4994 - val_loss: 0.4489 - val_mse: 0.4430\n",
      "Epoch 901/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5032 - val_loss: 0.4488 - val_mse: 0.4429\n",
      "Epoch 902/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4973 - val_loss: 0.4524 - val_mse: 0.4465\n",
      "Epoch 903/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5157 - mse: 0.5098 - val_loss: 0.4518 - val_mse: 0.4459\n",
      "Epoch 904/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4982 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 905/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5032 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 906/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4960 - val_loss: 0.4496 - val_mse: 0.4437\n",
      "Epoch 907/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5017 - val_loss: 0.4530 - val_mse: 0.4471\n",
      "Epoch 908/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5022 - val_loss: 0.4515 - val_mse: 0.4456\n",
      "Epoch 909/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4986 - val_loss: 0.4509 - val_mse: 0.4450\n",
      "Epoch 910/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5070 - mse: 0.5011\n",
      "Epoch 00910: saving model to Regression_Model/mle.linear-0910.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5004 - val_loss: 0.4515 - val_mse: 0.4456\n",
      "Epoch 911/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5043 - val_loss: 0.4511 - val_mse: 0.4452\n",
      "Epoch 912/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5044 - val_loss: 0.4502 - val_mse: 0.4443\n",
      "Epoch 913/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5126 - mse: 0.5067 - val_loss: 0.4517 - val_mse: 0.4458\n",
      "Epoch 914/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5073 - val_loss: 0.4507 - val_mse: 0.4448\n",
      "Epoch 915/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5137 - mse: 0.5078 - val_loss: 0.4502 - val_mse: 0.4443\n",
      "Epoch 916/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5012 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 917/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5055 - val_loss: 0.4507 - val_mse: 0.4448\n",
      "Epoch 918/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5012 - val_loss: 0.4501 - val_mse: 0.4442\n",
      "Epoch 919/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5008 - val_loss: 0.4503 - val_mse: 0.4444\n",
      "Epoch 920/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5057 - mse: 0.4998\n",
      "Epoch 00920: saving model to Regression_Model/mle.linear-0920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5000 - val_loss: 0.4502 - val_mse: 0.4443\n",
      "Epoch 921/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 922/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5049 - val_loss: 0.4536 - val_mse: 0.4477\n",
      "Epoch 923/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5004 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 924/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4972 - val_loss: 0.4512 - val_mse: 0.4453\n",
      "Epoch 925/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4986 - val_loss: 0.4519 - val_mse: 0.4460\n",
      "Epoch 926/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5053 - val_loss: 0.4502 - val_mse: 0.4443\n",
      "Epoch 927/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4975 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 928/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5000 - val_loss: 0.4510 - val_mse: 0.4451\n",
      "Epoch 929/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5074 - val_loss: 0.4489 - val_mse: 0.4430\n",
      "Epoch 930/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5076 - mse: 0.5017\n",
      "Epoch 00930: saving model to Regression_Model/mle.linear-0930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5003 - val_loss: 0.4519 - val_mse: 0.4460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 931/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5003 - val_loss: 0.4513 - val_mse: 0.4454\n",
      "Epoch 932/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5020 - val_loss: 0.4516 - val_mse: 0.4457\n",
      "Epoch 933/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5116 - mse: 0.5057 - val_loss: 0.4504 - val_mse: 0.4445\n",
      "Epoch 934/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5008 - val_loss: 0.4499 - val_mse: 0.4440\n",
      "Epoch 935/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4997 - val_loss: 0.4511 - val_mse: 0.4452\n",
      "Epoch 936/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5019 - val_loss: 0.4510 - val_mse: 0.4451\n",
      "Epoch 937/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5035 - val_loss: 0.4513 - val_mse: 0.4454\n",
      "Epoch 938/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5054 - val_loss: 0.4523 - val_mse: 0.4465\n",
      "Epoch 939/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5110 - mse: 0.5051 - val_loss: 0.4526 - val_mse: 0.4467\n",
      "Epoch 940/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5090 - mse: 0.5031\n",
      "Epoch 00940: saving model to Regression_Model/mle.linear-0940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5028 - val_loss: 0.4505 - val_mse: 0.4447\n",
      "Epoch 941/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5005 - val_loss: 0.4516 - val_mse: 0.4457\n",
      "Epoch 942/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4989 - val_loss: 0.4525 - val_mse: 0.4466\n",
      "Epoch 943/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4985 - val_loss: 0.4509 - val_mse: 0.4450\n",
      "Epoch 944/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4985 - val_loss: 0.4508 - val_mse: 0.4449\n",
      "Epoch 945/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4985 - val_loss: 0.4499 - val_mse: 0.4440\n",
      "Epoch 946/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4984 - val_loss: 0.4486 - val_mse: 0.4427\n",
      "Epoch 947/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5125 - mse: 0.5066 - val_loss: 0.4493 - val_mse: 0.4434\n",
      "Epoch 948/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5005 - val_loss: 0.4506 - val_mse: 0.4447\n",
      "Epoch 949/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4951 - val_loss: 0.4503 - val_mse: 0.4444\n",
      "Epoch 950/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5066 - mse: 0.5007\n",
      "Epoch 00950: saving model to Regression_Model/mle.linear-0950.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4519 - val_mse: 0.4460\n",
      "Epoch 951/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5065 - val_loss: 0.4509 - val_mse: 0.4450\n",
      "Epoch 952/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5026 - val_loss: 0.4528 - val_mse: 0.4469\n",
      "Epoch 953/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4948 - val_loss: 0.4510 - val_mse: 0.4451\n",
      "Epoch 954/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4509 - val_mse: 0.4450\n",
      "Epoch 955/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5058 - val_loss: 0.4509 - val_mse: 0.4450\n",
      "Epoch 956/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5009 - val_loss: 0.4506 - val_mse: 0.4447\n",
      "Epoch 957/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5037 - val_loss: 0.4503 - val_mse: 0.4444\n",
      "Epoch 958/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4988 - val_loss: 0.4512 - val_mse: 0.4453\n",
      "Epoch 959/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.4999 - val_loss: 0.4512 - val_mse: 0.4454\n",
      "Epoch 960/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5047 - mse: 0.4989\n",
      "Epoch 00960: saving model to Regression_Model/mle.linear-0960.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5026 - mse: 0.4967 - val_loss: 0.4532 - val_mse: 0.4473\n",
      "Epoch 961/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5074 - val_loss: 0.4513 - val_mse: 0.4455\n",
      "Epoch 962/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5043 - val_loss: 0.4519 - val_mse: 0.4460\n",
      "Epoch 963/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.4999 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 964/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5040 - val_loss: 0.4507 - val_mse: 0.4448\n",
      "Epoch 965/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5072 - val_loss: 0.4509 - val_mse: 0.4450\n",
      "Epoch 966/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4504 - val_mse: 0.4446\n",
      "Epoch 967/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5031 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 968/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4965 - val_loss: 0.4502 - val_mse: 0.4443\n",
      "Epoch 969/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5032 - val_loss: 0.4490 - val_mse: 0.4431\n",
      "Epoch 970/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5097 - mse: 0.5038\n",
      "Epoch 00970: saving model to Regression_Model/mle.linear-0970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5029 - val_loss: 0.4503 - val_mse: 0.4444\n",
      "Epoch 971/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5017 - val_loss: 0.4501 - val_mse: 0.4442\n",
      "Epoch 972/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4972 - mse: 0.4913 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 973/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5034 - val_loss: 0.4504 - val_mse: 0.4445\n",
      "Epoch 974/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5033 - val_loss: 0.4515 - val_mse: 0.4456\n",
      "Epoch 975/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4981 - val_loss: 0.4504 - val_mse: 0.4445\n",
      "Epoch 976/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5036 - val_loss: 0.4519 - val_mse: 0.4460\n",
      "Epoch 977/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5028 - val_loss: 0.4524 - val_mse: 0.4466\n",
      "Epoch 978/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5116 - mse: 0.5058 - val_loss: 0.4523 - val_mse: 0.4464\n",
      "Epoch 979/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5047 - val_loss: 0.4511 - val_mse: 0.4452\n",
      "Epoch 980/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5002 - mse: 0.4944\n",
      "Epoch 00980: saving model to Regression_Model/mle.linear-0980.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5002 - mse: 0.4943 - val_loss: 0.4516 - val_mse: 0.4457\n",
      "Epoch 981/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5043 - val_loss: 0.4510 - val_mse: 0.4451\n",
      "Epoch 982/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5017 - val_loss: 0.4510 - val_mse: 0.4451\n",
      "Epoch 983/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4990 - val_loss: 0.4499 - val_mse: 0.4440\n",
      "Epoch 984/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4998 - mse: 0.4939 - val_loss: 0.4496 - val_mse: 0.4437\n",
      "Epoch 985/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5033 - val_loss: 0.4501 - val_mse: 0.4442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 986/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5008 - val_loss: 0.4506 - val_mse: 0.4447\n",
      "Epoch 987/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5035 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 988/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5132 - mse: 0.5073 - val_loss: 0.4520 - val_mse: 0.4461\n",
      "Epoch 989/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5019 - val_loss: 0.4508 - val_mse: 0.4449\n",
      "Epoch 990/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5098 - mse: 0.5040\n",
      "Epoch 00990: saving model to Regression_Model/mle.linear-0990.ckpt\n",
      "368/368 [==============================] - 4s 11ms/step - loss: 0.5102 - mse: 0.5043 - val_loss: 0.4517 - val_mse: 0.4458\n",
      "Epoch 991/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5008 - val_loss: 0.4500 - val_mse: 0.4441\n",
      "Epoch 992/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5053 - val_loss: 0.4522 - val_mse: 0.4464\n",
      "Epoch 993/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4491 - val_mse: 0.4432\n",
      "Epoch 994/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5029 - val_loss: 0.4487 - val_mse: 0.4428\n",
      "Epoch 995/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 996/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5055 - val_loss: 0.4509 - val_mse: 0.4451\n",
      "Epoch 997/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5034 - val_loss: 0.4509 - val_mse: 0.4450\n",
      "Epoch 998/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5138 - mse: 0.5079 - val_loss: 0.4504 - val_mse: 0.4446\n",
      "Epoch 999/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5040 - val_loss: 0.4517 - val_mse: 0.4458\n",
      "Epoch 1000/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5094 - mse: 0.5036\n",
      "Epoch 01000: saving model to Regression_Model/mle.linear-1000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5034 - val_loss: 0.4507 - val_mse: 0.4449\n",
      "Epoch 1001/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4511 - val_mse: 0.4452\n",
      "Epoch 1002/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5026 - val_loss: 0.4502 - val_mse: 0.4444\n",
      "Epoch 1003/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4509 - val_mse: 0.4450\n",
      "Epoch 1004/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4494 - val_mse: 0.4436\n",
      "Epoch 1005/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5119 - mse: 0.5060 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 1006/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5064 - val_loss: 0.4502 - val_mse: 0.4444\n",
      "Epoch 1007/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5143 - mse: 0.5085 - val_loss: 0.4490 - val_mse: 0.4431\n",
      "Epoch 1008/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5020 - val_loss: 0.4511 - val_mse: 0.4453\n",
      "Epoch 1009/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5021 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1010/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5079 - mse: 0.5020\n",
      "Epoch 01010: saving model to Regression_Model/mle.linear-1010.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4496 - val_mse: 0.4437\n",
      "Epoch 1011/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4979 - val_loss: 0.4503 - val_mse: 0.4444\n",
      "Epoch 1012/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5005 - val_loss: 0.4494 - val_mse: 0.4435\n",
      "Epoch 1013/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5130 - mse: 0.5072 - val_loss: 0.4529 - val_mse: 0.4470\n",
      "Epoch 1014/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5034 - val_loss: 0.4499 - val_mse: 0.4441\n",
      "Epoch 1015/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4511 - val_mse: 0.4453\n",
      "Epoch 1016/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5023 - val_loss: 0.4498 - val_mse: 0.4439\n",
      "Epoch 1017/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4972 - val_loss: 0.4494 - val_mse: 0.4436\n",
      "Epoch 1018/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5083 - val_loss: 0.4510 - val_mse: 0.4451\n",
      "Epoch 1019/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4511 - val_mse: 0.4452\n",
      "Epoch 1020/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5035 - mse: 0.4977\n",
      "Epoch 01020: saving model to Regression_Model/mle.linear-1020.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5039 - mse: 0.4980 - val_loss: 0.4495 - val_mse: 0.4436\n",
      "Epoch 1021/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5013 - val_loss: 0.4495 - val_mse: 0.4436\n",
      "Epoch 1022/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4483 - val_mse: 0.4424\n",
      "Epoch 1023/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5082 - val_loss: 0.4500 - val_mse: 0.4441\n",
      "Epoch 1024/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 1025/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4982 - val_loss: 0.4490 - val_mse: 0.4431\n",
      "Epoch 1026/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5020 - val_loss: 0.4505 - val_mse: 0.4447\n",
      "Epoch 1027/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5048 - val_loss: 0.4501 - val_mse: 0.4442\n",
      "Epoch 1028/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4989 - val_loss: 0.4491 - val_mse: 0.4432\n",
      "Epoch 1029/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4501 - val_mse: 0.4443\n",
      "Epoch 1030/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5065 - mse: 0.5006\n",
      "Epoch 01030: saving model to Regression_Model/mle.linear-1030.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4992 - val_loss: 0.4496 - val_mse: 0.4438\n",
      "Epoch 1031/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5084 - val_loss: 0.4499 - val_mse: 0.4441\n",
      "Epoch 1032/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4949 - val_loss: 0.4492 - val_mse: 0.4433\n",
      "Epoch 1033/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1034/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5000 - mse: 0.4942 - val_loss: 0.4494 - val_mse: 0.4436\n",
      "Epoch 1035/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5023 - val_loss: 0.4500 - val_mse: 0.4441\n",
      "Epoch 1036/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4989 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1037/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4484 - val_mse: 0.4425\n",
      "Epoch 1038/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5025 - val_loss: 0.4504 - val_mse: 0.4445\n",
      "Epoch 1039/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4504 - val_mse: 0.4445\n",
      "Epoch 1040/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5164 - mse: 0.5106\n",
      "Epoch 01040: saving model to Regression_Model/mle.linear-1040.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5143 - mse: 0.5085 - val_loss: 0.4508 - val_mse: 0.4449\n",
      "Epoch 1041/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4963 - val_loss: 0.4508 - val_mse: 0.4449\n",
      "Epoch 1042/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5044 - val_loss: 0.4499 - val_mse: 0.4440\n",
      "Epoch 1043/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4507 - val_mse: 0.4448\n",
      "Epoch 1044/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4967 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 1045/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4517 - val_mse: 0.4459\n",
      "Epoch 1046/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5034 - val_loss: 0.4506 - val_mse: 0.4448\n",
      "Epoch 1047/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5031 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 1048/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5000 - val_loss: 0.4531 - val_mse: 0.4473\n",
      "Epoch 1049/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4517 - val_mse: 0.4458\n",
      "Epoch 1050/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5002 - mse: 0.4944\n",
      "Epoch 01050: saving model to Regression_Model/mle.linear-1050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4956 - val_loss: 0.4504 - val_mse: 0.4446\n",
      "Epoch 1051/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5119 - mse: 0.5061 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1052/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5042 - val_loss: 0.4491 - val_mse: 0.4432\n",
      "Epoch 1053/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5055 - val_loss: 0.4498 - val_mse: 0.4439\n",
      "Epoch 1054/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5102 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1055/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4978 - val_loss: 0.4490 - val_mse: 0.4432\n",
      "Epoch 1056/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5050 - val_loss: 0.4510 - val_mse: 0.4452\n",
      "Epoch 1057/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4510 - val_mse: 0.4452\n",
      "Epoch 1058/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5010 - val_loss: 0.4501 - val_mse: 0.4443\n",
      "Epoch 1059/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4513 - val_mse: 0.4455\n",
      "Epoch 1060/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5072 - mse: 0.5014\n",
      "Epoch 01060: saving model to Regression_Model/mle.linear-1060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5031 - val_loss: 0.4509 - val_mse: 0.4450\n",
      "Epoch 1061/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5120 - mse: 0.5061 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1062/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1063/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4505 - val_mse: 0.4447\n",
      "Epoch 1064/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4992 - val_loss: 0.4490 - val_mse: 0.4431\n",
      "Epoch 1065/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4991 - val_loss: 0.4502 - val_mse: 0.4443\n",
      "Epoch 1066/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5029 - val_loss: 0.4507 - val_mse: 0.4448\n",
      "Epoch 1067/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4504 - val_mse: 0.4446\n",
      "Epoch 1068/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5011 - val_loss: 0.4495 - val_mse: 0.4436\n",
      "Epoch 1069/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5024 - val_loss: 0.4509 - val_mse: 0.4451\n",
      "Epoch 1070/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5107 - mse: 0.5049\n",
      "Epoch 01070: saving model to Regression_Model/mle.linear-1070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5045 - val_loss: 0.4516 - val_mse: 0.4457\n",
      "Epoch 1071/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4516 - val_mse: 0.4458\n",
      "Epoch 1072/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4984 - val_loss: 0.4497 - val_mse: 0.4438\n",
      "Epoch 1073/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4976 - val_loss: 0.4493 - val_mse: 0.4434\n",
      "Epoch 1074/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5009 - val_loss: 0.4494 - val_mse: 0.4435\n",
      "Epoch 1075/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4495 - val_mse: 0.4436\n",
      "Epoch 1076/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5022 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1077/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5032 - val_loss: 0.4507 - val_mse: 0.4448\n",
      "Epoch 1078/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4989 - val_loss: 0.4499 - val_mse: 0.4441\n",
      "Epoch 1079/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5051 - val_loss: 0.4523 - val_mse: 0.4464\n",
      "Epoch 1080/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5022 - mse: 0.4963\n",
      "Epoch 01080: saving model to Regression_Model/mle.linear-1080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4498 - val_mse: 0.4440\n",
      "Epoch 1081/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4493 - val_mse: 0.4434\n",
      "Epoch 1082/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1083/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5047 - val_loss: 0.4497 - val_mse: 0.4439\n",
      "Epoch 1084/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4987 - val_loss: 0.4496 - val_mse: 0.4437\n",
      "Epoch 1085/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4508 - val_mse: 0.4449\n",
      "Epoch 1086/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5017 - val_loss: 0.4504 - val_mse: 0.4445\n",
      "Epoch 1087/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5052 - val_loss: 0.4503 - val_mse: 0.4445\n",
      "Epoch 1088/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5018 - val_loss: 0.4490 - val_mse: 0.4432\n",
      "Epoch 1089/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5038 - val_loss: 0.4498 - val_mse: 0.4440\n",
      "Epoch 1090/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5100 - mse: 0.5042\n",
      "Epoch 01090: saving model to Regression_Model/mle.linear-1090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5038 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1091/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4485 - val_mse: 0.4426\n",
      "Epoch 1092/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4490 - val_mse: 0.4432\n",
      "Epoch 1093/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5028 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1094/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5041 - val_loss: 0.4508 - val_mse: 0.4450\n",
      "Epoch 1095/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5023 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1096/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5005 - val_loss: 0.4494 - val_mse: 0.4436\n",
      "Epoch 1097/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5048 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1098/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4497 - val_mse: 0.4439\n",
      "Epoch 1099/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1100/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5115 - mse: 0.5057\n",
      "Epoch 01100: saving model to Regression_Model/mle.linear-1100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5054 - val_loss: 0.4514 - val_mse: 0.4455\n",
      "Epoch 1101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5015 - val_loss: 0.4487 - val_mse: 0.4428\n",
      "Epoch 1102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4490 - val_mse: 0.4432\n",
      "Epoch 1103/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4952 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5023 - val_loss: 0.4486 - val_mse: 0.4427\n",
      "Epoch 1106/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5019 - val_loss: 0.4496 - val_mse: 0.4438\n",
      "Epoch 1107/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5032 - val_loss: 0.4495 - val_mse: 0.4437\n",
      "Epoch 1108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4984 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5136 - mse: 0.5077 - val_loss: 0.4505 - val_mse: 0.4446\n",
      "Epoch 1110/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5048 - mse: 0.4989\n",
      "Epoch 01110: saving model to Regression_Model/mle.linear-1110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4986 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4500 - val_mse: 0.4441\n",
      "Epoch 1112/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4994 - val_loss: 0.4505 - val_mse: 0.4447\n",
      "Epoch 1113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5033 - val_loss: 0.4506 - val_mse: 0.4448\n",
      "Epoch 1114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5024 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5025 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1116/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5005 - val_loss: 0.4494 - val_mse: 0.4435\n",
      "Epoch 1117/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5059 - val_loss: 0.4501 - val_mse: 0.4443\n",
      "Epoch 1118/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5120 - mse: 0.5061 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5033 - val_loss: 0.4482 - val_mse: 0.4423\n",
      "Epoch 1120/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5054 - mse: 0.4995\n",
      "Epoch 01120: saving model to Regression_Model/mle.linear-1120.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.5053 - mse: 0.4994 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4956 - val_loss: 0.4496 - val_mse: 0.4438\n",
      "Epoch 1122/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4487 - val_mse: 0.4428\n",
      "Epoch 1123/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5020 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1124/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5017 - val_loss: 0.4513 - val_mse: 0.4455\n",
      "Epoch 1125/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4490 - val_mse: 0.4431\n",
      "Epoch 1126/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5024 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1127/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5032 - val_loss: 0.4497 - val_mse: 0.4439\n",
      "Epoch 1128/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4489 - val_mse: 0.4430\n",
      "Epoch 1129/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4497 - val_mse: 0.4438\n",
      "Epoch 1130/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5023 - mse: 0.4965\n",
      "Epoch 01130: saving model to Regression_Model/mle.linear-1130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1131/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4929 - val_loss: 0.4480 - val_mse: 0.4421\n",
      "Epoch 1132/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5016 - val_loss: 0.4508 - val_mse: 0.4450\n",
      "Epoch 1133/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4494 - val_mse: 0.4436\n",
      "Epoch 1134/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4982 - val_loss: 0.4502 - val_mse: 0.4444\n",
      "Epoch 1135/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4987 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1136/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5075 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1137/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1138/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5009 - val_loss: 0.4517 - val_mse: 0.4458\n",
      "Epoch 1139/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5021 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1140/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5051 - mse: 0.4993\n",
      "Epoch 01140: saving model to Regression_Model/mle.linear-1140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4980 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1141/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4980 - val_loss: 0.4499 - val_mse: 0.4441\n",
      "Epoch 1142/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4481 - val_mse: 0.4422\n",
      "Epoch 1143/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5017 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1144/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5045 - val_loss: 0.4500 - val_mse: 0.4441\n",
      "Epoch 1145/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4948 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1146/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1147/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1148/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4482 - val_mse: 0.4423\n",
      "Epoch 1149/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4980 - val_loss: 0.4506 - val_mse: 0.4447\n",
      "Epoch 1150/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5114 - mse: 0.5056\n",
      "Epoch 01150: saving model to Regression_Model/mle.linear-1150.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5096 - mse: 0.5038 - val_loss: 0.4496 - val_mse: 0.4438\n",
      "Epoch 1151/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5047 - val_loss: 0.4497 - val_mse: 0.4439\n",
      "Epoch 1152/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4496 - val_mse: 0.4438\n",
      "Epoch 1153/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4975 - val_loss: 0.4496 - val_mse: 0.4438\n",
      "Epoch 1154/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4496 - val_mse: 0.4438\n",
      "Epoch 1155/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1156/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5120 - mse: 0.5062 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1157/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5107 - mse: 0.5049 - val_loss: 0.4496 - val_mse: 0.4438\n",
      "Epoch 1158/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5035 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1159/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4947 - val_loss: 0.4506 - val_mse: 0.4448\n",
      "Epoch 1160/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5035 - mse: 0.4977\n",
      "Epoch 01160: saving model to Regression_Model/mle.linear-1160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4488 - val_mse: 0.4429\n",
      "Epoch 1161/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4947 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1162/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5110 - mse: 0.5051 - val_loss: 0.4508 - val_mse: 0.4449\n",
      "Epoch 1163/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5024 - val_loss: 0.4490 - val_mse: 0.4432\n",
      "Epoch 1164/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1165/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5051 - val_loss: 0.4504 - val_mse: 0.4445\n",
      "Epoch 1166/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1167/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5050 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1168/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4482 - val_mse: 0.4423\n",
      "Epoch 1169/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4495 - val_mse: 0.4437\n",
      "Epoch 1170/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5045 - mse: 0.4987\n",
      "Epoch 01170: saving model to Regression_Model/mle.linear-1170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1171/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4986 - val_loss: 0.4507 - val_mse: 0.4448\n",
      "Epoch 1172/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4936 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1173/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5035 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1174/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5039 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1175/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5017 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1176/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5066 - val_loss: 0.4499 - val_mse: 0.4441\n",
      "Epoch 1177/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4498 - val_mse: 0.4439\n",
      "Epoch 1178/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4977 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1179/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1180/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5107 - mse: 0.5049\n",
      "Epoch 01180: saving model to Regression_Model/mle.linear-1180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5042 - val_loss: 0.4495 - val_mse: 0.4436\n",
      "Epoch 1181/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5024 - val_loss: 0.4501 - val_mse: 0.4443\n",
      "Epoch 1182/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4956 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1183/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1184/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1185/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4495 - val_mse: 0.4437\n",
      "Epoch 1186/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1187/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1188/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5040 - val_loss: 0.4494 - val_mse: 0.4436\n",
      "Epoch 1189/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1190/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5080 - mse: 0.5021\n",
      "Epoch 01190: saving model to Regression_Model/mle.linear-1190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4487 - val_mse: 0.4428\n",
      "Epoch 1191/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5042 - val_loss: 0.4495 - val_mse: 0.4436\n",
      "Epoch 1192/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5014 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1193/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5059 - val_loss: 0.4495 - val_mse: 0.4437\n",
      "Epoch 1194/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1195/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1196/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1197/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5043 - val_loss: 0.4490 - val_mse: 0.4432\n",
      "Epoch 1198/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1199/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1200/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5066 - mse: 0.5008\n",
      "Epoch 01200: saving model to Regression_Model/mle.linear-1200.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4485 - val_mse: 0.4427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1201/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1202/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5152 - mse: 0.5094 - val_loss: 0.4495 - val_mse: 0.4437\n",
      "Epoch 1203/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1204/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5028 - val_loss: 0.4497 - val_mse: 0.4439\n",
      "Epoch 1205/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1206/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4973 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1207/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5065 - val_loss: 0.4498 - val_mse: 0.4440\n",
      "Epoch 1208/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1209/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4979 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1210/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5078 - mse: 0.5020\n",
      "Epoch 01210: saving model to Regression_Model/mle.linear-1210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5013 - val_loss: 0.4499 - val_mse: 0.4440\n",
      "Epoch 1211/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4501 - val_mse: 0.4443\n",
      "Epoch 1212/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5024 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1213/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1214/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5107 - mse: 0.5049 - val_loss: 0.4500 - val_mse: 0.4442\n",
      "Epoch 1215/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4970 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1216/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5028 - val_loss: 0.4509 - val_mse: 0.4451\n",
      "Epoch 1217/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5053 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1218/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4482 - val_mse: 0.4423\n",
      "Epoch 1219/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5026 - val_loss: 0.4489 - val_mse: 0.4430\n",
      "Epoch 1220/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5091 - mse: 0.5033\n",
      "Epoch 01220: saving model to Regression_Model/mle.linear-1220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5032 - val_loss: 0.4485 - val_mse: 0.4426\n",
      "Epoch 1221/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1222/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4971 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1223/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5115 - mse: 0.5057 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1224/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4939 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1225/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1226/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5059 - val_loss: 0.4490 - val_mse: 0.4431\n",
      "Epoch 1227/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4930 - val_loss: 0.4495 - val_mse: 0.4437\n",
      "Epoch 1228/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4498 - val_mse: 0.4439\n",
      "Epoch 1229/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5145 - mse: 0.5087 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1230/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5088 - mse: 0.5030\n",
      "Epoch 01230: saving model to Regression_Model/mle.linear-1230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5024 - val_loss: 0.4493 - val_mse: 0.4434\n",
      "Epoch 1231/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4956 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1232/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1233/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4946 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1234/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1235/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5110 - mse: 0.5052 - val_loss: 0.4482 - val_mse: 0.4423\n",
      "Epoch 1236/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4960 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1237/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5017 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1238/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1239/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5032 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1240/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5107 - mse: 0.5048\n",
      "Epoch 01240: saving model to Regression_Model/mle.linear-1240.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5077 - mse: 0.5019 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1241/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5015 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1242/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5029 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1243/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1244/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5047 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1245/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5034 - val_loss: 0.4489 - val_mse: 0.4430\n",
      "Epoch 1246/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1247/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1248/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1249/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4497 - val_mse: 0.4439\n",
      "Epoch 1250/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5019 - mse: 0.4961\n",
      "Epoch 01250: saving model to Regression_Model/mle.linear-1250.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4484 - val_mse: 0.4425\n",
      "Epoch 1251/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1252/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1253/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1254/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5040 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1255/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5010 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1256/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4499 - val_mse: 0.4441\n",
      "Epoch 1257/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1258/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1259/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1260/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5099 - mse: 0.5041\n",
      "Epoch 01260: saving model to Regression_Model/mle.linear-1260.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1261/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1262/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4481 - val_mse: 0.4422\n",
      "Epoch 1263/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5026 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1264/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5020 - mse: 0.4962 - val_loss: 0.4490 - val_mse: 0.4432\n",
      "Epoch 1265/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1266/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5033 - val_loss: 0.4483 - val_mse: 0.4424\n",
      "Epoch 1267/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4954 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1268/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1269/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1270/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5034 - mse: 0.4976\n",
      "Epoch 01270: saving model to Regression_Model/mle.linear-1270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1271/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1272/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5017 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1273/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1274/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1275/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4480 - val_mse: 0.4421\n",
      "Epoch 1276/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5110 - mse: 0.5052 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1277/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1278/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4496 - val_mse: 0.4438\n",
      "Epoch 1279/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1280/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5097 - mse: 0.5039\n",
      "Epoch 01280: saving model to Regression_Model/mle.linear-1280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5016 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1281/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5031 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1282/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4490 - val_mse: 0.4432\n",
      "Epoch 1283/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1284/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4495 - val_mse: 0.4437\n",
      "Epoch 1285/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4494 - val_mse: 0.4436\n",
      "Epoch 1286/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4487 - val_mse: 0.4428\n",
      "Epoch 1287/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1288/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1289/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1290/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5034 - mse: 0.4976\n",
      "Epoch 01290: saving model to Regression_Model/mle.linear-1290.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5038 - mse: 0.4979 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1291/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1292/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4950 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1293/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1294/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1295/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1296/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5037 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1297/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4963 - mse: 0.4905 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1298/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1299/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5028 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1300/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5043 - mse: 0.4985\n",
      "Epoch 01300: saving model to Regression_Model/mle.linear-1300.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1301/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4968 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1302/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4944 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1303/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4497 - val_mse: 0.4439\n",
      "Epoch 1304/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4950 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1305/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4933 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1306/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1307/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1308/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1309/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5022 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1310/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5104 - mse: 0.5046\n",
      "Epoch 01310: saving model to Regression_Model/mle.linear-1310.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5103 - mse: 0.5045 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1311/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5028 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1312/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1313/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1314/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1315/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4958 - mse: 0.4900 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1316/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1317/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1318/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5022 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1319/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1320/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5017 - mse: 0.4959\n",
      "Epoch 01320: saving model to Regression_Model/mle.linear-1320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4962 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1321/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4994 - mse: 0.4936 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1322/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1323/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1324/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4493 - val_mse: 0.4435\n",
      "Epoch 1325/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1326/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1327/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1328/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1329/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1330/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5045 - mse: 0.4987\n",
      "Epoch 01330: saving model to Regression_Model/mle.linear-1330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1331/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1332/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1333/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4903 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1334/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1335/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1336/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1337/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1338/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4987 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1339/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1340/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5042 - mse: 0.4984\n",
      "Epoch 01340: saving model to Regression_Model/mle.linear-1340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1341/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4487 - val_mse: 0.4429\n",
      "Epoch 1342/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4492 - val_mse: 0.4434\n",
      "Epoch 1343/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5136 - mse: 0.5078 - val_loss: 0.4498 - val_mse: 0.4440\n",
      "Epoch 1344/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4930 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1345/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5053 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1346/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5034 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1347/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1348/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1349/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5054 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1350/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5075 - mse: 0.5017\n",
      "Epoch 01350: saving model to Regression_Model/mle.linear-1350.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5071 - mse: 0.5013 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1351/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1352/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5064 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1353/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1354/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1355/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4488 - val_mse: 0.4430\n",
      "Epoch 1356/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4490 - val_mse: 0.4432\n",
      "Epoch 1357/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5037 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1358/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1359/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4495 - val_mse: 0.4437\n",
      "Epoch 1360/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4990 - mse: 0.4932\n",
      "Epoch 01360: saving model to Regression_Model/mle.linear-1360.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4979 - mse: 0.4921 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1361/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1362/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4934 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1363/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4950 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1364/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1365/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4934 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1366/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1367/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1368/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5023 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1369/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4966 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1370/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5048 - mse: 0.4990\n",
      "Epoch 01370: saving model to Regression_Model/mle.linear-1370.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1371/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1372/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1373/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1374/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4491 - val_mse: 0.4433\n",
      "Epoch 1375/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5023 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1376/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1377/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1378/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1379/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4938 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1380/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5070 - mse: 0.5012\n",
      "Epoch 01380: saving model to Regression_Model/mle.linear-1380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1381/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1382/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1383/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4483 - val_mse: 0.4426\n",
      "Epoch 1384/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5055 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1385/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1386/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1387/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4977 - mse: 0.4919 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1388/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1389/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1390/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4996 - mse: 0.4938\n",
      "Epoch 01390: saving model to Regression_Model/mle.linear-1390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5000 - mse: 0.4942 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1391/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1392/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1393/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1394/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1395/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1396/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1397/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5044 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1398/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4935 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1399/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1400/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5057 - mse: 0.4999\n",
      "Epoch 01400: saving model to Regression_Model/mle.linear-1400.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1401/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1402/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1403/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4949 - val_loss: 0.4489 - val_mse: 0.4431\n",
      "Epoch 1404/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5045 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1405/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5107 - mse: 0.5049 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1406/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1407/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1408/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1409/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5028 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1410/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5108 - mse: 0.5050\n",
      "Epoch 01410: saving model to Regression_Model/mle.linear-1410.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1411/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1412/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5110 - mse: 0.5052 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1413/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1414/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5045 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1415/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1416/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1417/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1418/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1419/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1420/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4950 - mse: 0.4892\n",
      "Epoch 01420: saving model to Regression_Model/mle.linear-1420.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4963 - mse: 0.4905 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1421/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4967 - val_loss: 0.4479 - val_mse: 0.4422\n",
      "Epoch 1422/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5006 - mse: 0.4948 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1423/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1424/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1425/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1426/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4987 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1427/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5025 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1428/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1429/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4932 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1430/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5020 - mse: 0.4962\n",
      "Epoch 01430: saving model to Regression_Model/mle.linear-1430.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5022 - mse: 0.4965 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1431/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5064 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1432/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1433/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1434/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1435/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5048 - val_loss: 0.4483 - val_mse: 0.4426\n",
      "Epoch 1436/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1437/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1438/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4993 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1439/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1440/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5056 - mse: 0.4999\n",
      "Epoch 01440: saving model to Regression_Model/mle.linear-1440.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1441/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5022 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1442/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4989 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1443/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1444/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1445/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5043 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1446/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4968 - mse: 0.4911 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1447/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4991 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1448/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4968 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1449/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4479 - val_mse: 0.4422\n",
      "Epoch 1450/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5047 - mse: 0.4990\n",
      "Epoch 01450: saving model to Regression_Model/mle.linear-1450.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1451/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1452/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4479 - val_mse: 0.4422\n",
      "Epoch 1453/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1454/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1455/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4937 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1456/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4985 - mse: 0.4927 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1457/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1458/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4938 - val_loss: 0.4486 - val_mse: 0.4428\n",
      "Epoch 1459/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1460/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5042 - mse: 0.4984\n",
      "Epoch 01460: saving model to Regression_Model/mle.linear-1460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1461/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1462/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1463/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4968 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1464/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4934 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1465/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1466/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4911 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1467/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1468/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5055 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1469/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1470/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5061 - mse: 0.5003\n",
      "Epoch 01470: saving model to Regression_Model/mle.linear-1470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1471/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1472/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4962 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1473/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1474/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4978 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1475/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1476/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1477/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1478/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5037 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1479/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4480 - val_mse: 0.4423\n",
      "Epoch 1480/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4957 - mse: 0.4900\n",
      "Epoch 01480: saving model to Regression_Model/mle.linear-1480.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4968 - mse: 0.4911 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1481/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4946 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1482/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1483/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5128 - mse: 0.5070 - val_loss: 0.4485 - val_mse: 0.4428\n",
      "Epoch 1484/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1485/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4938 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1486/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1487/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4480 - val_mse: 0.4423\n",
      "Epoch 1488/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4983 - mse: 0.4925 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1489/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1490/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5029 - mse: 0.4971\n",
      "Epoch 01490: saving model to Regression_Model/mle.linear-1490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4957 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1491/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1492/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1493/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1494/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1495/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5026 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1496/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5034 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1497/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1498/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1499/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5047 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1500/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5075 - mse: 0.5017\n",
      "Epoch 01500: saving model to Regression_Model/mle.linear-1500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1501/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1502/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1503/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1504/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1505/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1506/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1507/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1508/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4480 - val_mse: 0.4423\n",
      "Epoch 1509/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1510/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5036 - mse: 0.4978\n",
      "Epoch 01510: saving model to Regression_Model/mle.linear-1510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1511/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1512/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5026 - val_loss: 0.4469 - val_mse: 0.4411\n",
      "Epoch 1513/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1514/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5073 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1515/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1516/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1517/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5019 - mse: 0.4962 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1518/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4948 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1519/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4956 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1520/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5049 - mse: 0.4992\n",
      "Epoch 01520: saving model to Regression_Model/mle.linear-1520.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1521/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1522/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1523/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4960 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1524/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5026 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1525/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5116 - mse: 0.5058 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1526/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4479 - val_mse: 0.4422\n",
      "Epoch 1527/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4950 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1528/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1529/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1530/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5064 - mse: 0.5007\n",
      "Epoch 01530: saving model to Regression_Model/mle.linear-1530.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1531/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4904 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1532/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4478 - val_mse: 0.4421\n",
      "Epoch 1533/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4967 - val_loss: 0.4467 - val_mse: 0.4409\n",
      "Epoch 1534/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5045 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1535/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1536/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1537/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1538/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5054 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1539/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4479 - val_mse: 0.4422\n",
      "Epoch 1540/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5073 - mse: 0.5016\n",
      "Epoch 01540: saving model to Regression_Model/mle.linear-1540.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1541/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5025 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1542/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1543/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4933 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1544/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4973 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1545/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4962 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1546/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5041 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1547/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4947 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1548/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1549/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5053 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1550/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5034 - mse: 0.4976\n",
      "Epoch 01550: saving model to Regression_Model/mle.linear-1550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4973 - val_loss: 0.4480 - val_mse: 0.4423\n",
      "Epoch 1551/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4966 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1552/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1553/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5027 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1554/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1555/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4944 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1556/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1557/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1558/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1559/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1560/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5107 - mse: 0.5049\n",
      "Epoch 01560: saving model to Regression_Model/mle.linear-1560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5047 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1561/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1562/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1563/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4479 - val_mse: 0.4422\n",
      "Epoch 1564/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5035 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1565/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4478 - val_mse: 0.4421\n",
      "Epoch 1566/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1567/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4956 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1568/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5002 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1569/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4480 - val_mse: 0.4423\n",
      "Epoch 1570/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5015 - mse: 0.4957\n",
      "Epoch 01570: saving model to Regression_Model/mle.linear-1570.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1571/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1572/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4478 - val_mse: 0.4421\n",
      "Epoch 1573/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1574/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1575/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1576/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1577/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4944 - val_loss: 0.4484 - val_mse: 0.4426\n",
      "Epoch 1578/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1579/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5064 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1580/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5060 - mse: 0.5003\n",
      "Epoch 01580: saving model to Regression_Model/mle.linear-1580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5016 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1581/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5004 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1582/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1583/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1584/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4949 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1585/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4981 - mse: 0.4923 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1586/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1587/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5002 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1588/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1589/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5011 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1590/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5028 - mse: 0.4970\n",
      "Epoch 01590: saving model to Regression_Model/mle.linear-1590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1591/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1592/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4973 - mse: 0.4915 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1593/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1594/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1595/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1596/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1597/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1598/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1599/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5011 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1600/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5065 - mse: 0.5007\n",
      "Epoch 01600: saving model to Regression_Model/mle.linear-1600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1601/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1602/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1603/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1604/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5033 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1605/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1606/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1607/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5019 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1608/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4988 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1609/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1610/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5078 - mse: 0.5020\n",
      "Epoch 01610: saving model to Regression_Model/mle.linear-1610.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4485 - val_mse: 0.4427\n",
      "Epoch 1611/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1612/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4993 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1613/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1614/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4988 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1615/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5026 - val_loss: 0.4478 - val_mse: 0.4421\n",
      "Epoch 1616/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5031 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1617/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1618/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4967 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1619/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5036 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1620/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4974 - mse: 0.4916\n",
      "Epoch 01620: saving model to Regression_Model/mle.linear-1620.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4978 - mse: 0.4920 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1621/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4478 - val_mse: 0.4421\n",
      "Epoch 1622/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1623/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1624/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1625/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4933 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1626/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1627/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4478 - val_mse: 0.4421\n",
      "Epoch 1628/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1629/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1630/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5050 - mse: 0.4992\n",
      "Epoch 01630: saving model to Regression_Model/mle.linear-1630.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5051 - mse: 0.4994 - val_loss: 0.4477 - val_mse: 0.4420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1631/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5042 - val_loss: 0.4480 - val_mse: 0.4423\n",
      "Epoch 1632/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1633/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4968 - val_loss: 0.4482 - val_mse: 0.4424\n",
      "Epoch 1634/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4484 - val_mse: 0.4427\n",
      "Epoch 1635/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4478 - val_mse: 0.4421\n",
      "Epoch 1636/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1637/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1638/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5010 - mse: 0.4953 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1639/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5111 - mse: 0.5053 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1640/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5038 - mse: 0.4980\n",
      "Epoch 01640: saving model to Regression_Model/mle.linear-1640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4480 - val_mse: 0.4423\n",
      "Epoch 1641/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4480 - val_mse: 0.4423\n",
      "Epoch 1642/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1643/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1644/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1645/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1646/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1647/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4483 - val_mse: 0.4425\n",
      "Epoch 1648/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1649/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4983 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1650/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5057 - mse: 0.4999\n",
      "Epoch 01650: saving model to Regression_Model/mle.linear-1650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1651/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4968 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1652/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4989 - val_loss: 0.4482 - val_mse: 0.4425\n",
      "Epoch 1653/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4978 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1654/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.5000 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1655/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1656/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1657/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1658/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5064 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1659/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1660/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5059 - mse: 0.5002\n",
      "Epoch 01660: saving model to Regression_Model/mle.linear-1660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4481 - val_mse: 0.4423\n",
      "Epoch 1661/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1662/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1663/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4926 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1664/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1665/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1666/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5001 - mse: 0.4943 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1667/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1668/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1669/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5037 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1670/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5062 - mse: 0.5005\n",
      "Epoch 01670: saving model to Regression_Model/mle.linear-1670.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1671/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1672/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1673/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1674/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1675/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1676/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1677/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4944 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1678/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1679/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1680/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5071 - mse: 0.5013\n",
      "Epoch 01680: saving model to Regression_Model/mle.linear-1680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5005 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1681/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5010 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1682/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1683/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4478 - val_mse: 0.4421\n",
      "Epoch 1684/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5099 - mse: 0.5041 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1685/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4941 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1686/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1687/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1688/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5129 - mse: 0.5071 - val_loss: 0.4478 - val_mse: 0.4421\n",
      "Epoch 1689/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4956 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1690/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5034 - mse: 0.4976\n",
      "Epoch 01690: saving model to Regression_Model/mle.linear-1690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1691/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1692/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1693/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4484 - val_mse: 0.4427\n",
      "Epoch 1694/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5016 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1695/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1696/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1697/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5003 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1698/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1699/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5028 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1700/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5019 - mse: 0.4962\n",
      "Epoch 01700: saving model to Regression_Model/mle.linear-1700.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4949 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1701/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1702/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1703/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4983 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1704/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1705/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4939 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1706/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1707/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1708/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5003 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1709/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1710/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5033 - mse: 0.4976\n",
      "Epoch 01710: saving model to Regression_Model/mle.linear-1710.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5038 - mse: 0.4981 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1711/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1712/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4480 - val_mse: 0.4423\n",
      "Epoch 1713/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1714/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1715/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4986 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1716/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4955 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1717/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4935 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1718/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1719/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1720/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5030 - mse: 0.4973\n",
      "Epoch 01720: saving model to Regression_Model/mle.linear-1720.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5011 - mse: 0.4953 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1721/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5064 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1722/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5037 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1723/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5037 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1724/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5000 - mse: 0.4943 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1725/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1726/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1727/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5013 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1728/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5012 - val_loss: 0.4469 - val_mse: 0.4412\n",
      "Epoch 1729/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4973 - mse: 0.4915 - val_loss: 0.4469 - val_mse: 0.4412\n",
      "Epoch 1730/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5038 - mse: 0.4980\n",
      "Epoch 01730: saving model to Regression_Model/mle.linear-1730.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1731/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4468 - val_mse: 0.4410\n",
      "Epoch 1732/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4932 - val_loss: 0.4467 - val_mse: 0.4409\n",
      "Epoch 1733/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4961 - val_loss: 0.4469 - val_mse: 0.4412\n",
      "Epoch 1734/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1735/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1736/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4967 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1737/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1738/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4975 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1739/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1740/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5009 - mse: 0.4952\n",
      "Epoch 01740: saving model to Regression_Model/mle.linear-1740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4945 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1741/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4939 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1742/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5046 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1743/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4947 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1744/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5083 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1745/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4958 - val_loss: 0.4469 - val_mse: 0.4411\n",
      "Epoch 1746/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5036 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1747/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4961 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1748/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5084 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1749/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4966 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1750/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5057 - mse: 0.4999\n",
      "Epoch 01750: saving model to Regression_Model/mle.linear-1750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1751/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1752/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5036 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1753/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1754/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5031 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1755/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1756/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4999 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1757/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1758/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1759/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4479 - val_mse: 0.4422\n",
      "Epoch 1760/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4986 - mse: 0.4928\n",
      "Epoch 01760: saving model to Regression_Model/mle.linear-1760.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4941 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1761/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5004 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1762/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5054 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1763/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1764/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1765/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1766/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5009 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1767/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1768/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5034 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1769/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5017 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1770/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5028 - mse: 0.4970\n",
      "Epoch 01770: saving model to Regression_Model/mle.linear-1770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4972 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1771/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1772/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1773/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1774/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1775/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1776/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5038 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1777/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4948 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1778/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1779/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1780/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5022 - mse: 0.4964\n",
      "Epoch 01780: saving model to Regression_Model/mle.linear-1780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1781/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5051 - val_loss: 0.4479 - val_mse: 0.4422\n",
      "Epoch 1782/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1783/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4980 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1784/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1785/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1786/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4480 - val_mse: 0.4422\n",
      "Epoch 1787/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5015 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1788/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1789/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1790/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5043 - mse: 0.4985\n",
      "Epoch 01790: saving model to Regression_Model/mle.linear-1790.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1791/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1792/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1793/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5028 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1794/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4961 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1795/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1796/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5016 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1797/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4985 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1798/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5022 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1799/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1800/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.5038 - mse: 0.4981\n",
      "Epoch 01800: saving model to Regression_Model/mle.linear-1800.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5015 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1801/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1802/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1803/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1804/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5009 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1805/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4992 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1806/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4932 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1807/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1808/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1809/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5013 - val_loss: 0.4477 - val_mse: 0.4420\n",
      "Epoch 1810/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5022 - mse: 0.4964\n",
      "Epoch 01810: saving model to Regression_Model/mle.linear-1810.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1811/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4986 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1812/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4942 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1813/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4984 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1814/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5033 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1815/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4994 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1816/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4945 - val_loss: 0.4478 - val_mse: 0.4420\n",
      "Epoch 1817/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5047 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1818/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1819/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1820/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5034 - mse: 0.4976\n",
      "Epoch 01820: saving model to Regression_Model/mle.linear-1820.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1821/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1822/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1823/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4956 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1824/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4929 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1825/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4957 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1826/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1827/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1828/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1829/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5020 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1830/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5041 - mse: 0.4983\n",
      "Epoch 01830: saving model to Regression_Model/mle.linear-1830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1831/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1832/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1833/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4968 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1834/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5060 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1835/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4981 - mse: 0.4923 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1836/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1837/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5024 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1838/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4983 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1839/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1840/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4990 - mse: 0.4933\n",
      "Epoch 01840: saving model to Regression_Model/mle.linear-1840.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5000 - mse: 0.4942 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1841/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5128 - mse: 0.5071 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1842/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4968 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1843/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5007 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1844/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5033 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1845/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5011 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1846/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1847/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1848/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4962 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1849/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5043 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1850/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5044 - mse: 0.4986\n",
      "Epoch 01850: saving model to Regression_Model/mle.linear-1850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1851/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1852/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1853/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5034 - val_loss: 0.4479 - val_mse: 0.4421\n",
      "Epoch 1854/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4983 - mse: 0.4925 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1855/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4987 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1856/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1857/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4985 - mse: 0.4927 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1858/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5047 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1859/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5060 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1860/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5038 - mse: 0.4980\n",
      "Epoch 01860: saving model to Regression_Model/mle.linear-1860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1861/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4477 - val_mse: 0.4419\n",
      "Epoch 1862/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1863/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1864/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4949 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1865/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4941 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1866/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4961 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1867/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1868/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4937 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1869/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1870/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5085 - mse: 0.5027\n",
      "Epoch 01870: saving model to Regression_Model/mle.linear-1870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5023 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1871/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4953 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1872/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4937 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1873/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5059 - mse: 0.5002 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1874/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4972 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1875/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5113 - mse: 0.5056 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1876/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4964 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1877/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5011 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 1878/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5072 - mse: 0.5015 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1879/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4940 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1880/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5042 - mse: 0.4984\n",
      "Epoch 01880: saving model to Regression_Model/mle.linear-1880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1881/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4970 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1882/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1883/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4985 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1884/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4934 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1885/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4980 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1886/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4978 - mse: 0.4921 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1887/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5040 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1888/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1889/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1890/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4998 - mse: 0.4941\n",
      "Epoch 01890: saving model to Regression_Model/mle.linear-1890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4942 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1891/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1892/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4928 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1893/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4939 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1894/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1895/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5094 - mse: 0.5037 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1896/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5035 - val_loss: 0.4476 - val_mse: 0.4419\n",
      "Epoch 1897/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1898/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4981 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1899/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5007 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1900/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5016 - mse: 0.4958\n",
      "Epoch 01900: saving model to Regression_Model/mle.linear-1900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4954 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1901/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5043 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1902/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1903/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4968 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1904/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4990 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1905/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1906/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5006 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1907/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1908/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4972 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1909/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1910/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5036 - mse: 0.4978\n",
      "Epoch 01910: saving model to Regression_Model/mle.linear-1910.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5001 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1911/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1912/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5026 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1913/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1914/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4956 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1915/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4966 - mse: 0.4908 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1916/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5044 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1917/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5031 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1918/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5022 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1919/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1920/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5059 - mse: 0.5001\n",
      "Epoch 01920: saving model to Regression_Model/mle.linear-1920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1921/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1922/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4469 - val_mse: 0.4411\n",
      "Epoch 1923/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4468 - val_mse: 0.4411\n",
      "Epoch 1924/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4469 - val_mse: 0.4412\n",
      "Epoch 1925/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5011 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1926/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4954 - mse: 0.4896 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1927/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5001 - mse: 0.4943 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1928/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5021 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1929/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4948 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1930/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5041 - mse: 0.4984\n",
      "Epoch 01930: saving model to Regression_Model/mle.linear-1930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5026 - val_loss: 0.4469 - val_mse: 0.4411\n",
      "Epoch 1931/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1932/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1933/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4933 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1934/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1935/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4970 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1936/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5021 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1937/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5012 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1938/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1939/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4986 - mse: 0.4929 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1940/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5004 - mse: 0.4947\n",
      "Epoch 01940: saving model to Regression_Model/mle.linear-1940.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5004 - mse: 0.4947 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1941/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.5000 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1942/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5125 - mse: 0.5068 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 1943/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1944/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4946 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1945/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4980 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1946/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4999 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1947/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5017 - mse: 0.4960 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1948/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4972 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1949/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4936 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1950/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.4975 - mse: 0.4917\n",
      "Epoch 01950: saving model to Regression_Model/mle.linear-1950.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4965 - val_loss: 0.4469 - val_mse: 0.4411\n",
      "Epoch 1951/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4989 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1952/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1953/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5032 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1954/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4980 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1955/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1956/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5024 - val_loss: 0.4469 - val_mse: 0.4412\n",
      "Epoch 1957/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4978 - val_loss: 0.4469 - val_mse: 0.4411\n",
      "Epoch 1958/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5000 - mse: 0.4942 - val_loss: 0.4469 - val_mse: 0.4411\n",
      "Epoch 1959/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4980 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1960/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5035 - mse: 0.4977\n",
      "Epoch 01960: saving model to Regression_Model/mle.linear-1960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1961/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5026 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1962/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1963/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1964/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4942 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1965/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4970 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1966/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4948 - mse: 0.4890 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1967/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4996 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1968/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5001 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1969/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1970/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5023 - mse: 0.4965\n",
      "Epoch 01970: saving model to Regression_Model/mle.linear-1970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1971/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1972/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 1973/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1974/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 1975/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5061 - mse: 0.5004 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1976/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5034 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 1977/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4966 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1978/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1979/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 1980/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5099 - mse: 0.5042\n",
      "Epoch 01980: saving model to Regression_Model/mle.linear-1980.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5037 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1981/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4958 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1982/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4996 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1983/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 1984/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4939 - mse: 0.4882 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1985/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4938 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1986/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5007 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 1987/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1988/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4993 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1989/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4939 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1990/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5018 - mse: 0.4960\n",
      "Epoch 01990: saving model to Regression_Model/mle.linear-1990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1991/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4958 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 1992/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4962 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1993/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5025 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 1994/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 1995/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5037 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1996/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4989 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1997/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 1998/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 1999/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2000/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5052 - mse: 0.4994\n",
      "Epoch 02000: saving model to Regression_Model/mle.linear-2000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2001/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4966 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2002/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2003/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 2004/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4970 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 2005/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2006/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5038 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 2007/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4962 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2008/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2009/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2010/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.5064 - mse: 0.5006\n",
      "Epoch 02010: saving model to Regression_Model/mle.linear-2010.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4984 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2011/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4996 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2012/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5037 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2013/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4978 - mse: 0.4920 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2014/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5000 - mse: 0.4943 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2015/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2016/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2017/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5022 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2018/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4970 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2019/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2020/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5145 - mse: 0.5087\n",
      "Epoch 02020: saving model to Regression_Model/mle.linear-2020.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5146 - mse: 0.5089 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2021/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2022/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2023/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5010 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2024/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4968 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2025/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5036 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2026/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2027/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4973 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2028/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2029/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4955 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2030/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5043 - mse: 0.4986\n",
      "Epoch 02030: saving model to Regression_Model/mle.linear-2030.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2031/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4987 - val_loss: 0.4469 - val_mse: 0.4412\n",
      "Epoch 2032/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2033/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2034/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4948 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2035/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2036/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2037/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5045 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2038/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2039/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2040/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5053 - mse: 0.4995\n",
      "Epoch 02040: saving model to Regression_Model/mle.linear-2040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2041/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2042/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2043/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2044/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4967 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2045/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4947 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2046/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2047/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2048/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4937 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2049/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4962 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2050/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5080 - mse: 0.5022\n",
      "Epoch 02050: saving model to Regression_Model/mle.linear-2050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4987 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2051/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5025 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2052/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5040 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2053/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4944 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2054/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2055/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5047 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 2056/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4475 - val_mse: 0.4418\n",
      "Epoch 2057/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2058/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2059/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2060/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5003 - mse: 0.4945\n",
      "Epoch 02060: saving model to Regression_Model/mle.linear-2060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4937 - val_loss: 0.4472 - val_mse: 0.4414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2061/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2062/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5027 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2063/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5011 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2064/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5037 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2065/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2066/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2067/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5054 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2068/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 2069/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2070/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4948 - mse: 0.4891\n",
      "Epoch 02070: saving model to Regression_Model/mle.linear-2070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4948 - mse: 0.4890 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2071/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5043 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2072/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2073/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2074/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2075/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4989 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2076/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4978 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2077/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2078/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2079/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2080/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4995 - mse: 0.4937\n",
      "Epoch 02080: saving model to Regression_Model/mle.linear-2080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4959 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2081/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5050 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2082/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2083/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2084/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4949 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2085/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2086/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4976 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2087/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4971 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2088/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5025 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2089/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2090/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5116 - mse: 0.5058\n",
      "Epoch 02090: saving model to Regression_Model/mle.linear-2090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5051 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2091/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4951 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2092/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4985 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2093/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5017 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2094/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2095/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2096/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4999 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2097/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2098/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2099/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4995 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2100/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4981 - mse: 0.4923\n",
      "Epoch 02100: saving model to Regression_Model/mle.linear-2100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4935 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5042 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4975 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2103/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5154 - mse: 0.5096 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 2105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5044 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2106/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5009 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 2107/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 2108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4942 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 2109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5010 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2110/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4997 - mse: 0.4939\n",
      "Epoch 02110: saving model to Regression_Model/mle.linear-2110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4476 - val_mse: 0.4418\n",
      "Epoch 2111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4950 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2112/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4958 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4953 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2116/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4990 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2117/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4983 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2118/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4939 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2120/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5093 - mse: 0.5035\n",
      "Epoch 02120: saving model to Regression_Model/mle.linear-2120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5033 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2122/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2123/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4968 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2124/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4950 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2125/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2126/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2127/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2128/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2129/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2130/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5027 - mse: 0.4969\n",
      "Epoch 02130: saving model to Regression_Model/mle.linear-2130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2131/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2132/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4981 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2133/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2134/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5042 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2135/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5004 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2136/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2137/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5014 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2138/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2139/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2140/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5054 - mse: 0.4996\n",
      "Epoch 02140: saving model to Regression_Model/mle.linear-2140.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2141/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2142/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2143/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4995 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2144/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4955 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2145/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4988 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2146/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5026 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2147/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4934 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2148/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5036 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2149/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5029 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2150/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5082 - mse: 0.5024\n",
      "Epoch 02150: saving model to Regression_Model/mle.linear-2150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5030 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2151/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5024 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2152/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5060 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2153/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4944 - mse: 0.4886 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2154/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5035 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2155/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2156/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5011 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 2157/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2158/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4941 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2159/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5123 - mse: 0.5066 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2160/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5061 - mse: 0.5003\n",
      "Epoch 02160: saving model to Regression_Model/mle.linear-2160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4987 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2161/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2162/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2163/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2164/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4955 - mse: 0.4897 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2165/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2166/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2167/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5023 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2168/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5147 - mse: 0.5090 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2169/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4946 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2170/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5066 - mse: 0.5009\n",
      "Epoch 02170: saving model to Regression_Model/mle.linear-2170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5013 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2171/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5137 - mse: 0.5080 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2172/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2173/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4937 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2174/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4978 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2175/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2176/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4951 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2177/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4475 - val_mse: 0.4417\n",
      "Epoch 2178/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4950 - val_loss: 0.4474 - val_mse: 0.4417\n",
      "Epoch 2179/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2180/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5046 - mse: 0.4988\n",
      "Epoch 02180: saving model to Regression_Model/mle.linear-2180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2181/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2182/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4966 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2183/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2184/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4954 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2185/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4963 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2186/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2187/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4919 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2188/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4990 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2189/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2190/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5098 - mse: 0.5040\n",
      "Epoch 02190: saving model to Regression_Model/mle.linear-2190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5036 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2191/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5010 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2192/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2193/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4945 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2194/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4981 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2195/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2196/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2197/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5027 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2198/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5028 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2199/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5032 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2200/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5044 - mse: 0.4987\n",
      "Epoch 02200: saving model to Regression_Model/mle.linear-2200.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2201/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2202/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4999 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2203/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2204/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5041 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2205/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2206/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4944 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2207/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4983 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2208/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5050 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2209/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2210/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5061 - mse: 0.5004\n",
      "Epoch 02210: saving model to Regression_Model/mle.linear-2210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2211/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5003 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2212/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4952 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2213/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4982 - mse: 0.4925 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2214/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2215/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5119 - mse: 0.5061 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2216/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2217/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2218/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2219/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5000 - mse: 0.4942 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2220/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5055 - mse: 0.4997\n",
      "Epoch 02220: saving model to Regression_Model/mle.linear-2220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4992 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2221/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5134 - mse: 0.5076 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2222/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2223/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4962 - mse: 0.4904 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2224/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4992 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2225/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2226/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4955 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2227/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.5000 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2228/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4981 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2229/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5040 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2230/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5007 - mse: 0.4950\n",
      "Epoch 02230: saving model to Regression_Model/mle.linear-2230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4945 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2231/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4973 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2232/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5041 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2233/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4968 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2234/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4971 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2235/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5040 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2236/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2237/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2238/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5072 - mse: 0.5015 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2239/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2240/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5084 - mse: 0.5026\n",
      "Epoch 02240: saving model to Regression_Model/mle.linear-2240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5023 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2241/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4938 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2242/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2243/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2244/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5030 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2245/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4995 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2246/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2247/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4998 - mse: 0.4940 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2248/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5035 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2249/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2250/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4970 - mse: 0.4913\n",
      "Epoch 02250: saving model to Regression_Model/mle.linear-2250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4937 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2251/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2252/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2253/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4991 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2254/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2255/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5016 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2256/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5001 - mse: 0.4943 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2257/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4948 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2258/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5000 - mse: 0.4942 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2259/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2260/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5035 - mse: 0.4977\n",
      "Epoch 02260: saving model to Regression_Model/mle.linear-2260.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2261/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4962 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2262/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2263/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4935 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2264/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4938 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2265/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5035 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2266/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2267/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2268/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2269/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4933 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2270/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5006 - mse: 0.4949\n",
      "Epoch 02270: saving model to Regression_Model/mle.linear-2270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4938 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2271/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5025 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2272/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2273/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5032 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2274/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5022 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2275/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4992 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2276/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4991 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2277/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5024 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2278/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2279/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4999 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2280/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5100 - mse: 0.5043\n",
      "Epoch 02280: saving model to Regression_Model/mle.linear-2280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5030 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2281/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2282/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2283/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4941 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2284/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2285/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2286/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4969 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2287/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5021 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2288/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2289/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2290/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5063 - mse: 0.5005\n",
      "Epoch 02290: saving model to Regression_Model/mle.linear-2290.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2291/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4987 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2292/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5003 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2293/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2294/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2295/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4474 - val_mse: 0.4416\n",
      "Epoch 2296/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2297/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5101 - mse: 0.5043 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2298/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5016 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2299/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2300/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4975 - mse: 0.4917\n",
      "Epoch 02300: saving model to Regression_Model/mle.linear-2300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4972 - mse: 0.4914 - val_loss: 0.4473 - val_mse: 0.4416\n",
      "Epoch 2301/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2302/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2303/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5053 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2304/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2305/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4958 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2306/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4965 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2307/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4990 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2308/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5025 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2309/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5042 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2310/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5089 - mse: 0.5031\n",
      "Epoch 02310: saving model to Regression_Model/mle.linear-2310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2311/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5064 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2312/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5010 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2313/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2314/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5020 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2315/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2316/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5030 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2317/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2318/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4937 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2319/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2320/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5034 - mse: 0.4977\n",
      "Epoch 02320: saving model to Regression_Model/mle.linear-2320.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2321/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4928 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2322/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4940 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2323/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2324/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4968 - mse: 0.4910 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2325/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2326/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5004 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2327/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4975 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2328/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5033 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2329/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2330/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5061 - mse: 0.5003\n",
      "Epoch 02330: saving model to Regression_Model/mle.linear-2330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2331/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5089 - mse: 0.5031 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2332/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2333/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2334/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4996 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2335/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4986 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2336/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4965 - val_loss: 0.4473 - val_mse: 0.4415\n",
      "Epoch 2337/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4950 - mse: 0.4893 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2338/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2339/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5014 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2340/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5038 - mse: 0.4980\n",
      "Epoch 02340: saving model to Regression_Model/mle.linear-2340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4975 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2341/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2342/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4959 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2343/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4964 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2344/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4994 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2345/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4939 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2346/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4930 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2347/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2348/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4950 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2349/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2350/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5024 - mse: 0.4967\n",
      "Epoch 02350: saving model to Regression_Model/mle.linear-2350.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2351/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4930 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2352/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5053 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2353/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4941 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2354/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2355/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2356/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2357/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2358/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2359/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2360/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5042 - mse: 0.4985\n",
      "Epoch 02360: saving model to Regression_Model/mle.linear-2360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2361/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2362/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2363/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2364/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5030 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2365/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5013 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2366/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2367/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5009 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2368/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5107 - mse: 0.5049 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2369/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2370/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5018 - mse: 0.4961\n",
      "Epoch 02370: saving model to Regression_Model/mle.linear-2370.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4963 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2371/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4983 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2372/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2373/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2374/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4975 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2375/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5026 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2376/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4965 - mse: 0.4908 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2377/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5054 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2378/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2379/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2380/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5103 - mse: 0.5046\n",
      "Epoch 02380: saving model to Regression_Model/mle.linear-2380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5034 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2381/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4964 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2382/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2383/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2384/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2385/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5026 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2386/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4962 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2387/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2388/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5022 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2389/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5001 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2390/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5084 - mse: 0.5026\n",
      "Epoch 02390: saving model to Regression_Model/mle.linear-2390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2391/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5019 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2392/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5006 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2393/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4938 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2394/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4987 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2395/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5041 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2396/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2397/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2398/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5019 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2399/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4956 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2400/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5047 - mse: 0.4990\n",
      "Epoch 02400: saving model to Regression_Model/mle.linear-2400.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2401/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2402/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2403/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4980 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2404/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4945 - mse: 0.4887 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2405/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4966 - mse: 0.4909 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2406/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2407/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5120 - mse: 0.5062 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2408/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5047 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2409/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2410/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5010 - mse: 0.4953\n",
      "Epoch 02410: saving model to Regression_Model/mle.linear-2410.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2411/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5110 - mse: 0.5052 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2412/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2413/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5126 - mse: 0.5068 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2414/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4968 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2415/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5044 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2416/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4940 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2417/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4964 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2418/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2419/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4999 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2420/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5070 - mse: 0.5013\n",
      "Epoch 02420: saving model to Regression_Model/mle.linear-2420.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2421/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2422/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2423/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2424/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2425/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2426/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2427/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5018 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2428/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5036 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2429/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2430/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5008 - mse: 0.4950\n",
      "Epoch 02430: saving model to Regression_Model/mle.linear-2430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2431/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4958 - mse: 0.4900 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2432/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5042 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2433/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5019 - mse: 0.4962 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2434/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2435/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2436/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4950 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2437/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2438/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4931 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2439/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4971 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2440/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5000 - mse: 0.4943\n",
      "Epoch 02440: saving model to Regression_Model/mle.linear-2440.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4957 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2441/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4955 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2442/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4976 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2443/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2444/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2445/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4935 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2446/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4979 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2447/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2448/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4998 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2449/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4946 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2450/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5069 - mse: 0.5012\n",
      "Epoch 02450: saving model to Regression_Model/mle.linear-2450.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4987 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2451/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4981 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2452/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4960 - mse: 0.4903 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2453/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4966 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2454/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4988 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2455/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2456/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2457/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2458/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4963 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2459/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4979 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2460/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5097 - mse: 0.5040\n",
      "Epoch 02460: saving model to Regression_Model/mle.linear-2460.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5071 - mse: 0.5013 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2461/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2462/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2463/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4994 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2464/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4966 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2465/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5015 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2466/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2467/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4959 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2468/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2469/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2470/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5115 - mse: 0.5057\n",
      "Epoch 02470: saving model to Regression_Model/mle.linear-2470.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2471/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5059 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2472/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5022 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2473/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4975 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2474/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2475/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2476/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4972 - mse: 0.4914 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2477/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4996 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2478/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2479/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4941 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2480/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5016 - mse: 0.4958\n",
      "Epoch 02480: saving model to Regression_Model/mle.linear-2480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2481/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4974 - mse: 0.4917 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2482/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2483/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5040 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2484/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5001 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2485/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4992 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2486/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2487/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2488/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4965 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2489/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4993 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2490/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.5082 - mse: 0.5025\n",
      "Epoch 02490: saving model to Regression_Model/mle.linear-2490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5017 - val_loss: 0.4470 - val_mse: 0.4412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2491/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2492/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4470 - val_mse: 0.4412\n",
      "Epoch 2493/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2494/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5013 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2495/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2496/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2497/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4947 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2498/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5091 - mse: 0.5033 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2499/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4961 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2500/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5044 - mse: 0.4986\n",
      "Epoch 02500: saving model to Regression_Model/mle.linear-2500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5012 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2501/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2502/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2503/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2504/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4945 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2505/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2506/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2507/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2508/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4997 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2509/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2510/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5053 - mse: 0.4995\n",
      "Epoch 02510: saving model to Regression_Model/mle.linear-2510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2511/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2512/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4998 - mse: 0.4941 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2513/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2514/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4973 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2515/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2516/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4979 - mse: 0.4921 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2517/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4470 - val_mse: 0.4413\n",
      "Epoch 2518/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2519/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2520/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5027 - mse: 0.4969\n",
      "Epoch 02520: saving model to Regression_Model/mle.linear-2520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4960 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2521/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2522/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5007 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2523/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2524/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2525/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5071 - mse: 0.5014 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2526/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5044 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2527/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4949 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2528/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2529/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5061 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2530/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5078 - mse: 0.5020\n",
      "Epoch 02530: saving model to Regression_Model/mle.linear-2530.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2531/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4959 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2532/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5015 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2533/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5008 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2534/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4968 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2535/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2536/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2537/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4968 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2538/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5008 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2539/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2540/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5057 - mse: 0.4999\n",
      "Epoch 02540: saving model to Regression_Model/mle.linear-2540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2541/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2542/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5020 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2543/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2544/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5023 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2545/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2546/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2547/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2548/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2549/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5008 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2550/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5030 - mse: 0.4972\n",
      "Epoch 02550: saving model to Regression_Model/mle.linear-2550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4970 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2551/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4987 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2552/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5045 - mse: 0.4988 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2553/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5022 - mse: 0.4964 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2554/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4946 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2555/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5011 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2556/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2557/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2558/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2559/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5006 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2560/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5104 - mse: 0.5046\n",
      "Epoch 02560: saving model to Regression_Model/mle.linear-2560.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5083 - mse: 0.5025 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2561/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2562/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2563/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2564/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2565/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4974 - mse: 0.4916 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2566/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2567/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5039 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2568/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2569/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4994 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2570/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5015 - mse: 0.4957\n",
      "Epoch 02570: saving model to Regression_Model/mle.linear-2570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2571/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2572/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2573/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2574/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4961 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2575/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4985 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2576/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4932 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2577/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4933 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2578/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4984 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2579/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2580/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4996 - mse: 0.4938\n",
      "Epoch 02580: saving model to Regression_Model/mle.linear-2580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4939 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2581/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2582/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5126 - mse: 0.5068 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2583/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4950 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2584/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4987 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2585/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4960 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2586/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5029 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2587/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2588/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2589/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2590/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4995 - mse: 0.4937\n",
      "Epoch 02590: saving model to Regression_Model/mle.linear-2590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4935 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2591/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2592/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.5000 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2593/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4947 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2594/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4958 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2595/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5029 - mse: 0.4972 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2596/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4975 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2597/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2598/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2599/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2600/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5065 - mse: 0.5008\n",
      "Epoch 02600: saving model to Regression_Model/mle.linear-2600.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2601/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2602/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5019 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2603/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2604/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4986 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2605/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5022 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2606/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2607/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4967 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2608/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2609/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4972 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2610/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5041 - mse: 0.4984\n",
      "Epoch 02610: saving model to Regression_Model/mle.linear-2610.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5045 - mse: 0.4987 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2611/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2612/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4971 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2613/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4984 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2614/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5023 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2615/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2616/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4996 - mse: 0.4939 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2617/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5008 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2618/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4948 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2619/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5010 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2620/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5019 - mse: 0.4961\n",
      "Epoch 02620: saving model to Regression_Model/mle.linear-2620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2621/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4950 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2622/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4996 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2623/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2624/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2625/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5017 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2626/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2627/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2628/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2629/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2630/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5047 - mse: 0.4990\n",
      "Epoch 02630: saving model to Regression_Model/mle.linear-2630.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2631/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2632/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2633/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.5000 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2634/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2635/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2636/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4968 - mse: 0.4910 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2637/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5090 - mse: 0.5032 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2638/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4947 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2639/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2640/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5018 - mse: 0.4961\n",
      "Epoch 02640: saving model to Regression_Model/mle.linear-2640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2641/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2642/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5000 - mse: 0.4943 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2643/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4976 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2644/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4945 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2645/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2646/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2647/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5107 - mse: 0.5050 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2648/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4936 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2649/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4946 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2650/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.5074 - mse: 0.5017\n",
      "Epoch 02650: saving model to Regression_Model/mle.linear-2650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2651/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4976 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2652/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2653/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2654/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4993 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2655/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5005 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2656/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2657/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4998 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2658/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2659/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2660/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5059 - mse: 0.5002\n",
      "Epoch 02660: saving model to Regression_Model/mle.linear-2660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5016 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2661/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4976 - mse: 0.4919 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2662/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5002 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2663/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4989 - mse: 0.4932 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2664/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2665/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4985 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2666/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5016 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2667/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2668/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2669/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4967 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2670/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5145 - mse: 0.5088\n",
      "Epoch 02670: saving model to Regression_Model/mle.linear-2670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5085 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2671/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2672/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4971 - mse: 0.4913 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2673/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4952 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2674/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2675/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2676/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2677/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2678/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4973 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2679/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5004 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2680/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5049 - mse: 0.4992\n",
      "Epoch 02680: saving model to Regression_Model/mle.linear-2680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5002 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2681/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2682/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5077 - mse: 0.5019 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2683/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4998 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2684/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5060 - mse: 0.5003 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2685/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5034 - mse: 0.4977 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2686/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4957 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2687/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4954 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2688/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4995 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2689/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4983 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2690/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5066 - mse: 0.5009\n",
      "Epoch 02690: saving model to Regression_Model/mle.linear-2690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4991 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2691/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2692/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5005 - mse: 0.4947 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2693/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5039 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2694/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2695/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5053 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2696/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4970 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2697/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2698/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2699/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4976 - mse: 0.4918 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2700/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5003 - mse: 0.4945\n",
      "Epoch 02700: saving model to Regression_Model/mle.linear-2700.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4964 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2701/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5017 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2702/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5016 - mse: 0.4958 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2703/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4951 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2704/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2705/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4989 - mse: 0.4931 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2706/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5099 - mse: 0.5041 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2707/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2708/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4970 - mse: 0.4913 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2709/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5065 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2710/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5055 - mse: 0.4998\n",
      "Epoch 02710: saving model to Regression_Model/mle.linear-2710.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2711/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2712/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2713/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2714/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2715/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2716/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2717/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2718/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5131 - mse: 0.5074 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2719/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2720/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4994 - mse: 0.4937\n",
      "Epoch 02720: saving model to Regression_Model/mle.linear-2720.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5014 - mse: 0.4957 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2721/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2722/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2723/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4973 - mse: 0.4915 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2724/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2725/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2726/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2727/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2728/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5116 - mse: 0.5058 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2729/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5033 - mse: 0.4976 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2730/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5039 - mse: 0.4981\n",
      "Epoch 02730: saving model to Regression_Model/mle.linear-2730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4972 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2731/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5077 - mse: 0.5020 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2732/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4980 - mse: 0.4923 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2733/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4942 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2734/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4991 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2735/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2736/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4970 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2737/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4928 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2738/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2739/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2740/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5003 - mse: 0.4945\n",
      "Epoch 02740: saving model to Regression_Model/mle.linear-2740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4930 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2741/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4986 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2742/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5014 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2743/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2744/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2745/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2746/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5028 - mse: 0.4971 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2747/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2748/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4982 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2749/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5115 - mse: 0.5058 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2750/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5097 - mse: 0.5040\n",
      "Epoch 02750: saving model to Regression_Model/mle.linear-2750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5025 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2751/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2752/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4956 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2753/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4997 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2754/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4987 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2755/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5019 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2756/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5003 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2757/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2758/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5026 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2759/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5095 - mse: 0.5037 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2760/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4978 - mse: 0.4921\n",
      "Epoch 02760: saving model to Regression_Model/mle.linear-2760.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4931 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2761/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4940 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2762/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4986 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2763/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2764/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4982 - mse: 0.4924 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2765/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2766/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2767/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4945 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2768/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4976 - mse: 0.4918 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2769/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4955 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2770/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5065 - mse: 0.5007\n",
      "Epoch 02770: saving model to Regression_Model/mle.linear-2770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5013 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2771/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5001 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2772/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4996 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2773/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2774/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4949 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2775/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4945 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2776/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4951 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2777/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5008 - mse: 0.4951 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2778/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2779/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4956 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2780/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5070 - mse: 0.5012\n",
      "Epoch 02780: saving model to Regression_Model/mle.linear-2780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5007 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2781/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.5007 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2782/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2783/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4978 - mse: 0.4920 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2784/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2785/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2786/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4988 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2787/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5013 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2788/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4961 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2789/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2790/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4943 - mse: 0.4885\n",
      "Epoch 02790: saving model to Regression_Model/mle.linear-2790.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4946 - mse: 0.4889 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2791/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2792/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5021 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2793/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5050 - mse: 0.4993 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2794/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5002 - mse: 0.4945 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2795/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5113 - mse: 0.5056 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2796/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5004 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2797/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4983 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2798/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2799/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4979 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2800/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5034 - mse: 0.4976\n",
      "Epoch 02800: saving model to Regression_Model/mle.linear-2800.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5036 - mse: 0.4978 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2801/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2802/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5106 - mse: 0.5049 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2803/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.5007 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2804/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4963 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2805/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5077 - mse: 0.5019 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2806/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2807/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4970 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2808/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4934 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2809/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5068 - mse: 0.5010 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2810/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.5112 - mse: 0.5054\n",
      "Epoch 02810: saving model to Regression_Model/mle.linear-2810.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5077 - mse: 0.5020 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2811/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5085 - mse: 0.5027 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2812/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2813/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4971 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2814/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2815/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2816/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5059 - mse: 0.5002 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2817/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5005 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2818/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4968 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2819/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5049 - mse: 0.4992 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2820/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4998 - mse: 0.4940\n",
      "Epoch 02820: saving model to Regression_Model/mle.linear-2820.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4981 - mse: 0.4924 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2821/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5003 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2822/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4994 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2823/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4989 - mse: 0.4932 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2824/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5017 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2825/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4959 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2826/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5004 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2827/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5013 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2828/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2829/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4955 - mse: 0.4898 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2830/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5013 - mse: 0.4955\n",
      "Epoch 02830: saving model to Regression_Model/mle.linear-2830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4979 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2831/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4962 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2832/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5009 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2833/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4978 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2834/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4964 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2835/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2836/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2837/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5042 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2838/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5033 - mse: 0.4975 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2839/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.5000 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2840/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4987 - mse: 0.4930\n",
      "Epoch 02840: saving model to Regression_Model/mle.linear-2840.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4946 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2841/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2842/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4980 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2843/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4999 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2844/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2845/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2846/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2847/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2848/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4964 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2849/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5100 - mse: 0.5043 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2850/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5075 - mse: 0.5017\n",
      "Epoch 02850: saving model to Regression_Model/mle.linear-2850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5021 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2851/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2852/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5034 - mse: 0.4976 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2853/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5003 - mse: 0.4945 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2854/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4979 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2855/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2856/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5047 - mse: 0.4990 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2857/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4985 - mse: 0.4928 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2858/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5013 - mse: 0.4955 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2859/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4972 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2860/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5008 - mse: 0.4950\n",
      "Epoch 02860: saving model to Regression_Model/mle.linear-2860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4962 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2861/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5093 - mse: 0.5036 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2862/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5086 - mse: 0.5028 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2863/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4986 - mse: 0.4929 - val_loss: 0.4472 - val_mse: 0.4415\n",
      "Epoch 2864/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5051 - mse: 0.4994 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2865/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2866/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2867/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5049 - mse: 0.4992 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2868/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5002 - mse: 0.4944 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2869/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5095 - mse: 0.5037 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2870/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5122 - mse: 0.5065\n",
      "Epoch 02870: saving model to Regression_Model/mle.linear-2870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5133 - mse: 0.5076 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2871/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2872/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5087 - mse: 0.5029 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2873/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5137 - mse: 0.5080 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2874/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5036 - mse: 0.4978 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2875/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5030 - mse: 0.4973 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2876/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2877/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5064 - mse: 0.5006 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2878/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5017 - mse: 0.4960 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2879/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4997 - mse: 0.4939 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2880/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5070 - mse: 0.5012\n",
      "Epoch 02880: saving model to Regression_Model/mle.linear-2880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2881/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5071 - mse: 0.5014 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2882/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5075 - mse: 0.5017 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2883/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5083 - mse: 0.5026 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2884/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5043 - mse: 0.4985 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2885/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5044 - mse: 0.4986 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2886/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2887/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5001 - mse: 0.4944 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2888/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5050 - mse: 0.4992 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2889/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5004 - mse: 0.4947 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2890/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4998 - mse: 0.4940\n",
      "Epoch 02890: saving model to Regression_Model/mle.linear-2890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4961 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2891/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5066 - mse: 0.5008 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2892/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5040 - mse: 0.4983 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2893/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5027 - mse: 0.4969 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2894/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5054 - mse: 0.4996 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2895/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5037 - mse: 0.4980 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2896/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5076 - mse: 0.5018 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2897/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5067 - mse: 0.5010 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2898/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4973 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2899/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4995 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2900/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5054 - mse: 0.4997\n",
      "Epoch 02900: saving model to Regression_Model/mle.linear-2900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5020 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2901/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4962 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2902/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5001 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2903/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2904/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5118 - mse: 0.5061 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2905/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5041 - mse: 0.4983 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2906/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4963 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2907/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4997 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2908/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5052 - mse: 0.4994 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2909/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4974 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2910/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4990 - mse: 0.4932\n",
      "Epoch 02910: saving model to Regression_Model/mle.linear-2910.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4995 - mse: 0.4937 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2911/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2912/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5082 - mse: 0.5024 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2913/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4988 - mse: 0.4930 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2914/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5010 - mse: 0.4952 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2915/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5026 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2916/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5023 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2917/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2918/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2919/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4978 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2920/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5007 - mse: 0.4949\n",
      "Epoch 02920: saving model to Regression_Model/mle.linear-2920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4954 - val_loss: 0.4472 - val_mse: 0.4414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2921/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5015 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2922/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4985 - mse: 0.4928 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2923/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5014 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2924/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5036 - mse: 0.4979 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2925/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4981 - mse: 0.4923 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2926/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4972 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2927/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2928/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4998 - val_loss: 0.4472 - val_mse: 0.4414\n",
      "Epoch 2929/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5025 - mse: 0.4967 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2930/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5020 - mse: 0.4962\n",
      "Epoch 02930: saving model to Regression_Model/mle.linear-2930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4954 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2931/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4980 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2932/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4985 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2933/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4991 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2934/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4971 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2935/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5005 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2936/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4962 - mse: 0.4904 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2937/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5027 - mse: 0.4970 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2938/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4980 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2939/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4966 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2940/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5050 - mse: 0.4993\n",
      "Epoch 02940: saving model to Regression_Model/mle.linear-2940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5062 - mse: 0.5005 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2941/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5016 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2942/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4948 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2943/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5079 - mse: 0.5022 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2944/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2945/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4980 - mse: 0.4922 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2946/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2947/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5030 - mse: 0.4972 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2948/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4984 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2949/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5074 - mse: 0.5016 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2950/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5034 - mse: 0.4977\n",
      "Epoch 02950: saving model to Regression_Model/mle.linear-2950.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4961 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2951/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5013 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2952/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4965 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2953/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5013 - mse: 0.4956 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2954/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4989 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2955/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5058 - mse: 0.5000 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2956/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.5004 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2957/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5104 - mse: 0.5046 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2958/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4956 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2959/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5040 - mse: 0.4982 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2960/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.5087 - mse: 0.5029\n",
      "Epoch 02960: saving model to Regression_Model/mle.linear-2960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5060 - mse: 0.5003 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2961/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2962/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5023 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2963/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4911 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2964/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5023 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2965/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2966/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4930 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2967/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5045 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2968/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5030 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2969/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5021 - mse: 0.4963 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2970/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4980 - mse: 0.4922\n",
      "Epoch 02970: saving model to Regression_Model/mle.linear-2970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4999 - mse: 0.4941 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2971/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4992 - mse: 0.4934 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2972/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4957 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2973/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4974 - mse: 0.4916 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2974/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4951 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2975/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4975 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2976/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5097 - mse: 0.5039 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2977/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4994 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2978/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5063 - mse: 0.5006 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2979/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4971 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2980/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.5103 - mse: 0.5045\n",
      "Epoch 02980: saving model to Regression_Model/mle.linear-2980.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5105 - mse: 0.5047 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2981/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5080 - mse: 0.5023 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2982/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4978 - val_loss: 0.4471 - val_mse: 0.4413\n",
      "Epoch 2983/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4931 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2984/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5012 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2985/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5071 - mse: 0.5014 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2986/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4990 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2987/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4960 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2988/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4981 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2989/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4987 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2990/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4998 - mse: 0.4940\n",
      "Epoch 02990: saving model to Regression_Model/mle.linear-2990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4966 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2991/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4931 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2992/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4996 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2993/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4926 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2994/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4999 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2995/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5048 - mse: 0.4990 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2996/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4974 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2997/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4985 - mse: 0.4927 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2998/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5035 - mse: 0.4977 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 2999/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4978 - mse: 0.4921 - val_loss: 0.4471 - val_mse: 0.4414\n",
      "Epoch 3000/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5082 - mse: 0.5025\n",
      "Epoch 03000: saving model to Regression_Model/mle.linear-3000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5023 - val_loss: 0.4471 - val_mse: 0.4414\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=3000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "mse\n",
      "val_loss\n",
      "val_mse\n"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd8b20a3978>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-2500.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "testid='mse.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([492.], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
