{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 55918\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.regression.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    #train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3861275 2.4915485\n",
      "3.8266706 1.8094194\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f703c92c860>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f703c8c52b0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='bl6.mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1397 steps, validate for 1397 steps\n",
      "Epoch 1/2000\n",
      "1397/1397 [==============================] - 8s 6ms/step - loss: 0.7160 - mse: 0.7094 - val_loss: 0.6410 - val_mse: 0.6343\n",
      "Epoch 2/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6586 - mse: 0.6519 - val_loss: 0.5830 - val_mse: 0.5763\n",
      "Epoch 3/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6455 - mse: 0.6387 - val_loss: 0.5768 - val_mse: 0.5700\n",
      "Epoch 4/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6380 - mse: 0.6312 - val_loss: 0.5803 - val_mse: 0.5734\n",
      "Epoch 5/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6303 - mse: 0.6234 - val_loss: 0.6062 - val_mse: 0.5993\n",
      "Epoch 6/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6263 - mse: 0.6194 - val_loss: 0.5698 - val_mse: 0.5628\n",
      "Epoch 7/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6207 - mse: 0.6137 - val_loss: 0.5964 - val_mse: 0.5894\n",
      "Epoch 8/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6173 - mse: 0.6102 - val_loss: 0.5543 - val_mse: 0.5472\n",
      "Epoch 9/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6182 - mse: 0.6111 - val_loss: 0.5565 - val_mse: 0.5493\n",
      "Epoch 10/2000\n",
      "1378/1397 [============================>.] - ETA: 0s - loss: 0.6127 - mse: 0.6056\n",
      "Epoch 00010: saving model to Regression_Model/bl6.mle.linear-0010.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6125 - mse: 0.6054 - val_loss: 0.5673 - val_mse: 0.5602\n",
      "Epoch 11/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6144 - mse: 0.6072 - val_loss: 0.5397 - val_mse: 0.5325\n",
      "Epoch 12/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6166 - mse: 0.6094 - val_loss: 0.5656 - val_mse: 0.5584\n",
      "Epoch 13/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6037 - mse: 0.5964 - val_loss: 0.5391 - val_mse: 0.5318\n",
      "Epoch 14/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6040 - mse: 0.5967 - val_loss: 0.5494 - val_mse: 0.5421\n",
      "Epoch 15/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6011 - mse: 0.5938 - val_loss: 0.5536 - val_mse: 0.5462\n",
      "Epoch 16/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6040 - mse: 0.5966 - val_loss: 0.5404 - val_mse: 0.5330\n",
      "Epoch 17/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5932 - mse: 0.5858 - val_loss: 0.5267 - val_mse: 0.5193\n",
      "Epoch 18/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5960 - mse: 0.5886 - val_loss: 0.5684 - val_mse: 0.5610\n",
      "Epoch 19/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5980 - mse: 0.5905 - val_loss: 0.5240 - val_mse: 0.5165\n",
      "Epoch 20/2000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.5945 - mse: 0.5870\n",
      "Epoch 00020: saving model to Regression_Model/bl6.mle.linear-0020.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5953 - mse: 0.5878 - val_loss: 0.5262 - val_mse: 0.5187\n",
      "Epoch 21/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5909 - mse: 0.5834 - val_loss: 0.5345 - val_mse: 0.5270\n",
      "Epoch 22/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5939 - mse: 0.5864 - val_loss: 0.5216 - val_mse: 0.5140\n",
      "Epoch 23/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5902 - mse: 0.5826 - val_loss: 0.5259 - val_mse: 0.5184\n",
      "Epoch 24/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5899 - mse: 0.5823 - val_loss: 0.5253 - val_mse: 0.5177\n",
      "Epoch 25/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5915 - mse: 0.5839 - val_loss: 0.5353 - val_mse: 0.5277\n",
      "Epoch 26/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5926 - mse: 0.5849 - val_loss: 0.5313 - val_mse: 0.5237\n",
      "Epoch 27/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5865 - mse: 0.5789 - val_loss: 0.5211 - val_mse: 0.5134\n",
      "Epoch 28/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5898 - mse: 0.5821 - val_loss: 0.5144 - val_mse: 0.5067\n",
      "Epoch 29/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5862 - mse: 0.5785 - val_loss: 0.5241 - val_mse: 0.5164\n",
      "Epoch 30/2000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5885 - mse: 0.5808\n",
      "Epoch 00030: saving model to Regression_Model/bl6.mle.linear-0030.ckpt\n",
      "1397/1397 [==============================] - 11s 8ms/step - loss: 0.5885 - mse: 0.5808 - val_loss: 0.5263 - val_mse: 0.5186\n",
      "Epoch 31/2000\n",
      "1397/1397 [==============================] - 12s 9ms/step - loss: 0.5906 - mse: 0.5829 - val_loss: 0.5185 - val_mse: 0.5107\n",
      "Epoch 32/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5836 - mse: 0.5759 - val_loss: 0.5173 - val_mse: 0.5095\n",
      "Epoch 33/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5841 - mse: 0.5763 - val_loss: 0.5250 - val_mse: 0.5172\n",
      "Epoch 34/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5835 - mse: 0.5758 - val_loss: 0.5296 - val_mse: 0.5219\n",
      "Epoch 35/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5847 - mse: 0.5770 - val_loss: 0.5084 - val_mse: 0.5007\n",
      "Epoch 36/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5821 - mse: 0.5743 - val_loss: 0.5151 - val_mse: 0.5074\n",
      "Epoch 37/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5797 - mse: 0.5720 - val_loss: 0.5156 - val_mse: 0.5079\n",
      "Epoch 38/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5867 - mse: 0.5789 - val_loss: 0.5167 - val_mse: 0.5089\n",
      "Epoch 39/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5839 - mse: 0.5761 - val_loss: 0.5136 - val_mse: 0.5058\n",
      "Epoch 40/2000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.5786 - mse: 0.5709\n",
      "Epoch 00040: saving model to Regression_Model/bl6.mle.linear-0040.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5793 - mse: 0.5716 - val_loss: 0.5210 - val_mse: 0.5133\n",
      "Epoch 41/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5814 - mse: 0.5737 - val_loss: 0.5107 - val_mse: 0.5030\n",
      "Epoch 42/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5772 - mse: 0.5694 - val_loss: 0.5562 - val_mse: 0.5484\n",
      "Epoch 43/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5805 - mse: 0.5728 - val_loss: 0.5172 - val_mse: 0.5095\n",
      "Epoch 44/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5764 - mse: 0.5687 - val_loss: 0.5151 - val_mse: 0.5074\n",
      "Epoch 45/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5783 - mse: 0.5705 - val_loss: 0.5081 - val_mse: 0.5003\n",
      "Epoch 46/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5803 - mse: 0.5726 - val_loss: 0.5097 - val_mse: 0.5019\n",
      "Epoch 47/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5782 - mse: 0.5705 - val_loss: 0.5112 - val_mse: 0.5034\n",
      "Epoch 48/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5751 - mse: 0.5673 - val_loss: 0.5275 - val_mse: 0.5197\n",
      "Epoch 49/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5768 - mse: 0.5690 - val_loss: 0.5156 - val_mse: 0.5079\n",
      "Epoch 50/2000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5737 - mse: 0.5660\n",
      "Epoch 00050: saving model to Regression_Model/bl6.mle.linear-0050.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5747 - mse: 0.5669 - val_loss: 0.5245 - val_mse: 0.5168\n",
      "Epoch 51/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5777 - mse: 0.5699 - val_loss: 0.5128 - val_mse: 0.5050\n",
      "Epoch 52/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5708 - mse: 0.5631 - val_loss: 0.5145 - val_mse: 0.5067\n",
      "Epoch 53/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5749 - mse: 0.5671 - val_loss: 0.5059 - val_mse: 0.4982\n",
      "Epoch 54/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5792 - mse: 0.5715 - val_loss: 0.5181 - val_mse: 0.5104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5731 - mse: 0.5653 - val_loss: 0.5127 - val_mse: 0.5050\n",
      "Epoch 56/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5772 - mse: 0.5694 - val_loss: 0.5159 - val_mse: 0.5081\n",
      "Epoch 57/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5725 - mse: 0.5647 - val_loss: 0.5083 - val_mse: 0.5005\n",
      "Epoch 58/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5765 - mse: 0.5688 - val_loss: 0.5177 - val_mse: 0.5099\n",
      "Epoch 59/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5690 - mse: 0.5612 - val_loss: 0.5050 - val_mse: 0.4973\n",
      "Epoch 60/2000\n",
      "1394/1397 [============================>.] - ETA: 0s - loss: 0.5740 - mse: 0.5662\n",
      "Epoch 00060: saving model to Regression_Model/bl6.mle.linear-0060.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5739 - mse: 0.5662 - val_loss: 0.5310 - val_mse: 0.5232\n",
      "Epoch 61/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5711 - mse: 0.5633 - val_loss: 0.5053 - val_mse: 0.4976\n",
      "Epoch 62/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5677 - mse: 0.5599 - val_loss: 0.5034 - val_mse: 0.4956\n",
      "Epoch 63/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5683 - mse: 0.5606 - val_loss: 0.5074 - val_mse: 0.4997\n",
      "Epoch 64/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5733 - mse: 0.5655 - val_loss: 0.5229 - val_mse: 0.5152\n",
      "Epoch 65/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5728 - mse: 0.5651 - val_loss: 0.5131 - val_mse: 0.5053\n",
      "Epoch 66/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5707 - mse: 0.5630 - val_loss: 0.5201 - val_mse: 0.5124\n",
      "Epoch 67/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5727 - mse: 0.5650 - val_loss: 0.4990 - val_mse: 0.4913\n",
      "Epoch 68/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5738 - mse: 0.5660 - val_loss: 0.5009 - val_mse: 0.4931\n",
      "Epoch 69/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5705 - mse: 0.5628 - val_loss: 0.5035 - val_mse: 0.4958\n",
      "Epoch 70/2000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5684 - mse: 0.5607\n",
      "Epoch 00070: saving model to Regression_Model/bl6.mle.linear-0070.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5685 - mse: 0.5608 - val_loss: 0.5004 - val_mse: 0.4927\n",
      "Epoch 71/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5675 - mse: 0.5598 - val_loss: 0.5065 - val_mse: 0.4988\n",
      "Epoch 72/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5694 - mse: 0.5617 - val_loss: 0.5020 - val_mse: 0.4943\n",
      "Epoch 73/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5705 - mse: 0.5628 - val_loss: 0.5012 - val_mse: 0.4935\n",
      "Epoch 74/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5650 - mse: 0.5573 - val_loss: 0.5028 - val_mse: 0.4951\n",
      "Epoch 75/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5720 - mse: 0.5643 - val_loss: 0.5057 - val_mse: 0.4980\n",
      "Epoch 76/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5676 - mse: 0.5599 - val_loss: 0.5060 - val_mse: 0.4983\n",
      "Epoch 77/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5661 - mse: 0.5584 - val_loss: 0.5157 - val_mse: 0.5080\n",
      "Epoch 78/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5649 - mse: 0.5572 - val_loss: 0.5002 - val_mse: 0.4925\n",
      "Epoch 79/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5686 - mse: 0.5609 - val_loss: 0.4962 - val_mse: 0.4885\n",
      "Epoch 80/2000\n",
      "1386/1397 [============================>.] - ETA: 0s - loss: 0.5669 - mse: 0.5592\n",
      "Epoch 00080: saving model to Regression_Model/bl6.mle.linear-0080.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5666 - mse: 0.5589 - val_loss: 0.5178 - val_mse: 0.5101\n",
      "Epoch 81/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5686 - mse: 0.5609 - val_loss: 0.5018 - val_mse: 0.4941\n",
      "Epoch 82/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5636 - mse: 0.5559 - val_loss: 0.4992 - val_mse: 0.4915\n",
      "Epoch 83/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5651 - mse: 0.5574 - val_loss: 0.5095 - val_mse: 0.5018\n",
      "Epoch 84/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5662 - mse: 0.5585 - val_loss: 0.4993 - val_mse: 0.4916\n",
      "Epoch 85/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5654 - mse: 0.5577 - val_loss: 0.5031 - val_mse: 0.4954\n",
      "Epoch 86/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5621 - mse: 0.5545 - val_loss: 0.5036 - val_mse: 0.4959\n",
      "Epoch 87/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5654 - mse: 0.5577 - val_loss: 0.5030 - val_mse: 0.4954\n",
      "Epoch 88/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5658 - mse: 0.5581 - val_loss: 0.5009 - val_mse: 0.4933\n",
      "Epoch 89/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5662 - mse: 0.5586 - val_loss: 0.5035 - val_mse: 0.4958\n",
      "Epoch 90/2000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.5670 - mse: 0.5594\n",
      "Epoch 00090: saving model to Regression_Model/bl6.mle.linear-0090.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5670 - mse: 0.5593 - val_loss: 0.5155 - val_mse: 0.5079\n",
      "Epoch 91/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5651 - mse: 0.5575 - val_loss: 0.5018 - val_mse: 0.4942\n",
      "Epoch 92/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5659 - mse: 0.5583 - val_loss: 0.4936 - val_mse: 0.4860\n",
      "Epoch 93/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5636 - mse: 0.5559 - val_loss: 0.5080 - val_mse: 0.5004\n",
      "Epoch 94/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5663 - mse: 0.5587 - val_loss: 0.5047 - val_mse: 0.4971\n",
      "Epoch 95/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5636 - mse: 0.5560 - val_loss: 0.4979 - val_mse: 0.4903\n",
      "Epoch 96/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5650 - mse: 0.5574 - val_loss: 0.5047 - val_mse: 0.4971\n",
      "Epoch 97/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5682 - mse: 0.5606 - val_loss: 0.4981 - val_mse: 0.4905\n",
      "Epoch 98/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5660 - mse: 0.5584 - val_loss: 0.4985 - val_mse: 0.4909\n",
      "Epoch 99/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5651 - mse: 0.5576 - val_loss: 0.4935 - val_mse: 0.4859\n",
      "Epoch 100/2000\n",
      "1382/1397 [============================>.] - ETA: 0s - loss: 0.5610 - mse: 0.5534\n",
      "Epoch 00100: saving model to Regression_Model/bl6.mle.linear-0100.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5612 - mse: 0.5536 - val_loss: 0.5170 - val_mse: 0.5095\n",
      "Epoch 101/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5612 - mse: 0.5536 - val_loss: 0.5062 - val_mse: 0.4986\n",
      "Epoch 102/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5601 - mse: 0.5526 - val_loss: 0.5048 - val_mse: 0.4973\n",
      "Epoch 103/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5587 - mse: 0.5511 - val_loss: 0.4934 - val_mse: 0.4859\n",
      "Epoch 104/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5625 - mse: 0.5550 - val_loss: 0.4991 - val_mse: 0.4916\n",
      "Epoch 105/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5609 - mse: 0.5534 - val_loss: 0.4974 - val_mse: 0.4898\n",
      "Epoch 106/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5608 - mse: 0.5533 - val_loss: 0.4941 - val_mse: 0.4865\n",
      "Epoch 107/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5622 - mse: 0.5547 - val_loss: 0.4995 - val_mse: 0.4920\n",
      "Epoch 108/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5642 - mse: 0.5566 - val_loss: 0.5164 - val_mse: 0.5088\n",
      "Epoch 109/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5596 - mse: 0.5521 - val_loss: 0.4903 - val_mse: 0.4828\n",
      "Epoch 110/2000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.5634 - mse: 0.5559\n",
      "Epoch 00110: saving model to Regression_Model/bl6.mle.linear-0110.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5638 - mse: 0.5562 - val_loss: 0.4993 - val_mse: 0.4918\n",
      "Epoch 111/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5611 - mse: 0.5536 - val_loss: 0.4934 - val_mse: 0.4859\n",
      "Epoch 112/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5604 - mse: 0.5529 - val_loss: 0.4961 - val_mse: 0.4885\n",
      "Epoch 113/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5581 - mse: 0.5506 - val_loss: 0.4955 - val_mse: 0.4880\n",
      "Epoch 114/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5602 - mse: 0.5527 - val_loss: 0.4974 - val_mse: 0.4898\n",
      "Epoch 115/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5611 - mse: 0.5536 - val_loss: 0.4927 - val_mse: 0.4852\n",
      "Epoch 116/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5611 - mse: 0.5536 - val_loss: 0.4988 - val_mse: 0.4913\n",
      "Epoch 117/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5600 - mse: 0.5525 - val_loss: 0.4927 - val_mse: 0.4852\n",
      "Epoch 118/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5623 - mse: 0.5548 - val_loss: 0.4970 - val_mse: 0.4895\n",
      "Epoch 119/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5571 - mse: 0.5496 - val_loss: 0.4973 - val_mse: 0.4898\n",
      "Epoch 120/2000\n",
      "1387/1397 [============================>.] - ETA: 0s - loss: 0.5622 - mse: 0.5548\n",
      "Epoch 00120: saving model to Regression_Model/bl6.mle.linear-0120.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5629 - mse: 0.5554 - val_loss: 0.4961 - val_mse: 0.4886\n",
      "Epoch 121/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5612 - mse: 0.5538 - val_loss: 0.4971 - val_mse: 0.4896\n",
      "Epoch 122/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5608 - mse: 0.5533 - val_loss: 0.4946 - val_mse: 0.4871\n",
      "Epoch 123/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5560 - mse: 0.5485 - val_loss: 0.5085 - val_mse: 0.5011\n",
      "Epoch 124/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5610 - mse: 0.5536 - val_loss: 0.4998 - val_mse: 0.4924\n",
      "Epoch 125/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5606 - mse: 0.5532 - val_loss: 0.4959 - val_mse: 0.4884\n",
      "Epoch 126/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5572 - mse: 0.5498 - val_loss: 0.5036 - val_mse: 0.4961\n",
      "Epoch 127/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5637 - mse: 0.5563 - val_loss: 0.4978 - val_mse: 0.4904\n",
      "Epoch 128/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5580 - mse: 0.5506 - val_loss: 0.4945 - val_mse: 0.4870\n",
      "Epoch 129/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5560 - mse: 0.5485 - val_loss: 0.4915 - val_mse: 0.4841\n",
      "Epoch 130/2000\n",
      "1392/1397 [============================>.] - ETA: 0s - loss: 0.5611 - mse: 0.5536\n",
      "Epoch 00130: saving model to Regression_Model/bl6.mle.linear-0130.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5609 - mse: 0.5535 - val_loss: 0.4889 - val_mse: 0.4815\n",
      "Epoch 131/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5596 - mse: 0.5522 - val_loss: 0.4961 - val_mse: 0.4887\n",
      "Epoch 132/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5560 - mse: 0.5486 - val_loss: 0.4922 - val_mse: 0.4848\n",
      "Epoch 133/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5620 - mse: 0.5546 - val_loss: 0.4991 - val_mse: 0.4917\n",
      "Epoch 134/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5576 - mse: 0.5502 - val_loss: 0.5016 - val_mse: 0.4943\n",
      "Epoch 135/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5572 - mse: 0.5498 - val_loss: 0.4943 - val_mse: 0.4869\n",
      "Epoch 136/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5584 - mse: 0.5510 - val_loss: 0.4936 - val_mse: 0.4862\n",
      "Epoch 137/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5568 - mse: 0.5494 - val_loss: 0.4935 - val_mse: 0.4861\n",
      "Epoch 138/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5545 - mse: 0.5471 - val_loss: 0.5099 - val_mse: 0.5025\n",
      "Epoch 139/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5564 - mse: 0.5491 - val_loss: 0.5000 - val_mse: 0.4927\n",
      "Epoch 140/2000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5583 - mse: 0.5510\n",
      "Epoch 00140: saving model to Regression_Model/bl6.mle.linear-0140.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5590 - mse: 0.5516 - val_loss: 0.4904 - val_mse: 0.4830\n",
      "Epoch 141/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5556 - mse: 0.5483 - val_loss: 0.4938 - val_mse: 0.4865\n",
      "Epoch 142/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5542 - mse: 0.5468 - val_loss: 0.5005 - val_mse: 0.4931\n",
      "Epoch 143/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5556 - mse: 0.5482 - val_loss: 0.4900 - val_mse: 0.4826\n",
      "Epoch 144/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5553 - mse: 0.5479 - val_loss: 0.4910 - val_mse: 0.4836\n",
      "Epoch 145/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5556 - mse: 0.5483 - val_loss: 0.4930 - val_mse: 0.4856\n",
      "Epoch 146/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5564 - mse: 0.5490 - val_loss: 0.4956 - val_mse: 0.4883\n",
      "Epoch 147/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5570 - mse: 0.5497 - val_loss: 0.4957 - val_mse: 0.4884\n",
      "Epoch 148/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5550 - mse: 0.5477 - val_loss: 0.4931 - val_mse: 0.4858\n",
      "Epoch 149/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5570 - mse: 0.5497 - val_loss: 0.4899 - val_mse: 0.4826\n",
      "Epoch 150/2000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5552 - mse: 0.5479\n",
      "Epoch 00150: saving model to Regression_Model/bl6.mle.linear-0150.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5553 - mse: 0.5480 - val_loss: 0.4916 - val_mse: 0.4843\n",
      "Epoch 151/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5587 - mse: 0.5514 - val_loss: 0.4974 - val_mse: 0.4901\n",
      "Epoch 152/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5573 - mse: 0.5500 - val_loss: 0.4963 - val_mse: 0.4890\n",
      "Epoch 153/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5566 - mse: 0.5493 - val_loss: 0.4881 - val_mse: 0.4808\n",
      "Epoch 154/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5534 - mse: 0.5462 - val_loss: 0.4981 - val_mse: 0.4908\n",
      "Epoch 155/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5549 - mse: 0.5476 - val_loss: 0.4917 - val_mse: 0.4844\n",
      "Epoch 156/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5560 - mse: 0.5488 - val_loss: 0.4931 - val_mse: 0.4859\n",
      "Epoch 157/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5541 - mse: 0.5468 - val_loss: 0.4990 - val_mse: 0.4917\n",
      "Epoch 158/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5605 - mse: 0.5532 - val_loss: 0.4898 - val_mse: 0.4825\n",
      "Epoch 159/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5535 - mse: 0.5462 - val_loss: 0.4893 - val_mse: 0.4821\n",
      "Epoch 160/2000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5555 - mse: 0.5483\n",
      "Epoch 00160: saving model to Regression_Model/bl6.mle.linear-0160.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5555 - mse: 0.5483 - val_loss: 0.4924 - val_mse: 0.4852\n",
      "Epoch 161/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5558 - mse: 0.5486 - val_loss: 0.4950 - val_mse: 0.4878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5552 - mse: 0.5480 - val_loss: 0.4916 - val_mse: 0.4844\n",
      "Epoch 163/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5580 - mse: 0.5508 - val_loss: 0.4891 - val_mse: 0.4819\n",
      "Epoch 164/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5546 - mse: 0.5474 - val_loss: 0.4930 - val_mse: 0.4857\n",
      "Epoch 165/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5561 - mse: 0.5489 - val_loss: 0.4896 - val_mse: 0.4824\n",
      "Epoch 166/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5543 - mse: 0.5470 - val_loss: 0.4899 - val_mse: 0.4827\n",
      "Epoch 167/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5552 - mse: 0.5480 - val_loss: 0.4899 - val_mse: 0.4827\n",
      "Epoch 168/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5561 - mse: 0.5489 - val_loss: 0.4911 - val_mse: 0.4839\n",
      "Epoch 169/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5577 - mse: 0.5505 - val_loss: 0.4980 - val_mse: 0.4908\n",
      "Epoch 170/2000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5519 - mse: 0.5447\n",
      "Epoch 00170: saving model to Regression_Model/bl6.mle.linear-0170.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5517 - mse: 0.5445 - val_loss: 0.4870 - val_mse: 0.4798\n",
      "Epoch 171/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5541 - mse: 0.5470 - val_loss: 0.4885 - val_mse: 0.4813\n",
      "Epoch 172/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5548 - mse: 0.5476 - val_loss: 0.4929 - val_mse: 0.4857\n",
      "Epoch 173/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5568 - mse: 0.5496 - val_loss: 0.4934 - val_mse: 0.4862\n",
      "Epoch 174/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5512 - mse: 0.5440 - val_loss: 0.4871 - val_mse: 0.4799\n",
      "Epoch 175/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5547 - mse: 0.5475 - val_loss: 0.4865 - val_mse: 0.4793\n",
      "Epoch 176/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5534 - mse: 0.5462 - val_loss: 0.4865 - val_mse: 0.4794\n",
      "Epoch 177/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5545 - mse: 0.5473 - val_loss: 0.4963 - val_mse: 0.4892\n",
      "Epoch 178/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5529 - mse: 0.5458 - val_loss: 0.4886 - val_mse: 0.4815\n",
      "Epoch 179/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5507 - mse: 0.5435 - val_loss: 0.4943 - val_mse: 0.4871\n",
      "Epoch 180/2000\n",
      "1392/1397 [============================>.] - ETA: 0s - loss: 0.5528 - mse: 0.5457\n",
      "Epoch 00180: saving model to Regression_Model/bl6.mle.linear-0180.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5527 - mse: 0.5456 - val_loss: 0.4865 - val_mse: 0.4794\n",
      "Epoch 181/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5524 - mse: 0.5453 - val_loss: 0.4940 - val_mse: 0.4869\n",
      "Epoch 182/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5528 - mse: 0.5457 - val_loss: 0.4920 - val_mse: 0.4849\n",
      "Epoch 183/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5557 - mse: 0.5485 - val_loss: 0.4899 - val_mse: 0.4828\n",
      "Epoch 184/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5516 - mse: 0.5445 - val_loss: 0.4862 - val_mse: 0.4791\n",
      "Epoch 185/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5546 - mse: 0.5475 - val_loss: 0.4898 - val_mse: 0.4827\n",
      "Epoch 186/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5525 - mse: 0.5454 - val_loss: 0.4892 - val_mse: 0.4821\n",
      "Epoch 187/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5541 - mse: 0.5470 - val_loss: 0.4874 - val_mse: 0.4803\n",
      "Epoch 188/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5505 - mse: 0.5434 - val_loss: 0.4893 - val_mse: 0.4822\n",
      "Epoch 189/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5537 - mse: 0.5466 - val_loss: 0.4961 - val_mse: 0.4890\n",
      "Epoch 190/2000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5544 - mse: 0.5473\n",
      "Epoch 00190: saving model to Regression_Model/bl6.mle.linear-0190.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5545 - mse: 0.5474 - val_loss: 0.4893 - val_mse: 0.4822\n",
      "Epoch 191/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5540 - mse: 0.5470 - val_loss: 0.4868 - val_mse: 0.4797\n",
      "Epoch 192/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5525 - mse: 0.5454 - val_loss: 0.4939 - val_mse: 0.4868\n",
      "Epoch 193/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5520 - mse: 0.5450 - val_loss: 0.4900 - val_mse: 0.4829\n",
      "Epoch 194/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5524 - mse: 0.5453 - val_loss: 0.4922 - val_mse: 0.4851\n",
      "Epoch 195/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5522 - mse: 0.5451 - val_loss: 0.4868 - val_mse: 0.4798\n",
      "Epoch 196/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5540 - mse: 0.5469 - val_loss: 0.4919 - val_mse: 0.4848\n",
      "Epoch 197/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5548 - mse: 0.5477 - val_loss: 0.4886 - val_mse: 0.4815\n",
      "Epoch 198/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5529 - mse: 0.5459 - val_loss: 0.4884 - val_mse: 0.4813\n",
      "Epoch 199/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5514 - mse: 0.5443 - val_loss: 0.4863 - val_mse: 0.4793\n",
      "Epoch 200/2000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5505 - mse: 0.5435\n",
      "Epoch 00200: saving model to Regression_Model/bl6.mle.linear-0200.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5509 - mse: 0.5438 - val_loss: 0.4858 - val_mse: 0.4788\n",
      "Epoch 201/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5533 - mse: 0.5462 - val_loss: 0.4890 - val_mse: 0.4820\n",
      "Epoch 202/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5495 - mse: 0.5424 - val_loss: 0.4871 - val_mse: 0.4800\n",
      "Epoch 203/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5507 - mse: 0.5437 - val_loss: 0.4853 - val_mse: 0.4782\n",
      "Epoch 204/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5541 - mse: 0.5470 - val_loss: 0.4862 - val_mse: 0.4792\n",
      "Epoch 205/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5543 - mse: 0.5473 - val_loss: 0.4875 - val_mse: 0.4805\n",
      "Epoch 206/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5538 - mse: 0.5467 - val_loss: 0.4862 - val_mse: 0.4792\n",
      "Epoch 207/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5519 - mse: 0.5449 - val_loss: 0.4934 - val_mse: 0.4864\n",
      "Epoch 208/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5549 - mse: 0.5479 - val_loss: 0.4912 - val_mse: 0.4842\n",
      "Epoch 209/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5514 - mse: 0.5444 - val_loss: 0.4862 - val_mse: 0.4791\n",
      "Epoch 210/2000\n",
      "1393/1397 [============================>.] - ETA: 0s - loss: 0.5541 - mse: 0.5471\n",
      "Epoch 00210: saving model to Regression_Model/bl6.mle.linear-0210.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5539 - mse: 0.5469 - val_loss: 0.4867 - val_mse: 0.4797\n",
      "Epoch 211/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5511 - mse: 0.5441 - val_loss: 0.4868 - val_mse: 0.4798\n",
      "Epoch 212/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5491 - mse: 0.5421 - val_loss: 0.4857 - val_mse: 0.4787\n",
      "Epoch 213/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5499 - mse: 0.5429 - val_loss: 0.4894 - val_mse: 0.4824\n",
      "Epoch 214/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5495 - mse: 0.5425 - val_loss: 0.4858 - val_mse: 0.4788\n",
      "Epoch 215/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5541 - mse: 0.5471 - val_loss: 0.4861 - val_mse: 0.4791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5487 - mse: 0.5417 - val_loss: 0.4853 - val_mse: 0.4783\n",
      "Epoch 217/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5498 - mse: 0.5428 - val_loss: 0.4905 - val_mse: 0.4835\n",
      "Epoch 218/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5515 - mse: 0.5445 - val_loss: 0.4848 - val_mse: 0.4779\n",
      "Epoch 219/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5495 - mse: 0.5426 - val_loss: 0.4884 - val_mse: 0.4814\n",
      "Epoch 220/2000\n",
      "1393/1397 [============================>.] - ETA: 0s - loss: 0.5500 - mse: 0.5430\n",
      "Epoch 00220: saving model to Regression_Model/bl6.mle.linear-0220.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5501 - mse: 0.5431 - val_loss: 0.4860 - val_mse: 0.4791\n",
      "Epoch 221/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5507 - mse: 0.5438 - val_loss: 0.4963 - val_mse: 0.4893\n",
      "Epoch 222/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5519 - mse: 0.5449 - val_loss: 0.4848 - val_mse: 0.4779\n",
      "Epoch 223/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5488 - mse: 0.5419 - val_loss: 0.4890 - val_mse: 0.4820\n",
      "Epoch 224/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5491 - mse: 0.5421 - val_loss: 0.4872 - val_mse: 0.4802\n",
      "Epoch 225/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5496 - mse: 0.5427 - val_loss: 0.4828 - val_mse: 0.4758\n",
      "Epoch 226/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5518 - mse: 0.5448 - val_loss: 0.4874 - val_mse: 0.4804\n",
      "Epoch 227/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5494 - mse: 0.5424 - val_loss: 0.4867 - val_mse: 0.4797\n",
      "Epoch 228/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5495 - mse: 0.5426 - val_loss: 0.4825 - val_mse: 0.4756\n",
      "Epoch 229/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5482 - mse: 0.5412 - val_loss: 0.4884 - val_mse: 0.4815\n",
      "Epoch 230/2000\n",
      "1387/1397 [============================>.] - ETA: 0s - loss: 0.5489 - mse: 0.5419\n",
      "Epoch 00230: saving model to Regression_Model/bl6.mle.linear-0230.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5487 - mse: 0.5418 - val_loss: 0.4879 - val_mse: 0.4810\n",
      "Epoch 231/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5512 - mse: 0.5443 - val_loss: 0.4896 - val_mse: 0.4827\n",
      "Epoch 232/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5493 - mse: 0.5423 - val_loss: 0.4887 - val_mse: 0.4817\n",
      "Epoch 233/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5483 - mse: 0.5414 - val_loss: 0.4872 - val_mse: 0.4802\n",
      "Epoch 234/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5505 - mse: 0.5435 - val_loss: 0.4841 - val_mse: 0.4772\n",
      "Epoch 235/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5490 - mse: 0.5420 - val_loss: 0.4848 - val_mse: 0.4778\n",
      "Epoch 236/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5484 - mse: 0.5415 - val_loss: 0.4847 - val_mse: 0.4778\n",
      "Epoch 237/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5488 - mse: 0.5419 - val_loss: 0.4855 - val_mse: 0.4786\n",
      "Epoch 238/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5411 - val_loss: 0.4870 - val_mse: 0.4800\n",
      "Epoch 239/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5486 - mse: 0.5417 - val_loss: 0.4975 - val_mse: 0.4905\n",
      "Epoch 240/2000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5497 - mse: 0.5428\n",
      "Epoch 00240: saving model to Regression_Model/bl6.mle.linear-0240.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5496 - mse: 0.5427 - val_loss: 0.4836 - val_mse: 0.4767\n",
      "Epoch 241/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5494 - mse: 0.5425 - val_loss: 0.4867 - val_mse: 0.4798\n",
      "Epoch 242/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5411 - val_loss: 0.4862 - val_mse: 0.4793\n",
      "Epoch 243/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5504 - mse: 0.5435 - val_loss: 0.4853 - val_mse: 0.4784\n",
      "Epoch 244/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5395 - val_loss: 0.4847 - val_mse: 0.4778\n",
      "Epoch 245/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5501 - mse: 0.5432 - val_loss: 0.4850 - val_mse: 0.4781\n",
      "Epoch 246/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5366 - val_loss: 0.4846 - val_mse: 0.4777\n",
      "Epoch 247/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5502 - mse: 0.5433 - val_loss: 0.4869 - val_mse: 0.4800\n",
      "Epoch 248/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5397 - val_loss: 0.4869 - val_mse: 0.4801\n",
      "Epoch 249/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5401 - val_loss: 0.4861 - val_mse: 0.4792\n",
      "Epoch 250/2000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.5503 - mse: 0.5434\n",
      "Epoch 00250: saving model to Regression_Model/bl6.mle.linear-0250.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5510 - mse: 0.5441 - val_loss: 0.4920 - val_mse: 0.4852\n",
      "Epoch 251/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5503 - mse: 0.5435 - val_loss: 0.4837 - val_mse: 0.4768\n",
      "Epoch 252/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5492 - mse: 0.5424 - val_loss: 0.4823 - val_mse: 0.4754\n",
      "Epoch 253/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5522 - mse: 0.5453 - val_loss: 0.4877 - val_mse: 0.4808\n",
      "Epoch 254/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5506 - mse: 0.5437 - val_loss: 0.4885 - val_mse: 0.4817\n",
      "Epoch 255/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5502 - mse: 0.5434 - val_loss: 0.4918 - val_mse: 0.4850\n",
      "Epoch 256/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5494 - mse: 0.5425 - val_loss: 0.4841 - val_mse: 0.4773\n",
      "Epoch 257/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5484 - mse: 0.5416 - val_loss: 0.4906 - val_mse: 0.4837\n",
      "Epoch 258/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5503 - mse: 0.5434 - val_loss: 0.4855 - val_mse: 0.4787\n",
      "Epoch 259/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5412 - val_loss: 0.4834 - val_mse: 0.4766\n",
      "Epoch 260/2000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5483 - mse: 0.5414\n",
      "Epoch 00260: saving model to Regression_Model/bl6.mle.linear-0260.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5412 - val_loss: 0.4848 - val_mse: 0.4780\n",
      "Epoch 261/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5502 - mse: 0.5434 - val_loss: 0.4830 - val_mse: 0.4761\n",
      "Epoch 262/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5491 - mse: 0.5422 - val_loss: 0.4897 - val_mse: 0.4828\n",
      "Epoch 263/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5483 - mse: 0.5414 - val_loss: 0.4840 - val_mse: 0.4772\n",
      "Epoch 264/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5395 - val_loss: 0.4844 - val_mse: 0.4775\n",
      "Epoch 265/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5485 - mse: 0.5417 - val_loss: 0.4854 - val_mse: 0.4786\n",
      "Epoch 266/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5386 - val_loss: 0.4841 - val_mse: 0.4773\n",
      "Epoch 267/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5411 - val_loss: 0.4820 - val_mse: 0.4752\n",
      "Epoch 268/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5487 - mse: 0.5419 - val_loss: 0.4875 - val_mse: 0.4807\n",
      "Epoch 269/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5525 - mse: 0.5457 - val_loss: 0.4884 - val_mse: 0.4816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/2000\n",
      "1386/1397 [============================>.] - ETA: 0s - loss: 0.5538 - mse: 0.5470\n",
      "Epoch 00270: saving model to Regression_Model/bl6.mle.linear-0270.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5534 - mse: 0.5465 - val_loss: 0.4841 - val_mse: 0.4773\n",
      "Epoch 271/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5412 - val_loss: 0.4853 - val_mse: 0.4785\n",
      "Epoch 272/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5391 - val_loss: 0.4825 - val_mse: 0.4757\n",
      "Epoch 273/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5479 - mse: 0.5411 - val_loss: 0.4833 - val_mse: 0.4765\n",
      "Epoch 274/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5406 - val_loss: 0.4835 - val_mse: 0.4767\n",
      "Epoch 275/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5407 - val_loss: 0.4892 - val_mse: 0.4824\n",
      "Epoch 276/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5407 - val_loss: 0.4838 - val_mse: 0.4770\n",
      "Epoch 277/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5477 - mse: 0.5409 - val_loss: 0.4897 - val_mse: 0.4829\n",
      "Epoch 278/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5486 - mse: 0.5418 - val_loss: 0.4832 - val_mse: 0.4764\n",
      "Epoch 279/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5486 - mse: 0.5418 - val_loss: 0.4891 - val_mse: 0.4823\n",
      "Epoch 280/2000\n",
      "1382/1397 [============================>.] - ETA: 0s - loss: 0.5479 - mse: 0.5411\n",
      "Epoch 00280: saving model to Regression_Model/bl6.mle.linear-0280.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5482 - mse: 0.5414 - val_loss: 0.4841 - val_mse: 0.4773\n",
      "Epoch 281/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5397 - val_loss: 0.4848 - val_mse: 0.4780\n",
      "Epoch 282/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5486 - mse: 0.5418 - val_loss: 0.4857 - val_mse: 0.4789\n",
      "Epoch 283/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5397 - val_loss: 0.4858 - val_mse: 0.4790\n",
      "Epoch 284/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5496 - mse: 0.5428 - val_loss: 0.4866 - val_mse: 0.4798\n",
      "Epoch 285/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5391 - val_loss: 0.4892 - val_mse: 0.4824\n",
      "Epoch 286/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5392 - val_loss: 0.4843 - val_mse: 0.4775\n",
      "Epoch 287/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5400 - val_loss: 0.4904 - val_mse: 0.4837\n",
      "Epoch 288/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5471 - mse: 0.5403 - val_loss: 0.4855 - val_mse: 0.4787\n",
      "Epoch 289/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5380 - val_loss: 0.4871 - val_mse: 0.4803\n",
      "Epoch 290/2000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5490 - mse: 0.5422\n",
      "Epoch 00290: saving model to Regression_Model/bl6.mle.linear-0290.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5493 - mse: 0.5425 - val_loss: 0.4833 - val_mse: 0.4765\n",
      "Epoch 291/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5392 - val_loss: 0.4865 - val_mse: 0.4797\n",
      "Epoch 292/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5389 - val_loss: 0.4818 - val_mse: 0.4750\n",
      "Epoch 293/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5491 - mse: 0.5423 - val_loss: 0.4878 - val_mse: 0.4810\n",
      "Epoch 294/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5382 - val_loss: 0.4871 - val_mse: 0.4803\n",
      "Epoch 295/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5400 - val_loss: 0.4832 - val_mse: 0.4764\n",
      "Epoch 296/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5502 - mse: 0.5434 - val_loss: 0.4863 - val_mse: 0.4795\n",
      "Epoch 297/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5396 - val_loss: 0.4872 - val_mse: 0.4805\n",
      "Epoch 298/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5402 - val_loss: 0.4847 - val_mse: 0.4779\n",
      "Epoch 299/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5453 - mse: 0.5385 - val_loss: 0.4833 - val_mse: 0.4765\n",
      "Epoch 300/2000\n",
      "1381/1397 [============================>.] - ETA: 0s - loss: 0.5460 - mse: 0.5392\n",
      "Epoch 00300: saving model to Regression_Model/bl6.mle.linear-0300.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5464 - mse: 0.5396 - val_loss: 0.4846 - val_mse: 0.4778\n",
      "Epoch 301/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5367 - val_loss: 0.4827 - val_mse: 0.4759\n",
      "Epoch 302/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5471 - mse: 0.5403 - val_loss: 0.4846 - val_mse: 0.4778\n",
      "Epoch 303/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5408 - val_loss: 0.4865 - val_mse: 0.4798\n",
      "Epoch 304/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5373 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 305/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5502 - mse: 0.5435 - val_loss: 0.4901 - val_mse: 0.4834\n",
      "Epoch 306/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5469 - mse: 0.5402 - val_loss: 0.4819 - val_mse: 0.4752\n",
      "Epoch 307/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5476 - mse: 0.5409 - val_loss: 0.4844 - val_mse: 0.4776\n",
      "Epoch 308/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5403 - val_loss: 0.4841 - val_mse: 0.4773\n",
      "Epoch 309/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5376 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 310/2000\n",
      "1381/1397 [============================>.] - ETA: 0s - loss: 0.5485 - mse: 0.5418\n",
      "Epoch 00310: saving model to Regression_Model/bl6.mle.linear-0310.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5487 - mse: 0.5419 - val_loss: 0.4845 - val_mse: 0.4777\n",
      "Epoch 311/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5472 - mse: 0.5404 - val_loss: 0.4830 - val_mse: 0.4762\n",
      "Epoch 312/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5471 - mse: 0.5403 - val_loss: 0.4824 - val_mse: 0.4757\n",
      "Epoch 313/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5387 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 314/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5378 - val_loss: 0.4831 - val_mse: 0.4763\n",
      "Epoch 315/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5400 - val_loss: 0.4860 - val_mse: 0.4792\n",
      "Epoch 316/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5430 - mse: 0.5363 - val_loss: 0.4825 - val_mse: 0.4758\n",
      "Epoch 317/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5516 - mse: 0.5449 - val_loss: 0.4857 - val_mse: 0.4790\n",
      "Epoch 318/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5504 - mse: 0.5437 - val_loss: 0.4877 - val_mse: 0.4810\n",
      "Epoch 319/2000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5463 - mse: 0.5395 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 320/2000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5477 - mse: 0.5410\n",
      "Epoch 00320: saving model to Regression_Model/bl6.mle.linear-0320.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4849 - val_mse: 0.4782\n",
      "Epoch 321/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5481 - mse: 0.5414 - val_loss: 0.4844 - val_mse: 0.4777\n",
      "Epoch 322/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5481 - mse: 0.5414 - val_loss: 0.4859 - val_mse: 0.4792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5393 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 324/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5401 - val_loss: 0.4823 - val_mse: 0.4756\n",
      "Epoch 325/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5386 - val_loss: 0.4846 - val_mse: 0.4779\n",
      "Epoch 326/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5479 - mse: 0.5412 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 327/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5392 - val_loss: 0.4821 - val_mse: 0.4754\n",
      "Epoch 328/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5500 - mse: 0.5433 - val_loss: 0.4866 - val_mse: 0.4799\n",
      "Epoch 329/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5378 - val_loss: 0.4811 - val_mse: 0.4744\n",
      "Epoch 330/2000\n",
      "1394/1397 [============================>.] - ETA: 0s - loss: 0.5437 - mse: 0.5370\n",
      "Epoch 00330: saving model to Regression_Model/bl6.mle.linear-0330.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4822 - val_mse: 0.4755\n",
      "Epoch 331/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5385 - val_loss: 0.4822 - val_mse: 0.4755\n",
      "Epoch 332/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5413 - val_loss: 0.4850 - val_mse: 0.4783\n",
      "Epoch 333/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5413 - val_loss: 0.4847 - val_mse: 0.4780\n",
      "Epoch 334/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5408 - val_loss: 0.4828 - val_mse: 0.4761\n",
      "Epoch 335/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4846 - val_mse: 0.4779\n",
      "Epoch 336/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5476 - mse: 0.5409 - val_loss: 0.4826 - val_mse: 0.4759\n",
      "Epoch 337/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5375 - val_loss: 0.4856 - val_mse: 0.4789\n",
      "Epoch 338/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4848 - val_mse: 0.4781\n",
      "Epoch 339/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 340/2000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5434 - mse: 0.5367\n",
      "Epoch 00340: saving model to Regression_Model/bl6.mle.linear-0340.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5369 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 341/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5490 - mse: 0.5423 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 342/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5381 - val_loss: 0.4850 - val_mse: 0.4783\n",
      "Epoch 343/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5413 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 344/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5509 - mse: 0.5442 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 345/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5477 - mse: 0.5410 - val_loss: 0.4868 - val_mse: 0.4801\n",
      "Epoch 346/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5472 - mse: 0.5405 - val_loss: 0.4817 - val_mse: 0.4750\n",
      "Epoch 347/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5416 - mse: 0.5350 - val_loss: 0.4819 - val_mse: 0.4752\n",
      "Epoch 348/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5485 - mse: 0.5418 - val_loss: 0.4841 - val_mse: 0.4774\n",
      "Epoch 349/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5455 - mse: 0.5388 - val_loss: 0.4848 - val_mse: 0.4781\n",
      "Epoch 350/2000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5472 - mse: 0.5405\n",
      "Epoch 00350: saving model to Regression_Model/bl6.mle.linear-0350.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5404 - val_loss: 0.4815 - val_mse: 0.4748\n",
      "Epoch 351/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5408 - val_loss: 0.4838 - val_mse: 0.4771\n",
      "Epoch 352/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5386 - val_loss: 0.4858 - val_mse: 0.4791\n",
      "Epoch 353/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5381 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 354/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5484 - mse: 0.5418 - val_loss: 0.4849 - val_mse: 0.4782\n",
      "Epoch 355/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5485 - mse: 0.5418 - val_loss: 0.4862 - val_mse: 0.4796\n",
      "Epoch 356/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5424 - mse: 0.5357 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 357/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4811 - val_mse: 0.4745\n",
      "Epoch 358/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5401 - val_loss: 0.4847 - val_mse: 0.4780\n",
      "Epoch 359/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4846 - val_mse: 0.4779\n",
      "Epoch 360/2000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5461 - mse: 0.5395\n",
      "Epoch 00360: saving model to Regression_Model/bl6.mle.linear-0360.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5401 - val_loss: 0.4845 - val_mse: 0.4778\n",
      "Epoch 361/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5386 - val_loss: 0.4817 - val_mse: 0.4750\n",
      "Epoch 362/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5473 - mse: 0.5406 - val_loss: 0.4811 - val_mse: 0.4744\n",
      "Epoch 363/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5476 - mse: 0.5409 - val_loss: 0.4847 - val_mse: 0.4780\n",
      "Epoch 364/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5451 - mse: 0.5384 - val_loss: 0.4823 - val_mse: 0.4756\n",
      "Epoch 365/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5421 - mse: 0.5354 - val_loss: 0.4819 - val_mse: 0.4752\n",
      "Epoch 366/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5394 - val_loss: 0.4829 - val_mse: 0.4763\n",
      "Epoch 367/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5413 - val_loss: 0.4864 - val_mse: 0.4798\n",
      "Epoch 368/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5414 - mse: 0.5347 - val_loss: 0.4813 - val_mse: 0.4747\n",
      "Epoch 369/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5382 - val_loss: 0.4827 - val_mse: 0.4760\n",
      "Epoch 370/2000\n",
      "1381/1397 [============================>.] - ETA: 0s - loss: 0.5470 - mse: 0.5403\n",
      "Epoch 00370: saving model to Regression_Model/bl6.mle.linear-0370.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5471 - mse: 0.5404 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 371/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5411 - mse: 0.5345 - val_loss: 0.4810 - val_mse: 0.4744\n",
      "Epoch 372/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5397 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 373/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4818 - val_mse: 0.4752\n",
      "Epoch 374/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4823 - val_mse: 0.4756\n",
      "Epoch 375/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5433 - mse: 0.5366 - val_loss: 0.4818 - val_mse: 0.4751\n",
      "Epoch 376/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5404 - val_loss: 0.4847 - val_mse: 0.4780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5403 - val_loss: 0.4826 - val_mse: 0.4759\n",
      "Epoch 378/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5393 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 379/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4807 - val_mse: 0.4740\n",
      "Epoch 380/2000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.5470 - mse: 0.5403\n",
      "Epoch 00380: saving model to Regression_Model/bl6.mle.linear-0380.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4825 - val_mse: 0.4758\n",
      "Epoch 381/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5462 - mse: 0.5395 - val_loss: 0.4843 - val_mse: 0.4776\n",
      "Epoch 382/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5394 - val_loss: 0.4828 - val_mse: 0.4762\n",
      "Epoch 383/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5382 - val_loss: 0.4829 - val_mse: 0.4763\n",
      "Epoch 384/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5373 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 385/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 386/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 387/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4846 - val_mse: 0.4779\n",
      "Epoch 388/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5471 - mse: 0.5404 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 389/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5508 - mse: 0.5442 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 390/2000\n",
      "1392/1397 [============================>.] - ETA: 0s - loss: 0.5445 - mse: 0.5379\n",
      "Epoch 00390: saving model to Regression_Model/bl6.mle.linear-0390.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5442 - mse: 0.5375 - val_loss: 0.4821 - val_mse: 0.4754\n",
      "Epoch 391/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 392/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5387 - val_loss: 0.4822 - val_mse: 0.4756\n",
      "Epoch 393/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5497 - mse: 0.5431 - val_loss: 0.4824 - val_mse: 0.4757\n",
      "Epoch 394/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5424 - mse: 0.5357 - val_loss: 0.4818 - val_mse: 0.4751\n",
      "Epoch 395/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5414 - mse: 0.5348 - val_loss: 0.4828 - val_mse: 0.4762\n",
      "Epoch 396/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5485 - mse: 0.5419 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 397/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4844 - val_mse: 0.4778\n",
      "Epoch 398/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 399/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5430 - mse: 0.5363 - val_loss: 0.4819 - val_mse: 0.4752\n",
      "Epoch 400/2000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5441 - mse: 0.5375\n",
      "Epoch 00400: saving model to Regression_Model/bl6.mle.linear-0400.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4815 - val_mse: 0.4748\n",
      "Epoch 401/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4806 - val_mse: 0.4740\n",
      "Epoch 402/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5482 - mse: 0.5415 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 403/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5445 - mse: 0.5378 - val_loss: 0.4823 - val_mse: 0.4756\n",
      "Epoch 404/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5368 - val_loss: 0.4840 - val_mse: 0.4773\n",
      "Epoch 405/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4822 - val_mse: 0.4756\n",
      "Epoch 406/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 407/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4821 - val_mse: 0.4754\n",
      "Epoch 408/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4824 - val_mse: 0.4758\n",
      "Epoch 409/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5408 - mse: 0.5341 - val_loss: 0.4807 - val_mse: 0.4741\n",
      "Epoch 410/2000\n",
      "1381/1397 [============================>.] - ETA: 0s - loss: 0.5443 - mse: 0.5376\n",
      "Epoch 00410: saving model to Regression_Model/bl6.mle.linear-0410.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 411/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5422 - mse: 0.5355 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 412/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4806 - val_mse: 0.4740\n",
      "Epoch 413/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5387 - val_loss: 0.4827 - val_mse: 0.4761\n",
      "Epoch 414/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5372 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 415/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5408 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 416/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4826 - val_mse: 0.4759\n",
      "Epoch 417/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 418/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 419/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5483 - mse: 0.5416 - val_loss: 0.4818 - val_mse: 0.4751\n",
      "Epoch 420/2000\n",
      "1377/1397 [============================>.] - ETA: 0s - loss: 0.5486 - mse: 0.5420\n",
      "Epoch 00420: saving model to Regression_Model/bl6.mle.linear-0420.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5488 - mse: 0.5421 - val_loss: 0.4816 - val_mse: 0.4750\n",
      "Epoch 421/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5437 - mse: 0.5371 - val_loss: 0.4829 - val_mse: 0.4762\n",
      "Epoch 422/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5457 - mse: 0.5391 - val_loss: 0.4818 - val_mse: 0.4752\n",
      "Epoch 423/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5388 - val_loss: 0.4808 - val_mse: 0.4742\n",
      "Epoch 424/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5426 - mse: 0.5359 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 425/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5419 - mse: 0.5353 - val_loss: 0.4843 - val_mse: 0.4777\n",
      "Epoch 426/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5482 - mse: 0.5416 - val_loss: 0.4824 - val_mse: 0.4758\n",
      "Epoch 427/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5388 - val_loss: 0.4823 - val_mse: 0.4757\n",
      "Epoch 428/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5428 - mse: 0.5362 - val_loss: 0.4817 - val_mse: 0.4751\n",
      "Epoch 429/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5367 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 430/2000\n",
      "1378/1397 [============================>.] - ETA: 0s - loss: 0.5457 - mse: 0.5391\n",
      "Epoch 00430: saving model to Regression_Model/bl6.mle.linear-0430.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5398 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 431/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5387 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 432/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4819 - val_mse: 0.4753\n",
      "Epoch 433/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5457 - mse: 0.5391 - val_loss: 0.4827 - val_mse: 0.4761\n",
      "Epoch 434/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5370 - val_loss: 0.4819 - val_mse: 0.4753\n",
      "Epoch 435/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5398 - val_loss: 0.4817 - val_mse: 0.4751\n",
      "Epoch 436/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5371 - val_loss: 0.4824 - val_mse: 0.4757\n",
      "Epoch 437/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 438/2000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5472 - mse: 0.5405 - val_loss: 0.4838 - val_mse: 0.4771\n",
      "Epoch 439/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5372 - val_loss: 0.4811 - val_mse: 0.4745\n",
      "Epoch 440/2000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5462 - mse: 0.5396\n",
      "Epoch 00440: saving model to Regression_Model/bl6.mle.linear-0440.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5401 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 441/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5428 - mse: 0.5361 - val_loss: 0.4823 - val_mse: 0.4756\n",
      "Epoch 442/2000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4813 - val_mse: 0.4747\n",
      "Epoch 443/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4819 - val_mse: 0.4753\n",
      "Epoch 444/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5473 - mse: 0.5407 - val_loss: 0.4822 - val_mse: 0.4756\n",
      "Epoch 445/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4816 - val_mse: 0.4750\n",
      "Epoch 446/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4839 - val_mse: 0.4773\n",
      "Epoch 447/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5372 - val_loss: 0.4818 - val_mse: 0.4752\n",
      "Epoch 448/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5413 - mse: 0.5347 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 449/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4823 - val_mse: 0.4756\n",
      "Epoch 450/2000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5433 - mse: 0.5367\n",
      "Epoch 00450: saving model to Regression_Model/bl6.mle.linear-0450.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5430 - mse: 0.5364 - val_loss: 0.4828 - val_mse: 0.4762\n",
      "Epoch 451/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 452/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5369 - val_loss: 0.4817 - val_mse: 0.4751\n",
      "Epoch 453/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4816 - val_mse: 0.4750\n",
      "Epoch 454/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4813 - val_mse: 0.4747\n",
      "Epoch 455/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4811 - val_mse: 0.4745\n",
      "Epoch 456/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5412 - mse: 0.5346 - val_loss: 0.4812 - val_mse: 0.4745\n",
      "Epoch 457/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5451 - mse: 0.5385 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 458/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5431 - mse: 0.5365 - val_loss: 0.4815 - val_mse: 0.4749\n",
      "Epoch 459/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4828 - val_mse: 0.4762\n",
      "Epoch 460/2000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.5444 - mse: 0.5378\n",
      "Epoch 00460: saving model to Regression_Model/bl6.mle.linear-0460.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 461/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5424 - mse: 0.5358 - val_loss: 0.4815 - val_mse: 0.4749\n",
      "Epoch 462/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5401 - val_loss: 0.4829 - val_mse: 0.4763\n",
      "Epoch 463/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5398 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 464/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 465/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4829 - val_mse: 0.4763\n",
      "Epoch 466/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4823 - val_mse: 0.4757\n",
      "Epoch 467/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5471 - mse: 0.5405 - val_loss: 0.4823 - val_mse: 0.4757\n",
      "Epoch 468/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5372 - val_loss: 0.4829 - val_mse: 0.4763\n",
      "Epoch 469/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 470/2000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.5434 - mse: 0.5368\n",
      "Epoch 00470: saving model to Regression_Model/bl6.mle.linear-0470.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5433 - mse: 0.5367 - val_loss: 0.4828 - val_mse: 0.4761\n",
      "Epoch 471/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5429 - mse: 0.5363 - val_loss: 0.4829 - val_mse: 0.4763\n",
      "Epoch 472/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5430 - mse: 0.5364 - val_loss: 0.4823 - val_mse: 0.4757\n",
      "Epoch 473/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4822 - val_mse: 0.4756\n",
      "Epoch 474/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5433 - mse: 0.5367 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 475/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 476/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5409 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 477/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5419 - mse: 0.5353 - val_loss: 0.4817 - val_mse: 0.4751\n",
      "Epoch 478/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 479/2000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5473 - mse: 0.5407 - val_loss: 0.4824 - val_mse: 0.4758\n",
      "Epoch 480/2000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5465 - mse: 0.5399\n",
      "Epoch 00480: saving model to Regression_Model/bl6.mle.linear-0480.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 481/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4818 - val_mse: 0.4752\n",
      "Epoch 482/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5418 - mse: 0.5352 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 483/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5369 - val_loss: 0.4812 - val_mse: 0.4746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5405 - mse: 0.5339 - val_loss: 0.4810 - val_mse: 0.4744\n",
      "Epoch 485/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4822 - val_mse: 0.4756\n",
      "Epoch 486/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5366 - val_loss: 0.4810 - val_mse: 0.4744\n",
      "Epoch 487/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5481 - mse: 0.5415 - val_loss: 0.4827 - val_mse: 0.4761\n",
      "Epoch 488/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4829 - val_mse: 0.4763\n",
      "Epoch 489/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4816 - val_mse: 0.4750\n",
      "Epoch 490/2000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5455 - mse: 0.5389\n",
      "Epoch 00490: saving model to Regression_Model/bl6.mle.linear-0490.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5451 - mse: 0.5385 - val_loss: 0.4815 - val_mse: 0.4749\n",
      "Epoch 491/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5482 - mse: 0.5416 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 492/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4822 - val_mse: 0.4756\n",
      "Epoch 493/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5406 - mse: 0.5340 - val_loss: 0.4823 - val_mse: 0.4757\n",
      "Epoch 494/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5421 - mse: 0.5355 - val_loss: 0.4810 - val_mse: 0.4744\n",
      "Epoch 495/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5371 - val_loss: 0.4827 - val_mse: 0.4761\n",
      "Epoch 496/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4814 - val_mse: 0.4748\n",
      "Epoch 497/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 498/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5371 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 499/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4815 - val_mse: 0.4749\n",
      "Epoch 500/2000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.5444 - mse: 0.5378\n",
      "Epoch 00500: saving model to Regression_Model/bl6.mle.linear-0500.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4823 - val_mse: 0.4757\n",
      "Epoch 501/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5371 - val_loss: 0.4826 - val_mse: 0.4761\n",
      "Epoch 502/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 503/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5451 - mse: 0.5385 - val_loss: 0.4816 - val_mse: 0.4750\n",
      "Epoch 504/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5451 - mse: 0.5385 - val_loss: 0.4822 - val_mse: 0.4757\n",
      "Epoch 505/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5433 - mse: 0.5367 - val_loss: 0.4824 - val_mse: 0.4758\n",
      "Epoch 506/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5484 - mse: 0.5418 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 507/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5366 - val_loss: 0.4811 - val_mse: 0.4745\n",
      "Epoch 508/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5423 - mse: 0.5357 - val_loss: 0.4815 - val_mse: 0.4749\n",
      "Epoch 509/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4823 - val_mse: 0.4757\n",
      "Epoch 510/2000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5445 - mse: 0.5379\n",
      "Epoch 00510: saving model to Regression_Model/bl6.mle.linear-0510.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 511/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 512/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5397 - val_loss: 0.4818 - val_mse: 0.4752\n",
      "Epoch 513/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4818 - val_mse: 0.4752\n",
      "Epoch 514/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 515/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5431 - mse: 0.5365 - val_loss: 0.4820 - val_mse: 0.4755\n",
      "Epoch 516/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5422 - mse: 0.5356 - val_loss: 0.4819 - val_mse: 0.4753\n",
      "Epoch 517/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5499 - mse: 0.5433 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 518/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4824 - val_mse: 0.4758\n",
      "Epoch 519/2000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5368 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 520/2000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.5467 - mse: 0.5401\n",
      "Epoch 00520: saving model to Regression_Model/bl6.mle.linear-0520.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5465 - mse: 0.5399 - val_loss: 0.4820 - val_mse: 0.4754\n",
      "Epoch 521/2000\n",
      " 233/1397 [====>.........................] - ETA: 3s - loss: 0.5481 - mse: 0.5415"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=2000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-1900.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testid='bl6.mle.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
