{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 14753\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.predict.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    #train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    #valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    \n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    #train_data = (train_data-data_mean)/data_std\n",
    "    train_data = train_data/data_max\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #valid_data  = (valid_data-data_mean)/data_std\n",
    "    valid_data    = valid_data/data_max\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493.88113 3219.6182\n",
      "5.729239 1.606415\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd9559a8748>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd955945940>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "#model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='msle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 368 steps, validate for 368 steps\n",
      "Epoch 1/2000\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.1254 - mse: 1.0991 - val_loss: 0.1187 - val_mse: 1.0951\n",
      "Epoch 2/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1178 - mse: 1.0863 - val_loss: 0.1155 - val_mse: 1.0851\n",
      "Epoch 3/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1138 - mse: 1.0714 - val_loss: 0.1099 - val_mse: 1.0501\n",
      "Epoch 4/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1082 - mse: 1.0491 - val_loss: 0.1034 - val_mse: 1.0242\n",
      "Epoch 5/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1027 - mse: 1.0270 - val_loss: 0.0970 - val_mse: 0.9994\n",
      "Epoch 6/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0979 - mse: 1.0414 - val_loss: 0.0927 - val_mse: 1.0186\n",
      "Epoch 7/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0942 - mse: 1.0412 - val_loss: 0.0908 - val_mse: 1.0515\n",
      "Epoch 8/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0924 - mse: 1.0624 - val_loss: 0.0925 - val_mse: 1.0353\n",
      "Epoch 9/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0933 - mse: 1.0716 - val_loss: 0.0913 - val_mse: 1.1196\n",
      "Epoch 10/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0923 - mse: 1.1942\n",
      "Epoch 00010: saving model to Regression_Model/msle.linear-0010.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0923 - mse: 1.1922 - val_loss: 0.0886 - val_mse: 1.1067\n",
      "Epoch 11/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0904 - mse: 1.0798 - val_loss: 0.0869 - val_mse: 1.1093\n",
      "Epoch 12/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0901 - mse: 1.1615 - val_loss: 0.0867 - val_mse: 1.1012\n",
      "Epoch 13/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0894 - mse: 1.1521 - val_loss: 0.0859 - val_mse: 1.0461\n",
      "Epoch 14/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0900 - mse: 1.1804 - val_loss: 0.0847 - val_mse: 1.0696\n",
      "Epoch 15/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0870 - mse: 1.0821 - val_loss: 0.0854 - val_mse: 1.0872\n",
      "Epoch 16/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0865 - mse: 1.0925 - val_loss: 0.0837 - val_mse: 1.0223\n",
      "Epoch 17/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0860 - mse: 1.0752 - val_loss: 0.0827 - val_mse: 1.0114\n",
      "Epoch 18/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0867 - mse: 1.1470 - val_loss: 0.0809 - val_mse: 1.0282\n",
      "Epoch 19/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0859 - mse: 1.0639 - val_loss: 0.0811 - val_mse: 0.9725\n",
      "Epoch 20/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0842 - mse: 1.0474\n",
      "Epoch 00020: saving model to Regression_Model/msle.linear-0020.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0842 - mse: 1.0407 - val_loss: 0.0795 - val_mse: 0.9605\n",
      "Epoch 21/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 0.9990 - val_loss: 0.0796 - val_mse: 1.0111\n",
      "Epoch 22/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 1.0312 - val_loss: 0.0775 - val_mse: 0.9781\n",
      "Epoch 23/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 1.0965 - val_loss: 0.0773 - val_mse: 0.9622\n",
      "Epoch 24/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0818 - mse: 1.0242 - val_loss: 0.0760 - val_mse: 0.9532\n",
      "Epoch 25/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0813 - mse: 1.0123 - val_loss: 0.0783 - val_mse: 0.9189\n",
      "Epoch 26/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0835 - mse: 1.0748 - val_loss: 0.0765 - val_mse: 0.9743\n",
      "Epoch 27/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0821 - mse: 1.0243 - val_loss: 0.0814 - val_mse: 1.0243\n",
      "Epoch 28/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.0167 - val_loss: 0.0739 - val_mse: 0.9327\n",
      "Epoch 29/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.0275 - val_loss: 0.0732 - val_mse: 0.9154\n",
      "Epoch 30/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0804 - mse: 0.9629\n",
      "Epoch 00030: saving model to Regression_Model/msle.linear-0030.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0810 - mse: 0.9636 - val_loss: 0.0792 - val_mse: 0.9915\n",
      "Epoch 31/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0808 - mse: 1.0778 - val_loss: 0.0726 - val_mse: 0.9291\n",
      "Epoch 32/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.0005 - val_loss: 0.0740 - val_mse: 0.9607\n",
      "Epoch 33/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0807 - mse: 1.0669 - val_loss: 0.0719 - val_mse: 0.9054\n",
      "Epoch 34/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0803 - mse: 1.0160 - val_loss: 0.0721 - val_mse: 0.9019\n",
      "Epoch 35/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.0032 - val_loss: 0.0761 - val_mse: 0.9098\n",
      "Epoch 36/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 0.9593 - val_loss: 0.0711 - val_mse: 0.8999\n",
      "Epoch 37/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 0.9441 - val_loss: 0.0715 - val_mse: 0.9026\n",
      "Epoch 38/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 0.9689 - val_loss: 0.0741 - val_mse: 0.9319\n",
      "Epoch 39/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.0026 - val_loss: 0.0703 - val_mse: 0.8964\n",
      "Epoch 40/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0800 - mse: 1.0140\n",
      "Epoch 00040: saving model to Regression_Model/msle.linear-0040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.0098 - val_loss: 0.0719 - val_mse: 0.8584\n",
      "Epoch 41/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 0.9746 - val_loss: 0.0695 - val_mse: 0.8820\n",
      "Epoch 42/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 0.9458 - val_loss: 0.0693 - val_mse: 0.8762\n",
      "Epoch 43/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 0.9422 - val_loss: 0.0713 - val_mse: 0.9226\n",
      "Epoch 44/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 0.9323 - val_loss: 0.0707 - val_mse: 0.9003\n",
      "Epoch 45/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 0.9381 - val_loss: 0.0701 - val_mse: 0.8908\n",
      "Epoch 46/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 0.9519 - val_loss: 0.0699 - val_mse: 0.8950\n",
      "Epoch 47/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0764 - mse: 0.9227 - val_loss: 0.0682 - val_mse: 0.8593\n",
      "Epoch 48/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0780 - mse: 0.9446 - val_loss: 0.0685 - val_mse: 0.8568\n",
      "Epoch 49/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 0.9663 - val_loss: 0.0687 - val_mse: 0.8654\n",
      "Epoch 50/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0780 - mse: 0.9695\n",
      "Epoch 00050: saving model to Regression_Model/msle.linear-0050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 0.9671 - val_loss: 0.0687 - val_mse: 0.8339\n",
      "Epoch 51/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 0.9311 - val_loss: 0.0678 - val_mse: 0.8671\n",
      "Epoch 52/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 0.9777 - val_loss: 0.0673 - val_mse: 0.8524\n",
      "Epoch 53/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 0.8951 - val_loss: 0.0687 - val_mse: 0.8403\n",
      "Epoch 54/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 0.9257 - val_loss: 0.0682 - val_mse: 0.8246\n",
      "Epoch 55/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0747 - mse: 1.0241 - val_loss: 0.0671 - val_mse: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0752 - mse: 0.9120 - val_loss: 0.0677 - val_mse: 0.8537\n",
      "Epoch 57/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 0.9103 - val_loss: 0.0679 - val_mse: 0.8433\n",
      "Epoch 58/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0760 - mse: 0.9409 - val_loss: 0.0678 - val_mse: 0.8659\n",
      "Epoch 59/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 0.9397 - val_loss: 0.0672 - val_mse: 0.8628\n",
      "Epoch 60/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0741 - mse: 0.8919\n",
      "Epoch 00060: saving model to Regression_Model/msle.linear-0060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0746 - mse: 0.8959 - val_loss: 0.0668 - val_mse: 0.8449\n",
      "Epoch 61/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 0.9414 - val_loss: 0.0701 - val_mse: 0.8301\n",
      "Epoch 62/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0753 - mse: 0.9152 - val_loss: 0.0669 - val_mse: 0.8264\n",
      "Epoch 63/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0742 - mse: 0.9203 - val_loss: 0.0688 - val_mse: 0.8833\n",
      "Epoch 64/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0721 - mse: 0.8889 - val_loss: 0.0664 - val_mse: 0.8215\n",
      "Epoch 65/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0735 - mse: 0.9129 - val_loss: 0.0668 - val_mse: 0.8553\n",
      "Epoch 66/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0743 - mse: 0.8888 - val_loss: 0.0661 - val_mse: 0.8238\n",
      "Epoch 67/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0749 - mse: 0.8989 - val_loss: 0.0663 - val_mse: 0.8529\n",
      "Epoch 68/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0745 - mse: 0.9456 - val_loss: 0.0677 - val_mse: 0.8067\n",
      "Epoch 69/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0732 - mse: 0.8983 - val_loss: 0.0663 - val_mse: 0.8450\n",
      "Epoch 70/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0735 - mse: 0.8923\n",
      "Epoch 00070: saving model to Regression_Model/msle.linear-0070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0736 - mse: 0.8933 - val_loss: 0.0662 - val_mse: 0.8050\n",
      "Epoch 71/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0742 - mse: 0.9081 - val_loss: 0.0664 - val_mse: 0.8418\n",
      "Epoch 72/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0743 - mse: 0.8901 - val_loss: 0.0683 - val_mse: 0.8826\n",
      "Epoch 73/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0735 - mse: 0.8869 - val_loss: 0.0662 - val_mse: 0.8396\n",
      "Epoch 74/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0730 - mse: 0.8794 - val_loss: 0.0657 - val_mse: 0.8371\n",
      "Epoch 75/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0737 - mse: 0.9410 - val_loss: 0.0658 - val_mse: 0.8162\n",
      "Epoch 76/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0725 - mse: 0.8948 - val_loss: 0.0665 - val_mse: 0.8537\n",
      "Epoch 77/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0730 - mse: 0.9091 - val_loss: 0.0649 - val_mse: 0.8333\n",
      "Epoch 78/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0734 - mse: 0.8856 - val_loss: 0.0652 - val_mse: 0.8445\n",
      "Epoch 79/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0726 - mse: 0.8869 - val_loss: 0.0652 - val_mse: 0.8327\n",
      "Epoch 80/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0744 - mse: 0.8915\n",
      "Epoch 00080: saving model to Regression_Model/msle.linear-0080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0743 - mse: 0.8936 - val_loss: 0.0673 - val_mse: 0.8747\n",
      "Epoch 81/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0744 - mse: 0.9096 - val_loss: 0.0648 - val_mse: 0.8170\n",
      "Epoch 82/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0719 - mse: 0.8660 - val_loss: 0.0644 - val_mse: 0.8178\n",
      "Epoch 83/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0720 - mse: 0.8789 - val_loss: 0.0654 - val_mse: 0.8021\n",
      "Epoch 84/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0721 - mse: 0.8653 - val_loss: 0.0691 - val_mse: 0.8881\n",
      "Epoch 85/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0727 - mse: 0.8796 - val_loss: 0.0655 - val_mse: 0.8161\n",
      "Epoch 86/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0724 - mse: 0.8626 - val_loss: 0.0688 - val_mse: 0.7976\n",
      "Epoch 87/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0728 - mse: 0.8841 - val_loss: 0.0644 - val_mse: 0.8213\n",
      "Epoch 88/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0709 - mse: 0.8601 - val_loss: 0.0649 - val_mse: 0.8312\n",
      "Epoch 89/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0724 - mse: 0.8689 - val_loss: 0.0659 - val_mse: 0.8543\n",
      "Epoch 90/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0719 - mse: 0.8933\n",
      "Epoch 00090: saving model to Regression_Model/msle.linear-0090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0720 - mse: 0.8938 - val_loss: 0.0647 - val_mse: 0.8351\n",
      "Epoch 91/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8739 - val_loss: 0.0653 - val_mse: 0.8439\n",
      "Epoch 92/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0717 - mse: 0.8646 - val_loss: 0.0642 - val_mse: 0.8287\n",
      "Epoch 93/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0720 - mse: 0.8658 - val_loss: 0.0649 - val_mse: 0.8196\n",
      "Epoch 94/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8608 - val_loss: 0.0656 - val_mse: 0.8461\n",
      "Epoch 95/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0722 - mse: 0.8685 - val_loss: 0.0639 - val_mse: 0.8228\n",
      "Epoch 96/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0716 - mse: 0.8651 - val_loss: 0.0649 - val_mse: 0.8286\n",
      "Epoch 97/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0723 - mse: 0.8700 - val_loss: 0.0647 - val_mse: 0.8325\n",
      "Epoch 98/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8657 - val_loss: 0.0642 - val_mse: 0.8259\n",
      "Epoch 99/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8574 - val_loss: 0.0640 - val_mse: 0.8283\n",
      "Epoch 100/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0713 - mse: 0.8581\n",
      "Epoch 00100: saving model to Regression_Model/msle.linear-0100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8587 - val_loss: 0.0646 - val_mse: 0.8379\n",
      "Epoch 101/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8652 - val_loss: 0.0645 - val_mse: 0.8332\n",
      "Epoch 102/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0707 - mse: 0.8636 - val_loss: 0.0662 - val_mse: 0.8128\n",
      "Epoch 103/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8807 - val_loss: 0.0644 - val_mse: 0.8415\n",
      "Epoch 104/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0717 - mse: 0.8721 - val_loss: 0.0646 - val_mse: 0.8384\n",
      "Epoch 105/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0716 - mse: 0.8568 - val_loss: 0.0675 - val_mse: 0.8729\n",
      "Epoch 106/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8614 - val_loss: 0.0658 - val_mse: 0.8089\n",
      "Epoch 107/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8689 - val_loss: 0.0644 - val_mse: 0.8141\n",
      "Epoch 108/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0717 - mse: 0.8660 - val_loss: 0.0645 - val_mse: 0.8353\n",
      "Epoch 109/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0720 - mse: 0.8628 - val_loss: 0.0651 - val_mse: 0.8132\n",
      "Epoch 110/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0710 - mse: 0.8704\n",
      "Epoch 00110: saving model to Regression_Model/msle.linear-0110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0709 - mse: 0.8713 - val_loss: 0.0634 - val_mse: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8599 - val_loss: 0.0650 - val_mse: 0.8014\n",
      "Epoch 112/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0717 - mse: 0.8665 - val_loss: 0.0640 - val_mse: 0.8358\n",
      "Epoch 113/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8541 - val_loss: 0.0667 - val_mse: 0.7922\n",
      "Epoch 114/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0722 - mse: 0.8696 - val_loss: 0.0674 - val_mse: 0.8181\n",
      "Epoch 115/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0707 - mse: 0.8505 - val_loss: 0.0649 - val_mse: 0.8145\n",
      "Epoch 116/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0714 - mse: 0.8733 - val_loss: 0.0654 - val_mse: 0.8122\n",
      "Epoch 117/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0716 - mse: 0.8586 - val_loss: 0.0655 - val_mse: 0.8496\n",
      "Epoch 118/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8752 - val_loss: 0.0630 - val_mse: 0.8089\n",
      "Epoch 119/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0707 - mse: 0.8554 - val_loss: 0.0658 - val_mse: 0.8501\n",
      "Epoch 120/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0711 - mse: 0.8648\n",
      "Epoch 00120: saving model to Regression_Model/msle.linear-0120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8650 - val_loss: 0.0649 - val_mse: 0.8016\n",
      "Epoch 121/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0725 - mse: 0.8712 - val_loss: 0.0647 - val_mse: 0.8409\n",
      "Epoch 122/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8714 - val_loss: 0.0652 - val_mse: 0.7993\n",
      "Epoch 123/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8583 - val_loss: 0.0641 - val_mse: 0.8178\n",
      "Epoch 124/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0709 - mse: 0.8588 - val_loss: 0.0632 - val_mse: 0.7986\n",
      "Epoch 125/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0715 - mse: 0.8562 - val_loss: 0.0637 - val_mse: 0.8274\n",
      "Epoch 126/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8581 - val_loss: 0.0639 - val_mse: 0.7997\n",
      "Epoch 127/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8516 - val_loss: 0.0630 - val_mse: 0.8091\n",
      "Epoch 128/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8578 - val_loss: 0.0656 - val_mse: 0.8189\n",
      "Epoch 129/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8554 - val_loss: 0.0645 - val_mse: 0.8105\n",
      "Epoch 130/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0705 - mse: 0.8559\n",
      "Epoch 00130: saving model to Regression_Model/msle.linear-0130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8533 - val_loss: 0.0659 - val_mse: 0.7925\n",
      "Epoch 131/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8481 - val_loss: 0.0636 - val_mse: 0.8187\n",
      "Epoch 132/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8590 - val_loss: 0.0628 - val_mse: 0.8020\n",
      "Epoch 133/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8520 - val_loss: 0.0630 - val_mse: 0.8076\n",
      "Epoch 134/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8458 - val_loss: 0.0634 - val_mse: 0.8264\n",
      "Epoch 135/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0705 - mse: 0.8609 - val_loss: 0.0654 - val_mse: 0.8035\n",
      "Epoch 136/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8566 - val_loss: 0.0632 - val_mse: 0.8121\n",
      "Epoch 137/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8610 - val_loss: 0.0637 - val_mse: 0.8333\n",
      "Epoch 138/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8543 - val_loss: 0.0632 - val_mse: 0.8156\n",
      "Epoch 139/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8505 - val_loss: 0.0630 - val_mse: 0.8079\n",
      "Epoch 140/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0693 - mse: 0.8513\n",
      "Epoch 00140: saving model to Regression_Model/msle.linear-0140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8502 - val_loss: 0.0626 - val_mse: 0.8021\n",
      "Epoch 141/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8554 - val_loss: 0.0653 - val_mse: 0.8489\n",
      "Epoch 142/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8671 - val_loss: 0.0632 - val_mse: 0.8291\n",
      "Epoch 143/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8565 - val_loss: 0.0639 - val_mse: 0.7890\n",
      "Epoch 144/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8386 - val_loss: 0.0623 - val_mse: 0.7991\n",
      "Epoch 145/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0692 - mse: 0.8447 - val_loss: 0.0630 - val_mse: 0.8060\n",
      "Epoch 146/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8444 - val_loss: 0.0629 - val_mse: 0.8056\n",
      "Epoch 147/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8451 - val_loss: 0.0633 - val_mse: 0.7890\n",
      "Epoch 148/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0707 - mse: 0.8581 - val_loss: 0.0625 - val_mse: 0.8171\n",
      "Epoch 149/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8533 - val_loss: 0.0673 - val_mse: 0.8509\n",
      "Epoch 150/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0717 - mse: 0.8659\n",
      "Epoch 00150: saving model to Regression_Model/msle.linear-0150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0719 - mse: 0.8678 - val_loss: 0.0658 - val_mse: 0.8446\n",
      "Epoch 151/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8621 - val_loss: 0.0647 - val_mse: 0.8278\n",
      "Epoch 152/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8604 - val_loss: 0.0646 - val_mse: 0.8141\n",
      "Epoch 153/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0723 - mse: 0.8692 - val_loss: 0.0646 - val_mse: 0.8380\n",
      "Epoch 154/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0718 - mse: 0.8934 - val_loss: 0.0646 - val_mse: 0.8221\n",
      "Epoch 155/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8542 - val_loss: 0.0654 - val_mse: 0.8359\n",
      "Epoch 156/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0718 - mse: 0.8702 - val_loss: 0.0637 - val_mse: 0.8189\n",
      "Epoch 157/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0709 - mse: 0.8898 - val_loss: 0.0634 - val_mse: 0.8237\n",
      "Epoch 158/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0719 - mse: 0.8765 - val_loss: 0.0667 - val_mse: 0.8201\n",
      "Epoch 159/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0719 - mse: 0.8759 - val_loss: 0.0641 - val_mse: 0.8344\n",
      "Epoch 160/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0715 - mse: 0.8674\n",
      "Epoch 00160: saving model to Regression_Model/msle.linear-0160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8671 - val_loss: 0.0651 - val_mse: 0.8114\n",
      "Epoch 161/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8576 - val_loss: 0.0637 - val_mse: 0.8254\n",
      "Epoch 162/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0715 - mse: 0.8563 - val_loss: 0.0646 - val_mse: 0.7982\n",
      "Epoch 163/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0732 - mse: 0.8710 - val_loss: 0.0642 - val_mse: 0.8396\n",
      "Epoch 164/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8662 - val_loss: 0.0650 - val_mse: 0.8509\n",
      "Epoch 165/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0719 - mse: 0.8658 - val_loss: 0.0636 - val_mse: 0.8117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0718 - mse: 0.8918 - val_loss: 0.0642 - val_mse: 0.8274\n",
      "Epoch 167/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0715 - mse: 0.8604 - val_loss: 0.0646 - val_mse: 0.8438\n",
      "Epoch 168/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0705 - mse: 0.8519 - val_loss: 0.0635 - val_mse: 0.8045\n",
      "Epoch 169/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0707 - mse: 0.8643 - val_loss: 0.0642 - val_mse: 0.8310\n",
      "Epoch 170/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0715 - mse: 0.8653\n",
      "Epoch 00170: saving model to Regression_Model/msle.linear-0170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8656 - val_loss: 0.0640 - val_mse: 0.8280\n",
      "Epoch 171/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8672 - val_loss: 0.0633 - val_mse: 0.8187\n",
      "Epoch 172/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8871 - val_loss: 0.0630 - val_mse: 0.8281\n",
      "Epoch 173/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8588 - val_loss: 0.0628 - val_mse: 0.8173\n",
      "Epoch 174/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8958 - val_loss: 0.0628 - val_mse: 0.8074\n",
      "Epoch 175/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8563 - val_loss: 0.0636 - val_mse: 0.8127\n",
      "Epoch 176/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8832 - val_loss: 0.0632 - val_mse: 0.8234\n",
      "Epoch 177/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8706 - val_loss: 0.0648 - val_mse: 0.8554\n",
      "Epoch 178/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0705 - mse: 0.8561 - val_loss: 0.0629 - val_mse: 0.8155\n",
      "Epoch 179/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0698 - mse: 0.8636 - val_loss: 0.0656 - val_mse: 0.8610\n",
      "Epoch 180/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0715 - mse: 0.8814\n",
      "Epoch 00180: saving model to Regression_Model/msle.linear-0180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8813 - val_loss: 0.0635 - val_mse: 0.8048\n",
      "Epoch 181/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8597 - val_loss: 0.0634 - val_mse: 0.8371\n",
      "Epoch 182/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0715 - mse: 0.8702 - val_loss: 0.0640 - val_mse: 0.8027\n",
      "Epoch 183/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8553 - val_loss: 0.0627 - val_mse: 0.8228\n",
      "Epoch 184/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8850 - val_loss: 0.0633 - val_mse: 0.8101\n",
      "Epoch 185/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0705 - mse: 0.8499 - val_loss: 0.0639 - val_mse: 0.8029\n",
      "Epoch 186/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8511 - val_loss: 0.0626 - val_mse: 0.8195\n",
      "Epoch 187/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0718 - mse: 0.8692 - val_loss: 0.0703 - val_mse: 0.8353\n",
      "Epoch 188/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8620 - val_loss: 0.0624 - val_mse: 0.8076\n",
      "Epoch 189/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8594 - val_loss: 0.0641 - val_mse: 0.8445\n",
      "Epoch 190/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0704 - mse: 0.8656\n",
      "Epoch 00190: saving model to Regression_Model/msle.linear-0190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8619 - val_loss: 0.0629 - val_mse: 0.7993\n",
      "Epoch 191/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8483 - val_loss: 0.0622 - val_mse: 0.8154\n",
      "Epoch 192/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8455 - val_loss: 0.0628 - val_mse: 0.8032\n",
      "Epoch 193/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8604 - val_loss: 0.0631 - val_mse: 0.8399\n",
      "Epoch 194/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8701 - val_loss: 0.0626 - val_mse: 0.8079\n",
      "Epoch 195/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8646 - val_loss: 0.0628 - val_mse: 0.7960\n",
      "Epoch 196/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8503 - val_loss: 0.0623 - val_mse: 0.8185\n",
      "Epoch 197/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0690 - mse: 0.8551 - val_loss: 0.0622 - val_mse: 0.8084\n",
      "Epoch 198/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0701 - mse: 0.8490 - val_loss: 0.0620 - val_mse: 0.8130\n",
      "Epoch 199/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8513 - val_loss: 0.0626 - val_mse: 0.8091\n",
      "Epoch 200/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0706 - mse: 0.8741\n",
      "Epoch 00200: saving model to Regression_Model/msle.linear-0200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8742 - val_loss: 0.0624 - val_mse: 0.8094\n",
      "Epoch 201/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0705 - mse: 0.8557 - val_loss: 0.0628 - val_mse: 0.8313\n",
      "Epoch 202/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0690 - mse: 0.8560 - val_loss: 0.0621 - val_mse: 0.8088\n",
      "Epoch 203/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0698 - mse: 0.8622 - val_loss: 0.0636 - val_mse: 0.8046\n",
      "Epoch 204/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8606 - val_loss: 0.0623 - val_mse: 0.8124\n",
      "Epoch 205/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8522 - val_loss: 0.0628 - val_mse: 0.8206\n",
      "Epoch 206/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8552 - val_loss: 0.0624 - val_mse: 0.8221\n",
      "Epoch 207/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8600 - val_loss: 0.0626 - val_mse: 0.8253\n",
      "Epoch 208/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8542 - val_loss: 0.0647 - val_mse: 0.7928\n",
      "Epoch 209/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8553 - val_loss: 0.0623 - val_mse: 0.8219\n",
      "Epoch 210/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0692 - mse: 0.8540\n",
      "Epoch 00210: saving model to Regression_Model/msle.linear-0210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8573 - val_loss: 0.0644 - val_mse: 0.8133\n",
      "Epoch 211/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8536 - val_loss: 0.0619 - val_mse: 0.8067\n",
      "Epoch 212/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8475 - val_loss: 0.0622 - val_mse: 0.8214\n",
      "Epoch 213/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8574 - val_loss: 0.0636 - val_mse: 0.8439\n",
      "Epoch 214/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8528 - val_loss: 0.0621 - val_mse: 0.8141\n",
      "Epoch 215/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8443 - val_loss: 0.0620 - val_mse: 0.8148\n",
      "Epoch 216/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8465 - val_loss: 0.0619 - val_mse: 0.8104\n",
      "Epoch 217/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8644 - val_loss: 0.0637 - val_mse: 0.7960\n",
      "Epoch 218/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0701 - mse: 0.8516 - val_loss: 0.0637 - val_mse: 0.7832\n",
      "Epoch 219/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8659 - val_loss: 0.0634 - val_mse: 0.7987\n",
      "Epoch 220/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0688 - mse: 0.8469\n",
      "Epoch 00220: saving model to Regression_Model/msle.linear-0220.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0687 - mse: 0.8460 - val_loss: 0.0621 - val_mse: 0.8067\n",
      "Epoch 221/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8447 - val_loss: 0.0618 - val_mse: 0.8068\n",
      "Epoch 222/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8626 - val_loss: 0.0622 - val_mse: 0.8149\n",
      "Epoch 223/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8547 - val_loss: 0.0626 - val_mse: 0.8282\n",
      "Epoch 224/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8750 - val_loss: 0.0628 - val_mse: 0.8187\n",
      "Epoch 225/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8435 - val_loss: 0.0620 - val_mse: 0.8205\n",
      "Epoch 226/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8388 - val_loss: 0.0622 - val_mse: 0.8152\n",
      "Epoch 227/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8570 - val_loss: 0.0624 - val_mse: 0.8108\n",
      "Epoch 228/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8515 - val_loss: 0.0645 - val_mse: 0.7869\n",
      "Epoch 229/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8310 - val_loss: 0.0618 - val_mse: 0.8042\n",
      "Epoch 230/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0701 - mse: 0.8664\n",
      "Epoch 00230: saving model to Regression_Model/msle.linear-0230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8610 - val_loss: 0.0624 - val_mse: 0.8327\n",
      "Epoch 231/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8489 - val_loss: 0.0625 - val_mse: 0.8194\n",
      "Epoch 232/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8516 - val_loss: 0.0634 - val_mse: 0.8441\n",
      "Epoch 233/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8808 - val_loss: 0.0632 - val_mse: 0.7948\n",
      "Epoch 234/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8396 - val_loss: 0.0622 - val_mse: 0.8192\n",
      "Epoch 235/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0691 - mse: 0.8467 - val_loss: 0.0632 - val_mse: 0.8409\n",
      "Epoch 236/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0701 - mse: 0.8518 - val_loss: 0.0614 - val_mse: 0.8004\n",
      "Epoch 237/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8446 - val_loss: 0.0620 - val_mse: 0.7938\n",
      "Epoch 238/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8579 - val_loss: 0.0620 - val_mse: 0.8140\n",
      "Epoch 239/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8447 - val_loss: 0.0614 - val_mse: 0.8023\n",
      "Epoch 240/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0686 - mse: 0.8433\n",
      "Epoch 00240: saving model to Regression_Model/msle.linear-0240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8461 - val_loss: 0.0644 - val_mse: 0.8033\n",
      "Epoch 241/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8567 - val_loss: 0.0616 - val_mse: 0.8123\n",
      "Epoch 242/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8433 - val_loss: 0.0619 - val_mse: 0.8059\n",
      "Epoch 243/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8457 - val_loss: 0.0624 - val_mse: 0.8305\n",
      "Epoch 244/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0694 - mse: 0.8607 - val_loss: 0.0618 - val_mse: 0.8226\n",
      "Epoch 245/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8444 - val_loss: 0.0620 - val_mse: 0.8264\n",
      "Epoch 246/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8450 - val_loss: 0.0618 - val_mse: 0.7915\n",
      "Epoch 247/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0691 - mse: 0.8468 - val_loss: 0.0632 - val_mse: 0.7973\n",
      "Epoch 248/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8564 - val_loss: 0.0627 - val_mse: 0.7853\n",
      "Epoch 249/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0689 - mse: 0.8453 - val_loss: 0.0615 - val_mse: 0.8024\n",
      "Epoch 250/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0700 - mse: 0.8554\n",
      "Epoch 00250: saving model to Regression_Model/msle.linear-0250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8562 - val_loss: 0.0610 - val_mse: 0.7927\n",
      "Epoch 251/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8416 - val_loss: 0.0611 - val_mse: 0.8085\n",
      "Epoch 252/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8509 - val_loss: 0.0624 - val_mse: 0.8257\n",
      "Epoch 253/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8468 - val_loss: 0.0614 - val_mse: 0.7952\n",
      "Epoch 254/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8504 - val_loss: 0.0627 - val_mse: 0.8186\n",
      "Epoch 255/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8449 - val_loss: 0.0617 - val_mse: 0.8191\n",
      "Epoch 256/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8452 - val_loss: 0.0623 - val_mse: 0.8275\n",
      "Epoch 257/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8448 - val_loss: 0.0623 - val_mse: 0.8148\n",
      "Epoch 258/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8495 - val_loss: 0.0615 - val_mse: 0.8153\n",
      "Epoch 259/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8378 - val_loss: 0.0617 - val_mse: 0.8051\n",
      "Epoch 260/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0683 - mse: 0.8445\n",
      "Epoch 00260: saving model to Regression_Model/msle.linear-0260.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0683 - mse: 0.8440 - val_loss: 0.0621 - val_mse: 0.7915\n",
      "Epoch 261/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8560 - val_loss: 0.0615 - val_mse: 0.8183\n",
      "Epoch 262/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8573 - val_loss: 0.0615 - val_mse: 0.8187\n",
      "Epoch 263/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8481 - val_loss: 0.0631 - val_mse: 0.7793\n",
      "Epoch 264/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8556 - val_loss: 0.0612 - val_mse: 0.8086\n",
      "Epoch 265/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0690 - mse: 0.8397 - val_loss: 0.0634 - val_mse: 0.8103\n",
      "Epoch 266/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8483 - val_loss: 0.0614 - val_mse: 0.8084\n",
      "Epoch 267/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8481 - val_loss: 0.0619 - val_mse: 0.8257\n",
      "Epoch 268/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0691 - mse: 0.8550 - val_loss: 0.0614 - val_mse: 0.8113\n",
      "Epoch 269/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8505 - val_loss: 0.0612 - val_mse: 0.8028\n",
      "Epoch 270/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0687 - mse: 0.8471\n",
      "Epoch 00270: saving model to Regression_Model/msle.linear-0270.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0688 - mse: 0.8465 - val_loss: 0.0612 - val_mse: 0.8044\n",
      "Epoch 271/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8500 - val_loss: 0.0616 - val_mse: 0.8095\n",
      "Epoch 272/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8339 - val_loss: 0.0616 - val_mse: 0.8228\n",
      "Epoch 273/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0698 - mse: 0.8670 - val_loss: 0.0619 - val_mse: 0.7954\n",
      "Epoch 274/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0687 - mse: 0.8517 - val_loss: 0.0609 - val_mse: 0.7996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8473 - val_loss: 0.0614 - val_mse: 0.8178\n",
      "Epoch 276/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8407 - val_loss: 0.0620 - val_mse: 0.8137\n",
      "Epoch 277/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8566 - val_loss: 0.0610 - val_mse: 0.8068\n",
      "Epoch 278/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8491 - val_loss: 0.0619 - val_mse: 0.8092\n",
      "Epoch 279/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8535 - val_loss: 0.0623 - val_mse: 0.8352\n",
      "Epoch 280/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0690 - mse: 0.8574\n",
      "Epoch 00280: saving model to Regression_Model/msle.linear-0280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8525 - val_loss: 0.0610 - val_mse: 0.8050\n",
      "Epoch 281/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8478 - val_loss: 0.0614 - val_mse: 0.8192\n",
      "Epoch 282/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8512 - val_loss: 0.0616 - val_mse: 0.8239\n",
      "Epoch 283/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8539 - val_loss: 0.0626 - val_mse: 0.8349\n",
      "Epoch 284/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8481 - val_loss: 0.0608 - val_mse: 0.8052\n",
      "Epoch 285/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8358 - val_loss: 0.0612 - val_mse: 0.8072\n",
      "Epoch 286/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8456 - val_loss: 0.0615 - val_mse: 0.7878\n",
      "Epoch 287/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8402 - val_loss: 0.0618 - val_mse: 0.8224\n",
      "Epoch 288/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0681 - mse: 0.8419 - val_loss: 0.0612 - val_mse: 0.8151\n",
      "Epoch 289/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0686 - mse: 0.8513 - val_loss: 0.0614 - val_mse: 0.8257\n",
      "Epoch 290/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0683 - mse: 0.8439\n",
      "Epoch 00290: saving model to Regression_Model/msle.linear-0290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8463 - val_loss: 0.0620 - val_mse: 0.8001\n",
      "Epoch 291/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8436 - val_loss: 0.0618 - val_mse: 0.8258\n",
      "Epoch 292/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8478 - val_loss: 0.0622 - val_mse: 0.8361\n",
      "Epoch 293/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8389 - val_loss: 0.0616 - val_mse: 0.8188\n",
      "Epoch 294/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8482 - val_loss: 0.0613 - val_mse: 0.8180\n",
      "Epoch 295/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8465 - val_loss: 0.0631 - val_mse: 0.8420\n",
      "Epoch 296/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8530 - val_loss: 0.0612 - val_mse: 0.8031\n",
      "Epoch 297/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0690 - mse: 0.8531 - val_loss: 0.0621 - val_mse: 0.8266\n",
      "Epoch 298/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8475 - val_loss: 0.0613 - val_mse: 0.7955\n",
      "Epoch 299/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8417 - val_loss: 0.0614 - val_mse: 0.8205\n",
      "Epoch 300/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0683 - mse: 0.8459\n",
      "Epoch 00300: saving model to Regression_Model/msle.linear-0300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8503 - val_loss: 0.0608 - val_mse: 0.7994\n",
      "Epoch 301/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8546 - val_loss: 0.0612 - val_mse: 0.8198\n",
      "Epoch 302/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8451 - val_loss: 0.0642 - val_mse: 0.8607\n",
      "Epoch 303/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8624 - val_loss: 0.0607 - val_mse: 0.8037\n",
      "Epoch 304/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8390 - val_loss: 0.0617 - val_mse: 0.8287\n",
      "Epoch 305/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8451 - val_loss: 0.0618 - val_mse: 0.8108\n",
      "Epoch 306/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8401 - val_loss: 0.0617 - val_mse: 0.8264\n",
      "Epoch 307/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8474 - val_loss: 0.0615 - val_mse: 0.8254\n",
      "Epoch 308/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8435 - val_loss: 0.0618 - val_mse: 0.8040\n",
      "Epoch 309/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8446 - val_loss: 0.0617 - val_mse: 0.7858\n",
      "Epoch 310/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0688 - mse: 0.8390\n",
      "Epoch 00310: saving model to Regression_Model/msle.linear-0310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8421 - val_loss: 0.0609 - val_mse: 0.8102\n",
      "Epoch 311/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8365 - val_loss: 0.0611 - val_mse: 0.8143\n",
      "Epoch 312/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8439 - val_loss: 0.0609 - val_mse: 0.8044\n",
      "Epoch 313/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8594 - val_loss: 0.0609 - val_mse: 0.7917\n",
      "Epoch 314/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8398 - val_loss: 0.0613 - val_mse: 0.8188\n",
      "Epoch 315/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8392 - val_loss: 0.0624 - val_mse: 0.8341\n",
      "Epoch 316/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0691 - mse: 0.8554 - val_loss: 0.0605 - val_mse: 0.7937\n",
      "Epoch 317/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8361 - val_loss: 0.0613 - val_mse: 0.8173\n",
      "Epoch 318/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8381 - val_loss: 0.0610 - val_mse: 0.8116\n",
      "Epoch 319/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8334 - val_loss: 0.0607 - val_mse: 0.8050\n",
      "Epoch 320/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0685 - mse: 0.8442\n",
      "Epoch 00320: saving model to Regression_Model/msle.linear-0320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8422 - val_loss: 0.0607 - val_mse: 0.8081\n",
      "Epoch 321/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8315 - val_loss: 0.0608 - val_mse: 0.8120\n",
      "Epoch 322/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8428 - val_loss: 0.0615 - val_mse: 0.7812\n",
      "Epoch 323/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8404 - val_loss: 0.0618 - val_mse: 0.8040\n",
      "Epoch 324/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8393 - val_loss: 0.0634 - val_mse: 0.8466\n",
      "Epoch 325/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8489 - val_loss: 0.0608 - val_mse: 0.8106\n",
      "Epoch 326/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8411 - val_loss: 0.0606 - val_mse: 0.8118\n",
      "Epoch 327/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0680 - mse: 0.8383 - val_loss: 0.0612 - val_mse: 0.8163\n",
      "Epoch 328/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8507 - val_loss: 0.0611 - val_mse: 0.8205\n",
      "Epoch 329/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8428 - val_loss: 0.0610 - val_mse: 0.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8378\n",
      "Epoch 00330: saving model to Regression_Model/msle.linear-0330.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 0.0674 - mse: 0.8378 - val_loss: 0.0610 - val_mse: 0.8136\n",
      "Epoch 331/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8552 - val_loss: 0.0620 - val_mse: 0.8322\n",
      "Epoch 332/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8380 - val_loss: 0.0634 - val_mse: 0.7791\n",
      "Epoch 333/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8401 - val_loss: 0.0606 - val_mse: 0.8077\n",
      "Epoch 334/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8466 - val_loss: 0.0611 - val_mse: 0.8202\n",
      "Epoch 335/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8523 - val_loss: 0.0618 - val_mse: 0.8298\n",
      "Epoch 336/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8380 - val_loss: 0.0606 - val_mse: 0.7930\n",
      "Epoch 337/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8293 - val_loss: 0.0608 - val_mse: 0.8104\n",
      "Epoch 338/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8439 - val_loss: 0.0609 - val_mse: 0.7912\n",
      "Epoch 339/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8436 - val_loss: 0.0605 - val_mse: 0.8028\n",
      "Epoch 340/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0674 - mse: 0.8417\n",
      "Epoch 00340: saving model to Regression_Model/msle.linear-0340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8439 - val_loss: 0.0607 - val_mse: 0.7886\n",
      "Epoch 341/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8310 - val_loss: 0.0608 - val_mse: 0.8006\n",
      "Epoch 342/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8396 - val_loss: 0.0606 - val_mse: 0.8018\n",
      "Epoch 343/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8493 - val_loss: 0.0625 - val_mse: 0.8287\n",
      "Epoch 344/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8406 - val_loss: 0.0613 - val_mse: 0.8218\n",
      "Epoch 345/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8385 - val_loss: 0.0609 - val_mse: 0.7905\n",
      "Epoch 346/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8521 - val_loss: 0.0608 - val_mse: 0.8144\n",
      "Epoch 347/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8435 - val_loss: 0.0608 - val_mse: 0.7933\n",
      "Epoch 348/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8428 - val_loss: 0.0622 - val_mse: 0.8297\n",
      "Epoch 349/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8450 - val_loss: 0.0610 - val_mse: 0.7967\n",
      "Epoch 350/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0681 - mse: 0.8411\n",
      "Epoch 00350: saving model to Regression_Model/msle.linear-0350.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8417 - val_loss: 0.0604 - val_mse: 0.7917\n",
      "Epoch 351/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8321 - val_loss: 0.0620 - val_mse: 0.8295\n",
      "Epoch 352/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0669 - mse: 0.8379 - val_loss: 0.0608 - val_mse: 0.8128\n",
      "Epoch 353/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8417 - val_loss: 0.0606 - val_mse: 0.8085\n",
      "Epoch 354/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8511 - val_loss: 0.0609 - val_mse: 0.8134\n",
      "Epoch 355/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8230 - val_loss: 0.0603 - val_mse: 0.7992\n",
      "Epoch 356/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8293 - val_loss: 0.0606 - val_mse: 0.7963\n",
      "Epoch 357/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8385 - val_loss: 0.0604 - val_mse: 0.8103\n",
      "Epoch 358/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8375 - val_loss: 0.0611 - val_mse: 0.8219\n",
      "Epoch 359/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8362 - val_loss: 0.0607 - val_mse: 0.8137\n",
      "Epoch 360/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0675 - mse: 0.8469\n",
      "Epoch 00360: saving model to Regression_Model/msle.linear-0360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8467 - val_loss: 0.0609 - val_mse: 0.8210\n",
      "Epoch 361/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8422 - val_loss: 0.0607 - val_mse: 0.8165\n",
      "Epoch 362/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8297 - val_loss: 0.0606 - val_mse: 0.7966\n",
      "Epoch 363/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8422 - val_loss: 0.0602 - val_mse: 0.7955\n",
      "Epoch 364/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8275 - val_loss: 0.0605 - val_mse: 0.8073\n",
      "Epoch 365/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8380 - val_loss: 0.0607 - val_mse: 0.7897\n",
      "Epoch 366/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8385 - val_loss: 0.0610 - val_mse: 0.8227\n",
      "Epoch 367/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8395 - val_loss: 0.0636 - val_mse: 0.8046\n",
      "Epoch 368/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8641 - val_loss: 0.0619 - val_mse: 0.7914\n",
      "Epoch 369/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8377 - val_loss: 0.0609 - val_mse: 0.8184\n",
      "Epoch 370/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0674 - mse: 0.8404\n",
      "Epoch 00370: saving model to Regression_Model/msle.linear-0370.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8352 - val_loss: 0.0603 - val_mse: 0.8064\n",
      "Epoch 371/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8437 - val_loss: 0.0602 - val_mse: 0.8035\n",
      "Epoch 372/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8495 - val_loss: 0.0605 - val_mse: 0.7866\n",
      "Epoch 373/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8400 - val_loss: 0.0604 - val_mse: 0.8113\n",
      "Epoch 374/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8278 - val_loss: 0.0602 - val_mse: 0.8012\n",
      "Epoch 375/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0680 - mse: 0.8512 - val_loss: 0.0616 - val_mse: 0.8253\n",
      "Epoch 376/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8544 - val_loss: 0.0606 - val_mse: 0.7917\n",
      "Epoch 377/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8346 - val_loss: 0.0608 - val_mse: 0.8160\n",
      "Epoch 378/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8387 - val_loss: 0.0611 - val_mse: 0.8012\n",
      "Epoch 379/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8447 - val_loss: 0.0601 - val_mse: 0.8044\n",
      "Epoch 380/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0683 - mse: 0.8423\n",
      "Epoch 00380: saving model to Regression_Model/msle.linear-0380.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0680 - mse: 0.8428 - val_loss: 0.0604 - val_mse: 0.8105\n",
      "Epoch 381/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8350 - val_loss: 0.0604 - val_mse: 0.8070\n",
      "Epoch 382/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8408 - val_loss: 0.0609 - val_mse: 0.7973\n",
      "Epoch 383/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8346 - val_loss: 0.0610 - val_mse: 0.7896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8243 - val_loss: 0.0602 - val_mse: 0.7937\n",
      "Epoch 385/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8361 - val_loss: 0.0603 - val_mse: 0.8061\n",
      "Epoch 386/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8430 - val_loss: 0.0600 - val_mse: 0.8011\n",
      "Epoch 387/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8373 - val_loss: 0.0603 - val_mse: 0.8068\n",
      "Epoch 388/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8442 - val_loss: 0.0603 - val_mse: 0.7988\n",
      "Epoch 389/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8345 - val_loss: 0.0608 - val_mse: 0.8204\n",
      "Epoch 390/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0671 - mse: 0.8272\n",
      "Epoch 00390: saving model to Regression_Model/msle.linear-0390.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0670 - mse: 0.8320 - val_loss: 0.0616 - val_mse: 0.8230\n",
      "Epoch 391/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8318 - val_loss: 0.0609 - val_mse: 0.7893\n",
      "Epoch 392/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8371 - val_loss: 0.0629 - val_mse: 0.7774\n",
      "Epoch 393/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8407 - val_loss: 0.0610 - val_mse: 0.8192\n",
      "Epoch 394/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8369 - val_loss: 0.0603 - val_mse: 0.8130\n",
      "Epoch 395/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8362 - val_loss: 0.0603 - val_mse: 0.8050\n",
      "Epoch 396/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8400 - val_loss: 0.0605 - val_mse: 0.8116\n",
      "Epoch 397/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8337 - val_loss: 0.0601 - val_mse: 0.8022\n",
      "Epoch 398/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8341 - val_loss: 0.0600 - val_mse: 0.7945\n",
      "Epoch 399/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8354 - val_loss: 0.0602 - val_mse: 0.8083\n",
      "Epoch 400/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8393\n",
      "Epoch 00400: saving model to Regression_Model/msle.linear-0400.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8397 - val_loss: 0.0602 - val_mse: 0.7839\n",
      "Epoch 401/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8290 - val_loss: 0.0607 - val_mse: 0.8002\n",
      "Epoch 402/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8471 - val_loss: 0.0606 - val_mse: 0.8037\n",
      "Epoch 403/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8382 - val_loss: 0.0603 - val_mse: 0.8099\n",
      "Epoch 404/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8312 - val_loss: 0.0610 - val_mse: 0.8256\n",
      "Epoch 405/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8379 - val_loss: 0.0606 - val_mse: 0.7839\n",
      "Epoch 406/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8388 - val_loss: 0.0604 - val_mse: 0.8080\n",
      "Epoch 407/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8327 - val_loss: 0.0607 - val_mse: 0.8208\n",
      "Epoch 408/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8397 - val_loss: 0.0621 - val_mse: 0.8411\n",
      "Epoch 409/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8335 - val_loss: 0.0600 - val_mse: 0.7929\n",
      "Epoch 410/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0671 - mse: 0.8287\n",
      "Epoch 00410: saving model to Regression_Model/msle.linear-0410.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8287 - val_loss: 0.0615 - val_mse: 0.8261\n",
      "Epoch 411/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8347 - val_loss: 0.0605 - val_mse: 0.7895\n",
      "Epoch 412/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8348 - val_loss: 0.0599 - val_mse: 0.8021\n",
      "Epoch 413/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8240 - val_loss: 0.0601 - val_mse: 0.8079\n",
      "Epoch 414/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8287 - val_loss: 0.0601 - val_mse: 0.8077\n",
      "Epoch 415/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8438 - val_loss: 0.0607 - val_mse: 0.7842\n",
      "Epoch 416/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0671 - mse: 0.8463 - val_loss: 0.0599 - val_mse: 0.8067\n",
      "Epoch 417/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8449 - val_loss: 0.0605 - val_mse: 0.7915\n",
      "Epoch 418/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8241 - val_loss: 0.0604 - val_mse: 0.8156\n",
      "Epoch 419/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8397 - val_loss: 0.0604 - val_mse: 0.7857\n",
      "Epoch 420/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8477\n",
      "Epoch 00420: saving model to Regression_Model/msle.linear-0420.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0674 - mse: 0.8448 - val_loss: 0.0600 - val_mse: 0.7908\n",
      "Epoch 421/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8353 - val_loss: 0.0607 - val_mse: 0.7871\n",
      "Epoch 422/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8346 - val_loss: 0.0603 - val_mse: 0.8134\n",
      "Epoch 423/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8253 - val_loss: 0.0611 - val_mse: 0.7923\n",
      "Epoch 424/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8392 - val_loss: 0.0602 - val_mse: 0.8122\n",
      "Epoch 425/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8241 - val_loss: 0.0617 - val_mse: 0.8362\n",
      "Epoch 426/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8428 - val_loss: 0.0598 - val_mse: 0.7934\n",
      "Epoch 427/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8328 - val_loss: 0.0604 - val_mse: 0.8086\n",
      "Epoch 428/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8495 - val_loss: 0.0595 - val_mse: 0.7936\n",
      "Epoch 429/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8226 - val_loss: 0.0599 - val_mse: 0.7863\n",
      "Epoch 430/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0668 - mse: 0.8294\n",
      "Epoch 00430: saving model to Regression_Model/msle.linear-0430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8309 - val_loss: 0.0598 - val_mse: 0.8006\n",
      "Epoch 431/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8443 - val_loss: 0.0600 - val_mse: 0.7881\n",
      "Epoch 432/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0681 - mse: 0.8413 - val_loss: 0.0604 - val_mse: 0.8189\n",
      "Epoch 433/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8386 - val_loss: 0.0596 - val_mse: 0.7954\n",
      "Epoch 434/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8326 - val_loss: 0.0607 - val_mse: 0.8227\n",
      "Epoch 435/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8346 - val_loss: 0.0599 - val_mse: 0.8039\n",
      "Epoch 436/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8397 - val_loss: 0.0601 - val_mse: 0.7894\n",
      "Epoch 437/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8318 - val_loss: 0.0599 - val_mse: 0.8020\n",
      "Epoch 438/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8451 - val_loss: 0.0604 - val_mse: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8351 - val_loss: 0.0606 - val_mse: 0.8133\n",
      "Epoch 440/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8346\n",
      "Epoch 00440: saving model to Regression_Model/msle.linear-0440.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0675 - mse: 0.8348 - val_loss: 0.0602 - val_mse: 0.7978\n",
      "Epoch 441/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8390 - val_loss: 0.0603 - val_mse: 0.8114\n",
      "Epoch 442/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8286 - val_loss: 0.0597 - val_mse: 0.7927\n",
      "Epoch 443/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8296 - val_loss: 0.0601 - val_mse: 0.8111\n",
      "Epoch 444/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8369 - val_loss: 0.0604 - val_mse: 0.7851\n",
      "Epoch 445/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8461 - val_loss: 0.0600 - val_mse: 0.7973\n",
      "Epoch 446/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8390 - val_loss: 0.0602 - val_mse: 0.7953\n",
      "Epoch 447/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8421 - val_loss: 0.0599 - val_mse: 0.7999\n",
      "Epoch 448/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8390 - val_loss: 0.0597 - val_mse: 0.7954\n",
      "Epoch 449/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8346 - val_loss: 0.0607 - val_mse: 0.8183\n",
      "Epoch 450/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0665 - mse: 0.8281\n",
      "Epoch 00450: saving model to Regression_Model/msle.linear-0450.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0665 - mse: 0.8272 - val_loss: 0.0600 - val_mse: 0.7942\n",
      "Epoch 451/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8372 - val_loss: 0.0602 - val_mse: 0.7963\n",
      "Epoch 452/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8370 - val_loss: 0.0604 - val_mse: 0.8159\n",
      "Epoch 453/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8414 - val_loss: 0.0603 - val_mse: 0.8125\n",
      "Epoch 454/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8314 - val_loss: 0.0606 - val_mse: 0.8233\n",
      "Epoch 455/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8320 - val_loss: 0.0609 - val_mse: 0.7877\n",
      "Epoch 456/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8365 - val_loss: 0.0603 - val_mse: 0.8134\n",
      "Epoch 457/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8264 - val_loss: 0.0597 - val_mse: 0.8061\n",
      "Epoch 458/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8437 - val_loss: 0.0606 - val_mse: 0.8218\n",
      "Epoch 459/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8325 - val_loss: 0.0597 - val_mse: 0.8049\n",
      "Epoch 460/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0675 - mse: 0.8442\n",
      "Epoch 00460: saving model to Regression_Model/msle.linear-0460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8408 - val_loss: 0.0624 - val_mse: 0.8466\n",
      "Epoch 461/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8563 - val_loss: 0.0605 - val_mse: 0.8120\n",
      "Epoch 462/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8260 - val_loss: 0.0601 - val_mse: 0.8083\n",
      "Epoch 463/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8372 - val_loss: 0.0598 - val_mse: 0.8045\n",
      "Epoch 464/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8398 - val_loss: 0.0617 - val_mse: 0.8365\n",
      "Epoch 465/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8387 - val_loss: 0.0605 - val_mse: 0.8136\n",
      "Epoch 466/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8377 - val_loss: 0.0602 - val_mse: 0.8116\n",
      "Epoch 467/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8315 - val_loss: 0.0596 - val_mse: 0.7874\n",
      "Epoch 468/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8482 - val_loss: 0.0614 - val_mse: 0.8320\n",
      "Epoch 469/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8311 - val_loss: 0.0603 - val_mse: 0.7982\n",
      "Epoch 470/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8307\n",
      "Epoch 00470: saving model to Regression_Model/msle.linear-0470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8320 - val_loss: 0.0606 - val_mse: 0.8209\n",
      "Epoch 471/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8432 - val_loss: 0.0600 - val_mse: 0.8026\n",
      "Epoch 472/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8423 - val_loss: 0.0603 - val_mse: 0.8083\n",
      "Epoch 473/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8285 - val_loss: 0.0598 - val_mse: 0.7925\n",
      "Epoch 474/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8227 - val_loss: 0.0596 - val_mse: 0.7918\n",
      "Epoch 475/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8298 - val_loss: 0.0596 - val_mse: 0.8004\n",
      "Epoch 476/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8296 - val_loss: 0.0611 - val_mse: 0.7800\n",
      "Epoch 477/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8263 - val_loss: 0.0596 - val_mse: 0.8008\n",
      "Epoch 478/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8273 - val_loss: 0.0602 - val_mse: 0.8061\n",
      "Epoch 479/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8278 - val_loss: 0.0596 - val_mse: 0.8022\n",
      "Epoch 480/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0665 - mse: 0.8318\n",
      "Epoch 00480: saving model to Regression_Model/msle.linear-0480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8315 - val_loss: 0.0609 - val_mse: 0.8232\n",
      "Epoch 481/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8441 - val_loss: 0.0606 - val_mse: 0.7836\n",
      "Epoch 482/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8349 - val_loss: 0.0602 - val_mse: 0.8134\n",
      "Epoch 483/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8449 - val_loss: 0.0613 - val_mse: 0.8181\n",
      "Epoch 484/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8209 - val_loss: 0.0598 - val_mse: 0.8055\n",
      "Epoch 485/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8367 - val_loss: 0.0601 - val_mse: 0.7781\n",
      "Epoch 486/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8329 - val_loss: 0.0597 - val_mse: 0.8055\n",
      "Epoch 487/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8327 - val_loss: 0.0603 - val_mse: 0.7897\n",
      "Epoch 488/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8369 - val_loss: 0.0603 - val_mse: 0.8172\n",
      "Epoch 489/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8326 - val_loss: 0.0597 - val_mse: 0.7864\n",
      "Epoch 490/2000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.0673 - mse: 0.8359\n",
      "Epoch 00490: saving model to Regression_Model/msle.linear-0490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8348 - val_loss: 0.0614 - val_mse: 0.8337\n",
      "Epoch 491/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8460 - val_loss: 0.0604 - val_mse: 0.8184\n",
      "Epoch 492/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8492 - val_loss: 0.0600 - val_mse: 0.7943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8324 - val_loss: 0.0596 - val_mse: 0.8023\n",
      "Epoch 494/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8402 - val_loss: 0.0598 - val_mse: 0.8010\n",
      "Epoch 495/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8323 - val_loss: 0.0600 - val_mse: 0.8058\n",
      "Epoch 496/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8292 - val_loss: 0.0599 - val_mse: 0.8012\n",
      "Epoch 497/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8318 - val_loss: 0.0595 - val_mse: 0.7976\n",
      "Epoch 498/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8391 - val_loss: 0.0596 - val_mse: 0.7983\n",
      "Epoch 499/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8391 - val_loss: 0.0601 - val_mse: 0.8021\n",
      "Epoch 500/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0660 - mse: 0.8259\n",
      "Epoch 00500: saving model to Regression_Model/msle.linear-0500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8252 - val_loss: 0.0605 - val_mse: 0.7999\n",
      "Epoch 501/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8257 - val_loss: 0.0596 - val_mse: 0.7871\n",
      "Epoch 502/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8366 - val_loss: 0.0598 - val_mse: 0.8071\n",
      "Epoch 503/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8330 - val_loss: 0.0597 - val_mse: 0.7943\n",
      "Epoch 504/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8319 - val_loss: 0.0602 - val_mse: 0.7994\n",
      "Epoch 505/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8366 - val_loss: 0.0600 - val_mse: 0.7881\n",
      "Epoch 506/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8652 - val_loss: 0.0598 - val_mse: 0.8017\n",
      "Epoch 507/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0660 - mse: 0.8314 - val_loss: 0.0597 - val_mse: 0.8068\n",
      "Epoch 508/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8326 - val_loss: 0.0602 - val_mse: 0.7882\n",
      "Epoch 509/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8282 - val_loss: 0.0602 - val_mse: 0.8169\n",
      "Epoch 510/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0662 - mse: 0.8282\n",
      "Epoch 00510: saving model to Regression_Model/msle.linear-0510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8298 - val_loss: 0.0602 - val_mse: 0.8130\n",
      "Epoch 511/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8260 - val_loss: 0.0598 - val_mse: 0.7880\n",
      "Epoch 512/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8472 - val_loss: 0.0597 - val_mse: 0.8041\n",
      "Epoch 513/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8288 - val_loss: 0.0604 - val_mse: 0.8206\n",
      "Epoch 514/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8363 - val_loss: 0.0600 - val_mse: 0.8128\n",
      "Epoch 515/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8383 - val_loss: 0.0601 - val_mse: 0.7995\n",
      "Epoch 516/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8374 - val_loss: 0.0595 - val_mse: 0.8006\n",
      "Epoch 517/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8373 - val_loss: 0.0595 - val_mse: 0.7898\n",
      "Epoch 518/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8334 - val_loss: 0.0603 - val_mse: 0.8066\n",
      "Epoch 519/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8376 - val_loss: 0.0604 - val_mse: 0.7885\n",
      "Epoch 520/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0658 - mse: 0.8235\n",
      "Epoch 00520: saving model to Regression_Model/msle.linear-0520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8287 - val_loss: 0.0600 - val_mse: 0.8084\n",
      "Epoch 521/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8343 - val_loss: 0.0597 - val_mse: 0.8060\n",
      "Epoch 522/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8439 - val_loss: 0.0602 - val_mse: 0.8162\n",
      "Epoch 523/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8578 - val_loss: 0.0595 - val_mse: 0.7870\n",
      "Epoch 524/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8496 - val_loss: 0.0596 - val_mse: 0.8040\n",
      "Epoch 525/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8195 - val_loss: 0.0594 - val_mse: 0.8000\n",
      "Epoch 526/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8287 - val_loss: 0.0603 - val_mse: 0.8203\n",
      "Epoch 527/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8439 - val_loss: 0.0612 - val_mse: 0.7850\n",
      "Epoch 528/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8255 - val_loss: 0.0597 - val_mse: 0.8103\n",
      "Epoch 529/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8300 - val_loss: 0.0596 - val_mse: 0.8035\n",
      "Epoch 530/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0667 - mse: 0.8305\n",
      "Epoch 00530: saving model to Regression_Model/msle.linear-0530.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0664 - mse: 0.8299 - val_loss: 0.0596 - val_mse: 0.7939\n",
      "Epoch 531/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8400 - val_loss: 0.0599 - val_mse: 0.8059\n",
      "Epoch 532/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8352 - val_loss: 0.0593 - val_mse: 0.8017\n",
      "Epoch 533/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0673 - mse: 0.8288 - val_loss: 0.0594 - val_mse: 0.8032\n",
      "Epoch 534/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8429 - val_loss: 0.0595 - val_mse: 0.7976\n",
      "Epoch 535/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8333 - val_loss: 0.0594 - val_mse: 0.7953\n",
      "Epoch 536/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8280 - val_loss: 0.0599 - val_mse: 0.7930\n",
      "Epoch 537/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8339 - val_loss: 0.0594 - val_mse: 0.7987\n",
      "Epoch 538/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8292 - val_loss: 0.0597 - val_mse: 0.7965\n",
      "Epoch 539/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8274 - val_loss: 0.0597 - val_mse: 0.8079\n",
      "Epoch 540/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0655 - mse: 0.8273\n",
      "Epoch 00540: saving model to Regression_Model/msle.linear-0540.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0656 - mse: 0.8287 - val_loss: 0.0603 - val_mse: 0.8140\n",
      "Epoch 541/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8361 - val_loss: 0.0594 - val_mse: 0.7991\n",
      "Epoch 542/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8341 - val_loss: 0.0598 - val_mse: 0.7939\n",
      "Epoch 543/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8268 - val_loss: 0.0605 - val_mse: 0.8233\n",
      "Epoch 544/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0662 - mse: 0.8319 - val_loss: 0.0596 - val_mse: 0.8013\n",
      "Epoch 545/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8299 - val_loss: 0.0594 - val_mse: 0.8031\n",
      "Epoch 546/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8281 - val_loss: 0.0594 - val_mse: 0.7957\n",
      "Epoch 547/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8457 - val_loss: 0.0597 - val_mse: 0.7896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 548/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8385 - val_loss: 0.0597 - val_mse: 0.8078\n",
      "Epoch 549/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8285 - val_loss: 0.0597 - val_mse: 0.8073\n",
      "Epoch 550/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0654 - mse: 0.8226\n",
      "Epoch 00550: saving model to Regression_Model/msle.linear-0550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8269 - val_loss: 0.0604 - val_mse: 0.8251\n",
      "Epoch 551/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8238 - val_loss: 0.0594 - val_mse: 0.8060\n",
      "Epoch 552/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8327 - val_loss: 0.0600 - val_mse: 0.8173\n",
      "Epoch 553/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8423 - val_loss: 0.0595 - val_mse: 0.7911\n",
      "Epoch 554/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8294 - val_loss: 0.0593 - val_mse: 0.8007\n",
      "Epoch 555/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8278 - val_loss: 0.0592 - val_mse: 0.8013\n",
      "Epoch 556/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8312 - val_loss: 0.0600 - val_mse: 0.8121\n",
      "Epoch 557/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8238 - val_loss: 0.0593 - val_mse: 0.7934\n",
      "Epoch 558/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8330 - val_loss: 0.0601 - val_mse: 0.8177\n",
      "Epoch 559/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8326 - val_loss: 0.0591 - val_mse: 0.7914\n",
      "Epoch 560/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0669 - mse: 0.8400\n",
      "Epoch 00560: saving model to Regression_Model/msle.linear-0560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8409 - val_loss: 0.0593 - val_mse: 0.7915\n",
      "Epoch 561/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8357 - val_loss: 0.0593 - val_mse: 0.8042\n",
      "Epoch 562/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8247 - val_loss: 0.0592 - val_mse: 0.7990\n",
      "Epoch 563/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8231 - val_loss: 0.0609 - val_mse: 0.7822\n",
      "Epoch 564/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8309 - val_loss: 0.0592 - val_mse: 0.7952\n",
      "Epoch 565/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0662 - mse: 0.8297 - val_loss: 0.0594 - val_mse: 0.8013\n",
      "Epoch 566/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8261 - val_loss: 0.0597 - val_mse: 0.7788\n",
      "Epoch 567/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8283 - val_loss: 0.0594 - val_mse: 0.7914\n",
      "Epoch 568/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8384 - val_loss: 0.0592 - val_mse: 0.7949\n",
      "Epoch 569/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8230 - val_loss: 0.0594 - val_mse: 0.7873\n",
      "Epoch 570/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8203\n",
      "Epoch 00570: saving model to Regression_Model/msle.linear-0570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8214 - val_loss: 0.0605 - val_mse: 0.8261\n",
      "Epoch 571/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8284 - val_loss: 0.0592 - val_mse: 0.7978\n",
      "Epoch 572/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8294 - val_loss: 0.0596 - val_mse: 0.8090\n",
      "Epoch 573/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8418 - val_loss: 0.0593 - val_mse: 0.7996\n",
      "Epoch 574/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8271 - val_loss: 0.0597 - val_mse: 0.8075\n",
      "Epoch 575/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8358 - val_loss: 0.0594 - val_mse: 0.7935\n",
      "Epoch 576/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8331 - val_loss: 0.0595 - val_mse: 0.8043\n",
      "Epoch 577/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8254 - val_loss: 0.0593 - val_mse: 0.7973\n",
      "Epoch 578/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8494 - val_loss: 0.0603 - val_mse: 0.8224\n",
      "Epoch 579/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8263 - val_loss: 0.0594 - val_mse: 0.8026\n",
      "Epoch 580/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0656 - mse: 0.8317\n",
      "Epoch 00580: saving model to Regression_Model/msle.linear-0580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8304 - val_loss: 0.0592 - val_mse: 0.7972\n",
      "Epoch 581/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8349 - val_loss: 0.0592 - val_mse: 0.7970\n",
      "Epoch 582/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8260 - val_loss: 0.0595 - val_mse: 0.8075\n",
      "Epoch 583/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8338 - val_loss: 0.0604 - val_mse: 0.7822\n",
      "Epoch 584/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8274 - val_loss: 0.0593 - val_mse: 0.7986\n",
      "Epoch 585/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8310 - val_loss: 0.0597 - val_mse: 0.8117\n",
      "Epoch 586/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8358 - val_loss: 0.0593 - val_mse: 0.7903\n",
      "Epoch 587/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8286 - val_loss: 0.0601 - val_mse: 0.8030\n",
      "Epoch 588/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8363 - val_loss: 0.0597 - val_mse: 0.7982\n",
      "Epoch 589/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8322 - val_loss: 0.0594 - val_mse: 0.8062\n",
      "Epoch 590/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0652 - mse: 0.8192\n",
      "Epoch 00590: saving model to Regression_Model/msle.linear-0590.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0654 - mse: 0.8229 - val_loss: 0.0592 - val_mse: 0.8004\n",
      "Epoch 591/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8338 - val_loss: 0.0606 - val_mse: 0.7906\n",
      "Epoch 592/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8266 - val_loss: 0.0595 - val_mse: 0.8018\n",
      "Epoch 593/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8416 - val_loss: 0.0593 - val_mse: 0.8000\n",
      "Epoch 594/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8258 - val_loss: 0.0594 - val_mse: 0.8090\n",
      "Epoch 595/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8181 - val_loss: 0.0596 - val_mse: 0.8133\n",
      "Epoch 596/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8325 - val_loss: 0.0599 - val_mse: 0.7809\n",
      "Epoch 597/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8313 - val_loss: 0.0591 - val_mse: 0.7881\n",
      "Epoch 598/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8243 - val_loss: 0.0595 - val_mse: 0.8009\n",
      "Epoch 599/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8346 - val_loss: 0.0598 - val_mse: 0.7841\n",
      "Epoch 600/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0666 - mse: 0.8405\n",
      "Epoch 00600: saving model to Regression_Model/msle.linear-0600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8414 - val_loss: 0.0598 - val_mse: 0.7925\n",
      "Epoch 601/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8428 - val_loss: 0.0592 - val_mse: 0.7942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 602/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8234 - val_loss: 0.0590 - val_mse: 0.7901\n",
      "Epoch 603/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8148 - val_loss: 0.0595 - val_mse: 0.8044\n",
      "Epoch 604/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8227 - val_loss: 0.0591 - val_mse: 0.7949\n",
      "Epoch 605/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8254 - val_loss: 0.0594 - val_mse: 0.7959\n",
      "Epoch 606/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8306 - val_loss: 0.0591 - val_mse: 0.7846\n",
      "Epoch 607/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8269 - val_loss: 0.0596 - val_mse: 0.7801\n",
      "Epoch 608/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8298 - val_loss: 0.0593 - val_mse: 0.8050\n",
      "Epoch 609/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8320 - val_loss: 0.0595 - val_mse: 0.8065\n",
      "Epoch 610/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0661 - mse: 0.8367\n",
      "Epoch 00610: saving model to Regression_Model/msle.linear-0610.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8355 - val_loss: 0.0603 - val_mse: 0.7885\n",
      "Epoch 611/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8432 - val_loss: 0.0598 - val_mse: 0.7809\n",
      "Epoch 612/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8332 - val_loss: 0.0592 - val_mse: 0.7992\n",
      "Epoch 613/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8279 - val_loss: 0.0592 - val_mse: 0.7957\n",
      "Epoch 614/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8202 - val_loss: 0.0592 - val_mse: 0.7874\n",
      "Epoch 615/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8365 - val_loss: 0.0595 - val_mse: 0.8064\n",
      "Epoch 616/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8342 - val_loss: 0.0596 - val_mse: 0.7888\n",
      "Epoch 617/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8374 - val_loss: 0.0592 - val_mse: 0.8011\n",
      "Epoch 618/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8331 - val_loss: 0.0603 - val_mse: 0.8201\n",
      "Epoch 619/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8270 - val_loss: 0.0593 - val_mse: 0.8017\n",
      "Epoch 620/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0657 - mse: 0.8247\n",
      "Epoch 00620: saving model to Regression_Model/msle.linear-0620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8263 - val_loss: 0.0593 - val_mse: 0.8063\n",
      "Epoch 621/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8335 - val_loss: 0.0592 - val_mse: 0.7998\n",
      "Epoch 622/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8235 - val_loss: 0.0594 - val_mse: 0.7891\n",
      "Epoch 623/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8384 - val_loss: 0.0595 - val_mse: 0.8057\n",
      "Epoch 624/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8311 - val_loss: 0.0593 - val_mse: 0.7948\n",
      "Epoch 625/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8493 - val_loss: 0.0606 - val_mse: 0.8267\n",
      "Epoch 626/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8194 - val_loss: 0.0592 - val_mse: 0.8032\n",
      "Epoch 627/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8350 - val_loss: 0.0593 - val_mse: 0.7959\n",
      "Epoch 628/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8300 - val_loss: 0.0592 - val_mse: 0.7980\n",
      "Epoch 629/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8505 - val_loss: 0.0598 - val_mse: 0.7813\n",
      "Epoch 630/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0669 - mse: 0.8403\n",
      "Epoch 00630: saving model to Regression_Model/msle.linear-0630.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0669 - mse: 0.8410 - val_loss: 0.0592 - val_mse: 0.8018\n",
      "Epoch 631/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8292 - val_loss: 0.0592 - val_mse: 0.7997\n",
      "Epoch 632/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8324 - val_loss: 0.0608 - val_mse: 0.8309\n",
      "Epoch 633/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8497 - val_loss: 0.0592 - val_mse: 0.7984\n",
      "Epoch 634/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8303 - val_loss: 0.0610 - val_mse: 0.8332\n",
      "Epoch 635/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8289 - val_loss: 0.0592 - val_mse: 0.7874\n",
      "Epoch 636/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8330 - val_loss: 0.0594 - val_mse: 0.7941\n",
      "Epoch 637/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8310 - val_loss: 0.0594 - val_mse: 0.8042\n",
      "Epoch 638/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8276 - val_loss: 0.0592 - val_mse: 0.7997\n",
      "Epoch 639/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8293 - val_loss: 0.0590 - val_mse: 0.7970\n",
      "Epoch 640/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0660 - mse: 0.8268\n",
      "Epoch 00640: saving model to Regression_Model/msle.linear-0640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8275 - val_loss: 0.0590 - val_mse: 0.7932\n",
      "Epoch 641/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8215 - val_loss: 0.0596 - val_mse: 0.7835\n",
      "Epoch 642/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8442 - val_loss: 0.0601 - val_mse: 0.8185\n",
      "Epoch 643/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8258 - val_loss: 0.0591 - val_mse: 0.7872\n",
      "Epoch 644/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8519 - val_loss: 0.0590 - val_mse: 0.7991\n",
      "Epoch 645/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8258 - val_loss: 0.0596 - val_mse: 0.8093\n",
      "Epoch 646/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8288 - val_loss: 0.0600 - val_mse: 0.8165\n",
      "Epoch 647/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8439 - val_loss: 0.0592 - val_mse: 0.7865\n",
      "Epoch 648/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8306 - val_loss: 0.0597 - val_mse: 0.7793\n",
      "Epoch 649/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8221 - val_loss: 0.0592 - val_mse: 0.8050\n",
      "Epoch 650/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0669 - mse: 0.8400\n",
      "Epoch 00650: saving model to Regression_Model/msle.linear-0650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8378 - val_loss: 0.0590 - val_mse: 0.7953\n",
      "Epoch 651/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8399 - val_loss: 0.0591 - val_mse: 0.8037\n",
      "Epoch 652/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8343 - val_loss: 0.0619 - val_mse: 0.7720\n",
      "Epoch 653/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8422 - val_loss: 0.0593 - val_mse: 0.8011\n",
      "Epoch 654/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8313 - val_loss: 0.0590 - val_mse: 0.7874\n",
      "Epoch 655/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8217 - val_loss: 0.0596 - val_mse: 0.7831\n",
      "Epoch 656/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8272 - val_loss: 0.0606 - val_mse: 0.8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 657/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8293 - val_loss: 0.0591 - val_mse: 0.8037\n",
      "Epoch 658/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8374 - val_loss: 0.0591 - val_mse: 0.8038\n",
      "Epoch 659/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8327 - val_loss: 0.0592 - val_mse: 0.8036\n",
      "Epoch 660/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0665 - mse: 0.8376\n",
      "Epoch 00660: saving model to Regression_Model/msle.linear-0660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8361 - val_loss: 0.0594 - val_mse: 0.7880\n",
      "Epoch 661/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8389 - val_loss: 0.0591 - val_mse: 0.7932\n",
      "Epoch 662/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8389 - val_loss: 0.0595 - val_mse: 0.7840\n",
      "Epoch 663/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8301 - val_loss: 0.0596 - val_mse: 0.8117\n",
      "Epoch 664/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8304 - val_loss: 0.0593 - val_mse: 0.7855\n",
      "Epoch 665/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8323 - val_loss: 0.0591 - val_mse: 0.7971\n",
      "Epoch 666/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8321 - val_loss: 0.0591 - val_mse: 0.8020\n",
      "Epoch 667/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8247 - val_loss: 0.0592 - val_mse: 0.8041\n",
      "Epoch 668/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8225 - val_loss: 0.0589 - val_mse: 0.7885\n",
      "Epoch 669/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8208 - val_loss: 0.0594 - val_mse: 0.8068\n",
      "Epoch 670/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0655 - mse: 0.8311\n",
      "Epoch 00670: saving model to Regression_Model/msle.linear-0670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8317 - val_loss: 0.0590 - val_mse: 0.7913\n",
      "Epoch 671/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8310 - val_loss: 0.0591 - val_mse: 0.7904\n",
      "Epoch 672/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8296 - val_loss: 0.0594 - val_mse: 0.7909\n",
      "Epoch 673/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8344 - val_loss: 0.0591 - val_mse: 0.7963\n",
      "Epoch 674/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8290 - val_loss: 0.0601 - val_mse: 0.8223\n",
      "Epoch 675/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8391 - val_loss: 0.0596 - val_mse: 0.7991\n",
      "Epoch 676/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8259 - val_loss: 0.0593 - val_mse: 0.7905\n",
      "Epoch 677/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8266 - val_loss: 0.0602 - val_mse: 0.8136\n",
      "Epoch 678/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8260 - val_loss: 0.0590 - val_mse: 0.7923\n",
      "Epoch 679/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8209 - val_loss: 0.0592 - val_mse: 0.7996\n",
      "Epoch 680/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0653 - mse: 0.8320\n",
      "Epoch 00680: saving model to Regression_Model/msle.linear-0680.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0654 - mse: 0.8274 - val_loss: 0.0592 - val_mse: 0.7887\n",
      "Epoch 681/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8308 - val_loss: 0.0595 - val_mse: 0.8094\n",
      "Epoch 682/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8275 - val_loss: 0.0592 - val_mse: 0.7867\n",
      "Epoch 683/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8203 - val_loss: 0.0590 - val_mse: 0.7894\n",
      "Epoch 684/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8256 - val_loss: 0.0589 - val_mse: 0.7909\n",
      "Epoch 685/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8284 - val_loss: 0.0590 - val_mse: 0.7946\n",
      "Epoch 686/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8296 - val_loss: 0.0599 - val_mse: 0.7772\n",
      "Epoch 687/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8297 - val_loss: 0.0592 - val_mse: 0.7875\n",
      "Epoch 688/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0661 - mse: 0.8347 - val_loss: 0.0590 - val_mse: 0.7970\n",
      "Epoch 689/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8293 - val_loss: 0.0593 - val_mse: 0.7844\n",
      "Epoch 690/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0662 - mse: 0.8315\n",
      "Epoch 00690: saving model to Regression_Model/msle.linear-0690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8317 - val_loss: 0.0592 - val_mse: 0.7837\n",
      "Epoch 691/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8218 - val_loss: 0.0589 - val_mse: 0.7923\n",
      "Epoch 692/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8282 - val_loss: 0.0592 - val_mse: 0.8057\n",
      "Epoch 693/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8351 - val_loss: 0.0595 - val_mse: 0.8108\n",
      "Epoch 694/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8446 - val_loss: 0.0590 - val_mse: 0.7917\n",
      "Epoch 695/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8216 - val_loss: 0.0591 - val_mse: 0.7906\n",
      "Epoch 696/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8218 - val_loss: 0.0589 - val_mse: 0.7906\n",
      "Epoch 697/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8298 - val_loss: 0.0589 - val_mse: 0.7931\n",
      "Epoch 698/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8280 - val_loss: 0.0590 - val_mse: 0.7936\n",
      "Epoch 699/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8292 - val_loss: 0.0595 - val_mse: 0.8126\n",
      "Epoch 700/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0654 - mse: 0.8271\n",
      "Epoch 00700: saving model to Regression_Model/msle.linear-0700.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8253 - val_loss: 0.0591 - val_mse: 0.7958\n",
      "Epoch 701/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8186 - val_loss: 0.0590 - val_mse: 0.7836\n",
      "Epoch 702/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8342 - val_loss: 0.0591 - val_mse: 0.7943\n",
      "Epoch 703/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8277 - val_loss: 0.0591 - val_mse: 0.7828\n",
      "Epoch 704/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8187 - val_loss: 0.0593 - val_mse: 0.8080\n",
      "Epoch 705/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8384 - val_loss: 0.0597 - val_mse: 0.8138\n",
      "Epoch 706/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8199 - val_loss: 0.0590 - val_mse: 0.8000\n",
      "Epoch 707/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8262 - val_loss: 0.0596 - val_mse: 0.7806\n",
      "Epoch 708/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8233 - val_loss: 0.0592 - val_mse: 0.8054\n",
      "Epoch 709/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8280 - val_loss: 0.0592 - val_mse: 0.7876\n",
      "Epoch 710/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8241\n",
      "Epoch 00710: saving model to Regression_Model/msle.linear-0710.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8235 - val_loss: 0.0597 - val_mse: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 711/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8323 - val_loss: 0.0590 - val_mse: 0.7933\n",
      "Epoch 712/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8267 - val_loss: 0.0593 - val_mse: 0.8066\n",
      "Epoch 713/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8226 - val_loss: 0.0593 - val_mse: 0.7877\n",
      "Epoch 714/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8310 - val_loss: 0.0594 - val_mse: 0.8127\n",
      "Epoch 715/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8219 - val_loss: 0.0590 - val_mse: 0.7960\n",
      "Epoch 716/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8249 - val_loss: 0.0599 - val_mse: 0.8188\n",
      "Epoch 717/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8258 - val_loss: 0.0590 - val_mse: 0.7865\n",
      "Epoch 718/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8263 - val_loss: 0.0591 - val_mse: 0.7865\n",
      "Epoch 719/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8296 - val_loss: 0.0590 - val_mse: 0.7869\n",
      "Epoch 720/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0658 - mse: 0.8252\n",
      "Epoch 00720: saving model to Regression_Model/msle.linear-0720.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0657 - mse: 0.8273 - val_loss: 0.0589 - val_mse: 0.7911\n",
      "Epoch 721/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8207 - val_loss: 0.0594 - val_mse: 0.8084\n",
      "Epoch 722/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8379 - val_loss: 0.0590 - val_mse: 0.7954\n",
      "Epoch 723/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8193 - val_loss: 0.0590 - val_mse: 0.8027\n",
      "Epoch 724/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8252 - val_loss: 0.0594 - val_mse: 0.7904\n",
      "Epoch 725/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8232 - val_loss: 0.0588 - val_mse: 0.7951\n",
      "Epoch 726/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8185 - val_loss: 0.0589 - val_mse: 0.7987\n",
      "Epoch 727/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8233 - val_loss: 0.0593 - val_mse: 0.7860\n",
      "Epoch 728/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8228 - val_loss: 0.0588 - val_mse: 0.7899\n",
      "Epoch 729/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8293 - val_loss: 0.0590 - val_mse: 0.7875\n",
      "Epoch 730/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0656 - mse: 0.8329\n",
      "Epoch 00730: saving model to Regression_Model/msle.linear-0730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8330 - val_loss: 0.0591 - val_mse: 0.8013\n",
      "Epoch 731/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8281 - val_loss: 0.0590 - val_mse: 0.8027\n",
      "Epoch 732/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8225 - val_loss: 0.0588 - val_mse: 0.7897\n",
      "Epoch 733/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8179 - val_loss: 0.0592 - val_mse: 0.8013\n",
      "Epoch 734/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8202 - val_loss: 0.0608 - val_mse: 0.8260\n",
      "Epoch 735/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8380 - val_loss: 0.0590 - val_mse: 0.7890\n",
      "Epoch 736/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8310 - val_loss: 0.0591 - val_mse: 0.7954\n",
      "Epoch 737/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8328 - val_loss: 0.0592 - val_mse: 0.8002\n",
      "Epoch 738/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8321 - val_loss: 0.0590 - val_mse: 0.7965\n",
      "Epoch 739/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8159 - val_loss: 0.0588 - val_mse: 0.7893\n",
      "Epoch 740/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0654 - mse: 0.8212\n",
      "Epoch 00740: saving model to Regression_Model/msle.linear-0740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8230 - val_loss: 0.0591 - val_mse: 0.8056\n",
      "Epoch 741/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8251 - val_loss: 0.0588 - val_mse: 0.7918\n",
      "Epoch 742/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8204 - val_loss: 0.0591 - val_mse: 0.7827\n",
      "Epoch 743/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8275 - val_loss: 0.0591 - val_mse: 0.7833\n",
      "Epoch 744/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8245 - val_loss: 0.0588 - val_mse: 0.7953\n",
      "Epoch 745/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8345 - val_loss: 0.0593 - val_mse: 0.7802\n",
      "Epoch 746/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8260 - val_loss: 0.0589 - val_mse: 0.7980\n",
      "Epoch 747/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8269 - val_loss: 0.0590 - val_mse: 0.8002\n",
      "Epoch 748/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8275 - val_loss: 0.0590 - val_mse: 0.8051\n",
      "Epoch 749/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8192 - val_loss: 0.0590 - val_mse: 0.7830\n",
      "Epoch 750/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0659 - mse: 0.8314\n",
      "Epoch 00750: saving model to Regression_Model/msle.linear-0750.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0661 - mse: 0.8322 - val_loss: 0.0589 - val_mse: 0.7916\n",
      "Epoch 751/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8252 - val_loss: 0.0592 - val_mse: 0.8083\n",
      "Epoch 752/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8234 - val_loss: 0.0589 - val_mse: 0.7980\n",
      "Epoch 753/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8269 - val_loss: 0.0591 - val_mse: 0.8050\n",
      "Epoch 754/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8286 - val_loss: 0.0588 - val_mse: 0.7872\n",
      "Epoch 755/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8240 - val_loss: 0.0589 - val_mse: 0.8012\n",
      "Epoch 756/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8283 - val_loss: 0.0592 - val_mse: 0.8026\n",
      "Epoch 757/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8368 - val_loss: 0.0593 - val_mse: 0.7905\n",
      "Epoch 758/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8268 - val_loss: 0.0591 - val_mse: 0.8071\n",
      "Epoch 759/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8252 - val_loss: 0.0591 - val_mse: 0.8034\n",
      "Epoch 760/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0659 - mse: 0.8254\n",
      "Epoch 00760: saving model to Regression_Model/msle.linear-0760.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8260 - val_loss: 0.0591 - val_mse: 0.7967\n",
      "Epoch 761/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8355 - val_loss: 0.0592 - val_mse: 0.7808\n",
      "Epoch 762/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8282 - val_loss: 0.0589 - val_mse: 0.7981\n",
      "Epoch 763/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8419 - val_loss: 0.0589 - val_mse: 0.7929\n",
      "Epoch 764/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8270 - val_loss: 0.0597 - val_mse: 0.7852\n",
      "Epoch 765/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8229 - val_loss: 0.0594 - val_mse: 0.8064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 766/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8291 - val_loss: 0.0587 - val_mse: 0.7900\n",
      "Epoch 767/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8329 - val_loss: 0.0588 - val_mse: 0.7919\n",
      "Epoch 768/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8297 - val_loss: 0.0591 - val_mse: 0.8028\n",
      "Epoch 769/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8345 - val_loss: 0.0590 - val_mse: 0.7906\n",
      "Epoch 770/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0658 - mse: 0.8226\n",
      "Epoch 00770: saving model to Regression_Model/msle.linear-0770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8236 - val_loss: 0.0587 - val_mse: 0.7898\n",
      "Epoch 771/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8259 - val_loss: 0.0590 - val_mse: 0.7864\n",
      "Epoch 772/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8259 - val_loss: 0.0592 - val_mse: 0.8059\n",
      "Epoch 773/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8273 - val_loss: 0.0590 - val_mse: 0.8032\n",
      "Epoch 774/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8330 - val_loss: 0.0594 - val_mse: 0.8119\n",
      "Epoch 775/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8345 - val_loss: 0.0598 - val_mse: 0.8155\n",
      "Epoch 776/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8213 - val_loss: 0.0587 - val_mse: 0.7919\n",
      "Epoch 777/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8184 - val_loss: 0.0591 - val_mse: 0.8069\n",
      "Epoch 778/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8246 - val_loss: 0.0588 - val_mse: 0.7992\n",
      "Epoch 779/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8232 - val_loss: 0.0588 - val_mse: 0.7920\n",
      "Epoch 780/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0638 - mse: 0.8233\n",
      "Epoch 00780: saving model to Regression_Model/msle.linear-0780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8224 - val_loss: 0.0596 - val_mse: 0.8131\n",
      "Epoch 781/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8338 - val_loss: 0.0587 - val_mse: 0.7965\n",
      "Epoch 782/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8214 - val_loss: 0.0589 - val_mse: 0.7996\n",
      "Epoch 783/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8170 - val_loss: 0.0588 - val_mse: 0.7935\n",
      "Epoch 784/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8230 - val_loss: 0.0589 - val_mse: 0.7851\n",
      "Epoch 785/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8240 - val_loss: 0.0593 - val_mse: 0.8092\n",
      "Epoch 786/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8205 - val_loss: 0.0590 - val_mse: 0.8017\n",
      "Epoch 787/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8273 - val_loss: 0.0587 - val_mse: 0.7850\n",
      "Epoch 788/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8287 - val_loss: 0.0588 - val_mse: 0.7838\n",
      "Epoch 789/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8243 - val_loss: 0.0588 - val_mse: 0.7996\n",
      "Epoch 790/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0661 - mse: 0.8237\n",
      "Epoch 00790: saving model to Regression_Model/msle.linear-0790.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8249 - val_loss: 0.0589 - val_mse: 0.8013\n",
      "Epoch 791/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8235 - val_loss: 0.0589 - val_mse: 0.8031\n",
      "Epoch 792/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8230 - val_loss: 0.0597 - val_mse: 0.8180\n",
      "Epoch 793/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8384 - val_loss: 0.0593 - val_mse: 0.8121\n",
      "Epoch 794/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8215 - val_loss: 0.0587 - val_mse: 0.7920\n",
      "Epoch 795/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8258 - val_loss: 0.0595 - val_mse: 0.8095\n",
      "Epoch 796/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8252 - val_loss: 0.0587 - val_mse: 0.7977\n",
      "Epoch 797/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8261 - val_loss: 0.0587 - val_mse: 0.7917\n",
      "Epoch 798/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8350 - val_loss: 0.0590 - val_mse: 0.8050\n",
      "Epoch 799/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8288 - val_loss: 0.0591 - val_mse: 0.8049\n",
      "Epoch 800/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0650 - mse: 0.8246\n",
      "Epoch 00800: saving model to Regression_Model/msle.linear-0800.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.0649 - mse: 0.8236 - val_loss: 0.0587 - val_mse: 0.7913\n",
      "Epoch 801/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8221 - val_loss: 0.0588 - val_mse: 0.7915\n",
      "Epoch 802/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8251 - val_loss: 0.0587 - val_mse: 0.7954\n",
      "Epoch 803/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8282 - val_loss: 0.0591 - val_mse: 0.8047\n",
      "Epoch 804/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8239 - val_loss: 0.0591 - val_mse: 0.7844\n",
      "Epoch 805/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8246 - val_loss: 0.0588 - val_mse: 0.7877\n",
      "Epoch 806/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8304 - val_loss: 0.0588 - val_mse: 0.7985\n",
      "Epoch 807/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8237 - val_loss: 0.0589 - val_mse: 0.7985\n",
      "Epoch 808/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8262 - val_loss: 0.0589 - val_mse: 0.7873\n",
      "Epoch 809/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8392 - val_loss: 0.0587 - val_mse: 0.7963\n",
      "Epoch 810/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0659 - mse: 0.8274\n",
      "Epoch 00810: saving model to Regression_Model/msle.linear-0810.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8254 - val_loss: 0.0589 - val_mse: 0.7947\n",
      "Epoch 811/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8234 - val_loss: 0.0587 - val_mse: 0.7963\n",
      "Epoch 812/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8231 - val_loss: 0.0589 - val_mse: 0.7845\n",
      "Epoch 813/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8329 - val_loss: 0.0589 - val_mse: 0.7850\n",
      "Epoch 814/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8330 - val_loss: 0.0589 - val_mse: 0.7860\n",
      "Epoch 815/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8262 - val_loss: 0.0587 - val_mse: 0.7882\n",
      "Epoch 816/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8346 - val_loss: 0.0589 - val_mse: 0.7960\n",
      "Epoch 817/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8431 - val_loss: 0.0593 - val_mse: 0.8104\n",
      "Epoch 818/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8205 - val_loss: 0.0589 - val_mse: 0.8014\n",
      "Epoch 819/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8298 - val_loss: 0.0587 - val_mse: 0.7859\n",
      "Epoch 820/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0655 - mse: 0.8351\n",
      "Epoch 00820: saving model to Regression_Model/msle.linear-0820.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 7ms/step - loss: 0.0654 - mse: 0.8311 - val_loss: 0.0587 - val_mse: 0.7922\n",
      "Epoch 821/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8158 - val_loss: 0.0586 - val_mse: 0.7890\n",
      "Epoch 822/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8261 - val_loss: 0.0589 - val_mse: 0.7984\n",
      "Epoch 823/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8257 - val_loss: 0.0589 - val_mse: 0.8055\n",
      "Epoch 824/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8189 - val_loss: 0.0588 - val_mse: 0.8004\n",
      "Epoch 825/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8299 - val_loss: 0.0591 - val_mse: 0.8067\n",
      "Epoch 826/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8259 - val_loss: 0.0588 - val_mse: 0.7992\n",
      "Epoch 827/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8231 - val_loss: 0.0592 - val_mse: 0.8091\n",
      "Epoch 828/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8334 - val_loss: 0.0587 - val_mse: 0.7955\n",
      "Epoch 829/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8213 - val_loss: 0.0591 - val_mse: 0.8052\n",
      "Epoch 830/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8355\n",
      "Epoch 00830: saving model to Regression_Model/msle.linear-0830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8349 - val_loss: 0.0587 - val_mse: 0.7991\n",
      "Epoch 831/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8313 - val_loss: 0.0589 - val_mse: 0.8038\n",
      "Epoch 832/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8272 - val_loss: 0.0588 - val_mse: 0.8015\n",
      "Epoch 833/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8380 - val_loss: 0.0586 - val_mse: 0.7931\n",
      "Epoch 834/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8152 - val_loss: 0.0587 - val_mse: 0.7947\n",
      "Epoch 835/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8250 - val_loss: 0.0588 - val_mse: 0.7897\n",
      "Epoch 836/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8228 - val_loss: 0.0591 - val_mse: 0.7832\n",
      "Epoch 837/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8220 - val_loss: 0.0589 - val_mse: 0.8044\n",
      "Epoch 838/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8204 - val_loss: 0.0587 - val_mse: 0.7936\n",
      "Epoch 839/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8219 - val_loss: 0.0589 - val_mse: 0.7869\n",
      "Epoch 840/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0649 - mse: 0.8302\n",
      "Epoch 00840: saving model to Regression_Model/msle.linear-0840.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8344 - val_loss: 0.0594 - val_mse: 0.7799\n",
      "Epoch 841/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8293 - val_loss: 0.0593 - val_mse: 0.8124\n",
      "Epoch 842/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8291 - val_loss: 0.0588 - val_mse: 0.7825\n",
      "Epoch 843/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8244 - val_loss: 0.0589 - val_mse: 0.7897\n",
      "Epoch 844/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8246 - val_loss: 0.0595 - val_mse: 0.7960\n",
      "Epoch 845/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8230 - val_loss: 0.0591 - val_mse: 0.8093\n",
      "Epoch 846/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8355 - val_loss: 0.0592 - val_mse: 0.8087\n",
      "Epoch 847/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8260 - val_loss: 0.0589 - val_mse: 0.7843\n",
      "Epoch 848/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8320 - val_loss: 0.0586 - val_mse: 0.7879\n",
      "Epoch 849/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8282 - val_loss: 0.0591 - val_mse: 0.8077\n",
      "Epoch 850/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0647 - mse: 0.8234\n",
      "Epoch 00850: saving model to Regression_Model/msle.linear-0850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8239 - val_loss: 0.0587 - val_mse: 0.7851\n",
      "Epoch 851/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8244 - val_loss: 0.0598 - val_mse: 0.8147\n",
      "Epoch 852/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8232 - val_loss: 0.0589 - val_mse: 0.7897\n",
      "Epoch 853/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8161 - val_loss: 0.0591 - val_mse: 0.8099\n",
      "Epoch 854/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8230 - val_loss: 0.0587 - val_mse: 0.7983\n",
      "Epoch 855/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8304 - val_loss: 0.0592 - val_mse: 0.7800\n",
      "Epoch 856/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8291 - val_loss: 0.0586 - val_mse: 0.7948\n",
      "Epoch 857/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8130 - val_loss: 0.0588 - val_mse: 0.7934\n",
      "Epoch 858/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8340 - val_loss: 0.0586 - val_mse: 0.7961\n",
      "Epoch 859/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8262 - val_loss: 0.0591 - val_mse: 0.7789\n",
      "Epoch 860/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0650 - mse: 0.8211\n",
      "Epoch 00860: saving model to Regression_Model/msle.linear-0860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8212 - val_loss: 0.0587 - val_mse: 0.8003\n",
      "Epoch 861/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8212 - val_loss: 0.0589 - val_mse: 0.8028\n",
      "Epoch 862/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8282 - val_loss: 0.0586 - val_mse: 0.7936\n",
      "Epoch 863/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8254 - val_loss: 0.0586 - val_mse: 0.7891\n",
      "Epoch 864/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8372 - val_loss: 0.0587 - val_mse: 0.7898\n",
      "Epoch 865/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8291 - val_loss: 0.0592 - val_mse: 0.8068\n",
      "Epoch 866/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8260 - val_loss: 0.0588 - val_mse: 0.7932\n",
      "Epoch 867/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8352 - val_loss: 0.0587 - val_mse: 0.7958\n",
      "Epoch 868/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8283 - val_loss: 0.0592 - val_mse: 0.7782\n",
      "Epoch 869/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8291 - val_loss: 0.0589 - val_mse: 0.8028\n",
      "Epoch 870/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0651 - mse: 0.8308\n",
      "Epoch 00870: saving model to Regression_Model/msle.linear-0870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8336 - val_loss: 0.0586 - val_mse: 0.7873\n",
      "Epoch 871/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8281 - val_loss: 0.0587 - val_mse: 0.7978\n",
      "Epoch 872/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8244 - val_loss: 0.0589 - val_mse: 0.7804\n",
      "Epoch 873/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8342 - val_loss: 0.0588 - val_mse: 0.7881\n",
      "Epoch 874/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8300 - val_loss: 0.0588 - val_mse: 0.7896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8189 - val_loss: 0.0587 - val_mse: 0.7976\n",
      "Epoch 876/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8250 - val_loss: 0.0587 - val_mse: 0.7999\n",
      "Epoch 877/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8242 - val_loss: 0.0592 - val_mse: 0.7831\n",
      "Epoch 878/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0651 - mse: 0.8184 - val_loss: 0.0590 - val_mse: 0.8005\n",
      "Epoch 879/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8291 - val_loss: 0.0587 - val_mse: 0.7876\n",
      "Epoch 880/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0655 - mse: 0.8300\n",
      "Epoch 00880: saving model to Regression_Model/msle.linear-0880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8292 - val_loss: 0.0586 - val_mse: 0.7929\n",
      "Epoch 881/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8273 - val_loss: 0.0589 - val_mse: 0.7928\n",
      "Epoch 882/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8360 - val_loss: 0.0586 - val_mse: 0.7934\n",
      "Epoch 883/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8255 - val_loss: 0.0587 - val_mse: 0.7931\n",
      "Epoch 884/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8348 - val_loss: 0.0587 - val_mse: 0.7897\n",
      "Epoch 885/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8220 - val_loss: 0.0587 - val_mse: 0.7881\n",
      "Epoch 886/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8260 - val_loss: 0.0587 - val_mse: 0.7936\n",
      "Epoch 887/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8162 - val_loss: 0.0587 - val_mse: 0.8018\n",
      "Epoch 888/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8249 - val_loss: 0.0586 - val_mse: 0.7995\n",
      "Epoch 889/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8283 - val_loss: 0.0586 - val_mse: 0.7957\n",
      "Epoch 890/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8234\n",
      "Epoch 00890: saving model to Regression_Model/msle.linear-0890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8242 - val_loss: 0.0588 - val_mse: 0.8023\n",
      "Epoch 891/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8187 - val_loss: 0.0588 - val_mse: 0.8013\n",
      "Epoch 892/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8206 - val_loss: 0.0587 - val_mse: 0.7979\n",
      "Epoch 893/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8169 - val_loss: 0.0587 - val_mse: 0.7929\n",
      "Epoch 894/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8288 - val_loss: 0.0590 - val_mse: 0.8052\n",
      "Epoch 895/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8235 - val_loss: 0.0587 - val_mse: 0.7837\n",
      "Epoch 896/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8283 - val_loss: 0.0586 - val_mse: 0.7855\n",
      "Epoch 897/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8277 - val_loss: 0.0587 - val_mse: 0.7849\n",
      "Epoch 898/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8254 - val_loss: 0.0586 - val_mse: 0.7956\n",
      "Epoch 899/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8273 - val_loss: 0.0587 - val_mse: 0.7929\n",
      "Epoch 900/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8307\n",
      "Epoch 00900: saving model to Regression_Model/msle.linear-0900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8319 - val_loss: 0.0589 - val_mse: 0.8065\n",
      "Epoch 901/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8211 - val_loss: 0.0589 - val_mse: 0.7892\n",
      "Epoch 902/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8312 - val_loss: 0.0587 - val_mse: 0.7994\n",
      "Epoch 903/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8242 - val_loss: 0.0590 - val_mse: 0.8055\n",
      "Epoch 904/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8262 - val_loss: 0.0589 - val_mse: 0.8056\n",
      "Epoch 905/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8226 - val_loss: 0.0588 - val_mse: 0.7844\n",
      "Epoch 906/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8185 - val_loss: 0.0586 - val_mse: 0.7983\n",
      "Epoch 907/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8275 - val_loss: 0.0593 - val_mse: 0.8119\n",
      "Epoch 908/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8253 - val_loss: 0.0589 - val_mse: 0.7869\n",
      "Epoch 909/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8318 - val_loss: 0.0587 - val_mse: 0.7920\n",
      "Epoch 910/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0647 - mse: 0.8252\n",
      "Epoch 00910: saving model to Regression_Model/msle.linear-0910.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8255 - val_loss: 0.0588 - val_mse: 0.8008\n",
      "Epoch 911/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8389 - val_loss: 0.0590 - val_mse: 0.8055\n",
      "Epoch 912/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8383 - val_loss: 0.0591 - val_mse: 0.8090\n",
      "Epoch 913/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8264 - val_loss: 0.0588 - val_mse: 0.8006\n",
      "Epoch 914/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8245 - val_loss: 0.0586 - val_mse: 0.7914\n",
      "Epoch 915/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8263 - val_loss: 0.0588 - val_mse: 0.8002\n",
      "Epoch 916/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0656 - mse: 0.8286 - val_loss: 0.0586 - val_mse: 0.7875\n",
      "Epoch 917/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0660 - mse: 0.8235 - val_loss: 0.0588 - val_mse: 0.7993\n",
      "Epoch 918/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8249 - val_loss: 0.0592 - val_mse: 0.8097\n",
      "Epoch 919/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8250 - val_loss: 0.0586 - val_mse: 0.7920\n",
      "Epoch 920/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8226\n",
      "Epoch 00920: saving model to Regression_Model/msle.linear-0920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8230 - val_loss: 0.0589 - val_mse: 0.7926\n",
      "Epoch 921/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8273 - val_loss: 0.0587 - val_mse: 0.7992\n",
      "Epoch 922/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8206 - val_loss: 0.0586 - val_mse: 0.7915\n",
      "Epoch 923/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8214 - val_loss: 0.0588 - val_mse: 0.8028\n",
      "Epoch 924/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8435 - val_loss: 0.0587 - val_mse: 0.7979\n",
      "Epoch 925/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8218 - val_loss: 0.0587 - val_mse: 0.7866\n",
      "Epoch 926/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8302 - val_loss: 0.0590 - val_mse: 0.8072\n",
      "Epoch 927/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8363 - val_loss: 0.0597 - val_mse: 0.8114\n",
      "Epoch 928/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8442 - val_loss: 0.0589 - val_mse: 0.7991\n",
      "Epoch 929/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8240 - val_loss: 0.0586 - val_mse: 0.7902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8250\n",
      "Epoch 00930: saving model to Regression_Model/msle.linear-0930.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0655 - mse: 0.8257 - val_loss: 0.0586 - val_mse: 0.7923\n",
      "Epoch 931/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8181 - val_loss: 0.0588 - val_mse: 0.7989\n",
      "Epoch 932/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8227 - val_loss: 0.0586 - val_mse: 0.7901\n",
      "Epoch 933/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8308 - val_loss: 0.0588 - val_mse: 0.8035\n",
      "Epoch 934/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8215 - val_loss: 0.0586 - val_mse: 0.7890\n",
      "Epoch 935/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8105 - val_loss: 0.0588 - val_mse: 0.8028\n",
      "Epoch 936/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0641 - mse: 0.8168 - val_loss: 0.0587 - val_mse: 0.7888\n",
      "Epoch 937/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8342 - val_loss: 0.0587 - val_mse: 0.7969\n",
      "Epoch 938/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8258 - val_loss: 0.0588 - val_mse: 0.7948\n",
      "Epoch 939/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8267 - val_loss: 0.0588 - val_mse: 0.8022\n",
      "Epoch 940/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0652 - mse: 0.8378\n",
      "Epoch 00940: saving model to Regression_Model/msle.linear-0940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8376 - val_loss: 0.0586 - val_mse: 0.7892\n",
      "Epoch 941/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8315 - val_loss: 0.0589 - val_mse: 0.7983\n",
      "Epoch 942/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8327 - val_loss: 0.0587 - val_mse: 0.8021\n",
      "Epoch 943/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8315 - val_loss: 0.0586 - val_mse: 0.7924\n",
      "Epoch 944/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8241 - val_loss: 0.0588 - val_mse: 0.8018\n",
      "Epoch 945/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8205 - val_loss: 0.0589 - val_mse: 0.8053\n",
      "Epoch 946/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8198 - val_loss: 0.0587 - val_mse: 0.7887\n",
      "Epoch 947/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8240 - val_loss: 0.0586 - val_mse: 0.7978\n",
      "Epoch 948/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8255 - val_loss: 0.0589 - val_mse: 0.8050\n",
      "Epoch 949/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8223 - val_loss: 0.0587 - val_mse: 0.7963\n",
      "Epoch 950/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0649 - mse: 0.8278\n",
      "Epoch 00950: saving model to Regression_Model/msle.linear-0950.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.0650 - mse: 0.8268 - val_loss: 0.0585 - val_mse: 0.7892\n",
      "Epoch 951/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8212 - val_loss: 0.0589 - val_mse: 0.8042\n",
      "Epoch 952/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8316 - val_loss: 0.0587 - val_mse: 0.7999\n",
      "Epoch 953/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8251 - val_loss: 0.0586 - val_mse: 0.7904\n",
      "Epoch 954/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8154 - val_loss: 0.0586 - val_mse: 0.7930\n",
      "Epoch 955/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8249 - val_loss: 0.0587 - val_mse: 0.7827\n",
      "Epoch 956/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8295 - val_loss: 0.0585 - val_mse: 0.7952\n",
      "Epoch 957/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8261 - val_loss: 0.0587 - val_mse: 0.7844\n",
      "Epoch 958/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8326 - val_loss: 0.0585 - val_mse: 0.7884\n",
      "Epoch 959/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8178 - val_loss: 0.0585 - val_mse: 0.7973\n",
      "Epoch 960/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8234\n",
      "Epoch 00960: saving model to Regression_Model/msle.linear-0960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8221 - val_loss: 0.0591 - val_mse: 0.7862\n",
      "Epoch 961/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8268 - val_loss: 0.0586 - val_mse: 0.7977\n",
      "Epoch 962/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8293 - val_loss: 0.0589 - val_mse: 0.8053\n",
      "Epoch 963/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8225 - val_loss: 0.0588 - val_mse: 0.8037\n",
      "Epoch 964/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8326 - val_loss: 0.0587 - val_mse: 0.7907\n",
      "Epoch 965/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8292 - val_loss: 0.0585 - val_mse: 0.7882\n",
      "Epoch 966/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8340 - val_loss: 0.0590 - val_mse: 0.8070\n",
      "Epoch 967/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8212 - val_loss: 0.0591 - val_mse: 0.8087\n",
      "Epoch 968/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0639 - mse: 0.8151 - val_loss: 0.0590 - val_mse: 0.7751\n",
      "Epoch 969/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8170 - val_loss: 0.0584 - val_mse: 0.7899\n",
      "Epoch 970/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0652 - mse: 0.8180\n",
      "Epoch 00970: saving model to Regression_Model/msle.linear-0970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8206 - val_loss: 0.0586 - val_mse: 0.7933\n",
      "Epoch 971/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8224 - val_loss: 0.0586 - val_mse: 0.7968\n",
      "Epoch 972/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8259 - val_loss: 0.0585 - val_mse: 0.7908\n",
      "Epoch 973/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8242 - val_loss: 0.0586 - val_mse: 0.7853\n",
      "Epoch 974/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8294 - val_loss: 0.0585 - val_mse: 0.7920\n",
      "Epoch 975/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8168 - val_loss: 0.0586 - val_mse: 0.7841\n",
      "Epoch 976/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8341 - val_loss: 0.0586 - val_mse: 0.7884\n",
      "Epoch 977/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8324 - val_loss: 0.0585 - val_mse: 0.7936\n",
      "Epoch 978/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8226 - val_loss: 0.0586 - val_mse: 0.7936\n",
      "Epoch 979/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8326 - val_loss: 0.0586 - val_mse: 0.7869\n",
      "Epoch 980/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0650 - mse: 0.8272\n",
      "Epoch 00980: saving model to Regression_Model/msle.linear-0980.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8273 - val_loss: 0.0585 - val_mse: 0.7889\n",
      "Epoch 981/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8217 - val_loss: 0.0587 - val_mse: 0.7927\n",
      "Epoch 982/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8194 - val_loss: 0.0590 - val_mse: 0.8060\n",
      "Epoch 983/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8193 - val_loss: 0.0586 - val_mse: 0.7970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8297 - val_loss: 0.0586 - val_mse: 0.7895\n",
      "Epoch 985/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8232 - val_loss: 0.0588 - val_mse: 0.7989\n",
      "Epoch 986/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0657 - mse: 0.8288 - val_loss: 0.0588 - val_mse: 0.7842\n",
      "Epoch 987/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8217 - val_loss: 0.0585 - val_mse: 0.7938\n",
      "Epoch 988/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8218 - val_loss: 0.0587 - val_mse: 0.7988\n",
      "Epoch 989/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8231 - val_loss: 0.0586 - val_mse: 0.7987\n",
      "Epoch 990/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0652 - mse: 0.8243\n",
      "Epoch 00990: saving model to Regression_Model/msle.linear-0990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8266 - val_loss: 0.0585 - val_mse: 0.7931\n",
      "Epoch 991/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8405 - val_loss: 0.0590 - val_mse: 0.8073\n",
      "Epoch 992/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8230 - val_loss: 0.0587 - val_mse: 0.7865\n",
      "Epoch 993/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8232 - val_loss: 0.0586 - val_mse: 0.7965\n",
      "Epoch 994/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8297 - val_loss: 0.0589 - val_mse: 0.8048\n",
      "Epoch 995/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8236 - val_loss: 0.0588 - val_mse: 0.8030\n",
      "Epoch 996/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8212 - val_loss: 0.0585 - val_mse: 0.7916\n",
      "Epoch 997/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8277 - val_loss: 0.0588 - val_mse: 0.8014\n",
      "Epoch 998/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8283 - val_loss: 0.0587 - val_mse: 0.8005\n",
      "Epoch 999/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8263 - val_loss: 0.0585 - val_mse: 0.7916\n",
      "Epoch 1000/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0648 - mse: 0.8197\n",
      "Epoch 01000: saving model to Regression_Model/msle.linear-1000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8219 - val_loss: 0.0587 - val_mse: 0.7954\n",
      "Epoch 1001/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8195 - val_loss: 0.0588 - val_mse: 0.8019\n",
      "Epoch 1002/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8283 - val_loss: 0.0586 - val_mse: 0.7900\n",
      "Epoch 1003/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8257 - val_loss: 0.0586 - val_mse: 0.7961\n",
      "Epoch 1004/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8210 - val_loss: 0.0585 - val_mse: 0.7934\n",
      "Epoch 1005/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8135 - val_loss: 0.0585 - val_mse: 0.7900\n",
      "Epoch 1006/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8346 - val_loss: 0.0593 - val_mse: 0.8134\n",
      "Epoch 1007/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8284 - val_loss: 0.0585 - val_mse: 0.7936\n",
      "Epoch 1008/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8303 - val_loss: 0.0586 - val_mse: 0.7975\n",
      "Epoch 1009/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0653 - mse: 0.8189 - val_loss: 0.0585 - val_mse: 0.7880\n",
      "Epoch 1010/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0650 - mse: 0.8352\n",
      "Epoch 01010: saving model to Regression_Model/msle.linear-1010.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0650 - mse: 0.8327 - val_loss: 0.0592 - val_mse: 0.8110\n",
      "Epoch 1011/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8224 - val_loss: 0.0586 - val_mse: 0.7826\n",
      "Epoch 1012/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8243 - val_loss: 0.0585 - val_mse: 0.7949\n",
      "Epoch 1013/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8214 - val_loss: 0.0584 - val_mse: 0.7926\n",
      "Epoch 1014/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8214 - val_loss: 0.0585 - val_mse: 0.7932\n",
      "Epoch 1015/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8165 - val_loss: 0.0585 - val_mse: 0.7983\n",
      "Epoch 1016/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0656 - mse: 0.8242 - val_loss: 0.0588 - val_mse: 0.8024\n",
      "Epoch 1017/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0651 - mse: 0.8241 - val_loss: 0.0586 - val_mse: 0.7988\n",
      "Epoch 1018/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8171 - val_loss: 0.0586 - val_mse: 0.7856\n",
      "Epoch 1019/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8214 - val_loss: 0.0585 - val_mse: 0.7893\n",
      "Epoch 1020/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0653 - mse: 0.8277\n",
      "Epoch 01020: saving model to Regression_Model/msle.linear-1020.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0653 - mse: 0.8251 - val_loss: 0.0585 - val_mse: 0.7972\n",
      "Epoch 1021/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8241 - val_loss: 0.0585 - val_mse: 0.7913\n",
      "Epoch 1022/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8245 - val_loss: 0.0587 - val_mse: 0.7839\n",
      "Epoch 1023/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8133 - val_loss: 0.0586 - val_mse: 0.8018\n",
      "Epoch 1024/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8266 - val_loss: 0.0586 - val_mse: 0.7998\n",
      "Epoch 1025/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8205 - val_loss: 0.0585 - val_mse: 0.7978\n",
      "Epoch 1026/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8278 - val_loss: 0.0586 - val_mse: 0.7974\n",
      "Epoch 1027/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8244 - val_loss: 0.0593 - val_mse: 0.8146\n",
      "Epoch 1028/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8212 - val_loss: 0.0585 - val_mse: 0.7940\n",
      "Epoch 1029/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8263 - val_loss: 0.0585 - val_mse: 0.7968\n",
      "Epoch 1030/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0645 - mse: 0.8186\n",
      "Epoch 01030: saving model to Regression_Model/msle.linear-1030.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0646 - mse: 0.8213 - val_loss: 0.0586 - val_mse: 0.7870\n",
      "Epoch 1031/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8263 - val_loss: 0.0592 - val_mse: 0.7750\n",
      "Epoch 1032/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8261 - val_loss: 0.0587 - val_mse: 0.7982\n",
      "Epoch 1033/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8201 - val_loss: 0.0588 - val_mse: 0.8065\n",
      "Epoch 1034/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8206 - val_loss: 0.0585 - val_mse: 0.7897\n",
      "Epoch 1035/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0660 - mse: 0.8401 - val_loss: 0.0586 - val_mse: 0.7865\n",
      "Epoch 1036/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8252 - val_loss: 0.0585 - val_mse: 0.7890\n",
      "Epoch 1037/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8235 - val_loss: 0.0586 - val_mse: 0.7854\n",
      "Epoch 1038/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8252 - val_loss: 0.0588 - val_mse: 0.8038\n",
      "Epoch 1039/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8280 - val_loss: 0.0585 - val_mse: 0.7944\n",
      "Epoch 1040/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0644 - mse: 0.8195\n",
      "Epoch 01040: saving model to Regression_Model/msle.linear-1040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8211 - val_loss: 0.0587 - val_mse: 0.8017\n",
      "Epoch 1041/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8193 - val_loss: 0.0589 - val_mse: 0.8041\n",
      "Epoch 1042/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8227 - val_loss: 0.0589 - val_mse: 0.7843\n",
      "Epoch 1043/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8182 - val_loss: 0.0586 - val_mse: 0.7988\n",
      "Epoch 1044/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8189 - val_loss: 0.0585 - val_mse: 0.7920\n",
      "Epoch 1045/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8198 - val_loss: 0.0587 - val_mse: 0.7983\n",
      "Epoch 1046/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8308 - val_loss: 0.0585 - val_mse: 0.7908\n",
      "Epoch 1047/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8322 - val_loss: 0.0587 - val_mse: 0.7984\n",
      "Epoch 1048/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8210 - val_loss: 0.0586 - val_mse: 0.7850\n",
      "Epoch 1049/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8224 - val_loss: 0.0586 - val_mse: 0.7978\n",
      "Epoch 1050/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0650 - mse: 0.8202\n",
      "Epoch 01050: saving model to Regression_Model/msle.linear-1050.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0656 - mse: 0.8312 - val_loss: 0.0587 - val_mse: 0.8008\n",
      "Epoch 1051/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8191 - val_loss: 0.0587 - val_mse: 0.7988\n",
      "Epoch 1052/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8429 - val_loss: 0.0586 - val_mse: 0.7890\n",
      "Epoch 1053/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8257 - val_loss: 0.0587 - val_mse: 0.8002\n",
      "Epoch 1054/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8214 - val_loss: 0.0587 - val_mse: 0.8009\n",
      "Epoch 1055/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8167 - val_loss: 0.0586 - val_mse: 0.7866\n",
      "Epoch 1056/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8223 - val_loss: 0.0585 - val_mse: 0.7914\n",
      "Epoch 1057/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8261 - val_loss: 0.0585 - val_mse: 0.7885\n",
      "Epoch 1058/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8205 - val_loss: 0.0585 - val_mse: 0.7939\n",
      "Epoch 1059/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0652 - mse: 0.8289 - val_loss: 0.0585 - val_mse: 0.7869\n",
      "Epoch 1060/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0644 - mse: 0.8201\n",
      "Epoch 01060: saving model to Regression_Model/msle.linear-1060.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0646 - mse: 0.8296 - val_loss: 0.0585 - val_mse: 0.7880\n",
      "Epoch 1061/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8236 - val_loss: 0.0587 - val_mse: 0.8018\n",
      "Epoch 1062/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8300 - val_loss: 0.0585 - val_mse: 0.7887\n",
      "Epoch 1063/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8174 - val_loss: 0.0586 - val_mse: 0.7904\n",
      "Epoch 1064/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8209 - val_loss: 0.0586 - val_mse: 0.7942\n",
      "Epoch 1065/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8218 - val_loss: 0.0584 - val_mse: 0.7872\n",
      "Epoch 1066/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8180 - val_loss: 0.0585 - val_mse: 0.7980\n",
      "Epoch 1067/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8342 - val_loss: 0.0586 - val_mse: 0.7969\n",
      "Epoch 1068/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8394 - val_loss: 0.0585 - val_mse: 0.7993\n",
      "Epoch 1069/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8238 - val_loss: 0.0588 - val_mse: 0.8025\n",
      "Epoch 1070/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0646 - mse: 0.8163\n",
      "Epoch 01070: saving model to Regression_Model/msle.linear-1070.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0646 - mse: 0.8154 - val_loss: 0.0585 - val_mse: 0.7988\n",
      "Epoch 1071/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8227 - val_loss: 0.0585 - val_mse: 0.7949\n",
      "Epoch 1072/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8286 - val_loss: 0.0585 - val_mse: 0.7949\n",
      "Epoch 1073/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8227 - val_loss: 0.0586 - val_mse: 0.7886\n",
      "Epoch 1074/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8287 - val_loss: 0.0585 - val_mse: 0.7916\n",
      "Epoch 1075/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8265 - val_loss: 0.0586 - val_mse: 0.7954\n",
      "Epoch 1076/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8410 - val_loss: 0.0585 - val_mse: 0.7911\n",
      "Epoch 1077/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8288 - val_loss: 0.0591 - val_mse: 0.7775\n",
      "Epoch 1078/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8248 - val_loss: 0.0587 - val_mse: 0.7825\n",
      "Epoch 1079/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8179 - val_loss: 0.0585 - val_mse: 0.7967\n",
      "Epoch 1080/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8288\n",
      "Epoch 01080: saving model to Regression_Model/msle.linear-1080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8291 - val_loss: 0.0586 - val_mse: 0.7842\n",
      "Epoch 1081/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8187 - val_loss: 0.0587 - val_mse: 0.7844\n",
      "Epoch 1082/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8207 - val_loss: 0.0586 - val_mse: 0.7952\n",
      "Epoch 1083/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8275 - val_loss: 0.0585 - val_mse: 0.7955\n",
      "Epoch 1084/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8196 - val_loss: 0.0586 - val_mse: 0.7837\n",
      "Epoch 1085/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8250 - val_loss: 0.0587 - val_mse: 0.8003\n",
      "Epoch 1086/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8254 - val_loss: 0.0586 - val_mse: 0.7961\n",
      "Epoch 1087/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8304 - val_loss: 0.0585 - val_mse: 0.7957\n",
      "Epoch 1088/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8205 - val_loss: 0.0585 - val_mse: 0.7902\n",
      "Epoch 1089/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8304 - val_loss: 0.0585 - val_mse: 0.7940\n",
      "Epoch 1090/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0653 - mse: 0.8242\n",
      "Epoch 01090: saving model to Regression_Model/msle.linear-1090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8245 - val_loss: 0.0585 - val_mse: 0.7935\n",
      "Epoch 1091/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8249 - val_loss: 0.0585 - val_mse: 0.7932\n",
      "Epoch 1092/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0640 - mse: 0.8156 - val_loss: 0.0588 - val_mse: 0.8036\n",
      "Epoch 1093/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8306 - val_loss: 0.0585 - val_mse: 0.7940\n",
      "Epoch 1094/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8237 - val_loss: 0.0585 - val_mse: 0.7963\n",
      "Epoch 1095/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8223 - val_loss: 0.0585 - val_mse: 0.7959\n",
      "Epoch 1096/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8268 - val_loss: 0.0585 - val_mse: 0.7971\n",
      "Epoch 1097/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8263 - val_loss: 0.0585 - val_mse: 0.7879\n",
      "Epoch 1098/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0656 - mse: 0.8312 - val_loss: 0.0585 - val_mse: 0.7930\n",
      "Epoch 1099/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8309 - val_loss: 0.0585 - val_mse: 0.7959\n",
      "Epoch 1100/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8228\n",
      "Epoch 01100: saving model to Regression_Model/msle.linear-1100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8223 - val_loss: 0.0586 - val_mse: 0.7979\n",
      "Epoch 1101/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8250 - val_loss: 0.0586 - val_mse: 0.7979\n",
      "Epoch 1102/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8282 - val_loss: 0.0585 - val_mse: 0.7938\n",
      "Epoch 1103/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8213 - val_loss: 0.0586 - val_mse: 0.7985\n",
      "Epoch 1104/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8271 - val_loss: 0.0586 - val_mse: 0.7851\n",
      "Epoch 1105/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8200 - val_loss: 0.0585 - val_mse: 0.7965\n",
      "Epoch 1106/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8220 - val_loss: 0.0584 - val_mse: 0.7945\n",
      "Epoch 1107/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8258 - val_loss: 0.0584 - val_mse: 0.7898\n",
      "Epoch 1108/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8283 - val_loss: 0.0586 - val_mse: 0.7842\n",
      "Epoch 1109/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8195 - val_loss: 0.0584 - val_mse: 0.7885\n",
      "Epoch 1110/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8201\n",
      "Epoch 01110: saving model to Regression_Model/msle.linear-1110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8204 - val_loss: 0.0585 - val_mse: 0.7827\n",
      "Epoch 1111/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8263 - val_loss: 0.0586 - val_mse: 0.7925\n",
      "Epoch 1112/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8342 - val_loss: 0.0585 - val_mse: 0.7942\n",
      "Epoch 1113/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8262 - val_loss: 0.0585 - val_mse: 0.7890\n",
      "Epoch 1114/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8345 - val_loss: 0.0584 - val_mse: 0.7941\n",
      "Epoch 1115/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8232 - val_loss: 0.0585 - val_mse: 0.7931\n",
      "Epoch 1116/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8205 - val_loss: 0.0587 - val_mse: 0.8028\n",
      "Epoch 1117/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8171 - val_loss: 0.0587 - val_mse: 0.7835\n",
      "Epoch 1118/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8204 - val_loss: 0.0589 - val_mse: 0.7815\n",
      "Epoch 1119/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8152 - val_loss: 0.0586 - val_mse: 0.8002\n",
      "Epoch 1120/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0649 - mse: 0.8368\n",
      "Epoch 01120: saving model to Regression_Model/msle.linear-1120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8357 - val_loss: 0.0585 - val_mse: 0.7982\n",
      "Epoch 1121/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8285 - val_loss: 0.0586 - val_mse: 0.7880\n",
      "Epoch 1122/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8224 - val_loss: 0.0585 - val_mse: 0.7952\n",
      "Epoch 1123/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8257 - val_loss: 0.0584 - val_mse: 0.7892\n",
      "Epoch 1124/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8261 - val_loss: 0.0585 - val_mse: 0.7926\n",
      "Epoch 1125/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8177 - val_loss: 0.0585 - val_mse: 0.7864\n",
      "Epoch 1126/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8194 - val_loss: 0.0585 - val_mse: 0.7898\n",
      "Epoch 1127/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8278 - val_loss: 0.0585 - val_mse: 0.7923\n",
      "Epoch 1128/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0652 - mse: 0.8268 - val_loss: 0.0586 - val_mse: 0.7945\n",
      "Epoch 1129/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8214 - val_loss: 0.0585 - val_mse: 0.7941\n",
      "Epoch 1130/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0661 - mse: 0.8315\n",
      "Epoch 01130: saving model to Regression_Model/msle.linear-1130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8325 - val_loss: 0.0588 - val_mse: 0.8042\n",
      "Epoch 1131/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8266 - val_loss: 0.0586 - val_mse: 0.8000\n",
      "Epoch 1132/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8300 - val_loss: 0.0586 - val_mse: 0.7913\n",
      "Epoch 1133/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8338 - val_loss: 0.0585 - val_mse: 0.7900\n",
      "Epoch 1134/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8252 - val_loss: 0.0584 - val_mse: 0.7887\n",
      "Epoch 1135/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8119 - val_loss: 0.0585 - val_mse: 0.7878\n",
      "Epoch 1136/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8225 - val_loss: 0.0585 - val_mse: 0.7962\n",
      "Epoch 1137/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8161 - val_loss: 0.0584 - val_mse: 0.7896\n",
      "Epoch 1138/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8327 - val_loss: 0.0586 - val_mse: 0.7890\n",
      "Epoch 1139/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0641 - mse: 0.8139 - val_loss: 0.0585 - val_mse: 0.7949\n",
      "Epoch 1140/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0644 - mse: 0.8148\n",
      "Epoch 01140: saving model to Regression_Model/msle.linear-1140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8154 - val_loss: 0.0584 - val_mse: 0.7912\n",
      "Epoch 1141/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8455 - val_loss: 0.0587 - val_mse: 0.7804\n",
      "Epoch 1142/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8235 - val_loss: 0.0584 - val_mse: 0.7933\n",
      "Epoch 1143/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0649 - mse: 0.8247"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=2000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-1000.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testid='msle.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
