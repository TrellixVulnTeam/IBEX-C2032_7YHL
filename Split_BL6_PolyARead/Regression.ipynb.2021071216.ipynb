{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(901)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 901, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 890, 16)           208       \n",
      "_________________________________________________________________\n",
      "group_normalization (GroupNo (None, 890, 16)           32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 890, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 74, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 74, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1184)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                37920     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 38,193\n",
      "Trainable params: 38,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 11484\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('coverage_data/Finetune.thle2_control.usage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+0.01)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+0.01)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    #train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    #valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0961154 2.145691\n",
      "4.6720033 1.6808125\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1b2268b358>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1001),train_x[5,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr1:1254882:-'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,train_id,16,901)\n",
    "validation_generator = DataGenerator(valid_x,valid_y,valid_id,0,901)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(901),a[9])\n",
    "plt.xticks(np.arange(0, 901, 100))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='thle2.mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 287 steps, validate for 71 steps\n",
      "Epoch 1/2000\n",
      "287/287 [==============================] - 3s 11ms/step - loss: 0.9659 - mse: 0.9581 - val_loss: 0.8047 - val_mse: 0.7963\n",
      "Epoch 2/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.8439 - mse: 0.8355 - val_loss: 0.7362 - val_mse: 0.7278\n",
      "Epoch 3/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.8345 - mse: 0.8261 - val_loss: 0.7446 - val_mse: 0.7362\n",
      "Epoch 4/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.7988 - mse: 0.7904 - val_loss: 0.7183 - val_mse: 0.7098\n",
      "Epoch 5/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.7700 - mse: 0.7616 - val_loss: 0.6760 - val_mse: 0.6676\n",
      "Epoch 6/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.7396 - mse: 0.7312 - val_loss: 0.6561 - val_mse: 0.6477\n",
      "Epoch 7/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.7317 - mse: 0.7233 - val_loss: 0.6522 - val_mse: 0.6438\n",
      "Epoch 8/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.7227 - mse: 0.7142 - val_loss: 0.6541 - val_mse: 0.6457\n",
      "Epoch 9/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6965 - mse: 0.6880 - val_loss: 0.6435 - val_mse: 0.6351\n",
      "Epoch 10/2000\n",
      "279/287 [============================>.] - ETA: 0s - loss: 0.6970 - mse: 0.6886\n",
      "Epoch 00010: saving model to Regression_Model/thle2.mle.linear-0010.ckpt\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 0.6978 - mse: 0.6894 - val_loss: 0.6473 - val_mse: 0.6389\n",
      "Epoch 11/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6920 - mse: 0.6836 - val_loss: 0.6237 - val_mse: 0.6153\n",
      "Epoch 12/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6839 - mse: 0.6755 - val_loss: 0.6505 - val_mse: 0.6421\n",
      "Epoch 13/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6937 - mse: 0.6853 - val_loss: 0.6374 - val_mse: 0.6290\n",
      "Epoch 14/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6965 - mse: 0.6881 - val_loss: 0.6192 - val_mse: 0.6108\n",
      "Epoch 15/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6921 - mse: 0.6837 - val_loss: 0.6274 - val_mse: 0.6189\n",
      "Epoch 16/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6834 - mse: 0.6750 - val_loss: 0.6682 - val_mse: 0.6598\n",
      "Epoch 17/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6768 - mse: 0.6684 - val_loss: 0.6189 - val_mse: 0.6104\n",
      "Epoch 18/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6748 - mse: 0.6664 - val_loss: 0.6200 - val_mse: 0.6115\n",
      "Epoch 19/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6844 - mse: 0.6760 - val_loss: 0.6413 - val_mse: 0.6329\n",
      "Epoch 20/2000\n",
      "281/287 [============================>.] - ETA: 0s - loss: 0.6733 - mse: 0.6649\n",
      "Epoch 00020: saving model to Regression_Model/thle2.mle.linear-0020.ckpt\n",
      "287/287 [==============================] - 3s 9ms/step - loss: 0.6729 - mse: 0.6645 - val_loss: 0.6235 - val_mse: 0.6151\n",
      "Epoch 21/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6733 - mse: 0.6649 - val_loss: 0.6297 - val_mse: 0.6213\n",
      "Epoch 22/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6812 - mse: 0.6728 - val_loss: 0.6262 - val_mse: 0.6177\n",
      "Epoch 23/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6748 - mse: 0.6664 - val_loss: 0.6046 - val_mse: 0.5962\n",
      "Epoch 24/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6603 - mse: 0.6519 - val_loss: 0.6228 - val_mse: 0.6144\n",
      "Epoch 25/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6775 - mse: 0.6691 - val_loss: 0.6299 - val_mse: 0.6215\n",
      "Epoch 26/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6731 - mse: 0.6647 - val_loss: 0.6121 - val_mse: 0.6036\n",
      "Epoch 27/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6649 - mse: 0.6564 - val_loss: 0.6176 - val_mse: 0.6092\n",
      "Epoch 28/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6749 - mse: 0.6665 - val_loss: 0.6565 - val_mse: 0.6481\n",
      "Epoch 29/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6637 - mse: 0.6552 - val_loss: 0.6154 - val_mse: 0.6069\n",
      "Epoch 30/2000\n",
      "283/287 [============================>.] - ETA: 0s - loss: 0.6576 - mse: 0.6492\n",
      "Epoch 00030: saving model to Regression_Model/thle2.mle.linear-0030.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6591 - mse: 0.6507 - val_loss: 0.6173 - val_mse: 0.6089\n",
      "Epoch 31/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6652 - mse: 0.6568 - val_loss: 0.6314 - val_mse: 0.6229\n",
      "Epoch 32/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6616 - mse: 0.6532 - val_loss: 0.6288 - val_mse: 0.6204\n",
      "Epoch 33/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6664 - mse: 0.6580 - val_loss: 0.6194 - val_mse: 0.6110\n",
      "Epoch 34/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6603 - mse: 0.6518 - val_loss: 0.6050 - val_mse: 0.5965\n",
      "Epoch 35/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6655 - mse: 0.6571 - val_loss: 0.6142 - val_mse: 0.6058\n",
      "Epoch 36/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6584 - mse: 0.6500 - val_loss: 0.5998 - val_mse: 0.5913\n",
      "Epoch 37/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6561 - mse: 0.6477 - val_loss: 0.6165 - val_mse: 0.6080\n",
      "Epoch 38/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6581 - mse: 0.6497 - val_loss: 0.6141 - val_mse: 0.6057\n",
      "Epoch 39/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6456 - mse: 0.6372 - val_loss: 0.6168 - val_mse: 0.6084\n",
      "Epoch 40/2000\n",
      "285/287 [============================>.] - ETA: 0s - loss: 0.6450 - mse: 0.6366\n",
      "Epoch 00040: saving model to Regression_Model/thle2.mle.linear-0040.ckpt\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6447 - mse: 0.6363 - val_loss: 0.6011 - val_mse: 0.5926\n",
      "Epoch 41/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6640 - mse: 0.6556 - val_loss: 0.6170 - val_mse: 0.6086\n",
      "Epoch 42/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6599 - mse: 0.6515 - val_loss: 0.6167 - val_mse: 0.6083\n",
      "Epoch 43/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6501 - mse: 0.6417 - val_loss: 0.6122 - val_mse: 0.6038\n",
      "Epoch 44/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6586 - mse: 0.6502 - val_loss: 0.6182 - val_mse: 0.6098\n",
      "Epoch 45/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6486 - mse: 0.6402 - val_loss: 0.6098 - val_mse: 0.6014\n",
      "Epoch 46/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6533 - mse: 0.6449 - val_loss: 0.6130 - val_mse: 0.6045\n",
      "Epoch 47/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6573 - mse: 0.6489 - val_loss: 0.6083 - val_mse: 0.5999\n",
      "Epoch 48/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6527 - mse: 0.6443 - val_loss: 0.6122 - val_mse: 0.6038\n",
      "Epoch 49/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6593 - mse: 0.6509 - val_loss: 0.6136 - val_mse: 0.6052\n",
      "Epoch 50/2000\n",
      "283/287 [============================>.] - ETA: 0s - loss: 0.6608 - mse: 0.6524\n",
      "Epoch 00050: saving model to Regression_Model/thle2.mle.linear-0050.ckpt\n",
      "287/287 [==============================] - 2s 7ms/step - loss: 0.6605 - mse: 0.6521 - val_loss: 0.6179 - val_mse: 0.6095\n",
      "Epoch 51/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6526 - mse: 0.6442 - val_loss: 0.6199 - val_mse: 0.6115\n",
      "Epoch 52/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6545 - mse: 0.6462 - val_loss: 0.6309 - val_mse: 0.6225\n",
      "Epoch 53/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6512 - mse: 0.6428 - val_loss: 0.6104 - val_mse: 0.6020\n",
      "Epoch 54/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6479 - mse: 0.6395 - val_loss: 0.5955 - val_mse: 0.5872\n",
      "Epoch 55/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6553 - mse: 0.6469 - val_loss: 0.6197 - val_mse: 0.6113\n",
      "Epoch 56/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6442 - mse: 0.6358 - val_loss: 0.6082 - val_mse: 0.5998\n",
      "Epoch 57/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6529 - mse: 0.6445 - val_loss: 0.6038 - val_mse: 0.5954\n",
      "Epoch 58/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6453 - mse: 0.6369 - val_loss: 0.6116 - val_mse: 0.6033\n",
      "Epoch 59/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6518 - mse: 0.6434 - val_loss: 0.6133 - val_mse: 0.6049\n",
      "Epoch 60/2000\n",
      "282/287 [============================>.] - ETA: 0s - loss: 0.6460 - mse: 0.6376\n",
      "Epoch 00060: saving model to Regression_Model/thle2.mle.linear-0060.ckpt\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6461 - mse: 0.6377 - val_loss: 0.6055 - val_mse: 0.5971\n",
      "Epoch 61/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6573 - mse: 0.6490 - val_loss: 0.6081 - val_mse: 0.5997\n",
      "Epoch 62/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6529 - mse: 0.6445 - val_loss: 0.6169 - val_mse: 0.6085\n",
      "Epoch 63/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6448 - mse: 0.6364 - val_loss: 0.6017 - val_mse: 0.5933\n",
      "Epoch 64/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6420 - mse: 0.6337 - val_loss: 0.6188 - val_mse: 0.6105\n",
      "Epoch 65/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6493 - mse: 0.6410 - val_loss: 0.5976 - val_mse: 0.5892\n",
      "Epoch 66/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6506 - mse: 0.6422 - val_loss: 0.6264 - val_mse: 0.6180\n",
      "Epoch 67/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6455 - mse: 0.6372 - val_loss: 0.6172 - val_mse: 0.6089\n",
      "Epoch 68/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6473 - mse: 0.6389 - val_loss: 0.6007 - val_mse: 0.5923\n",
      "Epoch 69/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6485 - mse: 0.6401 - val_loss: 0.6183 - val_mse: 0.6099\n",
      "Epoch 70/2000\n",
      "272/287 [===========================>..] - ETA: 0s - loss: 0.6524 - mse: 0.6440\n",
      "Epoch 00070: saving model to Regression_Model/thle2.mle.linear-0070.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6505 - mse: 0.6421 - val_loss: 0.6090 - val_mse: 0.6007\n",
      "Epoch 71/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6486 - mse: 0.6402 - val_loss: 0.5956 - val_mse: 0.5872\n",
      "Epoch 72/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6349 - mse: 0.6266 - val_loss: 0.6112 - val_mse: 0.6029\n",
      "Epoch 73/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6483 - mse: 0.6400 - val_loss: 0.5982 - val_mse: 0.5899\n",
      "Epoch 74/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6506 - mse: 0.6423 - val_loss: 0.6127 - val_mse: 0.6044\n",
      "Epoch 75/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6437 - mse: 0.6354 - val_loss: 0.6005 - val_mse: 0.5922\n",
      "Epoch 76/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6410 - mse: 0.6327 - val_loss: 0.6084 - val_mse: 0.6001\n",
      "Epoch 77/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6515 - mse: 0.6432 - val_loss: 0.6177 - val_mse: 0.6094\n",
      "Epoch 78/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6491 - mse: 0.6408 - val_loss: 0.5999 - val_mse: 0.5916\n",
      "Epoch 79/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6453 - mse: 0.6370 - val_loss: 0.6040 - val_mse: 0.5957\n",
      "Epoch 80/2000\n",
      "274/287 [===========================>..] - ETA: 0s - loss: 0.6369 - mse: 0.6286\n",
      "Epoch 00080: saving model to Regression_Model/thle2.mle.linear-0080.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6395 - mse: 0.6312 - val_loss: 0.6009 - val_mse: 0.5926\n",
      "Epoch 81/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6386 - mse: 0.6303 - val_loss: 0.6114 - val_mse: 0.6031\n",
      "Epoch 82/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6450 - mse: 0.6367 - val_loss: 0.6134 - val_mse: 0.6051\n",
      "Epoch 83/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6542 - mse: 0.6459 - val_loss: 0.6111 - val_mse: 0.6028\n",
      "Epoch 84/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6378 - mse: 0.6295 - val_loss: 0.6077 - val_mse: 0.5994\n",
      "Epoch 85/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6399 - mse: 0.6316 - val_loss: 0.6205 - val_mse: 0.6122\n",
      "Epoch 86/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6423 - mse: 0.6340 - val_loss: 0.5994 - val_mse: 0.5911\n",
      "Epoch 87/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6397 - mse: 0.6314 - val_loss: 0.6056 - val_mse: 0.5973\n",
      "Epoch 88/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6455 - mse: 0.6372 - val_loss: 0.6061 - val_mse: 0.5978\n",
      "Epoch 89/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6331 - mse: 0.6248 - val_loss: 0.5995 - val_mse: 0.5912\n",
      "Epoch 90/2000\n",
      "274/287 [===========================>..] - ETA: 0s - loss: 0.6348 - mse: 0.6265\n",
      "Epoch 00090: saving model to Regression_Model/thle2.mle.linear-0090.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6331 - mse: 0.6248 - val_loss: 0.5992 - val_mse: 0.5909\n",
      "Epoch 91/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6356 - mse: 0.6273 - val_loss: 0.5996 - val_mse: 0.5913\n",
      "Epoch 92/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6315 - mse: 0.6232 - val_loss: 0.5946 - val_mse: 0.5864\n",
      "Epoch 93/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6429 - mse: 0.6346 - val_loss: 0.6008 - val_mse: 0.5926\n",
      "Epoch 94/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6448 - mse: 0.6365 - val_loss: 0.6151 - val_mse: 0.6069\n",
      "Epoch 95/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6393 - mse: 0.6311 - val_loss: 0.6081 - val_mse: 0.5998\n",
      "Epoch 96/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6349 - mse: 0.6266 - val_loss: 0.5943 - val_mse: 0.5860\n",
      "Epoch 97/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6389 - mse: 0.6307 - val_loss: 0.5972 - val_mse: 0.5889\n",
      "Epoch 98/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6430 - mse: 0.6348 - val_loss: 0.6115 - val_mse: 0.6032\n",
      "Epoch 99/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6344 - mse: 0.6262 - val_loss: 0.6079 - val_mse: 0.5996\n",
      "Epoch 100/2000\n",
      "275/287 [===========================>..] - ETA: 0s - loss: 0.6253 - mse: 0.6171\n",
      "Epoch 00100: saving model to Regression_Model/thle2.mle.linear-0100.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6282 - mse: 0.6199 - val_loss: 0.5979 - val_mse: 0.5897\n",
      "Epoch 101/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6336 - mse: 0.6254 - val_loss: 0.5940 - val_mse: 0.5858\n",
      "Epoch 102/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6282 - mse: 0.6200 - val_loss: 0.6035 - val_mse: 0.5953\n",
      "Epoch 103/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6409 - mse: 0.6326 - val_loss: 0.6023 - val_mse: 0.5941\n",
      "Epoch 104/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6337 - mse: 0.6255 - val_loss: 0.5964 - val_mse: 0.5882\n",
      "Epoch 105/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6353 - mse: 0.6271 - val_loss: 0.5994 - val_mse: 0.5912\n",
      "Epoch 106/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6350 - mse: 0.6268 - val_loss: 0.6008 - val_mse: 0.5926\n",
      "Epoch 107/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6384 - mse: 0.6302 - val_loss: 0.6276 - val_mse: 0.6194\n",
      "Epoch 108/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6409 - mse: 0.6327 - val_loss: 0.6022 - val_mse: 0.5940\n",
      "Epoch 109/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6342 - mse: 0.6260 - val_loss: 0.6054 - val_mse: 0.5972\n",
      "Epoch 110/2000\n",
      "283/287 [============================>.] - ETA: 0s - loss: 0.6353 - mse: 0.6271\n",
      "Epoch 00110: saving model to Regression_Model/thle2.mle.linear-0110.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6344 - mse: 0.6262 - val_loss: 0.6056 - val_mse: 0.5974\n",
      "Epoch 111/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6344 - mse: 0.6262 - val_loss: 0.6053 - val_mse: 0.5972\n",
      "Epoch 112/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6313 - mse: 0.6231 - val_loss: 0.6001 - val_mse: 0.5919\n",
      "Epoch 113/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6374 - mse: 0.6292 - val_loss: 0.5923 - val_mse: 0.5841\n",
      "Epoch 114/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6287 - mse: 0.6205 - val_loss: 0.5958 - val_mse: 0.5877\n",
      "Epoch 115/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6446 - mse: 0.6364 - val_loss: 0.5930 - val_mse: 0.5848\n",
      "Epoch 116/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6450 - mse: 0.6368 - val_loss: 0.6116 - val_mse: 0.6034\n",
      "Epoch 117/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6381 - mse: 0.6299 - val_loss: 0.6072 - val_mse: 0.5990\n",
      "Epoch 118/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6392 - mse: 0.6310 - val_loss: 0.6148 - val_mse: 0.6067\n",
      "Epoch 119/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6303 - mse: 0.6221 - val_loss: 0.6010 - val_mse: 0.5928\n",
      "Epoch 120/2000\n",
      "282/287 [============================>.] - ETA: 0s - loss: 0.6245 - mse: 0.6164\n",
      "Epoch 00120: saving model to Regression_Model/thle2.mle.linear-0120.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6274 - mse: 0.6192 - val_loss: 0.6022 - val_mse: 0.5941\n",
      "Epoch 121/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6309 - mse: 0.6227 - val_loss: 0.5914 - val_mse: 0.5832\n",
      "Epoch 122/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6285 - mse: 0.6203 - val_loss: 0.6020 - val_mse: 0.5939\n",
      "Epoch 123/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6365 - mse: 0.6283 - val_loss: 0.6104 - val_mse: 0.6022\n",
      "Epoch 124/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6298 - mse: 0.6216 - val_loss: 0.5995 - val_mse: 0.5913\n",
      "Epoch 125/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6395 - mse: 0.6314 - val_loss: 0.5996 - val_mse: 0.5914\n",
      "Epoch 126/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6361 - mse: 0.6279 - val_loss: 0.5972 - val_mse: 0.5891\n",
      "Epoch 127/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6285 - mse: 0.6203 - val_loss: 0.6101 - val_mse: 0.6020\n",
      "Epoch 128/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6274 - mse: 0.6193 - val_loss: 0.5995 - val_mse: 0.5913\n",
      "Epoch 129/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6317 - mse: 0.6236 - val_loss: 0.5982 - val_mse: 0.5901\n",
      "Epoch 130/2000\n",
      "286/287 [============================>.] - ETA: 0s - loss: 0.6379 - mse: 0.6298\n",
      "Epoch 00130: saving model to Regression_Model/thle2.mle.linear-0130.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6394 - mse: 0.6313 - val_loss: 0.6185 - val_mse: 0.6104\n",
      "Epoch 131/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6355 - mse: 0.6274 - val_loss: 0.5920 - val_mse: 0.5839\n",
      "Epoch 132/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6284 - mse: 0.6203 - val_loss: 0.6095 - val_mse: 0.6013\n",
      "Epoch 133/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6369 - mse: 0.6288 - val_loss: 0.5977 - val_mse: 0.5896\n",
      "Epoch 134/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6306 - mse: 0.6225 - val_loss: 0.6061 - val_mse: 0.5980\n",
      "Epoch 135/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6337 - mse: 0.6256 - val_loss: 0.6016 - val_mse: 0.5934\n",
      "Epoch 136/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6260 - mse: 0.6179 - val_loss: 0.5884 - val_mse: 0.5803\n",
      "Epoch 137/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6353 - mse: 0.6271 - val_loss: 0.6047 - val_mse: 0.5965\n",
      "Epoch 138/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6249 - mse: 0.6168 - val_loss: 0.6047 - val_mse: 0.5966\n",
      "Epoch 139/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6264 - mse: 0.6183 - val_loss: 0.5957 - val_mse: 0.5876\n",
      "Epoch 140/2000\n",
      "282/287 [============================>.] - ETA: 0s - loss: 0.6378 - mse: 0.6297\n",
      "Epoch 00140: saving model to Regression_Model/thle2.mle.linear-0140.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6359 - mse: 0.6278 - val_loss: 0.5998 - val_mse: 0.5917\n",
      "Epoch 141/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6293 - mse: 0.6212 - val_loss: 0.5951 - val_mse: 0.5870\n",
      "Epoch 142/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6279 - mse: 0.6198 - val_loss: 0.6109 - val_mse: 0.6028\n",
      "Epoch 143/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6249 - mse: 0.6168 - val_loss: 0.6007 - val_mse: 0.5926\n",
      "Epoch 144/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6329 - mse: 0.6248 - val_loss: 0.6113 - val_mse: 0.6033\n",
      "Epoch 145/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6328 - mse: 0.6248 - val_loss: 0.5971 - val_mse: 0.5890\n",
      "Epoch 146/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6335 - mse: 0.6254 - val_loss: 0.5972 - val_mse: 0.5891\n",
      "Epoch 147/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6195 - mse: 0.6115 - val_loss: 0.6006 - val_mse: 0.5926\n",
      "Epoch 148/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6212 - mse: 0.6131 - val_loss: 0.5969 - val_mse: 0.5889\n",
      "Epoch 149/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6202 - mse: 0.6121 - val_loss: 0.5977 - val_mse: 0.5896\n",
      "Epoch 150/2000\n",
      "284/287 [============================>.] - ETA: 0s - loss: 0.6271 - mse: 0.6190\n",
      "Epoch 00150: saving model to Regression_Model/thle2.mle.linear-0150.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6260 - mse: 0.6179 - val_loss: 0.5997 - val_mse: 0.5916\n",
      "Epoch 151/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6289 - mse: 0.6209 - val_loss: 0.6046 - val_mse: 0.5966\n",
      "Epoch 152/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6300 - mse: 0.6219 - val_loss: 0.5896 - val_mse: 0.5815\n",
      "Epoch 153/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6257 - mse: 0.6176 - val_loss: 0.6024 - val_mse: 0.5943\n",
      "Epoch 154/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6288 - mse: 0.6207 - val_loss: 0.5971 - val_mse: 0.5891\n",
      "Epoch 155/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6224 - mse: 0.6143 - val_loss: 0.5959 - val_mse: 0.5878\n",
      "Epoch 156/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6257 - mse: 0.6177 - val_loss: 0.5947 - val_mse: 0.5867\n",
      "Epoch 157/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6253 - mse: 0.6172 - val_loss: 0.6072 - val_mse: 0.5992\n",
      "Epoch 158/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6232 - mse: 0.6152 - val_loss: 0.6033 - val_mse: 0.5953\n",
      "Epoch 159/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6276 - mse: 0.6196 - val_loss: 0.6067 - val_mse: 0.5987\n",
      "Epoch 160/2000\n",
      "281/287 [============================>.] - ETA: 0s - loss: 0.6249 - mse: 0.6169\n",
      "Epoch 00160: saving model to Regression_Model/thle2.mle.linear-0160.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6235 - mse: 0.6155 - val_loss: 0.6108 - val_mse: 0.6028\n",
      "Epoch 161/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6261 - mse: 0.6181 - val_loss: 0.6007 - val_mse: 0.5926\n",
      "Epoch 162/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6313 - mse: 0.6233 - val_loss: 0.6025 - val_mse: 0.5945\n",
      "Epoch 163/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6243 - mse: 0.6162 - val_loss: 0.5866 - val_mse: 0.5786\n",
      "Epoch 164/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6239 - mse: 0.6159 - val_loss: 0.5923 - val_mse: 0.5843\n",
      "Epoch 165/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6230 - mse: 0.6150 - val_loss: 0.5964 - val_mse: 0.5884\n",
      "Epoch 166/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6311 - mse: 0.6231 - val_loss: 0.5935 - val_mse: 0.5855\n",
      "Epoch 167/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6364 - mse: 0.6283 - val_loss: 0.5919 - val_mse: 0.5838\n",
      "Epoch 168/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6252 - mse: 0.6172 - val_loss: 0.6096 - val_mse: 0.6016\n",
      "Epoch 169/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6230 - mse: 0.6150 - val_loss: 0.5924 - val_mse: 0.5844\n",
      "Epoch 170/2000\n",
      "279/287 [============================>.] - ETA: 0s - loss: 0.6219 - mse: 0.6139\n",
      "Epoch 00170: saving model to Regression_Model/thle2.mle.linear-0170.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6201 - mse: 0.6121 - val_loss: 0.6007 - val_mse: 0.5927\n",
      "Epoch 171/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6328 - mse: 0.6248 - val_loss: 0.5962 - val_mse: 0.5882\n",
      "Epoch 172/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6244 - mse: 0.6165 - val_loss: 0.5919 - val_mse: 0.5839\n",
      "Epoch 173/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6264 - mse: 0.6184 - val_loss: 0.5918 - val_mse: 0.5838\n",
      "Epoch 174/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6238 - mse: 0.6158 - val_loss: 0.6115 - val_mse: 0.6035\n",
      "Epoch 175/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6251 - mse: 0.6171 - val_loss: 0.6059 - val_mse: 0.5979\n",
      "Epoch 176/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6240 - mse: 0.6160 - val_loss: 0.6001 - val_mse: 0.5921\n",
      "Epoch 177/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6262 - mse: 0.6183 - val_loss: 0.6023 - val_mse: 0.5944\n",
      "Epoch 178/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6233 - mse: 0.6153 - val_loss: 0.5864 - val_mse: 0.5785\n",
      "Epoch 179/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6287 - mse: 0.6207 - val_loss: 0.5864 - val_mse: 0.5784\n",
      "Epoch 180/2000\n",
      "272/287 [===========================>..] - ETA: 0s - loss: 0.6188 - mse: 0.6108\n",
      "Epoch 00180: saving model to Regression_Model/thle2.mle.linear-0180.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6193 - mse: 0.6113 - val_loss: 0.5950 - val_mse: 0.5871\n",
      "Epoch 181/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6256 - mse: 0.6176 - val_loss: 0.5972 - val_mse: 0.5893\n",
      "Epoch 182/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6204 - mse: 0.6124 - val_loss: 0.5928 - val_mse: 0.5848\n",
      "Epoch 183/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6321 - mse: 0.6242 - val_loss: 0.5998 - val_mse: 0.5918\n",
      "Epoch 184/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6210 - mse: 0.6131 - val_loss: 0.6021 - val_mse: 0.5942\n",
      "Epoch 185/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6309 - mse: 0.6230 - val_loss: 0.6032 - val_mse: 0.5952\n",
      "Epoch 186/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6197 - mse: 0.6117 - val_loss: 0.5914 - val_mse: 0.5835\n",
      "Epoch 187/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6198 - mse: 0.6119 - val_loss: 0.6074 - val_mse: 0.5994\n",
      "Epoch 188/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6328 - mse: 0.6249 - val_loss: 0.6013 - val_mse: 0.5934\n",
      "Epoch 189/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6231 - mse: 0.6152 - val_loss: 0.6006 - val_mse: 0.5927\n",
      "Epoch 190/2000\n",
      "275/287 [===========================>..] - ETA: 0s - loss: 0.6170 - mse: 0.6090\n",
      "Epoch 00190: saving model to Regression_Model/thle2.mle.linear-0190.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6164 - mse: 0.6085 - val_loss: 0.5930 - val_mse: 0.5851\n",
      "Epoch 191/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6161 - mse: 0.6082 - val_loss: 0.6002 - val_mse: 0.5923\n",
      "Epoch 192/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6261 - mse: 0.6182 - val_loss: 0.6112 - val_mse: 0.6032\n",
      "Epoch 193/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6217 - mse: 0.6138 - val_loss: 0.5961 - val_mse: 0.5882\n",
      "Epoch 194/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6219 - mse: 0.6140 - val_loss: 0.5917 - val_mse: 0.5838\n",
      "Epoch 195/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6187 - mse: 0.6108 - val_loss: 0.5914 - val_mse: 0.5835\n",
      "Epoch 196/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6200 - mse: 0.6121 - val_loss: 0.6024 - val_mse: 0.5945\n",
      "Epoch 197/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6237 - mse: 0.6158 - val_loss: 0.5924 - val_mse: 0.5845\n",
      "Epoch 198/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6208 - mse: 0.6129 - val_loss: 0.5978 - val_mse: 0.5899\n",
      "Epoch 199/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6204 - mse: 0.6126 - val_loss: 0.5935 - val_mse: 0.5856\n",
      "Epoch 200/2000\n",
      "281/287 [============================>.] - ETA: 0s - loss: 0.6107 - mse: 0.6029\n",
      "Epoch 00200: saving model to Regression_Model/thle2.mle.linear-0200.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6105 - mse: 0.6026 - val_loss: 0.5988 - val_mse: 0.5909\n",
      "Epoch 201/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6267 - mse: 0.6188 - val_loss: 0.5976 - val_mse: 0.5897\n",
      "Epoch 202/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6141 - mse: 0.6062 - val_loss: 0.6078 - val_mse: 0.5999\n",
      "Epoch 203/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6252 - mse: 0.6173 - val_loss: 0.5948 - val_mse: 0.5869\n",
      "Epoch 204/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6138 - mse: 0.6059 - val_loss: 0.5898 - val_mse: 0.5820\n",
      "Epoch 205/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6233 - mse: 0.6155 - val_loss: 0.5960 - val_mse: 0.5881\n",
      "Epoch 206/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6175 - mse: 0.6096 - val_loss: 0.5957 - val_mse: 0.5879\n",
      "Epoch 207/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6213 - mse: 0.6134 - val_loss: 0.5921 - val_mse: 0.5843\n",
      "Epoch 208/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6179 - mse: 0.6100 - val_loss: 0.5902 - val_mse: 0.5824\n",
      "Epoch 209/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6212 - mse: 0.6134 - val_loss: 0.5928 - val_mse: 0.5849\n",
      "Epoch 210/2000\n",
      "277/287 [===========================>..] - ETA: 0s - loss: 0.6161 - mse: 0.6082\n",
      "Epoch 00210: saving model to Regression_Model/thle2.mle.linear-0210.ckpt\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6156 - mse: 0.6078 - val_loss: 0.5969 - val_mse: 0.5891\n",
      "Epoch 211/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6178 - mse: 0.6099 - val_loss: 0.5948 - val_mse: 0.5870\n",
      "Epoch 212/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6103 - mse: 0.6025 - val_loss: 0.5928 - val_mse: 0.5850\n",
      "Epoch 213/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6099 - mse: 0.6020 - val_loss: 0.5950 - val_mse: 0.5872\n",
      "Epoch 214/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6179 - mse: 0.6101 - val_loss: 0.5903 - val_mse: 0.5825\n",
      "Epoch 215/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6122 - mse: 0.6043 - val_loss: 0.5850 - val_mse: 0.5772\n",
      "Epoch 216/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6232 - mse: 0.6154 - val_loss: 0.5951 - val_mse: 0.5873\n",
      "Epoch 217/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6186 - mse: 0.6107 - val_loss: 0.6004 - val_mse: 0.5926\n",
      "Epoch 218/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6176 - mse: 0.6098 - val_loss: 0.6003 - val_mse: 0.5925\n",
      "Epoch 219/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6189 - mse: 0.6111 - val_loss: 0.5903 - val_mse: 0.5825\n",
      "Epoch 220/2000\n",
      "275/287 [===========================>..] - ETA: 0s - loss: 0.6247 - mse: 0.6169\n",
      "Epoch 00220: saving model to Regression_Model/thle2.mle.linear-0220.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6228 - mse: 0.6150 - val_loss: 0.5867 - val_mse: 0.5789\n",
      "Epoch 221/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6170 - mse: 0.6092 - val_loss: 0.5902 - val_mse: 0.5824\n",
      "Epoch 222/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6197 - mse: 0.6119 - val_loss: 0.5916 - val_mse: 0.5838\n",
      "Epoch 223/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6164 - mse: 0.6086 - val_loss: 0.5905 - val_mse: 0.5827\n",
      "Epoch 224/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6124 - mse: 0.6046 - val_loss: 0.5962 - val_mse: 0.5884\n",
      "Epoch 225/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6211 - mse: 0.6133 - val_loss: 0.6003 - val_mse: 0.5925\n",
      "Epoch 226/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6219 - mse: 0.6141 - val_loss: 0.6049 - val_mse: 0.5971\n",
      "Epoch 227/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6227 - mse: 0.6149 - val_loss: 0.6008 - val_mse: 0.5930\n",
      "Epoch 228/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6244 - mse: 0.6167 - val_loss: 0.5948 - val_mse: 0.5871\n",
      "Epoch 229/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6212 - mse: 0.6134 - val_loss: 0.5886 - val_mse: 0.5808\n",
      "Epoch 230/2000\n",
      "278/287 [============================>.] - ETA: 0s - loss: 0.6268 - mse: 0.6190\n",
      "Epoch 00230: saving model to Regression_Model/thle2.mle.linear-0230.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6246 - mse: 0.6169 - val_loss: 0.5892 - val_mse: 0.5815\n",
      "Epoch 231/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6166 - mse: 0.6088 - val_loss: 0.5868 - val_mse: 0.5790\n",
      "Epoch 232/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6134 - mse: 0.6056 - val_loss: 0.5902 - val_mse: 0.5824\n",
      "Epoch 233/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6299 - mse: 0.6221 - val_loss: 0.5870 - val_mse: 0.5792\n",
      "Epoch 234/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6098 - mse: 0.6020 - val_loss: 0.5869 - val_mse: 0.5791\n",
      "Epoch 235/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6250 - mse: 0.6173 - val_loss: 0.6040 - val_mse: 0.5962\n",
      "Epoch 236/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6237 - mse: 0.6159 - val_loss: 0.6122 - val_mse: 0.6045\n",
      "Epoch 237/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6229 - mse: 0.6152 - val_loss: 0.5959 - val_mse: 0.5882\n",
      "Epoch 238/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6192 - mse: 0.6115 - val_loss: 0.5957 - val_mse: 0.5879\n",
      "Epoch 239/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6171 - mse: 0.6094 - val_loss: 0.5884 - val_mse: 0.5807\n",
      "Epoch 240/2000\n",
      "279/287 [============================>.] - ETA: 0s - loss: 0.6176 - mse: 0.6099\n",
      "Epoch 00240: saving model to Regression_Model/thle2.mle.linear-0240.ckpt\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6203 - mse: 0.6125 - val_loss: 0.5925 - val_mse: 0.5848\n",
      "Epoch 241/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6236 - mse: 0.6159 - val_loss: 0.5906 - val_mse: 0.5828\n",
      "Epoch 242/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6157 - mse: 0.6080 - val_loss: 0.5878 - val_mse: 0.5801\n",
      "Epoch 243/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6124 - mse: 0.6047 - val_loss: 0.5970 - val_mse: 0.5893\n",
      "Epoch 244/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6182 - mse: 0.6104 - val_loss: 0.5926 - val_mse: 0.5849\n",
      "Epoch 245/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6175 - mse: 0.6098 - val_loss: 0.5929 - val_mse: 0.5852\n",
      "Epoch 246/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6141 - mse: 0.6064 - val_loss: 0.5936 - val_mse: 0.5859\n",
      "Epoch 247/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6167 - mse: 0.6090 - val_loss: 0.5939 - val_mse: 0.5862\n",
      "Epoch 248/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6160 - mse: 0.6083 - val_loss: 0.5912 - val_mse: 0.5835\n",
      "Epoch 249/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6106 - mse: 0.6029 - val_loss: 0.5891 - val_mse: 0.5814\n",
      "Epoch 250/2000\n",
      "280/287 [============================>.] - ETA: 0s - loss: 0.6140 - mse: 0.6063\n",
      "Epoch 00250: saving model to Regression_Model/thle2.mle.linear-0250.ckpt\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6131 - mse: 0.6054 - val_loss: 0.5943 - val_mse: 0.5866\n",
      "Epoch 251/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6153 - mse: 0.6076 - val_loss: 0.5966 - val_mse: 0.5889\n",
      "Epoch 252/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6176 - mse: 0.6099 - val_loss: 0.5931 - val_mse: 0.5854\n",
      "Epoch 253/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6135 - mse: 0.6058 - val_loss: 0.5957 - val_mse: 0.5880\n",
      "Epoch 254/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6104 - mse: 0.6027 - val_loss: 0.5931 - val_mse: 0.5854\n",
      "Epoch 255/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6148 - mse: 0.6072 - val_loss: 0.6112 - val_mse: 0.6036\n",
      "Epoch 256/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6190 - mse: 0.6114 - val_loss: 0.5909 - val_mse: 0.5833\n",
      "Epoch 257/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6173 - mse: 0.6096 - val_loss: 0.5921 - val_mse: 0.5844\n",
      "Epoch 258/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6128 - mse: 0.6051 - val_loss: 0.5867 - val_mse: 0.5791\n",
      "Epoch 259/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6158 - mse: 0.6082 - val_loss: 0.6082 - val_mse: 0.6006\n",
      "Epoch 260/2000\n",
      "285/287 [============================>.] - ETA: 0s - loss: 0.6185 - mse: 0.6109\n",
      "Epoch 00260: saving model to Regression_Model/thle2.mle.linear-0260.ckpt\n",
      "287/287 [==============================] - 3s 12ms/step - loss: 0.6188 - mse: 0.6111 - val_loss: 0.5985 - val_mse: 0.5908\n",
      "Epoch 261/2000\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6096 - mse: 0.6019 - val_loss: 0.5889 - val_mse: 0.5813\n",
      "Epoch 262/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6110 - mse: 0.6033 - val_loss: 0.5971 - val_mse: 0.5895\n",
      "Epoch 263/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6131 - mse: 0.6055 - val_loss: 0.5880 - val_mse: 0.5803\n",
      "Epoch 264/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6124 - mse: 0.6048 - val_loss: 0.5890 - val_mse: 0.5814\n",
      "Epoch 265/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6189 - mse: 0.6113 - val_loss: 0.5887 - val_mse: 0.5810\n",
      "Epoch 266/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6155 - mse: 0.6079 - val_loss: 0.5902 - val_mse: 0.5826\n",
      "Epoch 267/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6209 - mse: 0.6133 - val_loss: 0.5915 - val_mse: 0.5839\n",
      "Epoch 268/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6087 - mse: 0.6010 - val_loss: 0.5986 - val_mse: 0.5909\n",
      "Epoch 269/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6207 - mse: 0.6131 - val_loss: 0.6000 - val_mse: 0.5923\n",
      "Epoch 270/2000\n",
      "280/287 [============================>.] - ETA: 0s - loss: 0.6194 - mse: 0.6118\n",
      "Epoch 00270: saving model to Regression_Model/thle2.mle.linear-0270.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6220 - mse: 0.6144 - val_loss: 0.5923 - val_mse: 0.5847\n",
      "Epoch 271/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6131 - mse: 0.6054 - val_loss: 0.5926 - val_mse: 0.5850\n",
      "Epoch 272/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6155 - mse: 0.6079 - val_loss: 0.5978 - val_mse: 0.5902\n",
      "Epoch 273/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6255 - mse: 0.6178 - val_loss: 0.6100 - val_mse: 0.6024\n",
      "Epoch 274/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6182 - mse: 0.6106 - val_loss: 0.5897 - val_mse: 0.5821\n",
      "Epoch 275/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6151 - mse: 0.6075 - val_loss: 0.5890 - val_mse: 0.5814\n",
      "Epoch 276/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6085 - mse: 0.6009 - val_loss: 0.5920 - val_mse: 0.5844\n",
      "Epoch 277/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6152 - mse: 0.6076 - val_loss: 0.5923 - val_mse: 0.5846\n",
      "Epoch 278/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6158 - mse: 0.6082 - val_loss: 0.5955 - val_mse: 0.5879\n",
      "Epoch 279/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6127 - mse: 0.6051 - val_loss: 0.5921 - val_mse: 0.5845\n",
      "Epoch 280/2000\n",
      "281/287 [============================>.] - ETA: 0s - loss: 0.6194 - mse: 0.6118\n",
      "Epoch 00280: saving model to Regression_Model/thle2.mle.linear-0280.ckpt\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6204 - mse: 0.6128 - val_loss: 0.5900 - val_mse: 0.5824\n",
      "Epoch 281/2000\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6154 - mse: 0.6078 - val_loss: 0.5951 - val_mse: 0.5875\n",
      "Epoch 282/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6128 - mse: 0.6052 - val_loss: 0.5943 - val_mse: 0.5867\n",
      "Epoch 283/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6139 - mse: 0.6063 - val_loss: 0.5890 - val_mse: 0.5814\n",
      "Epoch 284/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6139 - mse: 0.6063 - val_loss: 0.5905 - val_mse: 0.5829\n",
      "Epoch 285/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6168 - mse: 0.6092 - val_loss: 0.5959 - val_mse: 0.5883\n",
      "Epoch 286/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6164 - mse: 0.6088 - val_loss: 0.5920 - val_mse: 0.5844\n",
      "Epoch 287/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6127 - mse: 0.6052 - val_loss: 0.5955 - val_mse: 0.5879\n",
      "Epoch 288/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6122 - mse: 0.6046 - val_loss: 0.5902 - val_mse: 0.5827\n",
      "Epoch 289/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6137 - mse: 0.6061 - val_loss: 0.5957 - val_mse: 0.5882\n",
      "Epoch 290/2000\n",
      "286/287 [============================>.] - ETA: 0s - loss: 0.6144 - mse: 0.6069\n",
      "Epoch 00290: saving model to Regression_Model/thle2.mle.linear-0290.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6141 - mse: 0.6065 - val_loss: 0.5905 - val_mse: 0.5829\n",
      "Epoch 291/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6152 - mse: 0.6077 - val_loss: 0.5922 - val_mse: 0.5846\n",
      "Epoch 292/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6084 - mse: 0.6009 - val_loss: 0.5927 - val_mse: 0.5852\n",
      "Epoch 293/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6235 - mse: 0.6160 - val_loss: 0.5888 - val_mse: 0.5813\n",
      "Epoch 294/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6133 - mse: 0.6057 - val_loss: 0.5962 - val_mse: 0.5886\n",
      "Epoch 295/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6081 - mse: 0.6006 - val_loss: 0.5963 - val_mse: 0.5888\n",
      "Epoch 296/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6123 - mse: 0.6047 - val_loss: 0.5920 - val_mse: 0.5845\n",
      "Epoch 297/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6093 - mse: 0.6018 - val_loss: 0.5907 - val_mse: 0.5831\n",
      "Epoch 298/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6113 - mse: 0.6038 - val_loss: 0.5879 - val_mse: 0.5803\n",
      "Epoch 299/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6110 - mse: 0.6035 - val_loss: 0.5926 - val_mse: 0.5851\n",
      "Epoch 300/2000\n",
      "273/287 [===========================>..] - ETA: 0s - loss: 0.6215 - mse: 0.6140\n",
      "Epoch 00300: saving model to Regression_Model/thle2.mle.linear-0300.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6195 - mse: 0.6120 - val_loss: 0.5916 - val_mse: 0.5841\n",
      "Epoch 301/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6073 - mse: 0.5998 - val_loss: 0.5896 - val_mse: 0.5821\n",
      "Epoch 302/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6107 - mse: 0.6031 - val_loss: 0.5976 - val_mse: 0.5901\n",
      "Epoch 303/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6075 - mse: 0.6000 - val_loss: 0.5903 - val_mse: 0.5828\n",
      "Epoch 304/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6162 - mse: 0.6086 - val_loss: 0.5859 - val_mse: 0.5783\n",
      "Epoch 305/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6074 - mse: 0.5999 - val_loss: 0.5893 - val_mse: 0.5818\n",
      "Epoch 306/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6180 - mse: 0.6104 - val_loss: 0.5906 - val_mse: 0.5831\n",
      "Epoch 307/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6181 - mse: 0.6105 - val_loss: 0.5966 - val_mse: 0.5891\n",
      "Epoch 308/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6088 - mse: 0.6013 - val_loss: 0.6008 - val_mse: 0.5933\n",
      "Epoch 309/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6096 - mse: 0.6021 - val_loss: 0.6037 - val_mse: 0.5962\n",
      "Epoch 310/2000\n",
      "283/287 [============================>.] - ETA: 0s - loss: 0.6099 - mse: 0.6024\n",
      "Epoch 00310: saving model to Regression_Model/thle2.mle.linear-0310.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6099 - mse: 0.6024 - val_loss: 0.5894 - val_mse: 0.5819\n",
      "Epoch 311/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6109 - mse: 0.6034 - val_loss: 0.5935 - val_mse: 0.5860\n",
      "Epoch 312/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6122 - mse: 0.6047 - val_loss: 0.5890 - val_mse: 0.5815\n",
      "Epoch 313/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6155 - mse: 0.6080 - val_loss: 0.5896 - val_mse: 0.5821\n",
      "Epoch 314/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6090 - mse: 0.6016 - val_loss: 0.5898 - val_mse: 0.5823\n",
      "Epoch 315/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6176 - mse: 0.6101 - val_loss: 0.5869 - val_mse: 0.5794\n",
      "Epoch 316/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6122 - mse: 0.6048 - val_loss: 0.5946 - val_mse: 0.5871\n",
      "Epoch 317/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6093 - mse: 0.6018 - val_loss: 0.5913 - val_mse: 0.5838\n",
      "Epoch 318/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6083 - mse: 0.6008 - val_loss: 0.5954 - val_mse: 0.5879\n",
      "Epoch 319/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6103 - mse: 0.6028 - val_loss: 0.5920 - val_mse: 0.5846\n",
      "Epoch 320/2000\n",
      "286/287 [============================>.] - ETA: 0s - loss: 0.6116 - mse: 0.6041\n",
      "Epoch 00320: saving model to Regression_Model/thle2.mle.linear-0320.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6113 - mse: 0.6038 - val_loss: 0.5941 - val_mse: 0.5866\n",
      "Epoch 321/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6070 - mse: 0.5996 - val_loss: 0.5940 - val_mse: 0.5866\n",
      "Epoch 322/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6124 - mse: 0.6049 - val_loss: 0.5920 - val_mse: 0.5846\n",
      "Epoch 323/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6043 - mse: 0.5969 - val_loss: 0.5944 - val_mse: 0.5869\n",
      "Epoch 324/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6129 - mse: 0.6054 - val_loss: 0.5964 - val_mse: 0.5890\n",
      "Epoch 325/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6184 - mse: 0.6109 - val_loss: 0.5916 - val_mse: 0.5842\n",
      "Epoch 326/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6149 - mse: 0.6075 - val_loss: 0.5860 - val_mse: 0.5785\n",
      "Epoch 327/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6127 - mse: 0.6053 - val_loss: 0.5941 - val_mse: 0.5866\n",
      "Epoch 328/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6073 - mse: 0.5999 - val_loss: 0.5932 - val_mse: 0.5858\n",
      "Epoch 329/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6077 - mse: 0.6002 - val_loss: 0.5863 - val_mse: 0.5788\n",
      "Epoch 330/2000\n",
      "273/287 [===========================>..] - ETA: 0s - loss: 0.6140 - mse: 0.6065\n",
      "Epoch 00330: saving model to Regression_Model/thle2.mle.linear-0330.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6097 - mse: 0.6023 - val_loss: 0.5937 - val_mse: 0.5863\n",
      "Epoch 331/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6090 - mse: 0.6016 - val_loss: 0.5999 - val_mse: 0.5925\n",
      "Epoch 332/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6061 - mse: 0.5987 - val_loss: 0.5874 - val_mse: 0.5800\n",
      "Epoch 333/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6152 - mse: 0.6078 - val_loss: 0.5979 - val_mse: 0.5905\n",
      "Epoch 334/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6086 - mse: 0.6011 - val_loss: 0.5930 - val_mse: 0.5855\n",
      "Epoch 335/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6071 - mse: 0.5996 - val_loss: 0.5959 - val_mse: 0.5884\n",
      "Epoch 336/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6121 - mse: 0.6047 - val_loss: 0.5884 - val_mse: 0.5810\n",
      "Epoch 337/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6141 - mse: 0.6067 - val_loss: 0.5939 - val_mse: 0.5865\n",
      "Epoch 338/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6129 - mse: 0.6055 - val_loss: 0.5929 - val_mse: 0.5855\n",
      "Epoch 339/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6115 - mse: 0.6040 - val_loss: 0.5892 - val_mse: 0.5818\n",
      "Epoch 340/2000\n",
      "277/287 [===========================>..] - ETA: 0s - loss: 0.6117 - mse: 0.6043\n",
      "Epoch 00340: saving model to Regression_Model/thle2.mle.linear-0340.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6097 - mse: 0.6022 - val_loss: 0.5869 - val_mse: 0.5795\n",
      "Epoch 341/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6219 - mse: 0.6145 - val_loss: 0.5886 - val_mse: 0.5812\n",
      "Epoch 342/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6126 - mse: 0.6052 - val_loss: 0.5867 - val_mse: 0.5793\n",
      "Epoch 343/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6108 - mse: 0.6034 - val_loss: 0.5917 - val_mse: 0.5843\n",
      "Epoch 344/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6137 - mse: 0.6063 - val_loss: 0.5879 - val_mse: 0.5805\n",
      "Epoch 345/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6136 - mse: 0.6062 - val_loss: 0.5938 - val_mse: 0.5864\n",
      "Epoch 346/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6148 - mse: 0.6074 - val_loss: 0.5928 - val_mse: 0.5854\n",
      "Epoch 347/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6162 - mse: 0.6088 - val_loss: 0.5916 - val_mse: 0.5842\n",
      "Epoch 348/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6090 - mse: 0.6016 - val_loss: 0.6049 - val_mse: 0.5975\n",
      "Epoch 349/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6144 - mse: 0.6070 - val_loss: 0.6016 - val_mse: 0.5943\n",
      "Epoch 350/2000\n",
      "285/287 [============================>.] - ETA: 0s - loss: 0.6181 - mse: 0.6107\n",
      "Epoch 00350: saving model to Regression_Model/thle2.mle.linear-0350.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6186 - mse: 0.6112 - val_loss: 0.5880 - val_mse: 0.5806\n",
      "Epoch 351/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6122 - mse: 0.6048 - val_loss: 0.5881 - val_mse: 0.5807\n",
      "Epoch 352/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6126 - mse: 0.6052 - val_loss: 0.5923 - val_mse: 0.5849\n",
      "Epoch 353/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6094 - mse: 0.6020 - val_loss: 0.5856 - val_mse: 0.5782\n",
      "Epoch 354/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6022 - mse: 0.5949 - val_loss: 0.5926 - val_mse: 0.5853\n",
      "Epoch 355/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6107 - mse: 0.6033 - val_loss: 0.5872 - val_mse: 0.5798\n",
      "Epoch 356/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6133 - mse: 0.6059 - val_loss: 0.5946 - val_mse: 0.5872\n",
      "Epoch 357/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6105 - mse: 0.6031 - val_loss: 0.5967 - val_mse: 0.5894\n",
      "Epoch 358/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6112 - mse: 0.6038 - val_loss: 0.5922 - val_mse: 0.5849\n",
      "Epoch 359/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6115 - mse: 0.6041 - val_loss: 0.5876 - val_mse: 0.5802\n",
      "Epoch 360/2000\n",
      "285/287 [============================>.] - ETA: 0s - loss: 0.6136 - mse: 0.6062\n",
      "Epoch 00360: saving model to Regression_Model/thle2.mle.linear-0360.ckpt\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6138 - mse: 0.6065 - val_loss: 0.5914 - val_mse: 0.5841\n",
      "Epoch 361/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6152 - mse: 0.6078 - val_loss: 0.5875 - val_mse: 0.5802\n",
      "Epoch 362/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6186 - mse: 0.6113 - val_loss: 0.5883 - val_mse: 0.5810\n",
      "Epoch 363/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6119 - mse: 0.6046 - val_loss: 0.5970 - val_mse: 0.5896\n",
      "Epoch 364/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6058 - mse: 0.5984 - val_loss: 0.5906 - val_mse: 0.5833\n",
      "Epoch 365/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6045 - mse: 0.5971 - val_loss: 0.5924 - val_mse: 0.5851\n",
      "Epoch 366/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6071 - mse: 0.5997 - val_loss: 0.5940 - val_mse: 0.5866\n",
      "Epoch 367/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6147 - mse: 0.6074 - val_loss: 0.5914 - val_mse: 0.5840\n",
      "Epoch 368/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6110 - mse: 0.6036 - val_loss: 0.5859 - val_mse: 0.5786\n",
      "Epoch 369/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6139 - mse: 0.6065 - val_loss: 0.5909 - val_mse: 0.5836\n",
      "Epoch 370/2000\n",
      "280/287 [============================>.] - ETA: 0s - loss: 0.6202 - mse: 0.6129\n",
      "Epoch 00370: saving model to Regression_Model/thle2.mle.linear-0370.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6187 - mse: 0.6114 - val_loss: 0.5892 - val_mse: 0.5819\n",
      "Epoch 371/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6097 - mse: 0.6023 - val_loss: 0.5916 - val_mse: 0.5843\n",
      "Epoch 372/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6179 - mse: 0.6105 - val_loss: 0.5922 - val_mse: 0.5849\n",
      "Epoch 373/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6141 - mse: 0.6067 - val_loss: 0.5872 - val_mse: 0.5799\n",
      "Epoch 374/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6040 - mse: 0.5967 - val_loss: 0.5902 - val_mse: 0.5829\n",
      "Epoch 375/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6119 - mse: 0.6046 - val_loss: 0.5862 - val_mse: 0.5789\n",
      "Epoch 376/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6116 - mse: 0.6042 - val_loss: 0.5913 - val_mse: 0.5840\n",
      "Epoch 377/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6018 - mse: 0.5945 - val_loss: 0.5877 - val_mse: 0.5804\n",
      "Epoch 378/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6091 - mse: 0.6018 - val_loss: 0.5890 - val_mse: 0.5817\n",
      "Epoch 379/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6047 - mse: 0.5974 - val_loss: 0.5909 - val_mse: 0.5836\n",
      "Epoch 380/2000\n",
      "274/287 [===========================>..] - ETA: 0s - loss: 0.6127 - mse: 0.6054\n",
      "Epoch 00380: saving model to Regression_Model/thle2.mle.linear-0380.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6124 - mse: 0.6051 - val_loss: 0.5894 - val_mse: 0.5821\n",
      "Epoch 381/2000\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6133 - mse: 0.6060 - val_loss: 0.5944 - val_mse: 0.5871\n",
      "Epoch 382/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6061 - mse: 0.5988 - val_loss: 0.5887 - val_mse: 0.5814\n",
      "Epoch 383/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6078 - mse: 0.6005 - val_loss: 0.5926 - val_mse: 0.5853\n",
      "Epoch 384/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6117 - mse: 0.6044 - val_loss: 0.5955 - val_mse: 0.5882\n",
      "Epoch 385/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6150 - mse: 0.6077 - val_loss: 0.5868 - val_mse: 0.5795\n",
      "Epoch 386/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6108 - mse: 0.6035 - val_loss: 0.5927 - val_mse: 0.5854\n",
      "Epoch 387/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6118 - mse: 0.6045 - val_loss: 0.5936 - val_mse: 0.5863\n",
      "Epoch 388/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6125 - mse: 0.6052 - val_loss: 0.5861 - val_mse: 0.5788\n",
      "Epoch 389/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5996 - mse: 0.5923 - val_loss: 0.5907 - val_mse: 0.5834\n",
      "Epoch 390/2000\n",
      "277/287 [===========================>..] - ETA: 0s - loss: 0.6056 - mse: 0.5983\n",
      "Epoch 00390: saving model to Regression_Model/thle2.mle.linear-0390.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6074 - mse: 0.6001 - val_loss: 0.5953 - val_mse: 0.5880\n",
      "Epoch 391/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6137 - mse: 0.6064 - val_loss: 0.5897 - val_mse: 0.5825\n",
      "Epoch 392/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6095 - mse: 0.6023 - val_loss: 0.5961 - val_mse: 0.5888\n",
      "Epoch 393/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6102 - mse: 0.6030 - val_loss: 0.5885 - val_mse: 0.5812\n",
      "Epoch 394/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6163 - mse: 0.6090 - val_loss: 0.5891 - val_mse: 0.5818\n",
      "Epoch 395/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6175 - mse: 0.6102 - val_loss: 0.5925 - val_mse: 0.5852\n",
      "Epoch 396/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6153 - mse: 0.6080 - val_loss: 0.5839 - val_mse: 0.5767\n",
      "Epoch 397/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6068 - mse: 0.5996 - val_loss: 0.5920 - val_mse: 0.5847\n",
      "Epoch 398/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6105 - mse: 0.6032 - val_loss: 0.5875 - val_mse: 0.5802\n",
      "Epoch 399/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5939 - mse: 0.5866 - val_loss: 0.5856 - val_mse: 0.5784\n",
      "Epoch 400/2000\n",
      "280/287 [============================>.] - ETA: 0s - loss: 0.6079 - mse: 0.6006\n",
      "Epoch 00400: saving model to Regression_Model/thle2.mle.linear-0400.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6103 - mse: 0.6030 - val_loss: 0.5925 - val_mse: 0.5852\n",
      "Epoch 401/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6051 - mse: 0.5979 - val_loss: 0.5880 - val_mse: 0.5808\n",
      "Epoch 402/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6073 - mse: 0.6000 - val_loss: 0.5834 - val_mse: 0.5761\n",
      "Epoch 403/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6070 - mse: 0.5998 - val_loss: 0.5892 - val_mse: 0.5819\n",
      "Epoch 404/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6096 - mse: 0.6024 - val_loss: 0.5868 - val_mse: 0.5795\n",
      "Epoch 405/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6130 - mse: 0.6057 - val_loss: 0.5841 - val_mse: 0.5768\n",
      "Epoch 406/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6050 - mse: 0.5978 - val_loss: 0.5876 - val_mse: 0.5804\n",
      "Epoch 407/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6110 - mse: 0.6038 - val_loss: 0.5889 - val_mse: 0.5816\n",
      "Epoch 408/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6044 - mse: 0.5971 - val_loss: 0.5942 - val_mse: 0.5869\n",
      "Epoch 409/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6146 - mse: 0.6073 - val_loss: 0.5906 - val_mse: 0.5833\n",
      "Epoch 410/2000\n",
      "283/287 [============================>.] - ETA: 0s - loss: 0.6027 - mse: 0.5955\n",
      "Epoch 00410: saving model to Regression_Model/thle2.mle.linear-0410.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6054 - mse: 0.5982 - val_loss: 0.5941 - val_mse: 0.5868\n",
      "Epoch 411/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6032 - mse: 0.5959 - val_loss: 0.5923 - val_mse: 0.5851\n",
      "Epoch 412/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6148 - mse: 0.6076 - val_loss: 0.5965 - val_mse: 0.5893\n",
      "Epoch 413/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6074 - mse: 0.6001 - val_loss: 0.5918 - val_mse: 0.5846\n",
      "Epoch 414/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6058 - mse: 0.5986 - val_loss: 0.5844 - val_mse: 0.5772\n",
      "Epoch 415/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6102 - mse: 0.6029 - val_loss: 0.5869 - val_mse: 0.5797\n",
      "Epoch 416/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6035 - mse: 0.5963 - val_loss: 0.5869 - val_mse: 0.5796\n",
      "Epoch 417/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6039 - mse: 0.5966 - val_loss: 0.5907 - val_mse: 0.5835\n",
      "Epoch 418/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6058 - mse: 0.5986 - val_loss: 0.5946 - val_mse: 0.5874\n",
      "Epoch 419/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6076 - mse: 0.6003 - val_loss: 0.5899 - val_mse: 0.5827\n",
      "Epoch 420/2000\n",
      "272/287 [===========================>..] - ETA: 0s - loss: 0.6153 - mse: 0.6081\n",
      "Epoch 00420: saving model to Regression_Model/thle2.mle.linear-0420.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6134 - mse: 0.6061 - val_loss: 0.5870 - val_mse: 0.5798\n",
      "Epoch 421/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6097 - mse: 0.6025 - val_loss: 0.5962 - val_mse: 0.5890\n",
      "Epoch 422/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6037 - mse: 0.5965 - val_loss: 0.5878 - val_mse: 0.5806\n",
      "Epoch 423/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6077 - mse: 0.6005 - val_loss: 0.5900 - val_mse: 0.5828\n",
      "Epoch 424/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5967 - mse: 0.5895 - val_loss: 0.5948 - val_mse: 0.5876\n",
      "Epoch 425/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6029 - mse: 0.5957 - val_loss: 0.5893 - val_mse: 0.5821\n",
      "Epoch 426/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6104 - mse: 0.6032 - val_loss: 0.5940 - val_mse: 0.5868\n",
      "Epoch 427/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6072 - mse: 0.6000 - val_loss: 0.5944 - val_mse: 0.5872\n",
      "Epoch 428/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6004 - mse: 0.5932 - val_loss: 0.5865 - val_mse: 0.5793\n",
      "Epoch 429/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6046 - mse: 0.5974 - val_loss: 0.5930 - val_mse: 0.5858\n",
      "Epoch 430/2000\n",
      "280/287 [============================>.] - ETA: 0s - loss: 0.6099 - mse: 0.6028\n",
      "Epoch 00430: saving model to Regression_Model/thle2.mle.linear-0430.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6117 - mse: 0.6045 - val_loss: 0.5930 - val_mse: 0.5858\n",
      "Epoch 431/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6089 - mse: 0.6018 - val_loss: 0.5914 - val_mse: 0.5843\n",
      "Epoch 432/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6092 - mse: 0.6020 - val_loss: 0.5905 - val_mse: 0.5833\n",
      "Epoch 433/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6099 - mse: 0.6027 - val_loss: 0.5930 - val_mse: 0.5858\n",
      "Epoch 434/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6029 - mse: 0.5957 - val_loss: 0.5911 - val_mse: 0.5840\n",
      "Epoch 435/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6114 - mse: 0.6043 - val_loss: 0.5937 - val_mse: 0.5865\n",
      "Epoch 436/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6057 - mse: 0.5986 - val_loss: 0.5915 - val_mse: 0.5844\n",
      "Epoch 437/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6072 - mse: 0.6001 - val_loss: 0.5887 - val_mse: 0.5816\n",
      "Epoch 438/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6052 - mse: 0.5980 - val_loss: 0.5844 - val_mse: 0.5772\n",
      "Epoch 439/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6077 - mse: 0.6006 - val_loss: 0.5942 - val_mse: 0.5871\n",
      "Epoch 440/2000\n",
      "278/287 [============================>.] - ETA: 0s - loss: 0.6074 - mse: 0.6003\n",
      "Epoch 00440: saving model to Regression_Model/thle2.mle.linear-0440.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6068 - mse: 0.5997 - val_loss: 0.5924 - val_mse: 0.5853\n",
      "Epoch 441/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6084 - mse: 0.6012 - val_loss: 0.5884 - val_mse: 0.5813\n",
      "Epoch 442/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6031 - mse: 0.5959 - val_loss: 0.5898 - val_mse: 0.5827\n",
      "Epoch 443/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6076 - mse: 0.6004 - val_loss: 0.5881 - val_mse: 0.5809\n",
      "Epoch 444/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6097 - mse: 0.6025 - val_loss: 0.5870 - val_mse: 0.5798\n",
      "Epoch 445/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6092 - mse: 0.6020 - val_loss: 0.5856 - val_mse: 0.5785\n",
      "Epoch 446/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6121 - mse: 0.6050 - val_loss: 0.5885 - val_mse: 0.5814\n",
      "Epoch 447/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6062 - mse: 0.5990 - val_loss: 0.5953 - val_mse: 0.5881\n",
      "Epoch 448/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6084 - mse: 0.6013 - val_loss: 0.5870 - val_mse: 0.5799\n",
      "Epoch 449/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6021 - mse: 0.5950 - val_loss: 0.5875 - val_mse: 0.5804\n",
      "Epoch 450/2000\n",
      "286/287 [============================>.] - ETA: 0s - loss: 0.6065 - mse: 0.5994\n",
      "Epoch 00450: saving model to Regression_Model/thle2.mle.linear-0450.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6066 - mse: 0.5994 - val_loss: 0.5854 - val_mse: 0.5782\n",
      "Epoch 451/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6148 - mse: 0.6077 - val_loss: 0.5925 - val_mse: 0.5853\n",
      "Epoch 452/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.5981 - mse: 0.5909 - val_loss: 0.5849 - val_mse: 0.5777\n",
      "Epoch 453/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6068 - mse: 0.5996 - val_loss: 0.5873 - val_mse: 0.5802\n",
      "Epoch 454/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5979 - mse: 0.5908 - val_loss: 0.5935 - val_mse: 0.5863\n",
      "Epoch 455/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6045 - mse: 0.5974 - val_loss: 0.5880 - val_mse: 0.5808\n",
      "Epoch 456/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6055 - mse: 0.5984 - val_loss: 0.5902 - val_mse: 0.5831\n",
      "Epoch 457/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6063 - mse: 0.5991 - val_loss: 0.5848 - val_mse: 0.5777\n",
      "Epoch 458/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6101 - mse: 0.6030 - val_loss: 0.5874 - val_mse: 0.5803\n",
      "Epoch 459/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6003 - mse: 0.5931 - val_loss: 0.5934 - val_mse: 0.5863\n",
      "Epoch 460/2000\n",
      "284/287 [============================>.] - ETA: 0s - loss: 0.5937 - mse: 0.5866\n",
      "Epoch 00460: saving model to Regression_Model/thle2.mle.linear-0460.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5953 - mse: 0.5882 - val_loss: 0.5845 - val_mse: 0.5774\n",
      "Epoch 461/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6102 - mse: 0.6031 - val_loss: 0.5935 - val_mse: 0.5864\n",
      "Epoch 462/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6106 - mse: 0.6035 - val_loss: 0.5882 - val_mse: 0.5811\n",
      "Epoch 463/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6037 - mse: 0.5966 - val_loss: 0.5986 - val_mse: 0.5915\n",
      "Epoch 464/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6100 - mse: 0.6029 - val_loss: 0.5877 - val_mse: 0.5806\n",
      "Epoch 465/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6083 - mse: 0.6012 - val_loss: 0.5913 - val_mse: 0.5842\n",
      "Epoch 466/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6085 - mse: 0.6014 - val_loss: 0.5902 - val_mse: 0.5831\n",
      "Epoch 467/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6054 - mse: 0.5983 - val_loss: 0.5898 - val_mse: 0.5827\n",
      "Epoch 468/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6018 - mse: 0.5947 - val_loss: 0.5891 - val_mse: 0.5820\n",
      "Epoch 469/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6035 - mse: 0.5964 - val_loss: 0.5871 - val_mse: 0.5800\n",
      "Epoch 470/2000\n",
      "280/287 [============================>.] - ETA: 0s - loss: 0.6057 - mse: 0.5986\n",
      "Epoch 00470: saving model to Regression_Model/thle2.mle.linear-0470.ckpt\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6049 - mse: 0.5979 - val_loss: 0.5882 - val_mse: 0.5812\n",
      "Epoch 471/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6023 - mse: 0.5952 - val_loss: 0.5843 - val_mse: 0.5772\n",
      "Epoch 472/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6050 - mse: 0.5979 - val_loss: 0.5895 - val_mse: 0.5824\n",
      "Epoch 473/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6017 - mse: 0.5946 - val_loss: 0.5908 - val_mse: 0.5837\n",
      "Epoch 474/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6085 - mse: 0.6014 - val_loss: 0.5849 - val_mse: 0.5778\n",
      "Epoch 475/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6028 - mse: 0.5957 - val_loss: 0.5869 - val_mse: 0.5798\n",
      "Epoch 476/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6008 - mse: 0.5937 - val_loss: 0.5860 - val_mse: 0.5789\n",
      "Epoch 477/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6102 - mse: 0.6031 - val_loss: 0.5861 - val_mse: 0.5790\n",
      "Epoch 478/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6103 - mse: 0.6032 - val_loss: 0.5898 - val_mse: 0.5827\n",
      "Epoch 479/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6119 - mse: 0.6049 - val_loss: 0.5933 - val_mse: 0.5862\n",
      "Epoch 480/2000\n",
      "284/287 [============================>.] - ETA: 0s - loss: 0.6028 - mse: 0.5958\n",
      "Epoch 00480: saving model to Regression_Model/thle2.mle.linear-0480.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6027 - mse: 0.5957 - val_loss: 0.5865 - val_mse: 0.5794\n",
      "Epoch 481/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6025 - mse: 0.5954 - val_loss: 0.5884 - val_mse: 0.5813\n",
      "Epoch 482/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6013 - mse: 0.5942 - val_loss: 0.5853 - val_mse: 0.5782\n",
      "Epoch 483/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6041 - mse: 0.5971 - val_loss: 0.5868 - val_mse: 0.5798\n",
      "Epoch 484/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6014 - mse: 0.5944 - val_loss: 0.5912 - val_mse: 0.5842\n",
      "Epoch 485/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6086 - mse: 0.6015 - val_loss: 0.5891 - val_mse: 0.5820\n",
      "Epoch 486/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6124 - mse: 0.6053 - val_loss: 0.5836 - val_mse: 0.5766\n",
      "Epoch 487/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6005 - mse: 0.5934 - val_loss: 0.5909 - val_mse: 0.5839\n",
      "Epoch 488/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6090 - mse: 0.6019 - val_loss: 0.5862 - val_mse: 0.5791\n",
      "Epoch 489/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6034 - mse: 0.5964 - val_loss: 0.5852 - val_mse: 0.5781\n",
      "Epoch 490/2000\n",
      "286/287 [============================>.] - ETA: 0s - loss: 0.6046 - mse: 0.5976\n",
      "Epoch 00490: saving model to Regression_Model/thle2.mle.linear-0490.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6037 - mse: 0.5967 - val_loss: 0.5997 - val_mse: 0.5927\n",
      "Epoch 491/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6050 - mse: 0.5980 - val_loss: 0.5877 - val_mse: 0.5806\n",
      "Epoch 492/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6034 - mse: 0.5964 - val_loss: 0.5855 - val_mse: 0.5785\n",
      "Epoch 493/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5984 - mse: 0.5913 - val_loss: 0.5911 - val_mse: 0.5840\n",
      "Epoch 494/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5971 - mse: 0.5901 - val_loss: 0.5892 - val_mse: 0.5822\n",
      "Epoch 495/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6073 - mse: 0.6003 - val_loss: 0.5914 - val_mse: 0.5844\n",
      "Epoch 496/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6053 - mse: 0.5983 - val_loss: 0.5859 - val_mse: 0.5789\n",
      "Epoch 497/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6033 - mse: 0.5962 - val_loss: 0.5864 - val_mse: 0.5793\n",
      "Epoch 498/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6087 - mse: 0.6017 - val_loss: 0.5908 - val_mse: 0.5838\n",
      "Epoch 499/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6034 - mse: 0.5964 - val_loss: 0.5867 - val_mse: 0.5797\n",
      "Epoch 500/2000\n",
      "273/287 [===========================>..] - ETA: 0s - loss: 0.5967 - mse: 0.5897\n",
      "Epoch 00500: saving model to Regression_Model/thle2.mle.linear-0500.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.5977 - mse: 0.5907 - val_loss: 0.5849 - val_mse: 0.5779\n",
      "Epoch 501/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6037 - mse: 0.5967 - val_loss: 0.5932 - val_mse: 0.5862\n",
      "Epoch 502/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6089 - mse: 0.6018 - val_loss: 0.5887 - val_mse: 0.5817\n",
      "Epoch 503/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6018 - mse: 0.5948 - val_loss: 0.5867 - val_mse: 0.5797\n",
      "Epoch 504/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6065 - mse: 0.5995 - val_loss: 0.5934 - val_mse: 0.5864\n",
      "Epoch 505/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6127 - mse: 0.6057 - val_loss: 0.5897 - val_mse: 0.5827\n",
      "Epoch 506/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6071 - mse: 0.6001 - val_loss: 0.5854 - val_mse: 0.5784\n",
      "Epoch 507/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6075 - mse: 0.6005 - val_loss: 0.5857 - val_mse: 0.5787\n",
      "Epoch 508/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6010 - mse: 0.5940 - val_loss: 0.5852 - val_mse: 0.5782\n",
      "Epoch 509/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6058 - mse: 0.5988 - val_loss: 0.5843 - val_mse: 0.5773\n",
      "Epoch 510/2000\n",
      "284/287 [============================>.] - ETA: 0s - loss: 0.6064 - mse: 0.5994\n",
      "Epoch 00510: saving model to Regression_Model/thle2.mle.linear-0510.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6061 - mse: 0.5991 - val_loss: 0.5851 - val_mse: 0.5781\n",
      "Epoch 511/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6046 - mse: 0.5976 - val_loss: 0.5897 - val_mse: 0.5827\n",
      "Epoch 512/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6082 - mse: 0.6012 - val_loss: 0.5906 - val_mse: 0.5836\n",
      "Epoch 513/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6082 - mse: 0.6012 - val_loss: 0.5946 - val_mse: 0.5876\n",
      "Epoch 514/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6027 - mse: 0.5957 - val_loss: 0.5917 - val_mse: 0.5847\n",
      "Epoch 515/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6156 - mse: 0.6086 - val_loss: 0.5900 - val_mse: 0.5830\n",
      "Epoch 516/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6025 - mse: 0.5955 - val_loss: 0.5970 - val_mse: 0.5900\n",
      "Epoch 517/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6016 - mse: 0.5946 - val_loss: 0.5939 - val_mse: 0.5869\n",
      "Epoch 518/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6002 - mse: 0.5932 - val_loss: 0.5865 - val_mse: 0.5795\n",
      "Epoch 519/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6037 - mse: 0.5967 - val_loss: 0.5845 - val_mse: 0.5775\n",
      "Epoch 520/2000\n",
      "282/287 [============================>.] - ETA: 0s - loss: 0.6001 - mse: 0.5931\n",
      "Epoch 00520: saving model to Regression_Model/thle2.mle.linear-0520.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5991 - mse: 0.5921 - val_loss: 0.5848 - val_mse: 0.5779\n",
      "Epoch 521/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5961 - mse: 0.5892 - val_loss: 0.5906 - val_mse: 0.5836\n",
      "Epoch 522/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6002 - mse: 0.5932 - val_loss: 0.5883 - val_mse: 0.5813\n",
      "Epoch 523/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6037 - mse: 0.5967 - val_loss: 0.5912 - val_mse: 0.5842\n",
      "Epoch 524/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6014 - mse: 0.5945 - val_loss: 0.5851 - val_mse: 0.5782\n",
      "Epoch 525/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6041 - mse: 0.5972 - val_loss: 0.5837 - val_mse: 0.5767\n",
      "Epoch 526/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6064 - mse: 0.5994 - val_loss: 0.5878 - val_mse: 0.5809\n",
      "Epoch 527/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6081 - mse: 0.6012 - val_loss: 0.5892 - val_mse: 0.5822\n",
      "Epoch 528/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6040 - mse: 0.5970 - val_loss: 0.5878 - val_mse: 0.5808\n",
      "Epoch 529/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6067 - mse: 0.5997 - val_loss: 0.5907 - val_mse: 0.5837\n",
      "Epoch 530/2000\n",
      "283/287 [============================>.] - ETA: 0s - loss: 0.6123 - mse: 0.6053\n",
      "Epoch 00530: saving model to Regression_Model/thle2.mle.linear-0530.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6124 - mse: 0.6054 - val_loss: 0.5869 - val_mse: 0.5799\n",
      "Epoch 531/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5960 - mse: 0.5890 - val_loss: 0.5872 - val_mse: 0.5802\n",
      "Epoch 532/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6077 - mse: 0.6007 - val_loss: 0.5850 - val_mse: 0.5781\n",
      "Epoch 533/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6032 - mse: 0.5962 - val_loss: 0.5865 - val_mse: 0.5795\n",
      "Epoch 534/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5990 - mse: 0.5920 - val_loss: 0.5868 - val_mse: 0.5799\n",
      "Epoch 535/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5978 - mse: 0.5909 - val_loss: 0.5892 - val_mse: 0.5822\n",
      "Epoch 536/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6103 - mse: 0.6034 - val_loss: 0.5869 - val_mse: 0.5800\n",
      "Epoch 537/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6010 - mse: 0.5941 - val_loss: 0.5899 - val_mse: 0.5830\n",
      "Epoch 538/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6032 - mse: 0.5962 - val_loss: 0.5876 - val_mse: 0.5806\n",
      "Epoch 539/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6025 - mse: 0.5956 - val_loss: 0.5898 - val_mse: 0.5829\n",
      "Epoch 540/2000\n",
      "277/287 [===========================>..] - ETA: 0s - loss: 0.5962 - mse: 0.5892\n",
      "Epoch 00540: saving model to Regression_Model/thle2.mle.linear-0540.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6001 - mse: 0.5932 - val_loss: 0.5907 - val_mse: 0.5838\n",
      "Epoch 541/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6037 - mse: 0.5968 - val_loss: 0.5913 - val_mse: 0.5844\n",
      "Epoch 542/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6003 - mse: 0.5934 - val_loss: 0.5935 - val_mse: 0.5866\n",
      "Epoch 543/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6012 - mse: 0.5942 - val_loss: 0.5905 - val_mse: 0.5835\n",
      "Epoch 544/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6048 - mse: 0.5979 - val_loss: 0.5875 - val_mse: 0.5805\n",
      "Epoch 545/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6065 - mse: 0.5996 - val_loss: 0.5926 - val_mse: 0.5856\n",
      "Epoch 546/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5978 - mse: 0.5909 - val_loss: 0.5884 - val_mse: 0.5815\n",
      "Epoch 547/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5948 - mse: 0.5879 - val_loss: 0.5868 - val_mse: 0.5798\n",
      "Epoch 548/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6072 - mse: 0.6003 - val_loss: 0.5858 - val_mse: 0.5788\n",
      "Epoch 549/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5942 - mse: 0.5873 - val_loss: 0.5850 - val_mse: 0.5781\n",
      "Epoch 550/2000\n",
      "280/287 [============================>.] - ETA: 0s - loss: 0.5970 - mse: 0.5900\n",
      "Epoch 00550: saving model to Regression_Model/thle2.mle.linear-0550.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5999 - mse: 0.5930 - val_loss: 0.5870 - val_mse: 0.5801\n",
      "Epoch 551/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6028 - mse: 0.5958 - val_loss: 0.5856 - val_mse: 0.5787\n",
      "Epoch 552/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6031 - mse: 0.5961 - val_loss: 0.5909 - val_mse: 0.5839\n",
      "Epoch 553/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6069 - mse: 0.5999 - val_loss: 0.5850 - val_mse: 0.5781\n",
      "Epoch 554/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5959 - mse: 0.5889 - val_loss: 0.5895 - val_mse: 0.5826\n",
      "Epoch 555/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6041 - mse: 0.5972 - val_loss: 0.5828 - val_mse: 0.5759\n",
      "Epoch 556/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6035 - mse: 0.5966 - val_loss: 0.5809 - val_mse: 0.5740\n",
      "Epoch 557/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6101 - mse: 0.6032 - val_loss: 0.5879 - val_mse: 0.5810\n",
      "Epoch 558/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6042 - mse: 0.5973 - val_loss: 0.5878 - val_mse: 0.5809\n",
      "Epoch 559/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6097 - mse: 0.6028 - val_loss: 0.5860 - val_mse: 0.5790\n",
      "Epoch 560/2000\n",
      "281/287 [============================>.] - ETA: 0s - loss: 0.6017 - mse: 0.5947\n",
      "Epoch 00560: saving model to Regression_Model/thle2.mle.linear-0560.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6008 - mse: 0.5939 - val_loss: 0.5865 - val_mse: 0.5796\n",
      "Epoch 561/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6036 - mse: 0.5967 - val_loss: 0.5907 - val_mse: 0.5838\n",
      "Epoch 562/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5972 - mse: 0.5903 - val_loss: 0.5892 - val_mse: 0.5823\n",
      "Epoch 563/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5936 - mse: 0.5867 - val_loss: 0.5852 - val_mse: 0.5783\n",
      "Epoch 564/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6037 - mse: 0.5968 - val_loss: 0.5874 - val_mse: 0.5805\n",
      "Epoch 565/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6017 - mse: 0.5948 - val_loss: 0.5882 - val_mse: 0.5813\n",
      "Epoch 566/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6079 - mse: 0.6010 - val_loss: 0.5861 - val_mse: 0.5792\n",
      "Epoch 567/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6068 - mse: 0.5999 - val_loss: 0.5881 - val_mse: 0.5812\n",
      "Epoch 568/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6089 - mse: 0.6020 - val_loss: 0.5884 - val_mse: 0.5815\n",
      "Epoch 569/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5974 - mse: 0.5906 - val_loss: 0.5844 - val_mse: 0.5775\n",
      "Epoch 570/2000\n",
      "284/287 [============================>.] - ETA: 0s - loss: 0.5998 - mse: 0.5929\n",
      "Epoch 00570: saving model to Regression_Model/thle2.mle.linear-0570.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5999 - mse: 0.5930 - val_loss: 0.5877 - val_mse: 0.5808\n",
      "Epoch 571/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6026 - mse: 0.5957 - val_loss: 0.5844 - val_mse: 0.5775\n",
      "Epoch 572/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6002 - mse: 0.5933 - val_loss: 0.5861 - val_mse: 0.5792\n",
      "Epoch 573/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6068 - mse: 0.6000 - val_loss: 0.5885 - val_mse: 0.5816\n",
      "Epoch 574/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6075 - mse: 0.6007 - val_loss: 0.5861 - val_mse: 0.5792\n",
      "Epoch 575/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6072 - mse: 0.6004 - val_loss: 0.5857 - val_mse: 0.5789\n",
      "Epoch 576/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6041 - mse: 0.5973 - val_loss: 0.5955 - val_mse: 0.5887\n",
      "Epoch 577/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6030 - mse: 0.5961 - val_loss: 0.5878 - val_mse: 0.5809\n",
      "Epoch 578/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5988 - mse: 0.5920 - val_loss: 0.5864 - val_mse: 0.5795\n",
      "Epoch 579/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5963 - mse: 0.5895 - val_loss: 0.5890 - val_mse: 0.5821\n",
      "Epoch 580/2000\n",
      "282/287 [============================>.] - ETA: 0s - loss: 0.6139 - mse: 0.6071\n",
      "Epoch 00580: saving model to Regression_Model/thle2.mle.linear-0580.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6118 - mse: 0.6049 - val_loss: 0.5837 - val_mse: 0.5769\n",
      "Epoch 581/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6043 - mse: 0.5974 - val_loss: 0.5892 - val_mse: 0.5824\n",
      "Epoch 582/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5989 - mse: 0.5920 - val_loss: 0.5847 - val_mse: 0.5778\n",
      "Epoch 583/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6118 - mse: 0.6050 - val_loss: 0.5901 - val_mse: 0.5832\n",
      "Epoch 584/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6091 - mse: 0.6022 - val_loss: 0.5877 - val_mse: 0.5808\n",
      "Epoch 585/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6032 - mse: 0.5964 - val_loss: 0.5853 - val_mse: 0.5785\n",
      "Epoch 586/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6039 - mse: 0.5970 - val_loss: 0.5854 - val_mse: 0.5786\n",
      "Epoch 587/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6048 - mse: 0.5979 - val_loss: 0.5921 - val_mse: 0.5852\n",
      "Epoch 588/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5993 - mse: 0.5924 - val_loss: 0.5854 - val_mse: 0.5785\n",
      "Epoch 589/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6037 - mse: 0.5968 - val_loss: 0.5893 - val_mse: 0.5825\n",
      "Epoch 590/2000\n",
      "276/287 [===========================>..] - ETA: 0s - loss: 0.6092 - mse: 0.6024\n",
      "Epoch 00590: saving model to Regression_Model/thle2.mle.linear-0590.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6074 - mse: 0.6005 - val_loss: 0.5927 - val_mse: 0.5858\n",
      "Epoch 591/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6040 - mse: 0.5972 - val_loss: 0.5871 - val_mse: 0.5803\n",
      "Epoch 592/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5920 - mse: 0.5851 - val_loss: 0.5910 - val_mse: 0.5842\n",
      "Epoch 593/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6054 - mse: 0.5985 - val_loss: 0.5857 - val_mse: 0.5789\n",
      "Epoch 594/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6015 - mse: 0.5947 - val_loss: 0.5890 - val_mse: 0.5822\n",
      "Epoch 595/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6029 - mse: 0.5960 - val_loss: 0.5880 - val_mse: 0.5812\n",
      "Epoch 596/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5992 - mse: 0.5924 - val_loss: 0.5884 - val_mse: 0.5815\n",
      "Epoch 597/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6013 - mse: 0.5945 - val_loss: 0.5882 - val_mse: 0.5814\n",
      "Epoch 598/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6018 - mse: 0.5949 - val_loss: 0.5895 - val_mse: 0.5826\n",
      "Epoch 599/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6013 - mse: 0.5945 - val_loss: 0.5875 - val_mse: 0.5807\n",
      "Epoch 600/2000\n",
      "285/287 [============================>.] - ETA: 0s - loss: 0.5985 - mse: 0.5917\n",
      "Epoch 00600: saving model to Regression_Model/thle2.mle.linear-0600.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5973 - mse: 0.5904 - val_loss: 0.5909 - val_mse: 0.5841\n",
      "Epoch 601/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6078 - mse: 0.6010 - val_loss: 0.5872 - val_mse: 0.5804\n",
      "Epoch 602/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6006 - mse: 0.5938 - val_loss: 0.5859 - val_mse: 0.5791\n",
      "Epoch 603/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6060 - mse: 0.5992 - val_loss: 0.5859 - val_mse: 0.5790\n",
      "Epoch 604/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5969 - mse: 0.5900 - val_loss: 0.5830 - val_mse: 0.5762\n",
      "Epoch 605/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5974 - mse: 0.5906 - val_loss: 0.5869 - val_mse: 0.5801\n",
      "Epoch 606/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5976 - mse: 0.5908 - val_loss: 0.5834 - val_mse: 0.5766\n",
      "Epoch 607/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6048 - mse: 0.5980 - val_loss: 0.5879 - val_mse: 0.5811\n",
      "Epoch 608/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5951 - mse: 0.5883 - val_loss: 0.5885 - val_mse: 0.5817\n",
      "Epoch 609/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6083 - mse: 0.6015 - val_loss: 0.5852 - val_mse: 0.5784\n",
      "Epoch 610/2000\n",
      "280/287 [============================>.] - ETA: 0s - loss: 0.6014 - mse: 0.5946\n",
      "Epoch 00610: saving model to Regression_Model/thle2.mle.linear-0610.ckpt\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6001 - mse: 0.5933 - val_loss: 0.5870 - val_mse: 0.5802\n",
      "Epoch 611/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5990 - mse: 0.5922 - val_loss: 0.5863 - val_mse: 0.5795\n",
      "Epoch 612/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6017 - mse: 0.5949 - val_loss: 0.5878 - val_mse: 0.5810\n",
      "Epoch 613/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6067 - mse: 0.5998 - val_loss: 0.5878 - val_mse: 0.5810\n",
      "Epoch 614/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6029 - mse: 0.5961 - val_loss: 0.5881 - val_mse: 0.5813\n",
      "Epoch 615/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6060 - mse: 0.5992 - val_loss: 0.5866 - val_mse: 0.5798\n",
      "Epoch 616/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6035 - mse: 0.5967 - val_loss: 0.5898 - val_mse: 0.5830\n",
      "Epoch 617/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6008 - mse: 0.5940 - val_loss: 0.5829 - val_mse: 0.5761\n",
      "Epoch 618/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6038 - mse: 0.5970 - val_loss: 0.5833 - val_mse: 0.5765\n",
      "Epoch 619/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5992 - mse: 0.5924 - val_loss: 0.5849 - val_mse: 0.5781\n",
      "Epoch 620/2000\n",
      "278/287 [============================>.] - ETA: 0s - loss: 0.5997 - mse: 0.5929\n",
      "Epoch 00620: saving model to Regression_Model/thle2.mle.linear-0620.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.5971 - mse: 0.5903 - val_loss: 0.5852 - val_mse: 0.5784\n",
      "Epoch 621/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6030 - mse: 0.5962 - val_loss: 0.5851 - val_mse: 0.5783\n",
      "Epoch 622/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5973 - mse: 0.5905 - val_loss: 0.5824 - val_mse: 0.5756\n",
      "Epoch 623/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6027 - mse: 0.5959 - val_loss: 0.5888 - val_mse: 0.5820\n",
      "Epoch 624/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5981 - mse: 0.5913 - val_loss: 0.5830 - val_mse: 0.5762\n",
      "Epoch 625/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6024 - mse: 0.5956 - val_loss: 0.5871 - val_mse: 0.5803\n",
      "Epoch 626/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6022 - mse: 0.5954 - val_loss: 0.5865 - val_mse: 0.5797\n",
      "Epoch 627/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6031 - mse: 0.5963 - val_loss: 0.5893 - val_mse: 0.5825\n",
      "Epoch 628/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5981 - mse: 0.5913 - val_loss: 0.5859 - val_mse: 0.5791\n",
      "Epoch 629/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5991 - mse: 0.5923 - val_loss: 0.5877 - val_mse: 0.5809\n",
      "Epoch 630/2000\n",
      "277/287 [===========================>..] - ETA: 0s - loss: 0.6019 - mse: 0.5951\n",
      "Epoch 00630: saving model to Regression_Model/thle2.mle.linear-0630.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.6032 - mse: 0.5964 - val_loss: 0.5943 - val_mse: 0.5875\n",
      "Epoch 631/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6022 - mse: 0.5955 - val_loss: 0.5917 - val_mse: 0.5849\n",
      "Epoch 632/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5967 - mse: 0.5899 - val_loss: 0.5853 - val_mse: 0.5786\n",
      "Epoch 633/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5977 - mse: 0.5910 - val_loss: 0.5895 - val_mse: 0.5827\n",
      "Epoch 634/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6001 - mse: 0.5934 - val_loss: 0.5873 - val_mse: 0.5806\n",
      "Epoch 635/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5976 - mse: 0.5908 - val_loss: 0.5852 - val_mse: 0.5785\n",
      "Epoch 636/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6042 - mse: 0.5974 - val_loss: 0.5883 - val_mse: 0.5816\n",
      "Epoch 637/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5955 - mse: 0.5887 - val_loss: 0.5852 - val_mse: 0.5785\n",
      "Epoch 638/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5985 - mse: 0.5918 - val_loss: 0.5855 - val_mse: 0.5788\n",
      "Epoch 639/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5985 - mse: 0.5918 - val_loss: 0.5837 - val_mse: 0.5770\n",
      "Epoch 640/2000\n",
      "278/287 [============================>.] - ETA: 0s - loss: 0.6048 - mse: 0.5981\n",
      "Epoch 00640: saving model to Regression_Model/thle2.mle.linear-0640.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6027 - mse: 0.5960 - val_loss: 0.5851 - val_mse: 0.5783\n",
      "Epoch 641/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5987 - mse: 0.5919 - val_loss: 0.5854 - val_mse: 0.5787\n",
      "Epoch 642/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6034 - mse: 0.5967 - val_loss: 0.5933 - val_mse: 0.5866\n",
      "Epoch 643/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5951 - mse: 0.5883 - val_loss: 0.5872 - val_mse: 0.5804\n",
      "Epoch 644/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6043 - mse: 0.5975 - val_loss: 0.5893 - val_mse: 0.5825\n",
      "Epoch 645/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6083 - mse: 0.6015 - val_loss: 0.5848 - val_mse: 0.5781\n",
      "Epoch 646/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5940 - mse: 0.5873 - val_loss: 0.5835 - val_mse: 0.5767\n",
      "Epoch 647/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5965 - mse: 0.5897 - val_loss: 0.5871 - val_mse: 0.5804\n",
      "Epoch 648/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6006 - mse: 0.5939 - val_loss: 0.5853 - val_mse: 0.5786\n",
      "Epoch 649/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6064 - mse: 0.5997 - val_loss: 0.5849 - val_mse: 0.5781\n",
      "Epoch 650/2000\n",
      "282/287 [============================>.] - ETA: 0s - loss: 0.5982 - mse: 0.5914\n",
      "Epoch 00650: saving model to Regression_Model/thle2.mle.linear-0650.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5987 - mse: 0.5919 - val_loss: 0.5863 - val_mse: 0.5796\n",
      "Epoch 651/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5972 - mse: 0.5904 - val_loss: 0.5858 - val_mse: 0.5791\n",
      "Epoch 652/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6034 - mse: 0.5967 - val_loss: 0.5888 - val_mse: 0.5821\n",
      "Epoch 653/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5989 - mse: 0.5922 - val_loss: 0.5887 - val_mse: 0.5819\n",
      "Epoch 654/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5956 - mse: 0.5888 - val_loss: 0.5867 - val_mse: 0.5800\n",
      "Epoch 655/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6005 - mse: 0.5937 - val_loss: 0.5908 - val_mse: 0.5841\n",
      "Epoch 656/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6051 - mse: 0.5984 - val_loss: 0.5909 - val_mse: 0.5842\n",
      "Epoch 657/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6059 - mse: 0.5992 - val_loss: 0.5869 - val_mse: 0.5802\n",
      "Epoch 658/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6042 - mse: 0.5974 - val_loss: 0.5913 - val_mse: 0.5845\n",
      "Epoch 659/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5927 - mse: 0.5859 - val_loss: 0.5849 - val_mse: 0.5782\n",
      "Epoch 660/2000\n",
      "286/287 [============================>.] - ETA: 0s - loss: 0.5965 - mse: 0.5898\n",
      "Epoch 00660: saving model to Regression_Model/thle2.mle.linear-0660.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5974 - mse: 0.5907 - val_loss: 0.5878 - val_mse: 0.5811\n",
      "Epoch 661/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5987 - mse: 0.5920 - val_loss: 0.5872 - val_mse: 0.5804\n",
      "Epoch 662/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5995 - mse: 0.5928 - val_loss: 0.5923 - val_mse: 0.5856\n",
      "Epoch 663/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5984 - mse: 0.5916 - val_loss: 0.5865 - val_mse: 0.5797\n",
      "Epoch 664/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6068 - mse: 0.6001 - val_loss: 0.5841 - val_mse: 0.5774\n",
      "Epoch 665/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6000 - mse: 0.5933 - val_loss: 0.5838 - val_mse: 0.5770\n",
      "Epoch 666/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5976 - mse: 0.5908 - val_loss: 0.5843 - val_mse: 0.5776\n",
      "Epoch 667/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6073 - mse: 0.6006 - val_loss: 0.5835 - val_mse: 0.5768\n",
      "Epoch 668/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6028 - mse: 0.5961 - val_loss: 0.5871 - val_mse: 0.5804\n",
      "Epoch 669/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5978 - mse: 0.5911 - val_loss: 0.5872 - val_mse: 0.5804\n",
      "Epoch 670/2000\n",
      "275/287 [===========================>..] - ETA: 0s - loss: 0.5945 - mse: 0.5878\n",
      "Epoch 00670: saving model to Regression_Model/thle2.mle.linear-0670.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5921 - mse: 0.5854 - val_loss: 0.5904 - val_mse: 0.5837\n",
      "Epoch 671/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5923 - mse: 0.5856 - val_loss: 0.5904 - val_mse: 0.5837\n",
      "Epoch 672/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5971 - mse: 0.5904 - val_loss: 0.5867 - val_mse: 0.5800\n",
      "Epoch 673/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6037 - mse: 0.5970 - val_loss: 0.5894 - val_mse: 0.5827\n",
      "Epoch 674/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5964 - mse: 0.5897 - val_loss: 0.5871 - val_mse: 0.5804\n",
      "Epoch 675/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5975 - mse: 0.5908 - val_loss: 0.5860 - val_mse: 0.5793\n",
      "Epoch 676/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6064 - mse: 0.5997 - val_loss: 0.5860 - val_mse: 0.5793\n",
      "Epoch 677/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6022 - mse: 0.5955 - val_loss: 0.5882 - val_mse: 0.5815\n",
      "Epoch 678/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6031 - mse: 0.5964 - val_loss: 0.5876 - val_mse: 0.5809\n",
      "Epoch 679/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6047 - mse: 0.5980 - val_loss: 0.5846 - val_mse: 0.5779\n",
      "Epoch 680/2000\n",
      "275/287 [===========================>..] - ETA: 0s - loss: 0.5931 - mse: 0.5863\n",
      "Epoch 00680: saving model to Regression_Model/thle2.mle.linear-0680.ckpt\n",
      "287/287 [==============================] - 2s 6ms/step - loss: 0.5977 - mse: 0.5910 - val_loss: 0.5867 - val_mse: 0.5800\n",
      "Epoch 681/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6005 - mse: 0.5938 - val_loss: 0.5841 - val_mse: 0.5774\n",
      "Epoch 682/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6066 - mse: 0.6000 - val_loss: 0.5853 - val_mse: 0.5786\n",
      "Epoch 683/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6006 - mse: 0.5940 - val_loss: 0.5844 - val_mse: 0.5777\n",
      "Epoch 684/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5979 - mse: 0.5913 - val_loss: 0.5862 - val_mse: 0.5795\n",
      "Epoch 685/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6041 - mse: 0.5974 - val_loss: 0.5865 - val_mse: 0.5798\n",
      "Epoch 686/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5926 - mse: 0.5859 - val_loss: 0.5882 - val_mse: 0.5815\n",
      "Epoch 687/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5964 - mse: 0.5897 - val_loss: 0.5872 - val_mse: 0.5805\n",
      "Epoch 688/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5971 - mse: 0.5904 - val_loss: 0.5850 - val_mse: 0.5783\n",
      "Epoch 689/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6010 - mse: 0.5943 - val_loss: 0.5878 - val_mse: 0.5811\n",
      "Epoch 690/2000\n",
      "281/287 [============================>.] - ETA: 0s - loss: 0.6046 - mse: 0.5979\n",
      "Epoch 00690: saving model to Regression_Model/thle2.mle.linear-0690.ckpt\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6042 - mse: 0.5975 - val_loss: 0.5881 - val_mse: 0.5814\n",
      "Epoch 691/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6018 - mse: 0.5951 - val_loss: 0.5896 - val_mse: 0.5829\n",
      "Epoch 692/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6011 - mse: 0.5944 - val_loss: 0.5853 - val_mse: 0.5786\n",
      "Epoch 693/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6042 - mse: 0.5975 - val_loss: 0.5875 - val_mse: 0.5808\n",
      "Epoch 694/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6000 - mse: 0.5933 - val_loss: 0.5887 - val_mse: 0.5820\n",
      "Epoch 695/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5962 - mse: 0.5895 - val_loss: 0.5841 - val_mse: 0.5774\n",
      "Epoch 696/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5989 - mse: 0.5922 - val_loss: 0.5867 - val_mse: 0.5800\n",
      "Epoch 697/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5945 - mse: 0.5878 - val_loss: 0.5842 - val_mse: 0.5775\n",
      "Epoch 698/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6010 - mse: 0.5943 - val_loss: 0.5926 - val_mse: 0.5860\n",
      "Epoch 699/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5992 - mse: 0.5926 - val_loss: 0.5872 - val_mse: 0.5806\n",
      "Epoch 700/2000\n",
      "284/287 [============================>.] - ETA: 0s - loss: 0.5981 - mse: 0.5914\n",
      "Epoch 00700: saving model to Regression_Model/thle2.mle.linear-0700.ckpt\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5988 - mse: 0.5922 - val_loss: 0.5861 - val_mse: 0.5794\n",
      "Epoch 701/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5960 - mse: 0.5893 - val_loss: 0.5906 - val_mse: 0.5840\n",
      "Epoch 702/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5998 - mse: 0.5931 - val_loss: 0.5870 - val_mse: 0.5804\n",
      "Epoch 703/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6050 - mse: 0.5984 - val_loss: 0.5847 - val_mse: 0.5780\n",
      "Epoch 704/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6005 - mse: 0.5938 - val_loss: 0.5866 - val_mse: 0.5799\n",
      "Epoch 705/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.5984 - mse: 0.5917 - val_loss: 0.5870 - val_mse: 0.5804\n",
      "Epoch 706/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5967 - mse: 0.5900 - val_loss: 0.5880 - val_mse: 0.5813\n",
      "Epoch 707/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6018 - mse: 0.5951 - val_loss: 0.5840 - val_mse: 0.5773\n",
      "Epoch 708/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6010 - mse: 0.5943 - val_loss: 0.5880 - val_mse: 0.5813\n",
      "Epoch 709/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6009 - mse: 0.5942 - val_loss: 0.5919 - val_mse: 0.5852\n",
      "Epoch 710/2000\n",
      "279/287 [============================>.] - ETA: 0s - loss: 0.6038 - mse: 0.5972\n",
      "Epoch 00710: saving model to Regression_Model/thle2.mle.linear-0710.ckpt\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6028 - mse: 0.5961 - val_loss: 0.5833 - val_mse: 0.5766\n",
      "Epoch 711/2000\n",
      "287/287 [==============================] - 2s 5ms/step - loss: 0.6046 - mse: 0.5980 - val_loss: 0.5970 - val_mse: 0.5903\n",
      "Epoch 712/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6053 - mse: 0.5987 - val_loss: 0.5876 - val_mse: 0.5810\n",
      "Epoch 713/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6029 - mse: 0.5963 - val_loss: 0.5860 - val_mse: 0.5794\n",
      "Epoch 714/2000\n",
      "287/287 [==============================] - 1s 4ms/step - loss: 0.6019 - mse: 0.5952 - val_loss: 0.5887 - val_mse: 0.5820\n",
      "Epoch 715/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.5947 - mse: 0.5880 - val_loss: 0.5824 - val_mse: 0.5758\n",
      "Epoch 716/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6043 - mse: 0.5976 - val_loss: 0.5867 - val_mse: 0.5800\n",
      "Epoch 717/2000\n",
      "287/287 [==============================] - 1s 5ms/step - loss: 0.6033 - mse: 0.5966 - val_loss: 0.5871 - val_mse: 0.5804\n",
      "Epoch 718/2000\n",
      " 54/287 [====>.........................] - ETA: 0s - loss: 0.5892 - mse: 0.5826"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=2000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x,901)\n",
    "    model = Regression_CNN(901)\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-1990.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testid='thle2.mle.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
