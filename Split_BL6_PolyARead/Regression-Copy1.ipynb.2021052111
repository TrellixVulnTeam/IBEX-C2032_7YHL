{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 55918\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.regression.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    \n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3861275 2.4915485\n",
      "3.8266706 1.8094194\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd95449b908>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd955945940>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='msle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 368 steps, validate for 368 steps\n",
      "Epoch 1/2000\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.1254 - mse: 1.0991 - val_loss: 0.1187 - val_mse: 1.0951\n",
      "Epoch 2/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1178 - mse: 1.0863 - val_loss: 0.1155 - val_mse: 1.0851\n",
      "Epoch 3/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1138 - mse: 1.0714 - val_loss: 0.1099 - val_mse: 1.0501\n",
      "Epoch 4/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1082 - mse: 1.0491 - val_loss: 0.1034 - val_mse: 1.0242\n",
      "Epoch 5/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.1027 - mse: 1.0270 - val_loss: 0.0970 - val_mse: 0.9994\n",
      "Epoch 6/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0979 - mse: 1.0414 - val_loss: 0.0927 - val_mse: 1.0186\n",
      "Epoch 7/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0942 - mse: 1.0412 - val_loss: 0.0908 - val_mse: 1.0515\n",
      "Epoch 8/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0924 - mse: 1.0624 - val_loss: 0.0925 - val_mse: 1.0353\n",
      "Epoch 9/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0933 - mse: 1.0716 - val_loss: 0.0913 - val_mse: 1.1196\n",
      "Epoch 10/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0923 - mse: 1.1942\n",
      "Epoch 00010: saving model to Regression_Model/msle.linear-0010.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0923 - mse: 1.1922 - val_loss: 0.0886 - val_mse: 1.1067\n",
      "Epoch 11/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0904 - mse: 1.0798 - val_loss: 0.0869 - val_mse: 1.1093\n",
      "Epoch 12/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0901 - mse: 1.1615 - val_loss: 0.0867 - val_mse: 1.1012\n",
      "Epoch 13/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0894 - mse: 1.1521 - val_loss: 0.0859 - val_mse: 1.0461\n",
      "Epoch 14/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0900 - mse: 1.1804 - val_loss: 0.0847 - val_mse: 1.0696\n",
      "Epoch 15/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0870 - mse: 1.0821 - val_loss: 0.0854 - val_mse: 1.0872\n",
      "Epoch 16/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0865 - mse: 1.0925 - val_loss: 0.0837 - val_mse: 1.0223\n",
      "Epoch 17/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0860 - mse: 1.0752 - val_loss: 0.0827 - val_mse: 1.0114\n",
      "Epoch 18/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0867 - mse: 1.1470 - val_loss: 0.0809 - val_mse: 1.0282\n",
      "Epoch 19/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0859 - mse: 1.0639 - val_loss: 0.0811 - val_mse: 0.9725\n",
      "Epoch 20/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0842 - mse: 1.0474\n",
      "Epoch 00020: saving model to Regression_Model/msle.linear-0020.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0842 - mse: 1.0407 - val_loss: 0.0795 - val_mse: 0.9605\n",
      "Epoch 21/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 0.9990 - val_loss: 0.0796 - val_mse: 1.0111\n",
      "Epoch 22/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 1.0312 - val_loss: 0.0775 - val_mse: 0.9781\n",
      "Epoch 23/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0841 - mse: 1.0965 - val_loss: 0.0773 - val_mse: 0.9622\n",
      "Epoch 24/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0818 - mse: 1.0242 - val_loss: 0.0760 - val_mse: 0.9532\n",
      "Epoch 25/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0813 - mse: 1.0123 - val_loss: 0.0783 - val_mse: 0.9189\n",
      "Epoch 26/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0835 - mse: 1.0748 - val_loss: 0.0765 - val_mse: 0.9743\n",
      "Epoch 27/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0821 - mse: 1.0243 - val_loss: 0.0814 - val_mse: 1.0243\n",
      "Epoch 28/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0811 - mse: 1.0167 - val_loss: 0.0739 - val_mse: 0.9327\n",
      "Epoch 29/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.0275 - val_loss: 0.0732 - val_mse: 0.9154\n",
      "Epoch 30/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0804 - mse: 0.9629\n",
      "Epoch 00030: saving model to Regression_Model/msle.linear-0030.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0810 - mse: 0.9636 - val_loss: 0.0792 - val_mse: 0.9915\n",
      "Epoch 31/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0808 - mse: 1.0778 - val_loss: 0.0726 - val_mse: 0.9291\n",
      "Epoch 32/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0796 - mse: 1.0005 - val_loss: 0.0740 - val_mse: 0.9607\n",
      "Epoch 33/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0807 - mse: 1.0669 - val_loss: 0.0719 - val_mse: 0.9054\n",
      "Epoch 34/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0803 - mse: 1.0160 - val_loss: 0.0721 - val_mse: 0.9019\n",
      "Epoch 35/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0800 - mse: 1.0032 - val_loss: 0.0761 - val_mse: 0.9098\n",
      "Epoch 36/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 0.9593 - val_loss: 0.0711 - val_mse: 0.8999\n",
      "Epoch 37/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0782 - mse: 0.9441 - val_loss: 0.0715 - val_mse: 0.9026\n",
      "Epoch 38/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0788 - mse: 0.9689 - val_loss: 0.0741 - val_mse: 0.9319\n",
      "Epoch 39/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0795 - mse: 1.0026 - val_loss: 0.0703 - val_mse: 0.8964\n",
      "Epoch 40/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0800 - mse: 1.0140\n",
      "Epoch 00040: saving model to Regression_Model/msle.linear-0040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0798 - mse: 1.0098 - val_loss: 0.0719 - val_mse: 0.8584\n",
      "Epoch 41/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0783 - mse: 0.9746 - val_loss: 0.0695 - val_mse: 0.8820\n",
      "Epoch 42/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0776 - mse: 0.9458 - val_loss: 0.0693 - val_mse: 0.8762\n",
      "Epoch 43/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0770 - mse: 0.9422 - val_loss: 0.0713 - val_mse: 0.9226\n",
      "Epoch 44/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0767 - mse: 0.9323 - val_loss: 0.0707 - val_mse: 0.9003\n",
      "Epoch 45/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0775 - mse: 0.9381 - val_loss: 0.0701 - val_mse: 0.8908\n",
      "Epoch 46/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0773 - mse: 0.9519 - val_loss: 0.0699 - val_mse: 0.8950\n",
      "Epoch 47/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0764 - mse: 0.9227 - val_loss: 0.0682 - val_mse: 0.8593\n",
      "Epoch 48/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0780 - mse: 0.9446 - val_loss: 0.0685 - val_mse: 0.8568\n",
      "Epoch 49/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0761 - mse: 0.9663 - val_loss: 0.0687 - val_mse: 0.8654\n",
      "Epoch 50/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0780 - mse: 0.9695\n",
      "Epoch 00050: saving model to Regression_Model/msle.linear-0050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0780 - mse: 0.9671 - val_loss: 0.0687 - val_mse: 0.8339\n",
      "Epoch 51/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 0.9311 - val_loss: 0.0678 - val_mse: 0.8671\n",
      "Epoch 52/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0769 - mse: 0.9777 - val_loss: 0.0673 - val_mse: 0.8524\n",
      "Epoch 53/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 0.8951 - val_loss: 0.0687 - val_mse: 0.8403\n",
      "Epoch 54/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0759 - mse: 0.9257 - val_loss: 0.0682 - val_mse: 0.8246\n",
      "Epoch 55/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0747 - mse: 1.0241 - val_loss: 0.0671 - val_mse: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0752 - mse: 0.9120 - val_loss: 0.0677 - val_mse: 0.8537\n",
      "Epoch 57/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0754 - mse: 0.9103 - val_loss: 0.0679 - val_mse: 0.8433\n",
      "Epoch 58/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0760 - mse: 0.9409 - val_loss: 0.0678 - val_mse: 0.8659\n",
      "Epoch 59/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0764 - mse: 0.9397 - val_loss: 0.0672 - val_mse: 0.8628\n",
      "Epoch 60/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0741 - mse: 0.8919\n",
      "Epoch 00060: saving model to Regression_Model/msle.linear-0060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0746 - mse: 0.8959 - val_loss: 0.0668 - val_mse: 0.8449\n",
      "Epoch 61/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0763 - mse: 0.9414 - val_loss: 0.0701 - val_mse: 0.8301\n",
      "Epoch 62/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0753 - mse: 0.9152 - val_loss: 0.0669 - val_mse: 0.8264\n",
      "Epoch 63/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0742 - mse: 0.9203 - val_loss: 0.0688 - val_mse: 0.8833\n",
      "Epoch 64/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0721 - mse: 0.8889 - val_loss: 0.0664 - val_mse: 0.8215\n",
      "Epoch 65/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0735 - mse: 0.9129 - val_loss: 0.0668 - val_mse: 0.8553\n",
      "Epoch 66/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0743 - mse: 0.8888 - val_loss: 0.0661 - val_mse: 0.8238\n",
      "Epoch 67/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0749 - mse: 0.8989 - val_loss: 0.0663 - val_mse: 0.8529\n",
      "Epoch 68/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0745 - mse: 0.9456 - val_loss: 0.0677 - val_mse: 0.8067\n",
      "Epoch 69/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0732 - mse: 0.8983 - val_loss: 0.0663 - val_mse: 0.8450\n",
      "Epoch 70/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0735 - mse: 0.8923\n",
      "Epoch 00070: saving model to Regression_Model/msle.linear-0070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0736 - mse: 0.8933 - val_loss: 0.0662 - val_mse: 0.8050\n",
      "Epoch 71/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0742 - mse: 0.9081 - val_loss: 0.0664 - val_mse: 0.8418\n",
      "Epoch 72/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0743 - mse: 0.8901 - val_loss: 0.0683 - val_mse: 0.8826\n",
      "Epoch 73/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0735 - mse: 0.8869 - val_loss: 0.0662 - val_mse: 0.8396\n",
      "Epoch 74/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0730 - mse: 0.8794 - val_loss: 0.0657 - val_mse: 0.8371\n",
      "Epoch 75/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0737 - mse: 0.9410 - val_loss: 0.0658 - val_mse: 0.8162\n",
      "Epoch 76/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0725 - mse: 0.8948 - val_loss: 0.0665 - val_mse: 0.8537\n",
      "Epoch 77/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0730 - mse: 0.9091 - val_loss: 0.0649 - val_mse: 0.8333\n",
      "Epoch 78/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0734 - mse: 0.8856 - val_loss: 0.0652 - val_mse: 0.8445\n",
      "Epoch 79/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0726 - mse: 0.8869 - val_loss: 0.0652 - val_mse: 0.8327\n",
      "Epoch 80/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0744 - mse: 0.8915\n",
      "Epoch 00080: saving model to Regression_Model/msle.linear-0080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0743 - mse: 0.8936 - val_loss: 0.0673 - val_mse: 0.8747\n",
      "Epoch 81/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0744 - mse: 0.9096 - val_loss: 0.0648 - val_mse: 0.8170\n",
      "Epoch 82/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0719 - mse: 0.8660 - val_loss: 0.0644 - val_mse: 0.8178\n",
      "Epoch 83/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0720 - mse: 0.8789 - val_loss: 0.0654 - val_mse: 0.8021\n",
      "Epoch 84/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0721 - mse: 0.8653 - val_loss: 0.0691 - val_mse: 0.8881\n",
      "Epoch 85/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0727 - mse: 0.8796 - val_loss: 0.0655 - val_mse: 0.8161\n",
      "Epoch 86/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0724 - mse: 0.8626 - val_loss: 0.0688 - val_mse: 0.7976\n",
      "Epoch 87/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0728 - mse: 0.8841 - val_loss: 0.0644 - val_mse: 0.8213\n",
      "Epoch 88/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0709 - mse: 0.8601 - val_loss: 0.0649 - val_mse: 0.8312\n",
      "Epoch 89/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0724 - mse: 0.8689 - val_loss: 0.0659 - val_mse: 0.8543\n",
      "Epoch 90/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0719 - mse: 0.8933\n",
      "Epoch 00090: saving model to Regression_Model/msle.linear-0090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0720 - mse: 0.8938 - val_loss: 0.0647 - val_mse: 0.8351\n",
      "Epoch 91/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8739 - val_loss: 0.0653 - val_mse: 0.8439\n",
      "Epoch 92/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0717 - mse: 0.8646 - val_loss: 0.0642 - val_mse: 0.8287\n",
      "Epoch 93/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0720 - mse: 0.8658 - val_loss: 0.0649 - val_mse: 0.8196\n",
      "Epoch 94/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8608 - val_loss: 0.0656 - val_mse: 0.8461\n",
      "Epoch 95/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0722 - mse: 0.8685 - val_loss: 0.0639 - val_mse: 0.8228\n",
      "Epoch 96/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0716 - mse: 0.8651 - val_loss: 0.0649 - val_mse: 0.8286\n",
      "Epoch 97/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0723 - mse: 0.8700 - val_loss: 0.0647 - val_mse: 0.8325\n",
      "Epoch 98/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8657 - val_loss: 0.0642 - val_mse: 0.8259\n",
      "Epoch 99/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8574 - val_loss: 0.0640 - val_mse: 0.8283\n",
      "Epoch 100/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0713 - mse: 0.8581\n",
      "Epoch 00100: saving model to Regression_Model/msle.linear-0100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8587 - val_loss: 0.0646 - val_mse: 0.8379\n",
      "Epoch 101/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8652 - val_loss: 0.0645 - val_mse: 0.8332\n",
      "Epoch 102/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0707 - mse: 0.8636 - val_loss: 0.0662 - val_mse: 0.8128\n",
      "Epoch 103/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8807 - val_loss: 0.0644 - val_mse: 0.8415\n",
      "Epoch 104/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0717 - mse: 0.8721 - val_loss: 0.0646 - val_mse: 0.8384\n",
      "Epoch 105/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0716 - mse: 0.8568 - val_loss: 0.0675 - val_mse: 0.8729\n",
      "Epoch 106/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8614 - val_loss: 0.0658 - val_mse: 0.8089\n",
      "Epoch 107/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8689 - val_loss: 0.0644 - val_mse: 0.8141\n",
      "Epoch 108/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0717 - mse: 0.8660 - val_loss: 0.0645 - val_mse: 0.8353\n",
      "Epoch 109/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0720 - mse: 0.8628 - val_loss: 0.0651 - val_mse: 0.8132\n",
      "Epoch 110/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0710 - mse: 0.8704\n",
      "Epoch 00110: saving model to Regression_Model/msle.linear-0110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0709 - mse: 0.8713 - val_loss: 0.0634 - val_mse: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8599 - val_loss: 0.0650 - val_mse: 0.8014\n",
      "Epoch 112/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0717 - mse: 0.8665 - val_loss: 0.0640 - val_mse: 0.8358\n",
      "Epoch 113/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8541 - val_loss: 0.0667 - val_mse: 0.7922\n",
      "Epoch 114/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0722 - mse: 0.8696 - val_loss: 0.0674 - val_mse: 0.8181\n",
      "Epoch 115/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0707 - mse: 0.8505 - val_loss: 0.0649 - val_mse: 0.8145\n",
      "Epoch 116/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0714 - mse: 0.8733 - val_loss: 0.0654 - val_mse: 0.8122\n",
      "Epoch 117/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0716 - mse: 0.8586 - val_loss: 0.0655 - val_mse: 0.8496\n",
      "Epoch 118/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8752 - val_loss: 0.0630 - val_mse: 0.8089\n",
      "Epoch 119/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0707 - mse: 0.8554 - val_loss: 0.0658 - val_mse: 0.8501\n",
      "Epoch 120/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0711 - mse: 0.8648\n",
      "Epoch 00120: saving model to Regression_Model/msle.linear-0120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8650 - val_loss: 0.0649 - val_mse: 0.8016\n",
      "Epoch 121/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0725 - mse: 0.8712 - val_loss: 0.0647 - val_mse: 0.8409\n",
      "Epoch 122/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8714 - val_loss: 0.0652 - val_mse: 0.7993\n",
      "Epoch 123/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8583 - val_loss: 0.0641 - val_mse: 0.8178\n",
      "Epoch 124/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0709 - mse: 0.8588 - val_loss: 0.0632 - val_mse: 0.7986\n",
      "Epoch 125/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0715 - mse: 0.8562 - val_loss: 0.0637 - val_mse: 0.8274\n",
      "Epoch 126/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8581 - val_loss: 0.0639 - val_mse: 0.7997\n",
      "Epoch 127/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8516 - val_loss: 0.0630 - val_mse: 0.8091\n",
      "Epoch 128/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8578 - val_loss: 0.0656 - val_mse: 0.8189\n",
      "Epoch 129/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8554 - val_loss: 0.0645 - val_mse: 0.8105\n",
      "Epoch 130/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0705 - mse: 0.8559\n",
      "Epoch 00130: saving model to Regression_Model/msle.linear-0130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8533 - val_loss: 0.0659 - val_mse: 0.7925\n",
      "Epoch 131/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8481 - val_loss: 0.0636 - val_mse: 0.8187\n",
      "Epoch 132/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8590 - val_loss: 0.0628 - val_mse: 0.8020\n",
      "Epoch 133/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8520 - val_loss: 0.0630 - val_mse: 0.8076\n",
      "Epoch 134/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8458 - val_loss: 0.0634 - val_mse: 0.8264\n",
      "Epoch 135/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0705 - mse: 0.8609 - val_loss: 0.0654 - val_mse: 0.8035\n",
      "Epoch 136/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8566 - val_loss: 0.0632 - val_mse: 0.8121\n",
      "Epoch 137/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8610 - val_loss: 0.0637 - val_mse: 0.8333\n",
      "Epoch 138/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8543 - val_loss: 0.0632 - val_mse: 0.8156\n",
      "Epoch 139/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8505 - val_loss: 0.0630 - val_mse: 0.8079\n",
      "Epoch 140/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0693 - mse: 0.8513\n",
      "Epoch 00140: saving model to Regression_Model/msle.linear-0140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8502 - val_loss: 0.0626 - val_mse: 0.8021\n",
      "Epoch 141/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8554 - val_loss: 0.0653 - val_mse: 0.8489\n",
      "Epoch 142/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8671 - val_loss: 0.0632 - val_mse: 0.8291\n",
      "Epoch 143/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8565 - val_loss: 0.0639 - val_mse: 0.7890\n",
      "Epoch 144/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8386 - val_loss: 0.0623 - val_mse: 0.7991\n",
      "Epoch 145/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0692 - mse: 0.8447 - val_loss: 0.0630 - val_mse: 0.8060\n",
      "Epoch 146/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8444 - val_loss: 0.0629 - val_mse: 0.8056\n",
      "Epoch 147/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8451 - val_loss: 0.0633 - val_mse: 0.7890\n",
      "Epoch 148/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0707 - mse: 0.8581 - val_loss: 0.0625 - val_mse: 0.8171\n",
      "Epoch 149/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8533 - val_loss: 0.0673 - val_mse: 0.8509\n",
      "Epoch 150/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0717 - mse: 0.8659\n",
      "Epoch 00150: saving model to Regression_Model/msle.linear-0150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0719 - mse: 0.8678 - val_loss: 0.0658 - val_mse: 0.8446\n",
      "Epoch 151/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8621 - val_loss: 0.0647 - val_mse: 0.8278\n",
      "Epoch 152/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8604 - val_loss: 0.0646 - val_mse: 0.8141\n",
      "Epoch 153/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0723 - mse: 0.8692 - val_loss: 0.0646 - val_mse: 0.8380\n",
      "Epoch 154/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0718 - mse: 0.8934 - val_loss: 0.0646 - val_mse: 0.8221\n",
      "Epoch 155/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8542 - val_loss: 0.0654 - val_mse: 0.8359\n",
      "Epoch 156/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0718 - mse: 0.8702 - val_loss: 0.0637 - val_mse: 0.8189\n",
      "Epoch 157/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0709 - mse: 0.8898 - val_loss: 0.0634 - val_mse: 0.8237\n",
      "Epoch 158/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0719 - mse: 0.8765 - val_loss: 0.0667 - val_mse: 0.8201\n",
      "Epoch 159/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0719 - mse: 0.8759 - val_loss: 0.0641 - val_mse: 0.8344\n",
      "Epoch 160/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0715 - mse: 0.8674\n",
      "Epoch 00160: saving model to Regression_Model/msle.linear-0160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8671 - val_loss: 0.0651 - val_mse: 0.8114\n",
      "Epoch 161/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8576 - val_loss: 0.0637 - val_mse: 0.8254\n",
      "Epoch 162/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0715 - mse: 0.8563 - val_loss: 0.0646 - val_mse: 0.7982\n",
      "Epoch 163/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0732 - mse: 0.8710 - val_loss: 0.0642 - val_mse: 0.8396\n",
      "Epoch 164/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8662 - val_loss: 0.0650 - val_mse: 0.8509\n",
      "Epoch 165/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0719 - mse: 0.8658 - val_loss: 0.0636 - val_mse: 0.8117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0718 - mse: 0.8918 - val_loss: 0.0642 - val_mse: 0.8274\n",
      "Epoch 167/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0715 - mse: 0.8604 - val_loss: 0.0646 - val_mse: 0.8438\n",
      "Epoch 168/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0705 - mse: 0.8519 - val_loss: 0.0635 - val_mse: 0.8045\n",
      "Epoch 169/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0707 - mse: 0.8643 - val_loss: 0.0642 - val_mse: 0.8310\n",
      "Epoch 170/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0715 - mse: 0.8653\n",
      "Epoch 00170: saving model to Regression_Model/msle.linear-0170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8656 - val_loss: 0.0640 - val_mse: 0.8280\n",
      "Epoch 171/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8672 - val_loss: 0.0633 - val_mse: 0.8187\n",
      "Epoch 172/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8871 - val_loss: 0.0630 - val_mse: 0.8281\n",
      "Epoch 173/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8588 - val_loss: 0.0628 - val_mse: 0.8173\n",
      "Epoch 174/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8958 - val_loss: 0.0628 - val_mse: 0.8074\n",
      "Epoch 175/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8563 - val_loss: 0.0636 - val_mse: 0.8127\n",
      "Epoch 176/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8832 - val_loss: 0.0632 - val_mse: 0.8234\n",
      "Epoch 177/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0712 - mse: 0.8706 - val_loss: 0.0648 - val_mse: 0.8554\n",
      "Epoch 178/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0705 - mse: 0.8561 - val_loss: 0.0629 - val_mse: 0.8155\n",
      "Epoch 179/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0698 - mse: 0.8636 - val_loss: 0.0656 - val_mse: 0.8610\n",
      "Epoch 180/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0715 - mse: 0.8814\n",
      "Epoch 00180: saving model to Regression_Model/msle.linear-0180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8813 - val_loss: 0.0635 - val_mse: 0.8048\n",
      "Epoch 181/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8597 - val_loss: 0.0634 - val_mse: 0.8371\n",
      "Epoch 182/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0715 - mse: 0.8702 - val_loss: 0.0640 - val_mse: 0.8027\n",
      "Epoch 183/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8553 - val_loss: 0.0627 - val_mse: 0.8228\n",
      "Epoch 184/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0714 - mse: 0.8850 - val_loss: 0.0633 - val_mse: 0.8101\n",
      "Epoch 185/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0705 - mse: 0.8499 - val_loss: 0.0639 - val_mse: 0.8029\n",
      "Epoch 186/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8511 - val_loss: 0.0626 - val_mse: 0.8195\n",
      "Epoch 187/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0718 - mse: 0.8692 - val_loss: 0.0703 - val_mse: 0.8353\n",
      "Epoch 188/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0708 - mse: 0.8620 - val_loss: 0.0624 - val_mse: 0.8076\n",
      "Epoch 189/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8594 - val_loss: 0.0641 - val_mse: 0.8445\n",
      "Epoch 190/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0704 - mse: 0.8656\n",
      "Epoch 00190: saving model to Regression_Model/msle.linear-0190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8619 - val_loss: 0.0629 - val_mse: 0.7993\n",
      "Epoch 191/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8483 - val_loss: 0.0622 - val_mse: 0.8154\n",
      "Epoch 192/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8455 - val_loss: 0.0628 - val_mse: 0.8032\n",
      "Epoch 193/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8604 - val_loss: 0.0631 - val_mse: 0.8399\n",
      "Epoch 194/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0711 - mse: 0.8701 - val_loss: 0.0626 - val_mse: 0.8079\n",
      "Epoch 195/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8646 - val_loss: 0.0628 - val_mse: 0.7960\n",
      "Epoch 196/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8503 - val_loss: 0.0623 - val_mse: 0.8185\n",
      "Epoch 197/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0690 - mse: 0.8551 - val_loss: 0.0622 - val_mse: 0.8084\n",
      "Epoch 198/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0701 - mse: 0.8490 - val_loss: 0.0620 - val_mse: 0.8130\n",
      "Epoch 199/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8513 - val_loss: 0.0626 - val_mse: 0.8091\n",
      "Epoch 200/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0706 - mse: 0.8741\n",
      "Epoch 00200: saving model to Regression_Model/msle.linear-0200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0706 - mse: 0.8742 - val_loss: 0.0624 - val_mse: 0.8094\n",
      "Epoch 201/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0705 - mse: 0.8557 - val_loss: 0.0628 - val_mse: 0.8313\n",
      "Epoch 202/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0690 - mse: 0.8560 - val_loss: 0.0621 - val_mse: 0.8088\n",
      "Epoch 203/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0698 - mse: 0.8622 - val_loss: 0.0636 - val_mse: 0.8046\n",
      "Epoch 204/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0713 - mse: 0.8606 - val_loss: 0.0623 - val_mse: 0.8124\n",
      "Epoch 205/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8522 - val_loss: 0.0628 - val_mse: 0.8206\n",
      "Epoch 206/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8552 - val_loss: 0.0624 - val_mse: 0.8221\n",
      "Epoch 207/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8600 - val_loss: 0.0626 - val_mse: 0.8253\n",
      "Epoch 208/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8542 - val_loss: 0.0647 - val_mse: 0.7928\n",
      "Epoch 209/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8553 - val_loss: 0.0623 - val_mse: 0.8219\n",
      "Epoch 210/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0692 - mse: 0.8540\n",
      "Epoch 00210: saving model to Regression_Model/msle.linear-0210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8573 - val_loss: 0.0644 - val_mse: 0.8133\n",
      "Epoch 211/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8536 - val_loss: 0.0619 - val_mse: 0.8067\n",
      "Epoch 212/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8475 - val_loss: 0.0622 - val_mse: 0.8214\n",
      "Epoch 213/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8574 - val_loss: 0.0636 - val_mse: 0.8439\n",
      "Epoch 214/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0704 - mse: 0.8528 - val_loss: 0.0621 - val_mse: 0.8141\n",
      "Epoch 215/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8443 - val_loss: 0.0620 - val_mse: 0.8148\n",
      "Epoch 216/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8465 - val_loss: 0.0619 - val_mse: 0.8104\n",
      "Epoch 217/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0703 - mse: 0.8644 - val_loss: 0.0637 - val_mse: 0.7960\n",
      "Epoch 218/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0701 - mse: 0.8516 - val_loss: 0.0637 - val_mse: 0.7832\n",
      "Epoch 219/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8659 - val_loss: 0.0634 - val_mse: 0.7987\n",
      "Epoch 220/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0688 - mse: 0.8469\n",
      "Epoch 00220: saving model to Regression_Model/msle.linear-0220.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0687 - mse: 0.8460 - val_loss: 0.0621 - val_mse: 0.8067\n",
      "Epoch 221/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8447 - val_loss: 0.0618 - val_mse: 0.8068\n",
      "Epoch 222/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8626 - val_loss: 0.0622 - val_mse: 0.8149\n",
      "Epoch 223/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8547 - val_loss: 0.0626 - val_mse: 0.8282\n",
      "Epoch 224/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8750 - val_loss: 0.0628 - val_mse: 0.8187\n",
      "Epoch 225/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8435 - val_loss: 0.0620 - val_mse: 0.8205\n",
      "Epoch 226/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8388 - val_loss: 0.0622 - val_mse: 0.8152\n",
      "Epoch 227/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8570 - val_loss: 0.0624 - val_mse: 0.8108\n",
      "Epoch 228/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8515 - val_loss: 0.0645 - val_mse: 0.7869\n",
      "Epoch 229/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8310 - val_loss: 0.0618 - val_mse: 0.8042\n",
      "Epoch 230/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0701 - mse: 0.8664\n",
      "Epoch 00230: saving model to Regression_Model/msle.linear-0230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0702 - mse: 0.8610 - val_loss: 0.0624 - val_mse: 0.8327\n",
      "Epoch 231/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0699 - mse: 0.8489 - val_loss: 0.0625 - val_mse: 0.8194\n",
      "Epoch 232/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8516 - val_loss: 0.0634 - val_mse: 0.8441\n",
      "Epoch 233/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8808 - val_loss: 0.0632 - val_mse: 0.7948\n",
      "Epoch 234/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8396 - val_loss: 0.0622 - val_mse: 0.8192\n",
      "Epoch 235/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0691 - mse: 0.8467 - val_loss: 0.0632 - val_mse: 0.8409\n",
      "Epoch 236/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0701 - mse: 0.8518 - val_loss: 0.0614 - val_mse: 0.8004\n",
      "Epoch 237/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8446 - val_loss: 0.0620 - val_mse: 0.7938\n",
      "Epoch 238/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8579 - val_loss: 0.0620 - val_mse: 0.8140\n",
      "Epoch 239/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0696 - mse: 0.8447 - val_loss: 0.0614 - val_mse: 0.8023\n",
      "Epoch 240/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0686 - mse: 0.8433\n",
      "Epoch 00240: saving model to Regression_Model/msle.linear-0240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8461 - val_loss: 0.0644 - val_mse: 0.8033\n",
      "Epoch 241/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8567 - val_loss: 0.0616 - val_mse: 0.8123\n",
      "Epoch 242/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8433 - val_loss: 0.0619 - val_mse: 0.8059\n",
      "Epoch 243/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8457 - val_loss: 0.0624 - val_mse: 0.8305\n",
      "Epoch 244/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0694 - mse: 0.8607 - val_loss: 0.0618 - val_mse: 0.8226\n",
      "Epoch 245/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8444 - val_loss: 0.0620 - val_mse: 0.8264\n",
      "Epoch 246/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8450 - val_loss: 0.0618 - val_mse: 0.7915\n",
      "Epoch 247/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0691 - mse: 0.8468 - val_loss: 0.0632 - val_mse: 0.7973\n",
      "Epoch 248/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8564 - val_loss: 0.0627 - val_mse: 0.7853\n",
      "Epoch 249/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0689 - mse: 0.8453 - val_loss: 0.0615 - val_mse: 0.8024\n",
      "Epoch 250/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0700 - mse: 0.8554\n",
      "Epoch 00250: saving model to Regression_Model/msle.linear-0250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8562 - val_loss: 0.0610 - val_mse: 0.7927\n",
      "Epoch 251/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8416 - val_loss: 0.0611 - val_mse: 0.8085\n",
      "Epoch 252/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8509 - val_loss: 0.0624 - val_mse: 0.8257\n",
      "Epoch 253/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8468 - val_loss: 0.0614 - val_mse: 0.7952\n",
      "Epoch 254/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8504 - val_loss: 0.0627 - val_mse: 0.8186\n",
      "Epoch 255/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8449 - val_loss: 0.0617 - val_mse: 0.8191\n",
      "Epoch 256/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8452 - val_loss: 0.0623 - val_mse: 0.8275\n",
      "Epoch 257/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8448 - val_loss: 0.0623 - val_mse: 0.8148\n",
      "Epoch 258/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8495 - val_loss: 0.0615 - val_mse: 0.8153\n",
      "Epoch 259/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8378 - val_loss: 0.0617 - val_mse: 0.8051\n",
      "Epoch 260/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0683 - mse: 0.8445\n",
      "Epoch 00260: saving model to Regression_Model/msle.linear-0260.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0683 - mse: 0.8440 - val_loss: 0.0621 - val_mse: 0.7915\n",
      "Epoch 261/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8560 - val_loss: 0.0615 - val_mse: 0.8183\n",
      "Epoch 262/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8573 - val_loss: 0.0615 - val_mse: 0.8187\n",
      "Epoch 263/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8481 - val_loss: 0.0631 - val_mse: 0.7793\n",
      "Epoch 264/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8556 - val_loss: 0.0612 - val_mse: 0.8086\n",
      "Epoch 265/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0690 - mse: 0.8397 - val_loss: 0.0634 - val_mse: 0.8103\n",
      "Epoch 266/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8483 - val_loss: 0.0614 - val_mse: 0.8084\n",
      "Epoch 267/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8481 - val_loss: 0.0619 - val_mse: 0.8257\n",
      "Epoch 268/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0691 - mse: 0.8550 - val_loss: 0.0614 - val_mse: 0.8113\n",
      "Epoch 269/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8505 - val_loss: 0.0612 - val_mse: 0.8028\n",
      "Epoch 270/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0687 - mse: 0.8471\n",
      "Epoch 00270: saving model to Regression_Model/msle.linear-0270.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0688 - mse: 0.8465 - val_loss: 0.0612 - val_mse: 0.8044\n",
      "Epoch 271/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8500 - val_loss: 0.0616 - val_mse: 0.8095\n",
      "Epoch 272/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8339 - val_loss: 0.0616 - val_mse: 0.8228\n",
      "Epoch 273/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0698 - mse: 0.8670 - val_loss: 0.0619 - val_mse: 0.7954\n",
      "Epoch 274/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0687 - mse: 0.8517 - val_loss: 0.0609 - val_mse: 0.7996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0695 - mse: 0.8473 - val_loss: 0.0614 - val_mse: 0.8178\n",
      "Epoch 276/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8407 - val_loss: 0.0620 - val_mse: 0.8137\n",
      "Epoch 277/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8566 - val_loss: 0.0610 - val_mse: 0.8068\n",
      "Epoch 278/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8491 - val_loss: 0.0619 - val_mse: 0.8092\n",
      "Epoch 279/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0697 - mse: 0.8535 - val_loss: 0.0623 - val_mse: 0.8352\n",
      "Epoch 280/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0690 - mse: 0.8574\n",
      "Epoch 00280: saving model to Regression_Model/msle.linear-0280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0687 - mse: 0.8525 - val_loss: 0.0610 - val_mse: 0.8050\n",
      "Epoch 281/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8478 - val_loss: 0.0614 - val_mse: 0.8192\n",
      "Epoch 282/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8512 - val_loss: 0.0616 - val_mse: 0.8239\n",
      "Epoch 283/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8539 - val_loss: 0.0626 - val_mse: 0.8349\n",
      "Epoch 284/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8481 - val_loss: 0.0608 - val_mse: 0.8052\n",
      "Epoch 285/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8358 - val_loss: 0.0612 - val_mse: 0.8072\n",
      "Epoch 286/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8456 - val_loss: 0.0615 - val_mse: 0.7878\n",
      "Epoch 287/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8402 - val_loss: 0.0618 - val_mse: 0.8224\n",
      "Epoch 288/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0681 - mse: 0.8419 - val_loss: 0.0612 - val_mse: 0.8151\n",
      "Epoch 289/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0686 - mse: 0.8513 - val_loss: 0.0614 - val_mse: 0.8257\n",
      "Epoch 290/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0683 - mse: 0.8439\n",
      "Epoch 00290: saving model to Regression_Model/msle.linear-0290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8463 - val_loss: 0.0620 - val_mse: 0.8001\n",
      "Epoch 291/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8436 - val_loss: 0.0618 - val_mse: 0.8258\n",
      "Epoch 292/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8478 - val_loss: 0.0622 - val_mse: 0.8361\n",
      "Epoch 293/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8389 - val_loss: 0.0616 - val_mse: 0.8188\n",
      "Epoch 294/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8482 - val_loss: 0.0613 - val_mse: 0.8180\n",
      "Epoch 295/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8465 - val_loss: 0.0631 - val_mse: 0.8420\n",
      "Epoch 296/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8530 - val_loss: 0.0612 - val_mse: 0.8031\n",
      "Epoch 297/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0690 - mse: 0.8531 - val_loss: 0.0621 - val_mse: 0.8266\n",
      "Epoch 298/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8475 - val_loss: 0.0613 - val_mse: 0.7955\n",
      "Epoch 299/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8417 - val_loss: 0.0614 - val_mse: 0.8205\n",
      "Epoch 300/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0683 - mse: 0.8459\n",
      "Epoch 00300: saving model to Regression_Model/msle.linear-0300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8503 - val_loss: 0.0608 - val_mse: 0.7994\n",
      "Epoch 301/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8546 - val_loss: 0.0612 - val_mse: 0.8198\n",
      "Epoch 302/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0692 - mse: 0.8451 - val_loss: 0.0642 - val_mse: 0.8607\n",
      "Epoch 303/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0700 - mse: 0.8624 - val_loss: 0.0607 - val_mse: 0.8037\n",
      "Epoch 304/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8390 - val_loss: 0.0617 - val_mse: 0.8287\n",
      "Epoch 305/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8451 - val_loss: 0.0618 - val_mse: 0.8108\n",
      "Epoch 306/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8401 - val_loss: 0.0617 - val_mse: 0.8264\n",
      "Epoch 307/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8474 - val_loss: 0.0615 - val_mse: 0.8254\n",
      "Epoch 308/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8435 - val_loss: 0.0618 - val_mse: 0.8040\n",
      "Epoch 309/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8446 - val_loss: 0.0617 - val_mse: 0.7858\n",
      "Epoch 310/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0688 - mse: 0.8390\n",
      "Epoch 00310: saving model to Regression_Model/msle.linear-0310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8421 - val_loss: 0.0609 - val_mse: 0.8102\n",
      "Epoch 311/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8365 - val_loss: 0.0611 - val_mse: 0.8143\n",
      "Epoch 312/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8439 - val_loss: 0.0609 - val_mse: 0.8044\n",
      "Epoch 313/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8594 - val_loss: 0.0609 - val_mse: 0.7917\n",
      "Epoch 314/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8398 - val_loss: 0.0613 - val_mse: 0.8188\n",
      "Epoch 315/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8392 - val_loss: 0.0624 - val_mse: 0.8341\n",
      "Epoch 316/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0691 - mse: 0.8554 - val_loss: 0.0605 - val_mse: 0.7937\n",
      "Epoch 317/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8361 - val_loss: 0.0613 - val_mse: 0.8173\n",
      "Epoch 318/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8381 - val_loss: 0.0610 - val_mse: 0.8116\n",
      "Epoch 319/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8334 - val_loss: 0.0607 - val_mse: 0.8050\n",
      "Epoch 320/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0685 - mse: 0.8442\n",
      "Epoch 00320: saving model to Regression_Model/msle.linear-0320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8422 - val_loss: 0.0607 - val_mse: 0.8081\n",
      "Epoch 321/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8315 - val_loss: 0.0608 - val_mse: 0.8120\n",
      "Epoch 322/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8428 - val_loss: 0.0615 - val_mse: 0.7812\n",
      "Epoch 323/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8404 - val_loss: 0.0618 - val_mse: 0.8040\n",
      "Epoch 324/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0684 - mse: 0.8393 - val_loss: 0.0634 - val_mse: 0.8466\n",
      "Epoch 325/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8489 - val_loss: 0.0608 - val_mse: 0.8106\n",
      "Epoch 326/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8411 - val_loss: 0.0606 - val_mse: 0.8118\n",
      "Epoch 327/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0680 - mse: 0.8383 - val_loss: 0.0612 - val_mse: 0.8163\n",
      "Epoch 328/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8507 - val_loss: 0.0611 - val_mse: 0.8205\n",
      "Epoch 329/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8428 - val_loss: 0.0610 - val_mse: 0.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8378\n",
      "Epoch 00330: saving model to Regression_Model/msle.linear-0330.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 0.0674 - mse: 0.8378 - val_loss: 0.0610 - val_mse: 0.8136\n",
      "Epoch 331/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0688 - mse: 0.8552 - val_loss: 0.0620 - val_mse: 0.8322\n",
      "Epoch 332/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8380 - val_loss: 0.0634 - val_mse: 0.7791\n",
      "Epoch 333/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8401 - val_loss: 0.0606 - val_mse: 0.8077\n",
      "Epoch 334/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8466 - val_loss: 0.0611 - val_mse: 0.8202\n",
      "Epoch 335/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0694 - mse: 0.8523 - val_loss: 0.0618 - val_mse: 0.8298\n",
      "Epoch 336/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8380 - val_loss: 0.0606 - val_mse: 0.7930\n",
      "Epoch 337/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8293 - val_loss: 0.0608 - val_mse: 0.8104\n",
      "Epoch 338/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8439 - val_loss: 0.0609 - val_mse: 0.7912\n",
      "Epoch 339/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8436 - val_loss: 0.0605 - val_mse: 0.8028\n",
      "Epoch 340/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0674 - mse: 0.8417\n",
      "Epoch 00340: saving model to Regression_Model/msle.linear-0340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8439 - val_loss: 0.0607 - val_mse: 0.7886\n",
      "Epoch 341/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8310 - val_loss: 0.0608 - val_mse: 0.8006\n",
      "Epoch 342/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8396 - val_loss: 0.0606 - val_mse: 0.8018\n",
      "Epoch 343/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0685 - mse: 0.8493 - val_loss: 0.0625 - val_mse: 0.8287\n",
      "Epoch 344/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8406 - val_loss: 0.0613 - val_mse: 0.8218\n",
      "Epoch 345/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8385 - val_loss: 0.0609 - val_mse: 0.7905\n",
      "Epoch 346/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0693 - mse: 0.8521 - val_loss: 0.0608 - val_mse: 0.8144\n",
      "Epoch 347/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8435 - val_loss: 0.0608 - val_mse: 0.7933\n",
      "Epoch 348/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8428 - val_loss: 0.0622 - val_mse: 0.8297\n",
      "Epoch 349/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8450 - val_loss: 0.0610 - val_mse: 0.7967\n",
      "Epoch 350/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0681 - mse: 0.8411\n",
      "Epoch 00350: saving model to Regression_Model/msle.linear-0350.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8417 - val_loss: 0.0604 - val_mse: 0.7917\n",
      "Epoch 351/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8321 - val_loss: 0.0620 - val_mse: 0.8295\n",
      "Epoch 352/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0669 - mse: 0.8379 - val_loss: 0.0608 - val_mse: 0.8128\n",
      "Epoch 353/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8417 - val_loss: 0.0606 - val_mse: 0.8085\n",
      "Epoch 354/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8511 - val_loss: 0.0609 - val_mse: 0.8134\n",
      "Epoch 355/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8230 - val_loss: 0.0603 - val_mse: 0.7992\n",
      "Epoch 356/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8293 - val_loss: 0.0606 - val_mse: 0.7963\n",
      "Epoch 357/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8385 - val_loss: 0.0604 - val_mse: 0.8103\n",
      "Epoch 358/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8375 - val_loss: 0.0611 - val_mse: 0.8219\n",
      "Epoch 359/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8362 - val_loss: 0.0607 - val_mse: 0.8137\n",
      "Epoch 360/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0675 - mse: 0.8469\n",
      "Epoch 00360: saving model to Regression_Model/msle.linear-0360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8467 - val_loss: 0.0609 - val_mse: 0.8210\n",
      "Epoch 361/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8422 - val_loss: 0.0607 - val_mse: 0.8165\n",
      "Epoch 362/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8297 - val_loss: 0.0606 - val_mse: 0.7966\n",
      "Epoch 363/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8422 - val_loss: 0.0602 - val_mse: 0.7955\n",
      "Epoch 364/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8275 - val_loss: 0.0605 - val_mse: 0.8073\n",
      "Epoch 365/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8380 - val_loss: 0.0607 - val_mse: 0.7897\n",
      "Epoch 366/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8385 - val_loss: 0.0610 - val_mse: 0.8227\n",
      "Epoch 367/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8395 - val_loss: 0.0636 - val_mse: 0.8046\n",
      "Epoch 368/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0686 - mse: 0.8641 - val_loss: 0.0619 - val_mse: 0.7914\n",
      "Epoch 369/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8377 - val_loss: 0.0609 - val_mse: 0.8184\n",
      "Epoch 370/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0674 - mse: 0.8404\n",
      "Epoch 00370: saving model to Regression_Model/msle.linear-0370.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8352 - val_loss: 0.0603 - val_mse: 0.8064\n",
      "Epoch 371/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8437 - val_loss: 0.0602 - val_mse: 0.8035\n",
      "Epoch 372/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8495 - val_loss: 0.0605 - val_mse: 0.7866\n",
      "Epoch 373/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8400 - val_loss: 0.0604 - val_mse: 0.8113\n",
      "Epoch 374/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8278 - val_loss: 0.0602 - val_mse: 0.8012\n",
      "Epoch 375/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0680 - mse: 0.8512 - val_loss: 0.0616 - val_mse: 0.8253\n",
      "Epoch 376/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8544 - val_loss: 0.0606 - val_mse: 0.7917\n",
      "Epoch 377/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8346 - val_loss: 0.0608 - val_mse: 0.8160\n",
      "Epoch 378/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8387 - val_loss: 0.0611 - val_mse: 0.8012\n",
      "Epoch 379/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8447 - val_loss: 0.0601 - val_mse: 0.8044\n",
      "Epoch 380/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0683 - mse: 0.8423\n",
      "Epoch 00380: saving model to Regression_Model/msle.linear-0380.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0680 - mse: 0.8428 - val_loss: 0.0604 - val_mse: 0.8105\n",
      "Epoch 381/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8350 - val_loss: 0.0604 - val_mse: 0.8070\n",
      "Epoch 382/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8408 - val_loss: 0.0609 - val_mse: 0.7973\n",
      "Epoch 383/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8346 - val_loss: 0.0610 - val_mse: 0.7896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8243 - val_loss: 0.0602 - val_mse: 0.7937\n",
      "Epoch 385/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8361 - val_loss: 0.0603 - val_mse: 0.8061\n",
      "Epoch 386/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8430 - val_loss: 0.0600 - val_mse: 0.8011\n",
      "Epoch 387/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8373 - val_loss: 0.0603 - val_mse: 0.8068\n",
      "Epoch 388/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8442 - val_loss: 0.0603 - val_mse: 0.7988\n",
      "Epoch 389/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8345 - val_loss: 0.0608 - val_mse: 0.8204\n",
      "Epoch 390/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0671 - mse: 0.8272\n",
      "Epoch 00390: saving model to Regression_Model/msle.linear-0390.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0670 - mse: 0.8320 - val_loss: 0.0616 - val_mse: 0.8230\n",
      "Epoch 391/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8318 - val_loss: 0.0609 - val_mse: 0.7893\n",
      "Epoch 392/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8371 - val_loss: 0.0629 - val_mse: 0.7774\n",
      "Epoch 393/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8407 - val_loss: 0.0610 - val_mse: 0.8192\n",
      "Epoch 394/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8369 - val_loss: 0.0603 - val_mse: 0.8130\n",
      "Epoch 395/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8362 - val_loss: 0.0603 - val_mse: 0.8050\n",
      "Epoch 396/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8400 - val_loss: 0.0605 - val_mse: 0.8116\n",
      "Epoch 397/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8337 - val_loss: 0.0601 - val_mse: 0.8022\n",
      "Epoch 398/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8341 - val_loss: 0.0600 - val_mse: 0.7945\n",
      "Epoch 399/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8354 - val_loss: 0.0602 - val_mse: 0.8083\n",
      "Epoch 400/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8393\n",
      "Epoch 00400: saving model to Regression_Model/msle.linear-0400.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8397 - val_loss: 0.0602 - val_mse: 0.7839\n",
      "Epoch 401/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8290 - val_loss: 0.0607 - val_mse: 0.8002\n",
      "Epoch 402/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8471 - val_loss: 0.0606 - val_mse: 0.8037\n",
      "Epoch 403/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8382 - val_loss: 0.0603 - val_mse: 0.8099\n",
      "Epoch 404/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8312 - val_loss: 0.0610 - val_mse: 0.8256\n",
      "Epoch 405/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8379 - val_loss: 0.0606 - val_mse: 0.7839\n",
      "Epoch 406/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8388 - val_loss: 0.0604 - val_mse: 0.8080\n",
      "Epoch 407/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8327 - val_loss: 0.0607 - val_mse: 0.8208\n",
      "Epoch 408/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8397 - val_loss: 0.0621 - val_mse: 0.8411\n",
      "Epoch 409/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8335 - val_loss: 0.0600 - val_mse: 0.7929\n",
      "Epoch 410/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0671 - mse: 0.8287\n",
      "Epoch 00410: saving model to Regression_Model/msle.linear-0410.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8287 - val_loss: 0.0615 - val_mse: 0.8261\n",
      "Epoch 411/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8347 - val_loss: 0.0605 - val_mse: 0.7895\n",
      "Epoch 412/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8348 - val_loss: 0.0599 - val_mse: 0.8021\n",
      "Epoch 413/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8240 - val_loss: 0.0601 - val_mse: 0.8079\n",
      "Epoch 414/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8287 - val_loss: 0.0601 - val_mse: 0.8077\n",
      "Epoch 415/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0683 - mse: 0.8438 - val_loss: 0.0607 - val_mse: 0.7842\n",
      "Epoch 416/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0671 - mse: 0.8463 - val_loss: 0.0599 - val_mse: 0.8067\n",
      "Epoch 417/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8449 - val_loss: 0.0605 - val_mse: 0.7915\n",
      "Epoch 418/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8241 - val_loss: 0.0604 - val_mse: 0.8156\n",
      "Epoch 419/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8397 - val_loss: 0.0604 - val_mse: 0.7857\n",
      "Epoch 420/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8477\n",
      "Epoch 00420: saving model to Regression_Model/msle.linear-0420.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0674 - mse: 0.8448 - val_loss: 0.0600 - val_mse: 0.7908\n",
      "Epoch 421/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8353 - val_loss: 0.0607 - val_mse: 0.7871\n",
      "Epoch 422/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8346 - val_loss: 0.0603 - val_mse: 0.8134\n",
      "Epoch 423/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8253 - val_loss: 0.0611 - val_mse: 0.7923\n",
      "Epoch 424/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8392 - val_loss: 0.0602 - val_mse: 0.8122\n",
      "Epoch 425/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8241 - val_loss: 0.0617 - val_mse: 0.8362\n",
      "Epoch 426/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8428 - val_loss: 0.0598 - val_mse: 0.7934\n",
      "Epoch 427/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8328 - val_loss: 0.0604 - val_mse: 0.8086\n",
      "Epoch 428/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0689 - mse: 0.8495 - val_loss: 0.0595 - val_mse: 0.7936\n",
      "Epoch 429/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8226 - val_loss: 0.0599 - val_mse: 0.7863\n",
      "Epoch 430/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0668 - mse: 0.8294\n",
      "Epoch 00430: saving model to Regression_Model/msle.linear-0430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8309 - val_loss: 0.0598 - val_mse: 0.8006\n",
      "Epoch 431/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8443 - val_loss: 0.0600 - val_mse: 0.7881\n",
      "Epoch 432/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0681 - mse: 0.8413 - val_loss: 0.0604 - val_mse: 0.8189\n",
      "Epoch 433/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8386 - val_loss: 0.0596 - val_mse: 0.7954\n",
      "Epoch 434/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8326 - val_loss: 0.0607 - val_mse: 0.8227\n",
      "Epoch 435/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8346 - val_loss: 0.0599 - val_mse: 0.8039\n",
      "Epoch 436/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8397 - val_loss: 0.0601 - val_mse: 0.7894\n",
      "Epoch 437/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8318 - val_loss: 0.0599 - val_mse: 0.8020\n",
      "Epoch 438/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8451 - val_loss: 0.0604 - val_mse: 0.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8351 - val_loss: 0.0606 - val_mse: 0.8133\n",
      "Epoch 440/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8346\n",
      "Epoch 00440: saving model to Regression_Model/msle.linear-0440.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0675 - mse: 0.8348 - val_loss: 0.0602 - val_mse: 0.7978\n",
      "Epoch 441/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8390 - val_loss: 0.0603 - val_mse: 0.8114\n",
      "Epoch 442/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8286 - val_loss: 0.0597 - val_mse: 0.7927\n",
      "Epoch 443/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8296 - val_loss: 0.0601 - val_mse: 0.8111\n",
      "Epoch 444/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8369 - val_loss: 0.0604 - val_mse: 0.7851\n",
      "Epoch 445/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8461 - val_loss: 0.0600 - val_mse: 0.7973\n",
      "Epoch 446/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8390 - val_loss: 0.0602 - val_mse: 0.7953\n",
      "Epoch 447/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8421 - val_loss: 0.0599 - val_mse: 0.7999\n",
      "Epoch 448/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0680 - mse: 0.8390 - val_loss: 0.0597 - val_mse: 0.7954\n",
      "Epoch 449/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8346 - val_loss: 0.0607 - val_mse: 0.8183\n",
      "Epoch 450/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0665 - mse: 0.8281\n",
      "Epoch 00450: saving model to Regression_Model/msle.linear-0450.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0665 - mse: 0.8272 - val_loss: 0.0600 - val_mse: 0.7942\n",
      "Epoch 451/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8372 - val_loss: 0.0602 - val_mse: 0.7963\n",
      "Epoch 452/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8370 - val_loss: 0.0604 - val_mse: 0.8159\n",
      "Epoch 453/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8414 - val_loss: 0.0603 - val_mse: 0.8125\n",
      "Epoch 454/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8314 - val_loss: 0.0606 - val_mse: 0.8233\n",
      "Epoch 455/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8320 - val_loss: 0.0609 - val_mse: 0.7877\n",
      "Epoch 456/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8365 - val_loss: 0.0603 - val_mse: 0.8134\n",
      "Epoch 457/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8264 - val_loss: 0.0597 - val_mse: 0.8061\n",
      "Epoch 458/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0679 - mse: 0.8437 - val_loss: 0.0606 - val_mse: 0.8218\n",
      "Epoch 459/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8325 - val_loss: 0.0597 - val_mse: 0.8049\n",
      "Epoch 460/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0675 - mse: 0.8442\n",
      "Epoch 00460: saving model to Regression_Model/msle.linear-0460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0676 - mse: 0.8408 - val_loss: 0.0624 - val_mse: 0.8466\n",
      "Epoch 461/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8563 - val_loss: 0.0605 - val_mse: 0.8120\n",
      "Epoch 462/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8260 - val_loss: 0.0601 - val_mse: 0.8083\n",
      "Epoch 463/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8372 - val_loss: 0.0598 - val_mse: 0.8045\n",
      "Epoch 464/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8398 - val_loss: 0.0617 - val_mse: 0.8365\n",
      "Epoch 465/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8387 - val_loss: 0.0605 - val_mse: 0.8136\n",
      "Epoch 466/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8377 - val_loss: 0.0602 - val_mse: 0.8116\n",
      "Epoch 467/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8315 - val_loss: 0.0596 - val_mse: 0.7874\n",
      "Epoch 468/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0678 - mse: 0.8482 - val_loss: 0.0614 - val_mse: 0.8320\n",
      "Epoch 469/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8311 - val_loss: 0.0603 - val_mse: 0.7982\n",
      "Epoch 470/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0674 - mse: 0.8307\n",
      "Epoch 00470: saving model to Regression_Model/msle.linear-0470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8320 - val_loss: 0.0606 - val_mse: 0.8209\n",
      "Epoch 471/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8432 - val_loss: 0.0600 - val_mse: 0.8026\n",
      "Epoch 472/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8423 - val_loss: 0.0603 - val_mse: 0.8083\n",
      "Epoch 473/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8285 - val_loss: 0.0598 - val_mse: 0.7925\n",
      "Epoch 474/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8227 - val_loss: 0.0596 - val_mse: 0.7918\n",
      "Epoch 475/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8298 - val_loss: 0.0596 - val_mse: 0.8004\n",
      "Epoch 476/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8296 - val_loss: 0.0611 - val_mse: 0.7800\n",
      "Epoch 477/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8263 - val_loss: 0.0596 - val_mse: 0.8008\n",
      "Epoch 478/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8273 - val_loss: 0.0602 - val_mse: 0.8061\n",
      "Epoch 479/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8278 - val_loss: 0.0596 - val_mse: 0.8022\n",
      "Epoch 480/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0665 - mse: 0.8318\n",
      "Epoch 00480: saving model to Regression_Model/msle.linear-0480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8315 - val_loss: 0.0609 - val_mse: 0.8232\n",
      "Epoch 481/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8441 - val_loss: 0.0606 - val_mse: 0.7836\n",
      "Epoch 482/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8349 - val_loss: 0.0602 - val_mse: 0.8134\n",
      "Epoch 483/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8449 - val_loss: 0.0613 - val_mse: 0.8181\n",
      "Epoch 484/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8209 - val_loss: 0.0598 - val_mse: 0.8055\n",
      "Epoch 485/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8367 - val_loss: 0.0601 - val_mse: 0.7781\n",
      "Epoch 486/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8329 - val_loss: 0.0597 - val_mse: 0.8055\n",
      "Epoch 487/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8327 - val_loss: 0.0603 - val_mse: 0.7897\n",
      "Epoch 488/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8369 - val_loss: 0.0603 - val_mse: 0.8172\n",
      "Epoch 489/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8326 - val_loss: 0.0597 - val_mse: 0.7864\n",
      "Epoch 490/2000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.0673 - mse: 0.8359\n",
      "Epoch 00490: saving model to Regression_Model/msle.linear-0490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0670 - mse: 0.8348 - val_loss: 0.0614 - val_mse: 0.8337\n",
      "Epoch 491/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8460 - val_loss: 0.0604 - val_mse: 0.8184\n",
      "Epoch 492/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8492 - val_loss: 0.0600 - val_mse: 0.7943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8324 - val_loss: 0.0596 - val_mse: 0.8023\n",
      "Epoch 494/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8402 - val_loss: 0.0598 - val_mse: 0.8010\n",
      "Epoch 495/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8323 - val_loss: 0.0600 - val_mse: 0.8058\n",
      "Epoch 496/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8292 - val_loss: 0.0599 - val_mse: 0.8012\n",
      "Epoch 497/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8318 - val_loss: 0.0595 - val_mse: 0.7976\n",
      "Epoch 498/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8391 - val_loss: 0.0596 - val_mse: 0.7983\n",
      "Epoch 499/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8391 - val_loss: 0.0601 - val_mse: 0.8021\n",
      "Epoch 500/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0660 - mse: 0.8259\n",
      "Epoch 00500: saving model to Regression_Model/msle.linear-0500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8252 - val_loss: 0.0605 - val_mse: 0.7999\n",
      "Epoch 501/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8257 - val_loss: 0.0596 - val_mse: 0.7871\n",
      "Epoch 502/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8366 - val_loss: 0.0598 - val_mse: 0.8071\n",
      "Epoch 503/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8330 - val_loss: 0.0597 - val_mse: 0.7943\n",
      "Epoch 504/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8319 - val_loss: 0.0602 - val_mse: 0.7994\n",
      "Epoch 505/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8366 - val_loss: 0.0600 - val_mse: 0.7881\n",
      "Epoch 506/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8652 - val_loss: 0.0598 - val_mse: 0.8017\n",
      "Epoch 507/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0660 - mse: 0.8314 - val_loss: 0.0597 - val_mse: 0.8068\n",
      "Epoch 508/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8326 - val_loss: 0.0602 - val_mse: 0.7882\n",
      "Epoch 509/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8282 - val_loss: 0.0602 - val_mse: 0.8169\n",
      "Epoch 510/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0662 - mse: 0.8282\n",
      "Epoch 00510: saving model to Regression_Model/msle.linear-0510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8298 - val_loss: 0.0602 - val_mse: 0.8130\n",
      "Epoch 511/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8260 - val_loss: 0.0598 - val_mse: 0.7880\n",
      "Epoch 512/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8472 - val_loss: 0.0597 - val_mse: 0.8041\n",
      "Epoch 513/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8288 - val_loss: 0.0604 - val_mse: 0.8206\n",
      "Epoch 514/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8363 - val_loss: 0.0600 - val_mse: 0.8128\n",
      "Epoch 515/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8383 - val_loss: 0.0601 - val_mse: 0.7995\n",
      "Epoch 516/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8374 - val_loss: 0.0595 - val_mse: 0.8006\n",
      "Epoch 517/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8373 - val_loss: 0.0595 - val_mse: 0.7898\n",
      "Epoch 518/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8334 - val_loss: 0.0603 - val_mse: 0.8066\n",
      "Epoch 519/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8376 - val_loss: 0.0604 - val_mse: 0.7885\n",
      "Epoch 520/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0658 - mse: 0.8235\n",
      "Epoch 00520: saving model to Regression_Model/msle.linear-0520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8287 - val_loss: 0.0600 - val_mse: 0.8084\n",
      "Epoch 521/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8343 - val_loss: 0.0597 - val_mse: 0.8060\n",
      "Epoch 522/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0682 - mse: 0.8439 - val_loss: 0.0602 - val_mse: 0.8162\n",
      "Epoch 523/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8578 - val_loss: 0.0595 - val_mse: 0.7870\n",
      "Epoch 524/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8496 - val_loss: 0.0596 - val_mse: 0.8040\n",
      "Epoch 525/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8195 - val_loss: 0.0594 - val_mse: 0.8000\n",
      "Epoch 526/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8287 - val_loss: 0.0603 - val_mse: 0.8203\n",
      "Epoch 527/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8439 - val_loss: 0.0612 - val_mse: 0.7850\n",
      "Epoch 528/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8255 - val_loss: 0.0597 - val_mse: 0.8103\n",
      "Epoch 529/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8300 - val_loss: 0.0596 - val_mse: 0.8035\n",
      "Epoch 530/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0667 - mse: 0.8305\n",
      "Epoch 00530: saving model to Regression_Model/msle.linear-0530.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0664 - mse: 0.8299 - val_loss: 0.0596 - val_mse: 0.7939\n",
      "Epoch 531/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8400 - val_loss: 0.0599 - val_mse: 0.8059\n",
      "Epoch 532/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8352 - val_loss: 0.0593 - val_mse: 0.8017\n",
      "Epoch 533/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0673 - mse: 0.8288 - val_loss: 0.0594 - val_mse: 0.8032\n",
      "Epoch 534/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8429 - val_loss: 0.0595 - val_mse: 0.7976\n",
      "Epoch 535/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8333 - val_loss: 0.0594 - val_mse: 0.7953\n",
      "Epoch 536/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8280 - val_loss: 0.0599 - val_mse: 0.7930\n",
      "Epoch 537/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8339 - val_loss: 0.0594 - val_mse: 0.7987\n",
      "Epoch 538/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8292 - val_loss: 0.0597 - val_mse: 0.7965\n",
      "Epoch 539/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8274 - val_loss: 0.0597 - val_mse: 0.8079\n",
      "Epoch 540/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0655 - mse: 0.8273\n",
      "Epoch 00540: saving model to Regression_Model/msle.linear-0540.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0656 - mse: 0.8287 - val_loss: 0.0603 - val_mse: 0.8140\n",
      "Epoch 541/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8361 - val_loss: 0.0594 - val_mse: 0.7991\n",
      "Epoch 542/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8341 - val_loss: 0.0598 - val_mse: 0.7939\n",
      "Epoch 543/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8268 - val_loss: 0.0605 - val_mse: 0.8233\n",
      "Epoch 544/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0662 - mse: 0.8319 - val_loss: 0.0596 - val_mse: 0.8013\n",
      "Epoch 545/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8299 - val_loss: 0.0594 - val_mse: 0.8031\n",
      "Epoch 546/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8281 - val_loss: 0.0594 - val_mse: 0.7957\n",
      "Epoch 547/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8457 - val_loss: 0.0597 - val_mse: 0.7896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 548/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8385 - val_loss: 0.0597 - val_mse: 0.8078\n",
      "Epoch 549/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8285 - val_loss: 0.0597 - val_mse: 0.8073\n",
      "Epoch 550/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0654 - mse: 0.8226\n",
      "Epoch 00550: saving model to Regression_Model/msle.linear-0550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8269 - val_loss: 0.0604 - val_mse: 0.8251\n",
      "Epoch 551/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8238 - val_loss: 0.0594 - val_mse: 0.8060\n",
      "Epoch 552/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8327 - val_loss: 0.0600 - val_mse: 0.8173\n",
      "Epoch 553/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8423 - val_loss: 0.0595 - val_mse: 0.7911\n",
      "Epoch 554/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8294 - val_loss: 0.0593 - val_mse: 0.8007\n",
      "Epoch 555/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8278 - val_loss: 0.0592 - val_mse: 0.8013\n",
      "Epoch 556/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8312 - val_loss: 0.0600 - val_mse: 0.8121\n",
      "Epoch 557/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8238 - val_loss: 0.0593 - val_mse: 0.7934\n",
      "Epoch 558/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8330 - val_loss: 0.0601 - val_mse: 0.8177\n",
      "Epoch 559/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8326 - val_loss: 0.0591 - val_mse: 0.7914\n",
      "Epoch 560/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0669 - mse: 0.8400\n",
      "Epoch 00560: saving model to Regression_Model/msle.linear-0560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8409 - val_loss: 0.0593 - val_mse: 0.7915\n",
      "Epoch 561/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8357 - val_loss: 0.0593 - val_mse: 0.8042\n",
      "Epoch 562/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8247 - val_loss: 0.0592 - val_mse: 0.7990\n",
      "Epoch 563/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8231 - val_loss: 0.0609 - val_mse: 0.7822\n",
      "Epoch 564/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8309 - val_loss: 0.0592 - val_mse: 0.7952\n",
      "Epoch 565/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0662 - mse: 0.8297 - val_loss: 0.0594 - val_mse: 0.8013\n",
      "Epoch 566/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8261 - val_loss: 0.0597 - val_mse: 0.7788\n",
      "Epoch 567/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8283 - val_loss: 0.0594 - val_mse: 0.7914\n",
      "Epoch 568/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8384 - val_loss: 0.0592 - val_mse: 0.7949\n",
      "Epoch 569/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8230 - val_loss: 0.0594 - val_mse: 0.7873\n",
      "Epoch 570/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8203\n",
      "Epoch 00570: saving model to Regression_Model/msle.linear-0570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8214 - val_loss: 0.0605 - val_mse: 0.8261\n",
      "Epoch 571/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8284 - val_loss: 0.0592 - val_mse: 0.7978\n",
      "Epoch 572/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8294 - val_loss: 0.0596 - val_mse: 0.8090\n",
      "Epoch 573/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0674 - mse: 0.8418 - val_loss: 0.0593 - val_mse: 0.7996\n",
      "Epoch 574/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8271 - val_loss: 0.0597 - val_mse: 0.8075\n",
      "Epoch 575/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8358 - val_loss: 0.0594 - val_mse: 0.7935\n",
      "Epoch 576/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8331 - val_loss: 0.0595 - val_mse: 0.8043\n",
      "Epoch 577/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8254 - val_loss: 0.0593 - val_mse: 0.7973\n",
      "Epoch 578/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0677 - mse: 0.8494 - val_loss: 0.0603 - val_mse: 0.8224\n",
      "Epoch 579/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8263 - val_loss: 0.0594 - val_mse: 0.8026\n",
      "Epoch 580/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0656 - mse: 0.8317\n",
      "Epoch 00580: saving model to Regression_Model/msle.linear-0580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8304 - val_loss: 0.0592 - val_mse: 0.7972\n",
      "Epoch 581/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8349 - val_loss: 0.0592 - val_mse: 0.7970\n",
      "Epoch 582/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8260 - val_loss: 0.0595 - val_mse: 0.8075\n",
      "Epoch 583/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8338 - val_loss: 0.0604 - val_mse: 0.7822\n",
      "Epoch 584/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8274 - val_loss: 0.0593 - val_mse: 0.7986\n",
      "Epoch 585/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8310 - val_loss: 0.0597 - val_mse: 0.8117\n",
      "Epoch 586/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8358 - val_loss: 0.0593 - val_mse: 0.7903\n",
      "Epoch 587/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8286 - val_loss: 0.0601 - val_mse: 0.8030\n",
      "Epoch 588/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8363 - val_loss: 0.0597 - val_mse: 0.7982\n",
      "Epoch 589/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8322 - val_loss: 0.0594 - val_mse: 0.8062\n",
      "Epoch 590/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0652 - mse: 0.8192\n",
      "Epoch 00590: saving model to Regression_Model/msle.linear-0590.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0654 - mse: 0.8229 - val_loss: 0.0592 - val_mse: 0.8004\n",
      "Epoch 591/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8338 - val_loss: 0.0606 - val_mse: 0.7906\n",
      "Epoch 592/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8266 - val_loss: 0.0595 - val_mse: 0.8018\n",
      "Epoch 593/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8416 - val_loss: 0.0593 - val_mse: 0.8000\n",
      "Epoch 594/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8258 - val_loss: 0.0594 - val_mse: 0.8090\n",
      "Epoch 595/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8181 - val_loss: 0.0596 - val_mse: 0.8133\n",
      "Epoch 596/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8325 - val_loss: 0.0599 - val_mse: 0.7809\n",
      "Epoch 597/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8313 - val_loss: 0.0591 - val_mse: 0.7881\n",
      "Epoch 598/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8243 - val_loss: 0.0595 - val_mse: 0.8009\n",
      "Epoch 599/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8346 - val_loss: 0.0598 - val_mse: 0.7841\n",
      "Epoch 600/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0666 - mse: 0.8405\n",
      "Epoch 00600: saving model to Regression_Model/msle.linear-0600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8414 - val_loss: 0.0598 - val_mse: 0.7925\n",
      "Epoch 601/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8428 - val_loss: 0.0592 - val_mse: 0.7942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 602/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8234 - val_loss: 0.0590 - val_mse: 0.7901\n",
      "Epoch 603/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8148 - val_loss: 0.0595 - val_mse: 0.8044\n",
      "Epoch 604/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8227 - val_loss: 0.0591 - val_mse: 0.7949\n",
      "Epoch 605/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8254 - val_loss: 0.0594 - val_mse: 0.7959\n",
      "Epoch 606/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8306 - val_loss: 0.0591 - val_mse: 0.7846\n",
      "Epoch 607/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8269 - val_loss: 0.0596 - val_mse: 0.7801\n",
      "Epoch 608/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8298 - val_loss: 0.0593 - val_mse: 0.8050\n",
      "Epoch 609/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8320 - val_loss: 0.0595 - val_mse: 0.8065\n",
      "Epoch 610/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0661 - mse: 0.8367\n",
      "Epoch 00610: saving model to Regression_Model/msle.linear-0610.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8355 - val_loss: 0.0603 - val_mse: 0.7885\n",
      "Epoch 611/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8432 - val_loss: 0.0598 - val_mse: 0.7809\n",
      "Epoch 612/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8332 - val_loss: 0.0592 - val_mse: 0.7992\n",
      "Epoch 613/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8279 - val_loss: 0.0592 - val_mse: 0.7957\n",
      "Epoch 614/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8202 - val_loss: 0.0592 - val_mse: 0.7874\n",
      "Epoch 615/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8365 - val_loss: 0.0595 - val_mse: 0.8064\n",
      "Epoch 616/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8342 - val_loss: 0.0596 - val_mse: 0.7888\n",
      "Epoch 617/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8374 - val_loss: 0.0592 - val_mse: 0.8011\n",
      "Epoch 618/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8331 - val_loss: 0.0603 - val_mse: 0.8201\n",
      "Epoch 619/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8270 - val_loss: 0.0593 - val_mse: 0.8017\n",
      "Epoch 620/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0657 - mse: 0.8247\n",
      "Epoch 00620: saving model to Regression_Model/msle.linear-0620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8263 - val_loss: 0.0593 - val_mse: 0.8063\n",
      "Epoch 621/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8335 - val_loss: 0.0592 - val_mse: 0.7998\n",
      "Epoch 622/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8235 - val_loss: 0.0594 - val_mse: 0.7891\n",
      "Epoch 623/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8384 - val_loss: 0.0595 - val_mse: 0.8057\n",
      "Epoch 624/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8311 - val_loss: 0.0593 - val_mse: 0.7948\n",
      "Epoch 625/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0675 - mse: 0.8493 - val_loss: 0.0606 - val_mse: 0.8267\n",
      "Epoch 626/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8194 - val_loss: 0.0592 - val_mse: 0.8032\n",
      "Epoch 627/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8350 - val_loss: 0.0593 - val_mse: 0.7959\n",
      "Epoch 628/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8300 - val_loss: 0.0592 - val_mse: 0.7980\n",
      "Epoch 629/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0671 - mse: 0.8505 - val_loss: 0.0598 - val_mse: 0.7813\n",
      "Epoch 630/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0669 - mse: 0.8403\n",
      "Epoch 00630: saving model to Regression_Model/msle.linear-0630.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0669 - mse: 0.8410 - val_loss: 0.0592 - val_mse: 0.8018\n",
      "Epoch 631/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8292 - val_loss: 0.0592 - val_mse: 0.7997\n",
      "Epoch 632/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8324 - val_loss: 0.0608 - val_mse: 0.8309\n",
      "Epoch 633/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8497 - val_loss: 0.0592 - val_mse: 0.7984\n",
      "Epoch 634/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8303 - val_loss: 0.0610 - val_mse: 0.8332\n",
      "Epoch 635/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8289 - val_loss: 0.0592 - val_mse: 0.7874\n",
      "Epoch 636/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8330 - val_loss: 0.0594 - val_mse: 0.7941\n",
      "Epoch 637/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8310 - val_loss: 0.0594 - val_mse: 0.8042\n",
      "Epoch 638/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8276 - val_loss: 0.0592 - val_mse: 0.7997\n",
      "Epoch 639/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8293 - val_loss: 0.0590 - val_mse: 0.7970\n",
      "Epoch 640/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0660 - mse: 0.8268\n",
      "Epoch 00640: saving model to Regression_Model/msle.linear-0640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8275 - val_loss: 0.0590 - val_mse: 0.7932\n",
      "Epoch 641/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8215 - val_loss: 0.0596 - val_mse: 0.7835\n",
      "Epoch 642/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8442 - val_loss: 0.0601 - val_mse: 0.8185\n",
      "Epoch 643/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8258 - val_loss: 0.0591 - val_mse: 0.7872\n",
      "Epoch 644/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8519 - val_loss: 0.0590 - val_mse: 0.7991\n",
      "Epoch 645/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8258 - val_loss: 0.0596 - val_mse: 0.8093\n",
      "Epoch 646/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8288 - val_loss: 0.0600 - val_mse: 0.8165\n",
      "Epoch 647/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8439 - val_loss: 0.0592 - val_mse: 0.7865\n",
      "Epoch 648/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8306 - val_loss: 0.0597 - val_mse: 0.7793\n",
      "Epoch 649/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8221 - val_loss: 0.0592 - val_mse: 0.8050\n",
      "Epoch 650/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0669 - mse: 0.8400\n",
      "Epoch 00650: saving model to Regression_Model/msle.linear-0650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8378 - val_loss: 0.0590 - val_mse: 0.7953\n",
      "Epoch 651/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0673 - mse: 0.8399 - val_loss: 0.0591 - val_mse: 0.8037\n",
      "Epoch 652/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8343 - val_loss: 0.0619 - val_mse: 0.7720\n",
      "Epoch 653/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8422 - val_loss: 0.0593 - val_mse: 0.8011\n",
      "Epoch 654/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8313 - val_loss: 0.0590 - val_mse: 0.7874\n",
      "Epoch 655/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8217 - val_loss: 0.0596 - val_mse: 0.7831\n",
      "Epoch 656/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8272 - val_loss: 0.0606 - val_mse: 0.8253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 657/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8293 - val_loss: 0.0591 - val_mse: 0.8037\n",
      "Epoch 658/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8374 - val_loss: 0.0591 - val_mse: 0.8038\n",
      "Epoch 659/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8327 - val_loss: 0.0592 - val_mse: 0.8036\n",
      "Epoch 660/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0665 - mse: 0.8376\n",
      "Epoch 00660: saving model to Regression_Model/msle.linear-0660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8361 - val_loss: 0.0594 - val_mse: 0.7880\n",
      "Epoch 661/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8389 - val_loss: 0.0591 - val_mse: 0.7932\n",
      "Epoch 662/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0669 - mse: 0.8389 - val_loss: 0.0595 - val_mse: 0.7840\n",
      "Epoch 663/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8301 - val_loss: 0.0596 - val_mse: 0.8117\n",
      "Epoch 664/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8304 - val_loss: 0.0593 - val_mse: 0.7855\n",
      "Epoch 665/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8323 - val_loss: 0.0591 - val_mse: 0.7971\n",
      "Epoch 666/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8321 - val_loss: 0.0591 - val_mse: 0.8020\n",
      "Epoch 667/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8247 - val_loss: 0.0592 - val_mse: 0.8041\n",
      "Epoch 668/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8225 - val_loss: 0.0589 - val_mse: 0.7885\n",
      "Epoch 669/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8208 - val_loss: 0.0594 - val_mse: 0.8068\n",
      "Epoch 670/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0655 - mse: 0.8311\n",
      "Epoch 00670: saving model to Regression_Model/msle.linear-0670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8317 - val_loss: 0.0590 - val_mse: 0.7913\n",
      "Epoch 671/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8310 - val_loss: 0.0591 - val_mse: 0.7904\n",
      "Epoch 672/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8296 - val_loss: 0.0594 - val_mse: 0.7909\n",
      "Epoch 673/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8344 - val_loss: 0.0591 - val_mse: 0.7963\n",
      "Epoch 674/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8290 - val_loss: 0.0601 - val_mse: 0.8223\n",
      "Epoch 675/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8391 - val_loss: 0.0596 - val_mse: 0.7991\n",
      "Epoch 676/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8259 - val_loss: 0.0593 - val_mse: 0.7905\n",
      "Epoch 677/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8266 - val_loss: 0.0602 - val_mse: 0.8136\n",
      "Epoch 678/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8260 - val_loss: 0.0590 - val_mse: 0.7923\n",
      "Epoch 679/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8209 - val_loss: 0.0592 - val_mse: 0.7996\n",
      "Epoch 680/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0653 - mse: 0.8320\n",
      "Epoch 00680: saving model to Regression_Model/msle.linear-0680.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0654 - mse: 0.8274 - val_loss: 0.0592 - val_mse: 0.7887\n",
      "Epoch 681/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8308 - val_loss: 0.0595 - val_mse: 0.8094\n",
      "Epoch 682/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8275 - val_loss: 0.0592 - val_mse: 0.7867\n",
      "Epoch 683/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8203 - val_loss: 0.0590 - val_mse: 0.7894\n",
      "Epoch 684/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8256 - val_loss: 0.0589 - val_mse: 0.7909\n",
      "Epoch 685/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8284 - val_loss: 0.0590 - val_mse: 0.7946\n",
      "Epoch 686/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8296 - val_loss: 0.0599 - val_mse: 0.7772\n",
      "Epoch 687/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8297 - val_loss: 0.0592 - val_mse: 0.7875\n",
      "Epoch 688/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0661 - mse: 0.8347 - val_loss: 0.0590 - val_mse: 0.7970\n",
      "Epoch 689/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8293 - val_loss: 0.0593 - val_mse: 0.7844\n",
      "Epoch 690/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0662 - mse: 0.8315\n",
      "Epoch 00690: saving model to Regression_Model/msle.linear-0690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8317 - val_loss: 0.0592 - val_mse: 0.7837\n",
      "Epoch 691/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8218 - val_loss: 0.0589 - val_mse: 0.7923\n",
      "Epoch 692/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8282 - val_loss: 0.0592 - val_mse: 0.8057\n",
      "Epoch 693/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8351 - val_loss: 0.0595 - val_mse: 0.8108\n",
      "Epoch 694/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0672 - mse: 0.8446 - val_loss: 0.0590 - val_mse: 0.7917\n",
      "Epoch 695/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8216 - val_loss: 0.0591 - val_mse: 0.7906\n",
      "Epoch 696/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8218 - val_loss: 0.0589 - val_mse: 0.7906\n",
      "Epoch 697/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8298 - val_loss: 0.0589 - val_mse: 0.7931\n",
      "Epoch 698/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8280 - val_loss: 0.0590 - val_mse: 0.7936\n",
      "Epoch 699/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8292 - val_loss: 0.0595 - val_mse: 0.8126\n",
      "Epoch 700/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0654 - mse: 0.8271\n",
      "Epoch 00700: saving model to Regression_Model/msle.linear-0700.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8253 - val_loss: 0.0591 - val_mse: 0.7958\n",
      "Epoch 701/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8186 - val_loss: 0.0590 - val_mse: 0.7836\n",
      "Epoch 702/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8342 - val_loss: 0.0591 - val_mse: 0.7943\n",
      "Epoch 703/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8277 - val_loss: 0.0591 - val_mse: 0.7828\n",
      "Epoch 704/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8187 - val_loss: 0.0593 - val_mse: 0.8080\n",
      "Epoch 705/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8384 - val_loss: 0.0597 - val_mse: 0.8138\n",
      "Epoch 706/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8199 - val_loss: 0.0590 - val_mse: 0.8000\n",
      "Epoch 707/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8262 - val_loss: 0.0596 - val_mse: 0.7806\n",
      "Epoch 708/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8233 - val_loss: 0.0592 - val_mse: 0.8054\n",
      "Epoch 709/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8280 - val_loss: 0.0592 - val_mse: 0.7876\n",
      "Epoch 710/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8241\n",
      "Epoch 00710: saving model to Regression_Model/msle.linear-0710.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8235 - val_loss: 0.0597 - val_mse: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 711/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8323 - val_loss: 0.0590 - val_mse: 0.7933\n",
      "Epoch 712/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8267 - val_loss: 0.0593 - val_mse: 0.8066\n",
      "Epoch 713/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8226 - val_loss: 0.0593 - val_mse: 0.7877\n",
      "Epoch 714/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8310 - val_loss: 0.0594 - val_mse: 0.8127\n",
      "Epoch 715/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8219 - val_loss: 0.0590 - val_mse: 0.7960\n",
      "Epoch 716/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8249 - val_loss: 0.0599 - val_mse: 0.8188\n",
      "Epoch 717/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8258 - val_loss: 0.0590 - val_mse: 0.7865\n",
      "Epoch 718/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8263 - val_loss: 0.0591 - val_mse: 0.7865\n",
      "Epoch 719/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8296 - val_loss: 0.0590 - val_mse: 0.7869\n",
      "Epoch 720/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0658 - mse: 0.8252\n",
      "Epoch 00720: saving model to Regression_Model/msle.linear-0720.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0657 - mse: 0.8273 - val_loss: 0.0589 - val_mse: 0.7911\n",
      "Epoch 721/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8207 - val_loss: 0.0594 - val_mse: 0.8084\n",
      "Epoch 722/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8379 - val_loss: 0.0590 - val_mse: 0.7954\n",
      "Epoch 723/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8193 - val_loss: 0.0590 - val_mse: 0.8027\n",
      "Epoch 724/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8252 - val_loss: 0.0594 - val_mse: 0.7904\n",
      "Epoch 725/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8232 - val_loss: 0.0588 - val_mse: 0.7951\n",
      "Epoch 726/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8185 - val_loss: 0.0589 - val_mse: 0.7987\n",
      "Epoch 727/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8233 - val_loss: 0.0593 - val_mse: 0.7860\n",
      "Epoch 728/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8228 - val_loss: 0.0588 - val_mse: 0.7899\n",
      "Epoch 729/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8293 - val_loss: 0.0590 - val_mse: 0.7875\n",
      "Epoch 730/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0656 - mse: 0.8329\n",
      "Epoch 00730: saving model to Regression_Model/msle.linear-0730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8330 - val_loss: 0.0591 - val_mse: 0.8013\n",
      "Epoch 731/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8281 - val_loss: 0.0590 - val_mse: 0.8027\n",
      "Epoch 732/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8225 - val_loss: 0.0588 - val_mse: 0.7897\n",
      "Epoch 733/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8179 - val_loss: 0.0592 - val_mse: 0.8013\n",
      "Epoch 734/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8202 - val_loss: 0.0608 - val_mse: 0.8260\n",
      "Epoch 735/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8380 - val_loss: 0.0590 - val_mse: 0.7890\n",
      "Epoch 736/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8310 - val_loss: 0.0591 - val_mse: 0.7954\n",
      "Epoch 737/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8328 - val_loss: 0.0592 - val_mse: 0.8002\n",
      "Epoch 738/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8321 - val_loss: 0.0590 - val_mse: 0.7965\n",
      "Epoch 739/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8159 - val_loss: 0.0588 - val_mse: 0.7893\n",
      "Epoch 740/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0654 - mse: 0.8212\n",
      "Epoch 00740: saving model to Regression_Model/msle.linear-0740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8230 - val_loss: 0.0591 - val_mse: 0.8056\n",
      "Epoch 741/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8251 - val_loss: 0.0588 - val_mse: 0.7918\n",
      "Epoch 742/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8204 - val_loss: 0.0591 - val_mse: 0.7827\n",
      "Epoch 743/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8275 - val_loss: 0.0591 - val_mse: 0.7833\n",
      "Epoch 744/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8245 - val_loss: 0.0588 - val_mse: 0.7953\n",
      "Epoch 745/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8345 - val_loss: 0.0593 - val_mse: 0.7802\n",
      "Epoch 746/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8260 - val_loss: 0.0589 - val_mse: 0.7980\n",
      "Epoch 747/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8269 - val_loss: 0.0590 - val_mse: 0.8002\n",
      "Epoch 748/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8275 - val_loss: 0.0590 - val_mse: 0.8051\n",
      "Epoch 749/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8192 - val_loss: 0.0590 - val_mse: 0.7830\n",
      "Epoch 750/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0659 - mse: 0.8314\n",
      "Epoch 00750: saving model to Regression_Model/msle.linear-0750.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0661 - mse: 0.8322 - val_loss: 0.0589 - val_mse: 0.7916\n",
      "Epoch 751/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8252 - val_loss: 0.0592 - val_mse: 0.8083\n",
      "Epoch 752/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8234 - val_loss: 0.0589 - val_mse: 0.7980\n",
      "Epoch 753/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8269 - val_loss: 0.0591 - val_mse: 0.8050\n",
      "Epoch 754/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8286 - val_loss: 0.0588 - val_mse: 0.7872\n",
      "Epoch 755/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8240 - val_loss: 0.0589 - val_mse: 0.8012\n",
      "Epoch 756/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8283 - val_loss: 0.0592 - val_mse: 0.8026\n",
      "Epoch 757/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8368 - val_loss: 0.0593 - val_mse: 0.7905\n",
      "Epoch 758/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8268 - val_loss: 0.0591 - val_mse: 0.8071\n",
      "Epoch 759/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8252 - val_loss: 0.0591 - val_mse: 0.8034\n",
      "Epoch 760/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0659 - mse: 0.8254\n",
      "Epoch 00760: saving model to Regression_Model/msle.linear-0760.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8260 - val_loss: 0.0591 - val_mse: 0.7967\n",
      "Epoch 761/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8355 - val_loss: 0.0592 - val_mse: 0.7808\n",
      "Epoch 762/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8282 - val_loss: 0.0589 - val_mse: 0.7981\n",
      "Epoch 763/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8419 - val_loss: 0.0589 - val_mse: 0.7929\n",
      "Epoch 764/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8270 - val_loss: 0.0597 - val_mse: 0.7852\n",
      "Epoch 765/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8229 - val_loss: 0.0594 - val_mse: 0.8064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 766/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8291 - val_loss: 0.0587 - val_mse: 0.7900\n",
      "Epoch 767/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8329 - val_loss: 0.0588 - val_mse: 0.7919\n",
      "Epoch 768/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8297 - val_loss: 0.0591 - val_mse: 0.8028\n",
      "Epoch 769/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8345 - val_loss: 0.0590 - val_mse: 0.7906\n",
      "Epoch 770/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0658 - mse: 0.8226\n",
      "Epoch 00770: saving model to Regression_Model/msle.linear-0770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8236 - val_loss: 0.0587 - val_mse: 0.7898\n",
      "Epoch 771/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8259 - val_loss: 0.0590 - val_mse: 0.7864\n",
      "Epoch 772/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8259 - val_loss: 0.0592 - val_mse: 0.8059\n",
      "Epoch 773/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8273 - val_loss: 0.0590 - val_mse: 0.8032\n",
      "Epoch 774/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8330 - val_loss: 0.0594 - val_mse: 0.8119\n",
      "Epoch 775/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8345 - val_loss: 0.0598 - val_mse: 0.8155\n",
      "Epoch 776/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8213 - val_loss: 0.0587 - val_mse: 0.7919\n",
      "Epoch 777/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8184 - val_loss: 0.0591 - val_mse: 0.8069\n",
      "Epoch 778/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8246 - val_loss: 0.0588 - val_mse: 0.7992\n",
      "Epoch 779/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8232 - val_loss: 0.0588 - val_mse: 0.7920\n",
      "Epoch 780/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0638 - mse: 0.8233\n",
      "Epoch 00780: saving model to Regression_Model/msle.linear-0780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8224 - val_loss: 0.0596 - val_mse: 0.8131\n",
      "Epoch 781/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8338 - val_loss: 0.0587 - val_mse: 0.7965\n",
      "Epoch 782/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8214 - val_loss: 0.0589 - val_mse: 0.7996\n",
      "Epoch 783/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8170 - val_loss: 0.0588 - val_mse: 0.7935\n",
      "Epoch 784/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8230 - val_loss: 0.0589 - val_mse: 0.7851\n",
      "Epoch 785/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8240 - val_loss: 0.0593 - val_mse: 0.8092\n",
      "Epoch 786/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8205 - val_loss: 0.0590 - val_mse: 0.8017\n",
      "Epoch 787/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8273 - val_loss: 0.0587 - val_mse: 0.7850\n",
      "Epoch 788/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8287 - val_loss: 0.0588 - val_mse: 0.7838\n",
      "Epoch 789/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8243 - val_loss: 0.0588 - val_mse: 0.7996\n",
      "Epoch 790/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0661 - mse: 0.8237\n",
      "Epoch 00790: saving model to Regression_Model/msle.linear-0790.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8249 - val_loss: 0.0589 - val_mse: 0.8013\n",
      "Epoch 791/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8235 - val_loss: 0.0589 - val_mse: 0.8031\n",
      "Epoch 792/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8230 - val_loss: 0.0597 - val_mse: 0.8180\n",
      "Epoch 793/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8384 - val_loss: 0.0593 - val_mse: 0.8121\n",
      "Epoch 794/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8215 - val_loss: 0.0587 - val_mse: 0.7920\n",
      "Epoch 795/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8258 - val_loss: 0.0595 - val_mse: 0.8095\n",
      "Epoch 796/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8252 - val_loss: 0.0587 - val_mse: 0.7977\n",
      "Epoch 797/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8261 - val_loss: 0.0587 - val_mse: 0.7917\n",
      "Epoch 798/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8350 - val_loss: 0.0590 - val_mse: 0.8050\n",
      "Epoch 799/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8288 - val_loss: 0.0591 - val_mse: 0.8049\n",
      "Epoch 800/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0650 - mse: 0.8246\n",
      "Epoch 00800: saving model to Regression_Model/msle.linear-0800.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.0649 - mse: 0.8236 - val_loss: 0.0587 - val_mse: 0.7913\n",
      "Epoch 801/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8221 - val_loss: 0.0588 - val_mse: 0.7915\n",
      "Epoch 802/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8251 - val_loss: 0.0587 - val_mse: 0.7954\n",
      "Epoch 803/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8282 - val_loss: 0.0591 - val_mse: 0.8047\n",
      "Epoch 804/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8239 - val_loss: 0.0591 - val_mse: 0.7844\n",
      "Epoch 805/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8246 - val_loss: 0.0588 - val_mse: 0.7877\n",
      "Epoch 806/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8304 - val_loss: 0.0588 - val_mse: 0.7985\n",
      "Epoch 807/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8237 - val_loss: 0.0589 - val_mse: 0.7985\n",
      "Epoch 808/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8262 - val_loss: 0.0589 - val_mse: 0.7873\n",
      "Epoch 809/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8392 - val_loss: 0.0587 - val_mse: 0.7963\n",
      "Epoch 810/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0659 - mse: 0.8274\n",
      "Epoch 00810: saving model to Regression_Model/msle.linear-0810.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8254 - val_loss: 0.0589 - val_mse: 0.7947\n",
      "Epoch 811/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8234 - val_loss: 0.0587 - val_mse: 0.7963\n",
      "Epoch 812/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8231 - val_loss: 0.0589 - val_mse: 0.7845\n",
      "Epoch 813/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8329 - val_loss: 0.0589 - val_mse: 0.7850\n",
      "Epoch 814/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8330 - val_loss: 0.0589 - val_mse: 0.7860\n",
      "Epoch 815/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8262 - val_loss: 0.0587 - val_mse: 0.7882\n",
      "Epoch 816/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8346 - val_loss: 0.0589 - val_mse: 0.7960\n",
      "Epoch 817/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8431 - val_loss: 0.0593 - val_mse: 0.8104\n",
      "Epoch 818/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8205 - val_loss: 0.0589 - val_mse: 0.8014\n",
      "Epoch 819/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8298 - val_loss: 0.0587 - val_mse: 0.7859\n",
      "Epoch 820/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0655 - mse: 0.8351\n",
      "Epoch 00820: saving model to Regression_Model/msle.linear-0820.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 7ms/step - loss: 0.0654 - mse: 0.8311 - val_loss: 0.0587 - val_mse: 0.7922\n",
      "Epoch 821/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8158 - val_loss: 0.0586 - val_mse: 0.7890\n",
      "Epoch 822/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8261 - val_loss: 0.0589 - val_mse: 0.7984\n",
      "Epoch 823/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8257 - val_loss: 0.0589 - val_mse: 0.8055\n",
      "Epoch 824/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8189 - val_loss: 0.0588 - val_mse: 0.8004\n",
      "Epoch 825/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8299 - val_loss: 0.0591 - val_mse: 0.8067\n",
      "Epoch 826/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8259 - val_loss: 0.0588 - val_mse: 0.7992\n",
      "Epoch 827/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8231 - val_loss: 0.0592 - val_mse: 0.8091\n",
      "Epoch 828/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8334 - val_loss: 0.0587 - val_mse: 0.7955\n",
      "Epoch 829/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8213 - val_loss: 0.0591 - val_mse: 0.8052\n",
      "Epoch 830/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8355\n",
      "Epoch 00830: saving model to Regression_Model/msle.linear-0830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8349 - val_loss: 0.0587 - val_mse: 0.7991\n",
      "Epoch 831/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8313 - val_loss: 0.0589 - val_mse: 0.8038\n",
      "Epoch 832/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8272 - val_loss: 0.0588 - val_mse: 0.8015\n",
      "Epoch 833/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8380 - val_loss: 0.0586 - val_mse: 0.7931\n",
      "Epoch 834/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8152 - val_loss: 0.0587 - val_mse: 0.7947\n",
      "Epoch 835/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8250 - val_loss: 0.0588 - val_mse: 0.7897\n",
      "Epoch 836/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8228 - val_loss: 0.0591 - val_mse: 0.7832\n",
      "Epoch 837/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8220 - val_loss: 0.0589 - val_mse: 0.8044\n",
      "Epoch 838/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8204 - val_loss: 0.0587 - val_mse: 0.7936\n",
      "Epoch 839/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8219 - val_loss: 0.0589 - val_mse: 0.7869\n",
      "Epoch 840/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0649 - mse: 0.8302\n",
      "Epoch 00840: saving model to Regression_Model/msle.linear-0840.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8344 - val_loss: 0.0594 - val_mse: 0.7799\n",
      "Epoch 841/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8293 - val_loss: 0.0593 - val_mse: 0.8124\n",
      "Epoch 842/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8291 - val_loss: 0.0588 - val_mse: 0.7825\n",
      "Epoch 843/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8244 - val_loss: 0.0589 - val_mse: 0.7897\n",
      "Epoch 844/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8246 - val_loss: 0.0595 - val_mse: 0.7960\n",
      "Epoch 845/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8230 - val_loss: 0.0591 - val_mse: 0.8093\n",
      "Epoch 846/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8355 - val_loss: 0.0592 - val_mse: 0.8087\n",
      "Epoch 847/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8260 - val_loss: 0.0589 - val_mse: 0.7843\n",
      "Epoch 848/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8320 - val_loss: 0.0586 - val_mse: 0.7879\n",
      "Epoch 849/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8282 - val_loss: 0.0591 - val_mse: 0.8077\n",
      "Epoch 850/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0647 - mse: 0.8234\n",
      "Epoch 00850: saving model to Regression_Model/msle.linear-0850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8239 - val_loss: 0.0587 - val_mse: 0.7851\n",
      "Epoch 851/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8244 - val_loss: 0.0598 - val_mse: 0.8147\n",
      "Epoch 852/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8232 - val_loss: 0.0589 - val_mse: 0.7897\n",
      "Epoch 853/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8161 - val_loss: 0.0591 - val_mse: 0.8099\n",
      "Epoch 854/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8230 - val_loss: 0.0587 - val_mse: 0.7983\n",
      "Epoch 855/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8304 - val_loss: 0.0592 - val_mse: 0.7800\n",
      "Epoch 856/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8291 - val_loss: 0.0586 - val_mse: 0.7948\n",
      "Epoch 857/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8130 - val_loss: 0.0588 - val_mse: 0.7934\n",
      "Epoch 858/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8340 - val_loss: 0.0586 - val_mse: 0.7961\n",
      "Epoch 859/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8262 - val_loss: 0.0591 - val_mse: 0.7789\n",
      "Epoch 860/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0650 - mse: 0.8211\n",
      "Epoch 00860: saving model to Regression_Model/msle.linear-0860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8212 - val_loss: 0.0587 - val_mse: 0.8003\n",
      "Epoch 861/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8212 - val_loss: 0.0589 - val_mse: 0.8028\n",
      "Epoch 862/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8282 - val_loss: 0.0586 - val_mse: 0.7936\n",
      "Epoch 863/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8254 - val_loss: 0.0586 - val_mse: 0.7891\n",
      "Epoch 864/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8372 - val_loss: 0.0587 - val_mse: 0.7898\n",
      "Epoch 865/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8291 - val_loss: 0.0592 - val_mse: 0.8068\n",
      "Epoch 866/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8260 - val_loss: 0.0588 - val_mse: 0.7932\n",
      "Epoch 867/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8352 - val_loss: 0.0587 - val_mse: 0.7958\n",
      "Epoch 868/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8283 - val_loss: 0.0592 - val_mse: 0.7782\n",
      "Epoch 869/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8291 - val_loss: 0.0589 - val_mse: 0.8028\n",
      "Epoch 870/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0651 - mse: 0.8308\n",
      "Epoch 00870: saving model to Regression_Model/msle.linear-0870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8336 - val_loss: 0.0586 - val_mse: 0.7873\n",
      "Epoch 871/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8281 - val_loss: 0.0587 - val_mse: 0.7978\n",
      "Epoch 872/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8244 - val_loss: 0.0589 - val_mse: 0.7804\n",
      "Epoch 873/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0666 - mse: 0.8342 - val_loss: 0.0588 - val_mse: 0.7881\n",
      "Epoch 874/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8300 - val_loss: 0.0588 - val_mse: 0.7896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8189 - val_loss: 0.0587 - val_mse: 0.7976\n",
      "Epoch 876/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8250 - val_loss: 0.0587 - val_mse: 0.7999\n",
      "Epoch 877/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8242 - val_loss: 0.0592 - val_mse: 0.7831\n",
      "Epoch 878/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0651 - mse: 0.8184 - val_loss: 0.0590 - val_mse: 0.8005\n",
      "Epoch 879/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8291 - val_loss: 0.0587 - val_mse: 0.7876\n",
      "Epoch 880/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0655 - mse: 0.8300\n",
      "Epoch 00880: saving model to Regression_Model/msle.linear-0880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8292 - val_loss: 0.0586 - val_mse: 0.7929\n",
      "Epoch 881/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8273 - val_loss: 0.0589 - val_mse: 0.7928\n",
      "Epoch 882/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8360 - val_loss: 0.0586 - val_mse: 0.7934\n",
      "Epoch 883/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8255 - val_loss: 0.0587 - val_mse: 0.7931\n",
      "Epoch 884/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8348 - val_loss: 0.0587 - val_mse: 0.7897\n",
      "Epoch 885/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8220 - val_loss: 0.0587 - val_mse: 0.7881\n",
      "Epoch 886/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8260 - val_loss: 0.0587 - val_mse: 0.7936\n",
      "Epoch 887/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8162 - val_loss: 0.0587 - val_mse: 0.8018\n",
      "Epoch 888/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8249 - val_loss: 0.0586 - val_mse: 0.7995\n",
      "Epoch 889/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8283 - val_loss: 0.0586 - val_mse: 0.7957\n",
      "Epoch 890/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8234\n",
      "Epoch 00890: saving model to Regression_Model/msle.linear-0890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8242 - val_loss: 0.0588 - val_mse: 0.8023\n",
      "Epoch 891/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8187 - val_loss: 0.0588 - val_mse: 0.8013\n",
      "Epoch 892/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8206 - val_loss: 0.0587 - val_mse: 0.7979\n",
      "Epoch 893/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8169 - val_loss: 0.0587 - val_mse: 0.7929\n",
      "Epoch 894/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8288 - val_loss: 0.0590 - val_mse: 0.8052\n",
      "Epoch 895/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8235 - val_loss: 0.0587 - val_mse: 0.7837\n",
      "Epoch 896/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8283 - val_loss: 0.0586 - val_mse: 0.7855\n",
      "Epoch 897/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8277 - val_loss: 0.0587 - val_mse: 0.7849\n",
      "Epoch 898/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8254 - val_loss: 0.0586 - val_mse: 0.7956\n",
      "Epoch 899/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8273 - val_loss: 0.0587 - val_mse: 0.7929\n",
      "Epoch 900/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8307\n",
      "Epoch 00900: saving model to Regression_Model/msle.linear-0900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8319 - val_loss: 0.0589 - val_mse: 0.8065\n",
      "Epoch 901/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8211 - val_loss: 0.0589 - val_mse: 0.7892\n",
      "Epoch 902/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8312 - val_loss: 0.0587 - val_mse: 0.7994\n",
      "Epoch 903/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8242 - val_loss: 0.0590 - val_mse: 0.8055\n",
      "Epoch 904/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8262 - val_loss: 0.0589 - val_mse: 0.8056\n",
      "Epoch 905/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8226 - val_loss: 0.0588 - val_mse: 0.7844\n",
      "Epoch 906/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8185 - val_loss: 0.0586 - val_mse: 0.7983\n",
      "Epoch 907/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8275 - val_loss: 0.0593 - val_mse: 0.8119\n",
      "Epoch 908/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8253 - val_loss: 0.0589 - val_mse: 0.7869\n",
      "Epoch 909/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8318 - val_loss: 0.0587 - val_mse: 0.7920\n",
      "Epoch 910/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0647 - mse: 0.8252\n",
      "Epoch 00910: saving model to Regression_Model/msle.linear-0910.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8255 - val_loss: 0.0588 - val_mse: 0.8008\n",
      "Epoch 911/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8389 - val_loss: 0.0590 - val_mse: 0.8055\n",
      "Epoch 912/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8383 - val_loss: 0.0591 - val_mse: 0.8090\n",
      "Epoch 913/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8264 - val_loss: 0.0588 - val_mse: 0.8006\n",
      "Epoch 914/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8245 - val_loss: 0.0586 - val_mse: 0.7914\n",
      "Epoch 915/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8263 - val_loss: 0.0588 - val_mse: 0.8002\n",
      "Epoch 916/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0656 - mse: 0.8286 - val_loss: 0.0586 - val_mse: 0.7875\n",
      "Epoch 917/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0660 - mse: 0.8235 - val_loss: 0.0588 - val_mse: 0.7993\n",
      "Epoch 918/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8249 - val_loss: 0.0592 - val_mse: 0.8097\n",
      "Epoch 919/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8250 - val_loss: 0.0586 - val_mse: 0.7920\n",
      "Epoch 920/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8226\n",
      "Epoch 00920: saving model to Regression_Model/msle.linear-0920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8230 - val_loss: 0.0589 - val_mse: 0.7926\n",
      "Epoch 921/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8273 - val_loss: 0.0587 - val_mse: 0.7992\n",
      "Epoch 922/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8206 - val_loss: 0.0586 - val_mse: 0.7915\n",
      "Epoch 923/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8214 - val_loss: 0.0588 - val_mse: 0.8028\n",
      "Epoch 924/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0668 - mse: 0.8435 - val_loss: 0.0587 - val_mse: 0.7979\n",
      "Epoch 925/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8218 - val_loss: 0.0587 - val_mse: 0.7866\n",
      "Epoch 926/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8302 - val_loss: 0.0590 - val_mse: 0.8072\n",
      "Epoch 927/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8363 - val_loss: 0.0597 - val_mse: 0.8114\n",
      "Epoch 928/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8442 - val_loss: 0.0589 - val_mse: 0.7991\n",
      "Epoch 929/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8240 - val_loss: 0.0586 - val_mse: 0.7902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0657 - mse: 0.8250\n",
      "Epoch 00930: saving model to Regression_Model/msle.linear-0930.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0655 - mse: 0.8257 - val_loss: 0.0586 - val_mse: 0.7923\n",
      "Epoch 931/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8181 - val_loss: 0.0588 - val_mse: 0.7989\n",
      "Epoch 932/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8227 - val_loss: 0.0586 - val_mse: 0.7901\n",
      "Epoch 933/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8308 - val_loss: 0.0588 - val_mse: 0.8035\n",
      "Epoch 934/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8215 - val_loss: 0.0586 - val_mse: 0.7890\n",
      "Epoch 935/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8105 - val_loss: 0.0588 - val_mse: 0.8028\n",
      "Epoch 936/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0641 - mse: 0.8168 - val_loss: 0.0587 - val_mse: 0.7888\n",
      "Epoch 937/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8342 - val_loss: 0.0587 - val_mse: 0.7969\n",
      "Epoch 938/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8258 - val_loss: 0.0588 - val_mse: 0.7948\n",
      "Epoch 939/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8267 - val_loss: 0.0588 - val_mse: 0.8022\n",
      "Epoch 940/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0652 - mse: 0.8378\n",
      "Epoch 00940: saving model to Regression_Model/msle.linear-0940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8376 - val_loss: 0.0586 - val_mse: 0.7892\n",
      "Epoch 941/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8315 - val_loss: 0.0589 - val_mse: 0.7983\n",
      "Epoch 942/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8327 - val_loss: 0.0587 - val_mse: 0.8021\n",
      "Epoch 943/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8315 - val_loss: 0.0586 - val_mse: 0.7924\n",
      "Epoch 944/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8241 - val_loss: 0.0588 - val_mse: 0.8018\n",
      "Epoch 945/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8205 - val_loss: 0.0589 - val_mse: 0.8053\n",
      "Epoch 946/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8198 - val_loss: 0.0587 - val_mse: 0.7887\n",
      "Epoch 947/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8240 - val_loss: 0.0586 - val_mse: 0.7978\n",
      "Epoch 948/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8255 - val_loss: 0.0589 - val_mse: 0.8050\n",
      "Epoch 949/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8223 - val_loss: 0.0587 - val_mse: 0.7963\n",
      "Epoch 950/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0649 - mse: 0.8278\n",
      "Epoch 00950: saving model to Regression_Model/msle.linear-0950.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.0650 - mse: 0.8268 - val_loss: 0.0585 - val_mse: 0.7892\n",
      "Epoch 951/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8212 - val_loss: 0.0589 - val_mse: 0.8042\n",
      "Epoch 952/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8316 - val_loss: 0.0587 - val_mse: 0.7999\n",
      "Epoch 953/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8251 - val_loss: 0.0586 - val_mse: 0.7904\n",
      "Epoch 954/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8154 - val_loss: 0.0586 - val_mse: 0.7930\n",
      "Epoch 955/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8249 - val_loss: 0.0587 - val_mse: 0.7827\n",
      "Epoch 956/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8295 - val_loss: 0.0585 - val_mse: 0.7952\n",
      "Epoch 957/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8261 - val_loss: 0.0587 - val_mse: 0.7844\n",
      "Epoch 958/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8326 - val_loss: 0.0585 - val_mse: 0.7884\n",
      "Epoch 959/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8178 - val_loss: 0.0585 - val_mse: 0.7973\n",
      "Epoch 960/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8234\n",
      "Epoch 00960: saving model to Regression_Model/msle.linear-0960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8221 - val_loss: 0.0591 - val_mse: 0.7862\n",
      "Epoch 961/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8268 - val_loss: 0.0586 - val_mse: 0.7977\n",
      "Epoch 962/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8293 - val_loss: 0.0589 - val_mse: 0.8053\n",
      "Epoch 963/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8225 - val_loss: 0.0588 - val_mse: 0.8037\n",
      "Epoch 964/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8326 - val_loss: 0.0587 - val_mse: 0.7907\n",
      "Epoch 965/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0659 - mse: 0.8292 - val_loss: 0.0585 - val_mse: 0.7882\n",
      "Epoch 966/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8340 - val_loss: 0.0590 - val_mse: 0.8070\n",
      "Epoch 967/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8212 - val_loss: 0.0591 - val_mse: 0.8087\n",
      "Epoch 968/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0639 - mse: 0.8151 - val_loss: 0.0590 - val_mse: 0.7751\n",
      "Epoch 969/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8170 - val_loss: 0.0584 - val_mse: 0.7899\n",
      "Epoch 970/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0652 - mse: 0.8180\n",
      "Epoch 00970: saving model to Regression_Model/msle.linear-0970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8206 - val_loss: 0.0586 - val_mse: 0.7933\n",
      "Epoch 971/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8224 - val_loss: 0.0586 - val_mse: 0.7968\n",
      "Epoch 972/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8259 - val_loss: 0.0585 - val_mse: 0.7908\n",
      "Epoch 973/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8242 - val_loss: 0.0586 - val_mse: 0.7853\n",
      "Epoch 974/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8294 - val_loss: 0.0585 - val_mse: 0.7920\n",
      "Epoch 975/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8168 - val_loss: 0.0586 - val_mse: 0.7841\n",
      "Epoch 976/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8341 - val_loss: 0.0586 - val_mse: 0.7884\n",
      "Epoch 977/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8324 - val_loss: 0.0585 - val_mse: 0.7936\n",
      "Epoch 978/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8226 - val_loss: 0.0586 - val_mse: 0.7936\n",
      "Epoch 979/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8326 - val_loss: 0.0586 - val_mse: 0.7869\n",
      "Epoch 980/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0650 - mse: 0.8272\n",
      "Epoch 00980: saving model to Regression_Model/msle.linear-0980.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8273 - val_loss: 0.0585 - val_mse: 0.7889\n",
      "Epoch 981/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8217 - val_loss: 0.0587 - val_mse: 0.7927\n",
      "Epoch 982/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8194 - val_loss: 0.0590 - val_mse: 0.8060\n",
      "Epoch 983/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8193 - val_loss: 0.0586 - val_mse: 0.7970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8297 - val_loss: 0.0586 - val_mse: 0.7895\n",
      "Epoch 985/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8232 - val_loss: 0.0588 - val_mse: 0.7989\n",
      "Epoch 986/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0657 - mse: 0.8288 - val_loss: 0.0588 - val_mse: 0.7842\n",
      "Epoch 987/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8217 - val_loss: 0.0585 - val_mse: 0.7938\n",
      "Epoch 988/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8218 - val_loss: 0.0587 - val_mse: 0.7988\n",
      "Epoch 989/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8231 - val_loss: 0.0586 - val_mse: 0.7987\n",
      "Epoch 990/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0652 - mse: 0.8243\n",
      "Epoch 00990: saving model to Regression_Model/msle.linear-0990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8266 - val_loss: 0.0585 - val_mse: 0.7931\n",
      "Epoch 991/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8405 - val_loss: 0.0590 - val_mse: 0.8073\n",
      "Epoch 992/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8230 - val_loss: 0.0587 - val_mse: 0.7865\n",
      "Epoch 993/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8232 - val_loss: 0.0586 - val_mse: 0.7965\n",
      "Epoch 994/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8297 - val_loss: 0.0589 - val_mse: 0.8048\n",
      "Epoch 995/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8236 - val_loss: 0.0588 - val_mse: 0.8030\n",
      "Epoch 996/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8212 - val_loss: 0.0585 - val_mse: 0.7916\n",
      "Epoch 997/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8277 - val_loss: 0.0588 - val_mse: 0.8014\n",
      "Epoch 998/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8283 - val_loss: 0.0587 - val_mse: 0.8005\n",
      "Epoch 999/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8263 - val_loss: 0.0585 - val_mse: 0.7916\n",
      "Epoch 1000/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0648 - mse: 0.8197\n",
      "Epoch 01000: saving model to Regression_Model/msle.linear-1000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8219 - val_loss: 0.0587 - val_mse: 0.7954\n",
      "Epoch 1001/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8195 - val_loss: 0.0588 - val_mse: 0.8019\n",
      "Epoch 1002/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8283 - val_loss: 0.0586 - val_mse: 0.7900\n",
      "Epoch 1003/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8257 - val_loss: 0.0586 - val_mse: 0.7961\n",
      "Epoch 1004/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8210 - val_loss: 0.0585 - val_mse: 0.7934\n",
      "Epoch 1005/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8135 - val_loss: 0.0585 - val_mse: 0.7900\n",
      "Epoch 1006/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8346 - val_loss: 0.0593 - val_mse: 0.8134\n",
      "Epoch 1007/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8284 - val_loss: 0.0585 - val_mse: 0.7936\n",
      "Epoch 1008/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8303 - val_loss: 0.0586 - val_mse: 0.7975\n",
      "Epoch 1009/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0653 - mse: 0.8189 - val_loss: 0.0585 - val_mse: 0.7880\n",
      "Epoch 1010/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0650 - mse: 0.8352\n",
      "Epoch 01010: saving model to Regression_Model/msle.linear-1010.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0650 - mse: 0.8327 - val_loss: 0.0592 - val_mse: 0.8110\n",
      "Epoch 1011/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8224 - val_loss: 0.0586 - val_mse: 0.7826\n",
      "Epoch 1012/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8243 - val_loss: 0.0585 - val_mse: 0.7949\n",
      "Epoch 1013/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8214 - val_loss: 0.0584 - val_mse: 0.7926\n",
      "Epoch 1014/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8214 - val_loss: 0.0585 - val_mse: 0.7932\n",
      "Epoch 1015/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8165 - val_loss: 0.0585 - val_mse: 0.7983\n",
      "Epoch 1016/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0656 - mse: 0.8242 - val_loss: 0.0588 - val_mse: 0.8024\n",
      "Epoch 1017/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0651 - mse: 0.8241 - val_loss: 0.0586 - val_mse: 0.7988\n",
      "Epoch 1018/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8171 - val_loss: 0.0586 - val_mse: 0.7856\n",
      "Epoch 1019/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8214 - val_loss: 0.0585 - val_mse: 0.7893\n",
      "Epoch 1020/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0653 - mse: 0.8277\n",
      "Epoch 01020: saving model to Regression_Model/msle.linear-1020.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0653 - mse: 0.8251 - val_loss: 0.0585 - val_mse: 0.7972\n",
      "Epoch 1021/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8241 - val_loss: 0.0585 - val_mse: 0.7913\n",
      "Epoch 1022/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8245 - val_loss: 0.0587 - val_mse: 0.7839\n",
      "Epoch 1023/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8133 - val_loss: 0.0586 - val_mse: 0.8018\n",
      "Epoch 1024/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8266 - val_loss: 0.0586 - val_mse: 0.7998\n",
      "Epoch 1025/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8205 - val_loss: 0.0585 - val_mse: 0.7978\n",
      "Epoch 1026/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8278 - val_loss: 0.0586 - val_mse: 0.7974\n",
      "Epoch 1027/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8244 - val_loss: 0.0593 - val_mse: 0.8146\n",
      "Epoch 1028/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8212 - val_loss: 0.0585 - val_mse: 0.7940\n",
      "Epoch 1029/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8263 - val_loss: 0.0585 - val_mse: 0.7968\n",
      "Epoch 1030/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0645 - mse: 0.8186\n",
      "Epoch 01030: saving model to Regression_Model/msle.linear-1030.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0646 - mse: 0.8213 - val_loss: 0.0586 - val_mse: 0.7870\n",
      "Epoch 1031/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8263 - val_loss: 0.0592 - val_mse: 0.7750\n",
      "Epoch 1032/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8261 - val_loss: 0.0587 - val_mse: 0.7982\n",
      "Epoch 1033/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8201 - val_loss: 0.0588 - val_mse: 0.8065\n",
      "Epoch 1034/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8206 - val_loss: 0.0585 - val_mse: 0.7897\n",
      "Epoch 1035/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0660 - mse: 0.8401 - val_loss: 0.0586 - val_mse: 0.7865\n",
      "Epoch 1036/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8252 - val_loss: 0.0585 - val_mse: 0.7890\n",
      "Epoch 1037/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8235 - val_loss: 0.0586 - val_mse: 0.7854\n",
      "Epoch 1038/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8252 - val_loss: 0.0588 - val_mse: 0.8038\n",
      "Epoch 1039/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8280 - val_loss: 0.0585 - val_mse: 0.7944\n",
      "Epoch 1040/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0644 - mse: 0.8195\n",
      "Epoch 01040: saving model to Regression_Model/msle.linear-1040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8211 - val_loss: 0.0587 - val_mse: 0.8017\n",
      "Epoch 1041/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8193 - val_loss: 0.0589 - val_mse: 0.8041\n",
      "Epoch 1042/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8227 - val_loss: 0.0589 - val_mse: 0.7843\n",
      "Epoch 1043/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8182 - val_loss: 0.0586 - val_mse: 0.7988\n",
      "Epoch 1044/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8189 - val_loss: 0.0585 - val_mse: 0.7920\n",
      "Epoch 1045/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8198 - val_loss: 0.0587 - val_mse: 0.7983\n",
      "Epoch 1046/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8308 - val_loss: 0.0585 - val_mse: 0.7908\n",
      "Epoch 1047/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8322 - val_loss: 0.0587 - val_mse: 0.7984\n",
      "Epoch 1048/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8210 - val_loss: 0.0586 - val_mse: 0.7850\n",
      "Epoch 1049/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8224 - val_loss: 0.0586 - val_mse: 0.7978\n",
      "Epoch 1050/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0650 - mse: 0.8202\n",
      "Epoch 01050: saving model to Regression_Model/msle.linear-1050.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0656 - mse: 0.8312 - val_loss: 0.0587 - val_mse: 0.8008\n",
      "Epoch 1051/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8191 - val_loss: 0.0587 - val_mse: 0.7988\n",
      "Epoch 1052/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8429 - val_loss: 0.0586 - val_mse: 0.7890\n",
      "Epoch 1053/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8257 - val_loss: 0.0587 - val_mse: 0.8002\n",
      "Epoch 1054/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8214 - val_loss: 0.0587 - val_mse: 0.8009\n",
      "Epoch 1055/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8167 - val_loss: 0.0586 - val_mse: 0.7866\n",
      "Epoch 1056/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8223 - val_loss: 0.0585 - val_mse: 0.7914\n",
      "Epoch 1057/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8261 - val_loss: 0.0585 - val_mse: 0.7885\n",
      "Epoch 1058/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8205 - val_loss: 0.0585 - val_mse: 0.7939\n",
      "Epoch 1059/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0652 - mse: 0.8289 - val_loss: 0.0585 - val_mse: 0.7869\n",
      "Epoch 1060/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0644 - mse: 0.8201\n",
      "Epoch 01060: saving model to Regression_Model/msle.linear-1060.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0646 - mse: 0.8296 - val_loss: 0.0585 - val_mse: 0.7880\n",
      "Epoch 1061/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8236 - val_loss: 0.0587 - val_mse: 0.8018\n",
      "Epoch 1062/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8300 - val_loss: 0.0585 - val_mse: 0.7887\n",
      "Epoch 1063/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8174 - val_loss: 0.0586 - val_mse: 0.7904\n",
      "Epoch 1064/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8209 - val_loss: 0.0586 - val_mse: 0.7942\n",
      "Epoch 1065/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8218 - val_loss: 0.0584 - val_mse: 0.7872\n",
      "Epoch 1066/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8180 - val_loss: 0.0585 - val_mse: 0.7980\n",
      "Epoch 1067/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8342 - val_loss: 0.0586 - val_mse: 0.7969\n",
      "Epoch 1068/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0667 - mse: 0.8394 - val_loss: 0.0585 - val_mse: 0.7993\n",
      "Epoch 1069/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8238 - val_loss: 0.0588 - val_mse: 0.8025\n",
      "Epoch 1070/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0646 - mse: 0.8163\n",
      "Epoch 01070: saving model to Regression_Model/msle.linear-1070.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0646 - mse: 0.8154 - val_loss: 0.0585 - val_mse: 0.7988\n",
      "Epoch 1071/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8227 - val_loss: 0.0585 - val_mse: 0.7949\n",
      "Epoch 1072/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8286 - val_loss: 0.0585 - val_mse: 0.7949\n",
      "Epoch 1073/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8227 - val_loss: 0.0586 - val_mse: 0.7886\n",
      "Epoch 1074/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8287 - val_loss: 0.0585 - val_mse: 0.7916\n",
      "Epoch 1075/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8265 - val_loss: 0.0586 - val_mse: 0.7954\n",
      "Epoch 1076/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8410 - val_loss: 0.0585 - val_mse: 0.7911\n",
      "Epoch 1077/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8288 - val_loss: 0.0591 - val_mse: 0.7775\n",
      "Epoch 1078/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8248 - val_loss: 0.0587 - val_mse: 0.7825\n",
      "Epoch 1079/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8179 - val_loss: 0.0585 - val_mse: 0.7967\n",
      "Epoch 1080/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8288\n",
      "Epoch 01080: saving model to Regression_Model/msle.linear-1080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8291 - val_loss: 0.0586 - val_mse: 0.7842\n",
      "Epoch 1081/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8187 - val_loss: 0.0587 - val_mse: 0.7844\n",
      "Epoch 1082/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8207 - val_loss: 0.0586 - val_mse: 0.7952\n",
      "Epoch 1083/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8275 - val_loss: 0.0585 - val_mse: 0.7955\n",
      "Epoch 1084/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8196 - val_loss: 0.0586 - val_mse: 0.7837\n",
      "Epoch 1085/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8250 - val_loss: 0.0587 - val_mse: 0.8003\n",
      "Epoch 1086/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8254 - val_loss: 0.0586 - val_mse: 0.7961\n",
      "Epoch 1087/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8304 - val_loss: 0.0585 - val_mse: 0.7957\n",
      "Epoch 1088/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8205 - val_loss: 0.0585 - val_mse: 0.7902\n",
      "Epoch 1089/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8304 - val_loss: 0.0585 - val_mse: 0.7940\n",
      "Epoch 1090/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0653 - mse: 0.8242\n",
      "Epoch 01090: saving model to Regression_Model/msle.linear-1090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8245 - val_loss: 0.0585 - val_mse: 0.7935\n",
      "Epoch 1091/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8249 - val_loss: 0.0585 - val_mse: 0.7932\n",
      "Epoch 1092/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0640 - mse: 0.8156 - val_loss: 0.0588 - val_mse: 0.8036\n",
      "Epoch 1093/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8306 - val_loss: 0.0585 - val_mse: 0.7940\n",
      "Epoch 1094/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8237 - val_loss: 0.0585 - val_mse: 0.7963\n",
      "Epoch 1095/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8223 - val_loss: 0.0585 - val_mse: 0.7959\n",
      "Epoch 1096/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8268 - val_loss: 0.0585 - val_mse: 0.7971\n",
      "Epoch 1097/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8263 - val_loss: 0.0585 - val_mse: 0.7879\n",
      "Epoch 1098/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0656 - mse: 0.8312 - val_loss: 0.0585 - val_mse: 0.7930\n",
      "Epoch 1099/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8309 - val_loss: 0.0585 - val_mse: 0.7959\n",
      "Epoch 1100/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8228\n",
      "Epoch 01100: saving model to Regression_Model/msle.linear-1100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8223 - val_loss: 0.0586 - val_mse: 0.7979\n",
      "Epoch 1101/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8250 - val_loss: 0.0586 - val_mse: 0.7979\n",
      "Epoch 1102/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8282 - val_loss: 0.0585 - val_mse: 0.7938\n",
      "Epoch 1103/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8213 - val_loss: 0.0586 - val_mse: 0.7985\n",
      "Epoch 1104/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8271 - val_loss: 0.0586 - val_mse: 0.7851\n",
      "Epoch 1105/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8200 - val_loss: 0.0585 - val_mse: 0.7965\n",
      "Epoch 1106/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8220 - val_loss: 0.0584 - val_mse: 0.7945\n",
      "Epoch 1107/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8258 - val_loss: 0.0584 - val_mse: 0.7898\n",
      "Epoch 1108/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8283 - val_loss: 0.0586 - val_mse: 0.7842\n",
      "Epoch 1109/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8195 - val_loss: 0.0584 - val_mse: 0.7885\n",
      "Epoch 1110/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8201\n",
      "Epoch 01110: saving model to Regression_Model/msle.linear-1110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8204 - val_loss: 0.0585 - val_mse: 0.7827\n",
      "Epoch 1111/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8263 - val_loss: 0.0586 - val_mse: 0.7925\n",
      "Epoch 1112/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8342 - val_loss: 0.0585 - val_mse: 0.7942\n",
      "Epoch 1113/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8262 - val_loss: 0.0585 - val_mse: 0.7890\n",
      "Epoch 1114/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8345 - val_loss: 0.0584 - val_mse: 0.7941\n",
      "Epoch 1115/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8232 - val_loss: 0.0585 - val_mse: 0.7931\n",
      "Epoch 1116/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8205 - val_loss: 0.0587 - val_mse: 0.8028\n",
      "Epoch 1117/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8171 - val_loss: 0.0587 - val_mse: 0.7835\n",
      "Epoch 1118/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8204 - val_loss: 0.0589 - val_mse: 0.7815\n",
      "Epoch 1119/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8152 - val_loss: 0.0586 - val_mse: 0.8002\n",
      "Epoch 1120/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0649 - mse: 0.8368\n",
      "Epoch 01120: saving model to Regression_Model/msle.linear-1120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8357 - val_loss: 0.0585 - val_mse: 0.7982\n",
      "Epoch 1121/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8285 - val_loss: 0.0586 - val_mse: 0.7880\n",
      "Epoch 1122/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8224 - val_loss: 0.0585 - val_mse: 0.7952\n",
      "Epoch 1123/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8257 - val_loss: 0.0584 - val_mse: 0.7892\n",
      "Epoch 1124/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8261 - val_loss: 0.0585 - val_mse: 0.7926\n",
      "Epoch 1125/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8177 - val_loss: 0.0585 - val_mse: 0.7864\n",
      "Epoch 1126/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8194 - val_loss: 0.0585 - val_mse: 0.7898\n",
      "Epoch 1127/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8278 - val_loss: 0.0585 - val_mse: 0.7923\n",
      "Epoch 1128/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0652 - mse: 0.8268 - val_loss: 0.0586 - val_mse: 0.7945\n",
      "Epoch 1129/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8214 - val_loss: 0.0585 - val_mse: 0.7941\n",
      "Epoch 1130/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0661 - mse: 0.8315\n",
      "Epoch 01130: saving model to Regression_Model/msle.linear-1130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8325 - val_loss: 0.0588 - val_mse: 0.8042\n",
      "Epoch 1131/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8266 - val_loss: 0.0586 - val_mse: 0.8000\n",
      "Epoch 1132/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8300 - val_loss: 0.0586 - val_mse: 0.7913\n",
      "Epoch 1133/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8338 - val_loss: 0.0585 - val_mse: 0.7900\n",
      "Epoch 1134/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8252 - val_loss: 0.0584 - val_mse: 0.7887\n",
      "Epoch 1135/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8119 - val_loss: 0.0585 - val_mse: 0.7878\n",
      "Epoch 1136/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8225 - val_loss: 0.0585 - val_mse: 0.7962\n",
      "Epoch 1137/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8161 - val_loss: 0.0584 - val_mse: 0.7896\n",
      "Epoch 1138/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8327 - val_loss: 0.0586 - val_mse: 0.7890\n",
      "Epoch 1139/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0641 - mse: 0.8139 - val_loss: 0.0585 - val_mse: 0.7949\n",
      "Epoch 1140/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0644 - mse: 0.8148\n",
      "Epoch 01140: saving model to Regression_Model/msle.linear-1140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8154 - val_loss: 0.0584 - val_mse: 0.7912\n",
      "Epoch 1141/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8455 - val_loss: 0.0587 - val_mse: 0.7804\n",
      "Epoch 1142/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8235 - val_loss: 0.0584 - val_mse: 0.7933\n",
      "Epoch 1143/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8227 - val_loss: 0.0585 - val_mse: 0.7866\n",
      "Epoch 1144/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8206 - val_loss: 0.0585 - val_mse: 0.7946\n",
      "Epoch 1145/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8331 - val_loss: 0.0588 - val_mse: 0.8035\n",
      "Epoch 1146/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8169 - val_loss: 0.0586 - val_mse: 0.7849\n",
      "Epoch 1147/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8269 - val_loss: 0.0585 - val_mse: 0.7929\n",
      "Epoch 1148/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8164 - val_loss: 0.0584 - val_mse: 0.7922\n",
      "Epoch 1149/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8256 - val_loss: 0.0585 - val_mse: 0.7959\n",
      "Epoch 1150/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0648 - mse: 0.8193\n",
      "Epoch 01150: saving model to Regression_Model/msle.linear-1150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8188 - val_loss: 0.0585 - val_mse: 0.7859\n",
      "Epoch 1151/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8146 - val_loss: 0.0585 - val_mse: 0.7894\n",
      "Epoch 1152/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0660 - mse: 0.8280 - val_loss: 0.0585 - val_mse: 0.7931\n",
      "Epoch 1153/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0658 - mse: 0.8250 - val_loss: 0.0586 - val_mse: 0.8000\n",
      "Epoch 1154/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8274 - val_loss: 0.0586 - val_mse: 0.7991\n",
      "Epoch 1155/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8250 - val_loss: 0.0585 - val_mse: 0.7976\n",
      "Epoch 1156/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8318 - val_loss: 0.0585 - val_mse: 0.7974\n",
      "Epoch 1157/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8265 - val_loss: 0.0585 - val_mse: 0.7954\n",
      "Epoch 1158/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8262 - val_loss: 0.0585 - val_mse: 0.7980\n",
      "Epoch 1159/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8293 - val_loss: 0.0589 - val_mse: 0.8062\n",
      "Epoch 1160/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0656 - mse: 0.8341\n",
      "Epoch 01160: saving model to Regression_Model/msle.linear-1160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8321 - val_loss: 0.0585 - val_mse: 0.7934\n",
      "Epoch 1161/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8275 - val_loss: 0.0586 - val_mse: 0.8012\n",
      "Epoch 1162/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8202 - val_loss: 0.0585 - val_mse: 0.7949\n",
      "Epoch 1163/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8279 - val_loss: 0.0585 - val_mse: 0.7890\n",
      "Epoch 1164/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8256 - val_loss: 0.0586 - val_mse: 0.7921\n",
      "Epoch 1165/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8225 - val_loss: 0.0585 - val_mse: 0.7882\n",
      "Epoch 1166/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8267 - val_loss: 0.0585 - val_mse: 0.7963\n",
      "Epoch 1167/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8200 - val_loss: 0.0588 - val_mse: 0.7824\n",
      "Epoch 1168/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8272 - val_loss: 0.0585 - val_mse: 0.7876\n",
      "Epoch 1169/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8156 - val_loss: 0.0588 - val_mse: 0.8041\n",
      "Epoch 1170/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0647 - mse: 0.8261\n",
      "Epoch 01170: saving model to Regression_Model/msle.linear-1170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8244 - val_loss: 0.0585 - val_mse: 0.7941\n",
      "Epoch 1171/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8221 - val_loss: 0.0585 - val_mse: 0.7908\n",
      "Epoch 1172/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8269 - val_loss: 0.0585 - val_mse: 0.7966\n",
      "Epoch 1173/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0644 - mse: 0.8189 - val_loss: 0.0584 - val_mse: 0.7932\n",
      "Epoch 1174/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8208 - val_loss: 0.0586 - val_mse: 0.7991\n",
      "Epoch 1175/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8231 - val_loss: 0.0584 - val_mse: 0.7880\n",
      "Epoch 1176/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8254 - val_loss: 0.0585 - val_mse: 0.7933\n",
      "Epoch 1177/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8273 - val_loss: 0.0587 - val_mse: 0.8014\n",
      "Epoch 1178/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8125 - val_loss: 0.0585 - val_mse: 0.7868\n",
      "Epoch 1179/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8200 - val_loss: 0.0585 - val_mse: 0.7958\n",
      "Epoch 1180/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0649 - mse: 0.8215\n",
      "Epoch 01180: saving model to Regression_Model/msle.linear-1180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8215 - val_loss: 0.0587 - val_mse: 0.8015\n",
      "Epoch 1181/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8290 - val_loss: 0.0586 - val_mse: 0.7821\n",
      "Epoch 1182/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8175 - val_loss: 0.0584 - val_mse: 0.7955\n",
      "Epoch 1183/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0645 - mse: 0.8179 - val_loss: 0.0585 - val_mse: 0.7890\n",
      "Epoch 1184/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8411 - val_loss: 0.0584 - val_mse: 0.7905\n",
      "Epoch 1185/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8227 - val_loss: 0.0584 - val_mse: 0.7953\n",
      "Epoch 1186/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8275 - val_loss: 0.0585 - val_mse: 0.7945\n",
      "Epoch 1187/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8215 - val_loss: 0.0585 - val_mse: 0.7933\n",
      "Epoch 1188/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8265 - val_loss: 0.0585 - val_mse: 0.7877\n",
      "Epoch 1189/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8227 - val_loss: 0.0585 - val_mse: 0.7944\n",
      "Epoch 1190/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0652 - mse: 0.8184\n",
      "Epoch 01190: saving model to Regression_Model/msle.linear-1190.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0653 - mse: 0.8216 - val_loss: 0.0586 - val_mse: 0.7959\n",
      "Epoch 1191/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8133 - val_loss: 0.0585 - val_mse: 0.7915\n",
      "Epoch 1192/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8264 - val_loss: 0.0587 - val_mse: 0.7900\n",
      "Epoch 1193/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8171 - val_loss: 0.0585 - val_mse: 0.7933\n",
      "Epoch 1194/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8194 - val_loss: 0.0586 - val_mse: 0.7983\n",
      "Epoch 1195/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8235 - val_loss: 0.0585 - val_mse: 0.7910\n",
      "Epoch 1196/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8289 - val_loss: 0.0585 - val_mse: 0.7939\n",
      "Epoch 1197/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8177 - val_loss: 0.0586 - val_mse: 0.7862\n",
      "Epoch 1198/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8169 - val_loss: 0.0585 - val_mse: 0.7933\n",
      "Epoch 1199/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0639 - mse: 0.8178 - val_loss: 0.0585 - val_mse: 0.7873\n",
      "Epoch 1200/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0648 - mse: 0.8240\n",
      "Epoch 01200: saving model to Regression_Model/msle.linear-1200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8250 - val_loss: 0.0586 - val_mse: 0.7974\n",
      "Epoch 1201/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8264 - val_loss: 0.0586 - val_mse: 0.7831\n",
      "Epoch 1202/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8197 - val_loss: 0.0587 - val_mse: 0.8006\n",
      "Epoch 1203/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8254 - val_loss: 0.0584 - val_mse: 0.7944\n",
      "Epoch 1204/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8267 - val_loss: 0.0586 - val_mse: 0.7848\n",
      "Epoch 1205/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8248 - val_loss: 0.0588 - val_mse: 0.8028\n",
      "Epoch 1206/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8223 - val_loss: 0.0584 - val_mse: 0.7960\n",
      "Epoch 1207/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8214 - val_loss: 0.0584 - val_mse: 0.7880\n",
      "Epoch 1208/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0643 - mse: 0.8231 - val_loss: 0.0584 - val_mse: 0.7902\n",
      "Epoch 1209/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8242 - val_loss: 0.0585 - val_mse: 0.7965\n",
      "Epoch 1210/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0664 - mse: 0.8396\n",
      "Epoch 01210: saving model to Regression_Model/msle.linear-1210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0663 - mse: 0.8383 - val_loss: 0.0585 - val_mse: 0.7856\n",
      "Epoch 1211/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8236 - val_loss: 0.0585 - val_mse: 0.7864\n",
      "Epoch 1212/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8262 - val_loss: 0.0585 - val_mse: 0.8000\n",
      "Epoch 1213/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8195 - val_loss: 0.0587 - val_mse: 0.8019\n",
      "Epoch 1214/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8215 - val_loss: 0.0585 - val_mse: 0.7962\n",
      "Epoch 1215/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8163 - val_loss: 0.0585 - val_mse: 0.7882\n",
      "Epoch 1216/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8171 - val_loss: 0.0585 - val_mse: 0.7964\n",
      "Epoch 1217/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8168 - val_loss: 0.0584 - val_mse: 0.7938\n",
      "Epoch 1218/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8163 - val_loss: 0.0584 - val_mse: 0.7878\n",
      "Epoch 1219/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8220 - val_loss: 0.0584 - val_mse: 0.7908\n",
      "Epoch 1220/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0650 - mse: 0.8281\n",
      "Epoch 01220: saving model to Regression_Model/msle.linear-1220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8256 - val_loss: 0.0585 - val_mse: 0.7995\n",
      "Epoch 1221/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8341 - val_loss: 0.0584 - val_mse: 0.7867\n",
      "Epoch 1222/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0645 - mse: 0.8252 - val_loss: 0.0586 - val_mse: 0.7998\n",
      "Epoch 1223/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8195 - val_loss: 0.0585 - val_mse: 0.8000\n",
      "Epoch 1224/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8229 - val_loss: 0.0586 - val_mse: 0.7999\n",
      "Epoch 1225/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8221 - val_loss: 0.0586 - val_mse: 0.7836\n",
      "Epoch 1226/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8240 - val_loss: 0.0584 - val_mse: 0.7948\n",
      "Epoch 1227/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8303 - val_loss: 0.0584 - val_mse: 0.7901\n",
      "Epoch 1228/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8244 - val_loss: 0.0584 - val_mse: 0.7937\n",
      "Epoch 1229/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0643 - mse: 0.8222 - val_loss: 0.0588 - val_mse: 0.8055\n",
      "Epoch 1230/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0641 - mse: 0.8234\n",
      "Epoch 01230: saving model to Regression_Model/msle.linear-1230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8231 - val_loss: 0.0586 - val_mse: 0.8005\n",
      "Epoch 1231/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8258 - val_loss: 0.0585 - val_mse: 0.7977\n",
      "Epoch 1232/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8280 - val_loss: 0.0585 - val_mse: 0.7981\n",
      "Epoch 1233/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8203 - val_loss: 0.0584 - val_mse: 0.7910\n",
      "Epoch 1234/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8256 - val_loss: 0.0587 - val_mse: 0.8021\n",
      "Epoch 1235/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8177 - val_loss: 0.0584 - val_mse: 0.7864\n",
      "Epoch 1236/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8191 - val_loss: 0.0587 - val_mse: 0.7999\n",
      "Epoch 1237/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8254 - val_loss: 0.0585 - val_mse: 0.7843\n",
      "Epoch 1238/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0637 - mse: 0.8110 - val_loss: 0.0585 - val_mse: 0.7984\n",
      "Epoch 1239/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8223 - val_loss: 0.0584 - val_mse: 0.7884\n",
      "Epoch 1240/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0652 - mse: 0.8222\n",
      "Epoch 01240: saving model to Regression_Model/msle.linear-1240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8240 - val_loss: 0.0585 - val_mse: 0.7966\n",
      "Epoch 1241/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8218 - val_loss: 0.0586 - val_mse: 0.7918\n",
      "Epoch 1242/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8234 - val_loss: 0.0584 - val_mse: 0.7909\n",
      "Epoch 1243/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8229 - val_loss: 0.0585 - val_mse: 0.7976\n",
      "Epoch 1244/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8218 - val_loss: 0.0584 - val_mse: 0.7931\n",
      "Epoch 1245/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0662 - mse: 0.8279 - val_loss: 0.0584 - val_mse: 0.7912\n",
      "Epoch 1246/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0636 - mse: 0.8091 - val_loss: 0.0585 - val_mse: 0.7887\n",
      "Epoch 1247/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8239 - val_loss: 0.0584 - val_mse: 0.7891\n",
      "Epoch 1248/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8138 - val_loss: 0.0585 - val_mse: 0.7843\n",
      "Epoch 1249/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8250 - val_loss: 0.0584 - val_mse: 0.7932\n",
      "Epoch 1250/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0649 - mse: 0.8251\n",
      "Epoch 01250: saving model to Regression_Model/msle.linear-1250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8273 - val_loss: 0.0584 - val_mse: 0.7916\n",
      "Epoch 1251/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8213 - val_loss: 0.0584 - val_mse: 0.7954\n",
      "Epoch 1252/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8196 - val_loss: 0.0585 - val_mse: 0.7955\n",
      "Epoch 1253/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8199 - val_loss: 0.0585 - val_mse: 0.7861\n",
      "Epoch 1254/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8227 - val_loss: 0.0584 - val_mse: 0.7889\n",
      "Epoch 1255/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8223 - val_loss: 0.0584 - val_mse: 0.7933\n",
      "Epoch 1256/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8663 - val_loss: 0.0584 - val_mse: 0.7891\n",
      "Epoch 1257/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8261 - val_loss: 0.0584 - val_mse: 0.7932\n",
      "Epoch 1258/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8267 - val_loss: 0.0584 - val_mse: 0.7875\n",
      "Epoch 1259/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8355 - val_loss: 0.0584 - val_mse: 0.7965\n",
      "Epoch 1260/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0653 - mse: 0.8326\n",
      "Epoch 01260: saving model to Regression_Model/msle.linear-1260.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8320 - val_loss: 0.0584 - val_mse: 0.7876\n",
      "Epoch 1261/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8139 - val_loss: 0.0585 - val_mse: 0.7970\n",
      "Epoch 1262/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8182 - val_loss: 0.0584 - val_mse: 0.7936\n",
      "Epoch 1263/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8165 - val_loss: 0.0584 - val_mse: 0.7933\n",
      "Epoch 1264/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8201 - val_loss: 0.0583 - val_mse: 0.7930\n",
      "Epoch 1265/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8193 - val_loss: 0.0586 - val_mse: 0.7808\n",
      "Epoch 1266/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8214 - val_loss: 0.0584 - val_mse: 0.7887\n",
      "Epoch 1267/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8226 - val_loss: 0.0584 - val_mse: 0.7969\n",
      "Epoch 1268/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8289 - val_loss: 0.0585 - val_mse: 0.7968\n",
      "Epoch 1269/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8228 - val_loss: 0.0584 - val_mse: 0.7871\n",
      "Epoch 1270/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0645 - mse: 0.8188\n",
      "Epoch 01270: saving model to Regression_Model/msle.linear-1270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8187 - val_loss: 0.0584 - val_mse: 0.7898\n",
      "Epoch 1271/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8195 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1272/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8215 - val_loss: 0.0584 - val_mse: 0.7917\n",
      "Epoch 1273/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8320 - val_loss: 0.0584 - val_mse: 0.7883\n",
      "Epoch 1274/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8161 - val_loss: 0.0585 - val_mse: 0.7849\n",
      "Epoch 1275/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0657 - mse: 0.8320 - val_loss: 0.0584 - val_mse: 0.7869\n",
      "Epoch 1276/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8275 - val_loss: 0.0584 - val_mse: 0.7885\n",
      "Epoch 1277/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8290 - val_loss: 0.0586 - val_mse: 0.7996\n",
      "Epoch 1278/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8341 - val_loss: 0.0584 - val_mse: 0.7916\n",
      "Epoch 1279/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8188 - val_loss: 0.0585 - val_mse: 0.7853\n",
      "Epoch 1280/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0648 - mse: 0.8223\n",
      "Epoch 01280: saving model to Regression_Model/msle.linear-1280.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0646 - mse: 0.8184 - val_loss: 0.0585 - val_mse: 0.7936\n",
      "Epoch 1281/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8201 - val_loss: 0.0584 - val_mse: 0.7973\n",
      "Epoch 1282/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8184 - val_loss: 0.0584 - val_mse: 0.7951\n",
      "Epoch 1283/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8262 - val_loss: 0.0584 - val_mse: 0.7930\n",
      "Epoch 1284/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0653 - mse: 0.8284 - val_loss: 0.0585 - val_mse: 0.7990\n",
      "Epoch 1285/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8334 - val_loss: 0.0584 - val_mse: 0.7900\n",
      "Epoch 1286/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8166 - val_loss: 0.0584 - val_mse: 0.7909\n",
      "Epoch 1287/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8141 - val_loss: 0.0584 - val_mse: 0.7954\n",
      "Epoch 1288/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8150 - val_loss: 0.0584 - val_mse: 0.7935\n",
      "Epoch 1289/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8277 - val_loss: 0.0585 - val_mse: 0.7838\n",
      "Epoch 1290/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0645 - mse: 0.8137\n",
      "Epoch 01290: saving model to Regression_Model/msle.linear-1290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8161 - val_loss: 0.0584 - val_mse: 0.7954\n",
      "Epoch 1291/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8251 - val_loss: 0.0584 - val_mse: 0.7891\n",
      "Epoch 1292/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8244 - val_loss: 0.0584 - val_mse: 0.7920\n",
      "Epoch 1293/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8148 - val_loss: 0.0584 - val_mse: 0.7883\n",
      "Epoch 1294/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8139 - val_loss: 0.0584 - val_mse: 0.7926\n",
      "Epoch 1295/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8191 - val_loss: 0.0585 - val_mse: 0.7996\n",
      "Epoch 1296/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8209 - val_loss: 0.0585 - val_mse: 0.7962\n",
      "Epoch 1297/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8272 - val_loss: 0.0584 - val_mse: 0.7903\n",
      "Epoch 1298/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8179 - val_loss: 0.0585 - val_mse: 0.7830\n",
      "Epoch 1299/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8206 - val_loss: 0.0583 - val_mse: 0.7894\n",
      "Epoch 1300/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0644 - mse: 0.8201\n",
      "Epoch 01300: saving model to Regression_Model/msle.linear-1300.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0644 - mse: 0.8197 - val_loss: 0.0586 - val_mse: 0.7996\n",
      "Epoch 1301/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8289 - val_loss: 0.0583 - val_mse: 0.7904\n",
      "Epoch 1302/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8231 - val_loss: 0.0584 - val_mse: 0.7963\n",
      "Epoch 1303/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8247 - val_loss: 0.0584 - val_mse: 0.7902\n",
      "Epoch 1304/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8286 - val_loss: 0.0584 - val_mse: 0.7942\n",
      "Epoch 1305/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8334 - val_loss: 0.0584 - val_mse: 0.7948\n",
      "Epoch 1306/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8303 - val_loss: 0.0584 - val_mse: 0.7934\n",
      "Epoch 1307/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8173 - val_loss: 0.0584 - val_mse: 0.7902\n",
      "Epoch 1308/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8284 - val_loss: 0.0583 - val_mse: 0.7920\n",
      "Epoch 1309/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8260 - val_loss: 0.0584 - val_mse: 0.7958\n",
      "Epoch 1310/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0650 - mse: 0.8185\n",
      "Epoch 01310: saving model to Regression_Model/msle.linear-1310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8210 - val_loss: 0.0584 - val_mse: 0.7914\n",
      "Epoch 1311/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8173 - val_loss: 0.0584 - val_mse: 0.7916\n",
      "Epoch 1312/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8274 - val_loss: 0.0584 - val_mse: 0.7945\n",
      "Epoch 1313/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8137 - val_loss: 0.0584 - val_mse: 0.7946\n",
      "Epoch 1314/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8157 - val_loss: 0.0588 - val_mse: 0.7796\n",
      "Epoch 1315/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8245 - val_loss: 0.0584 - val_mse: 0.7931\n",
      "Epoch 1316/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8196 - val_loss: 0.0584 - val_mse: 0.7874\n",
      "Epoch 1317/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8292 - val_loss: 0.0584 - val_mse: 0.7946\n",
      "Epoch 1318/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8204 - val_loss: 0.0584 - val_mse: 0.7961\n",
      "Epoch 1319/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8208 - val_loss: 0.0585 - val_mse: 0.7985\n",
      "Epoch 1320/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0652 - mse: 0.8206\n",
      "Epoch 01320: saving model to Regression_Model/msle.linear-1320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8226 - val_loss: 0.0584 - val_mse: 0.7951\n",
      "Epoch 1321/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8221 - val_loss: 0.0584 - val_mse: 0.7887\n",
      "Epoch 1322/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8291 - val_loss: 0.0583 - val_mse: 0.7937\n",
      "Epoch 1323/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8174 - val_loss: 0.0583 - val_mse: 0.7892\n",
      "Epoch 1324/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8305 - val_loss: 0.0584 - val_mse: 0.7921\n",
      "Epoch 1325/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8141 - val_loss: 0.0585 - val_mse: 0.7823\n",
      "Epoch 1326/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8233 - val_loss: 0.0586 - val_mse: 0.8025\n",
      "Epoch 1327/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8223 - val_loss: 0.0584 - val_mse: 0.7873\n",
      "Epoch 1328/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8157 - val_loss: 0.0584 - val_mse: 0.7865\n",
      "Epoch 1329/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8147 - val_loss: 0.0585 - val_mse: 0.7979\n",
      "Epoch 1330/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0642 - mse: 0.8156\n",
      "Epoch 01330: saving model to Regression_Model/msle.linear-1330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8166 - val_loss: 0.0584 - val_mse: 0.7857\n",
      "Epoch 1331/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8207 - val_loss: 0.0584 - val_mse: 0.7899\n",
      "Epoch 1332/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8162 - val_loss: 0.0585 - val_mse: 0.7989\n",
      "Epoch 1333/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8277 - val_loss: 0.0584 - val_mse: 0.7936\n",
      "Epoch 1334/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8155 - val_loss: 0.0584 - val_mse: 0.7879\n",
      "Epoch 1335/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8211 - val_loss: 0.0584 - val_mse: 0.7890\n",
      "Epoch 1336/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8447 - val_loss: 0.0585 - val_mse: 0.7976\n",
      "Epoch 1337/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8301 - val_loss: 0.0584 - val_mse: 0.7955\n",
      "Epoch 1338/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8182 - val_loss: 0.0584 - val_mse: 0.7866\n",
      "Epoch 1339/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8279 - val_loss: 0.0584 - val_mse: 0.7945\n",
      "Epoch 1340/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0651 - mse: 0.8222\n",
      "Epoch 01340: saving model to Regression_Model/msle.linear-1340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8276 - val_loss: 0.0584 - val_mse: 0.7959\n",
      "Epoch 1341/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8229 - val_loss: 0.0584 - val_mse: 0.7911\n",
      "Epoch 1342/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8175 - val_loss: 0.0588 - val_mse: 0.7794\n",
      "Epoch 1343/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8402 - val_loss: 0.0584 - val_mse: 0.7960\n",
      "Epoch 1344/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8250 - val_loss: 0.0584 - val_mse: 0.7892\n",
      "Epoch 1345/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8207 - val_loss: 0.0584 - val_mse: 0.7914\n",
      "Epoch 1346/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8223 - val_loss: 0.0584 - val_mse: 0.7898\n",
      "Epoch 1347/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8265 - val_loss: 0.0585 - val_mse: 0.7840\n",
      "Epoch 1348/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8287 - val_loss: 0.0584 - val_mse: 0.7959\n",
      "Epoch 1349/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8222 - val_loss: 0.0584 - val_mse: 0.7902\n",
      "Epoch 1350/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0647 - mse: 0.8264\n",
      "Epoch 01350: saving model to Regression_Model/msle.linear-1350.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0649 - mse: 0.8288 - val_loss: 0.0584 - val_mse: 0.7942\n",
      "Epoch 1351/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8223 - val_loss: 0.0584 - val_mse: 0.7925\n",
      "Epoch 1352/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8141 - val_loss: 0.0584 - val_mse: 0.7868\n",
      "Epoch 1353/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8159 - val_loss: 0.0584 - val_mse: 0.7945\n",
      "Epoch 1354/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8202 - val_loss: 0.0586 - val_mse: 0.8016\n",
      "Epoch 1355/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8126 - val_loss: 0.0584 - val_mse: 0.7951\n",
      "Epoch 1356/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8207 - val_loss: 0.0584 - val_mse: 0.7956\n",
      "Epoch 1357/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8244 - val_loss: 0.0583 - val_mse: 0.7945\n",
      "Epoch 1358/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8187 - val_loss: 0.0584 - val_mse: 0.7953\n",
      "Epoch 1359/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8229 - val_loss: 0.0584 - val_mse: 0.7944\n",
      "Epoch 1360/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0640 - mse: 0.8179\n",
      "Epoch 01360: saving model to Regression_Model/msle.linear-1360.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.0641 - mse: 0.8177 - val_loss: 0.0583 - val_mse: 0.7906\n",
      "Epoch 1361/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8224 - val_loss: 0.0584 - val_mse: 0.7935\n",
      "Epoch 1362/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8233 - val_loss: 0.0585 - val_mse: 0.7975\n",
      "Epoch 1363/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8285 - val_loss: 0.0584 - val_mse: 0.7856\n",
      "Epoch 1364/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8183 - val_loss: 0.0584 - val_mse: 0.7946\n",
      "Epoch 1365/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8197 - val_loss: 0.0584 - val_mse: 0.7948\n",
      "Epoch 1366/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8183 - val_loss: 0.0584 - val_mse: 0.7958\n",
      "Epoch 1367/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8200 - val_loss: 0.0584 - val_mse: 0.7933\n",
      "Epoch 1368/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8272 - val_loss: 0.0584 - val_mse: 0.7876\n",
      "Epoch 1369/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8265 - val_loss: 0.0583 - val_mse: 0.7892\n",
      "Epoch 1370/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0647 - mse: 0.8200\n",
      "Epoch 01370: saving model to Regression_Model/msle.linear-1370.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8185 - val_loss: 0.0585 - val_mse: 0.7988\n",
      "Epoch 1371/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8212 - val_loss: 0.0584 - val_mse: 0.7969\n",
      "Epoch 1372/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8296 - val_loss: 0.0584 - val_mse: 0.7965\n",
      "Epoch 1373/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8222 - val_loss: 0.0583 - val_mse: 0.7913\n",
      "Epoch 1374/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8190 - val_loss: 0.0584 - val_mse: 0.7982\n",
      "Epoch 1375/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0636 - mse: 0.8156 - val_loss: 0.0583 - val_mse: 0.7915\n",
      "Epoch 1376/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8279 - val_loss: 0.0584 - val_mse: 0.7900\n",
      "Epoch 1377/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8246 - val_loss: 0.0584 - val_mse: 0.7920\n",
      "Epoch 1378/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8265 - val_loss: 0.0584 - val_mse: 0.7947\n",
      "Epoch 1379/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8135 - val_loss: 0.0583 - val_mse: 0.7927\n",
      "Epoch 1380/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0644 - mse: 0.8175\n",
      "Epoch 01380: saving model to Regression_Model/msle.linear-1380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8154 - val_loss: 0.0583 - val_mse: 0.7938\n",
      "Epoch 1381/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8274 - val_loss: 0.0584 - val_mse: 0.7945\n",
      "Epoch 1382/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8297 - val_loss: 0.0583 - val_mse: 0.7936\n",
      "Epoch 1383/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8431 - val_loss: 0.0584 - val_mse: 0.7938\n",
      "Epoch 1384/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8269 - val_loss: 0.0583 - val_mse: 0.7917\n",
      "Epoch 1385/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0646 - mse: 0.8210 - val_loss: 0.0584 - val_mse: 0.7961\n",
      "Epoch 1386/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8217 - val_loss: 0.0583 - val_mse: 0.7893\n",
      "Epoch 1387/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8209 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1388/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8301 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1389/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8297 - val_loss: 0.0585 - val_mse: 0.7992\n",
      "Epoch 1390/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0645 - mse: 0.8239\n",
      "Epoch 01390: saving model to Regression_Model/msle.linear-1390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8250 - val_loss: 0.0584 - val_mse: 0.7951\n",
      "Epoch 1391/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8187 - val_loss: 0.0583 - val_mse: 0.7936\n",
      "Epoch 1392/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0639 - mse: 0.8150 - val_loss: 0.0584 - val_mse: 0.7959\n",
      "Epoch 1393/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0652 - mse: 0.8221 - val_loss: 0.0584 - val_mse: 0.7854\n",
      "Epoch 1394/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0653 - mse: 0.8322 - val_loss: 0.0583 - val_mse: 0.7910\n",
      "Epoch 1395/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8161 - val_loss: 0.0584 - val_mse: 0.7947\n",
      "Epoch 1396/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8210 - val_loss: 0.0585 - val_mse: 0.7845\n",
      "Epoch 1397/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8149 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1398/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8282 - val_loss: 0.0583 - val_mse: 0.7915\n",
      "Epoch 1399/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8168 - val_loss: 0.0584 - val_mse: 0.7951\n",
      "Epoch 1400/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0652 - mse: 0.8287\n",
      "Epoch 01400: saving model to Regression_Model/msle.linear-1400.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8331 - val_loss: 0.0585 - val_mse: 0.7955\n",
      "Epoch 1401/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8240 - val_loss: 0.0584 - val_mse: 0.7954\n",
      "Epoch 1402/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8334 - val_loss: 0.0584 - val_mse: 0.7880\n",
      "Epoch 1403/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8193 - val_loss: 0.0584 - val_mse: 0.7961\n",
      "Epoch 1404/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0656 - mse: 0.8272 - val_loss: 0.0584 - val_mse: 0.7976\n",
      "Epoch 1405/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8176 - val_loss: 0.0584 - val_mse: 0.7939\n",
      "Epoch 1406/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8249 - val_loss: 0.0584 - val_mse: 0.7961\n",
      "Epoch 1407/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0642 - mse: 0.8161 - val_loss: 0.0583 - val_mse: 0.7887\n",
      "Epoch 1408/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8214 - val_loss: 0.0583 - val_mse: 0.7950\n",
      "Epoch 1409/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8194 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1410/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0641 - mse: 0.8104\n",
      "Epoch 01410: saving model to Regression_Model/msle.linear-1410.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.0641 - mse: 0.8130 - val_loss: 0.0583 - val_mse: 0.7913\n",
      "Epoch 1411/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8189 - val_loss: 0.0583 - val_mse: 0.7941\n",
      "Epoch 1412/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8331 - val_loss: 0.0583 - val_mse: 0.7927\n",
      "Epoch 1413/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8196 - val_loss: 0.0583 - val_mse: 0.7888\n",
      "Epoch 1414/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8290 - val_loss: 0.0583 - val_mse: 0.7943\n",
      "Epoch 1415/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8229 - val_loss: 0.0583 - val_mse: 0.7933\n",
      "Epoch 1416/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8140 - val_loss: 0.0583 - val_mse: 0.7912\n",
      "Epoch 1417/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8179 - val_loss: 0.0584 - val_mse: 0.7960\n",
      "Epoch 1418/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8191 - val_loss: 0.0583 - val_mse: 0.7907\n",
      "Epoch 1419/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8203 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1420/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0648 - mse: 0.8221\n",
      "Epoch 01420: saving model to Regression_Model/msle.linear-1420.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8224 - val_loss: 0.0584 - val_mse: 0.7904\n",
      "Epoch 1421/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8216 - val_loss: 0.0583 - val_mse: 0.7950\n",
      "Epoch 1422/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0654 - mse: 0.8374 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1423/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8196 - val_loss: 0.0583 - val_mse: 0.7916\n",
      "Epoch 1424/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8245 - val_loss: 0.0583 - val_mse: 0.7911\n",
      "Epoch 1425/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8332 - val_loss: 0.0584 - val_mse: 0.7870\n",
      "Epoch 1426/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8274 - val_loss: 0.0583 - val_mse: 0.7939\n",
      "Epoch 1427/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8281 - val_loss: 0.0583 - val_mse: 0.7934\n",
      "Epoch 1428/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8204 - val_loss: 0.0583 - val_mse: 0.7880\n",
      "Epoch 1429/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8187 - val_loss: 0.0585 - val_mse: 0.7974\n",
      "Epoch 1430/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0650 - mse: 0.8260\n",
      "Epoch 01430: saving model to Regression_Model/msle.linear-1430.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0651 - mse: 0.8256 - val_loss: 0.0583 - val_mse: 0.7905\n",
      "Epoch 1431/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8188 - val_loss: 0.0583 - val_mse: 0.7898\n",
      "Epoch 1432/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8186 - val_loss: 0.0583 - val_mse: 0.7888\n",
      "Epoch 1433/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8211 - val_loss: 0.0584 - val_mse: 0.7970\n",
      "Epoch 1434/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8309 - val_loss: 0.0583 - val_mse: 0.7901\n",
      "Epoch 1435/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8186 - val_loss: 0.0583 - val_mse: 0.7897\n",
      "Epoch 1436/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8263 - val_loss: 0.0584 - val_mse: 0.7904\n",
      "Epoch 1437/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8232 - val_loss: 0.0584 - val_mse: 0.7853\n",
      "Epoch 1438/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8287 - val_loss: 0.0583 - val_mse: 0.7934\n",
      "Epoch 1439/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8174 - val_loss: 0.0584 - val_mse: 0.7927\n",
      "Epoch 1440/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0643 - mse: 0.8209\n",
      "Epoch 01440: saving model to Regression_Model/msle.linear-1440.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8184 - val_loss: 0.0583 - val_mse: 0.7936\n",
      "Epoch 1441/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8237 - val_loss: 0.0584 - val_mse: 0.7854\n",
      "Epoch 1442/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8169 - val_loss: 0.0584 - val_mse: 0.7890\n",
      "Epoch 1443/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8174 - val_loss: 0.0583 - val_mse: 0.7918\n",
      "Epoch 1444/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8290 - val_loss: 0.0583 - val_mse: 0.7909\n",
      "Epoch 1445/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8301 - val_loss: 0.0583 - val_mse: 0.7941\n",
      "Epoch 1446/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8237 - val_loss: 0.0583 - val_mse: 0.7933\n",
      "Epoch 1447/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8363 - val_loss: 0.0583 - val_mse: 0.7905\n",
      "Epoch 1448/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8166 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1449/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8228 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1450/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0654 - mse: 0.8224\n",
      "Epoch 01450: saving model to Regression_Model/msle.linear-1450.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0653 - mse: 0.8227 - val_loss: 0.0584 - val_mse: 0.7866\n",
      "Epoch 1451/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8420 - val_loss: 0.0584 - val_mse: 0.7870\n",
      "Epoch 1452/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8169 - val_loss: 0.0583 - val_mse: 0.7900\n",
      "Epoch 1453/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8224 - val_loss: 0.0584 - val_mse: 0.7948\n",
      "Epoch 1454/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8273 - val_loss: 0.0583 - val_mse: 0.7938\n",
      "Epoch 1455/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0646 - mse: 0.8201 - val_loss: 0.0583 - val_mse: 0.7936\n",
      "Epoch 1456/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8246 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1457/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8181 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1458/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8300 - val_loss: 0.0583 - val_mse: 0.7895\n",
      "Epoch 1459/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8206 - val_loss: 0.0583 - val_mse: 0.7915\n",
      "Epoch 1460/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0645 - mse: 0.8203\n",
      "Epoch 01460: saving model to Regression_Model/msle.linear-1460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8190 - val_loss: 0.0583 - val_mse: 0.7897\n",
      "Epoch 1461/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8205 - val_loss: 0.0583 - val_mse: 0.7941\n",
      "Epoch 1462/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8168 - val_loss: 0.0583 - val_mse: 0.7915\n",
      "Epoch 1463/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8265 - val_loss: 0.0583 - val_mse: 0.7897\n",
      "Epoch 1464/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0646 - mse: 0.8199 - val_loss: 0.0583 - val_mse: 0.7936\n",
      "Epoch 1465/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8221 - val_loss: 0.0585 - val_mse: 0.7983\n",
      "Epoch 1466/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0652 - mse: 0.8242 - val_loss: 0.0583 - val_mse: 0.7934\n",
      "Epoch 1467/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8251 - val_loss: 0.0583 - val_mse: 0.7914\n",
      "Epoch 1468/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8202 - val_loss: 0.0583 - val_mse: 0.7939\n",
      "Epoch 1469/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8232 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1470/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0641 - mse: 0.8153\n",
      "Epoch 01470: saving model to Regression_Model/msle.linear-1470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8145 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1471/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8247 - val_loss: 0.0585 - val_mse: 0.7988\n",
      "Epoch 1472/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8252 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1473/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8259 - val_loss: 0.0583 - val_mse: 0.7891\n",
      "Epoch 1474/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8218 - val_loss: 0.0583 - val_mse: 0.7883\n",
      "Epoch 1475/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8277 - val_loss: 0.0584 - val_mse: 0.7941\n",
      "Epoch 1476/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8217 - val_loss: 0.0583 - val_mse: 0.7946\n",
      "Epoch 1477/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8223 - val_loss: 0.0583 - val_mse: 0.7911\n",
      "Epoch 1478/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8148 - val_loss: 0.0583 - val_mse: 0.7938\n",
      "Epoch 1479/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8190 - val_loss: 0.0583 - val_mse: 0.7938\n",
      "Epoch 1480/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0643 - mse: 0.8154\n",
      "Epoch 01480: saving model to Regression_Model/msle.linear-1480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8157 - val_loss: 0.0583 - val_mse: 0.7915\n",
      "Epoch 1481/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8366 - val_loss: 0.0584 - val_mse: 0.7952\n",
      "Epoch 1482/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8248 - val_loss: 0.0583 - val_mse: 0.7899\n",
      "Epoch 1483/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8314 - val_loss: 0.0583 - val_mse: 0.7944\n",
      "Epoch 1484/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8210 - val_loss: 0.0583 - val_mse: 0.7917\n",
      "Epoch 1485/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8181 - val_loss: 0.0583 - val_mse: 0.7935\n",
      "Epoch 1486/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8158 - val_loss: 0.0584 - val_mse: 0.7949\n",
      "Epoch 1487/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8208 - val_loss: 0.0583 - val_mse: 0.7916\n",
      "Epoch 1488/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8156 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1489/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8243 - val_loss: 0.0584 - val_mse: 0.7934\n",
      "Epoch 1490/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0646 - mse: 0.8249\n",
      "Epoch 01490: saving model to Regression_Model/msle.linear-1490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8213 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1491/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8215 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1492/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8183 - val_loss: 0.0583 - val_mse: 0.7888\n",
      "Epoch 1493/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8225 - val_loss: 0.0584 - val_mse: 0.7946\n",
      "Epoch 1494/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8162 - val_loss: 0.0583 - val_mse: 0.7892\n",
      "Epoch 1495/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8173 - val_loss: 0.0584 - val_mse: 0.7952\n",
      "Epoch 1496/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0652 - mse: 0.8203 - val_loss: 0.0584 - val_mse: 0.7958\n",
      "Epoch 1497/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8264 - val_loss: 0.0583 - val_mse: 0.7880\n",
      "Epoch 1498/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8220 - val_loss: 0.0583 - val_mse: 0.7942\n",
      "Epoch 1499/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8305 - val_loss: 0.0583 - val_mse: 0.7935\n",
      "Epoch 1500/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0632 - mse: 0.8131\n",
      "Epoch 01500: saving model to Regression_Model/msle.linear-1500.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0634 - mse: 0.8135 - val_loss: 0.0583 - val_mse: 0.7903\n",
      "Epoch 1501/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8290 - val_loss: 0.0583 - val_mse: 0.7941\n",
      "Epoch 1502/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8197 - val_loss: 0.0583 - val_mse: 0.7930\n",
      "Epoch 1503/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8164 - val_loss: 0.0583 - val_mse: 0.7903\n",
      "Epoch 1504/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8198 - val_loss: 0.0583 - val_mse: 0.7918\n",
      "Epoch 1505/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8472 - val_loss: 0.0583 - val_mse: 0.7940\n",
      "Epoch 1506/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8213 - val_loss: 0.0583 - val_mse: 0.7932\n",
      "Epoch 1507/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8153 - val_loss: 0.0583 - val_mse: 0.7938\n",
      "Epoch 1508/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8175 - val_loss: 0.0584 - val_mse: 0.7937\n",
      "Epoch 1509/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8209 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1510/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0649 - mse: 0.8174\n",
      "Epoch 01510: saving model to Regression_Model/msle.linear-1510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8212 - val_loss: 0.0583 - val_mse: 0.7916\n",
      "Epoch 1511/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8225 - val_loss: 0.0583 - val_mse: 0.7940\n",
      "Epoch 1512/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8244 - val_loss: 0.0583 - val_mse: 0.7899\n",
      "Epoch 1513/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8277 - val_loss: 0.0584 - val_mse: 0.7942\n",
      "Epoch 1514/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8350 - val_loss: 0.0584 - val_mse: 0.7963\n",
      "Epoch 1515/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8301 - val_loss: 0.0583 - val_mse: 0.7950\n",
      "Epoch 1516/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8249 - val_loss: 0.0584 - val_mse: 0.7902\n",
      "Epoch 1517/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8192 - val_loss: 0.0583 - val_mse: 0.7907\n",
      "Epoch 1518/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8286 - val_loss: 0.0584 - val_mse: 0.7929\n",
      "Epoch 1519/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8163 - val_loss: 0.0584 - val_mse: 0.7958\n",
      "Epoch 1520/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0649 - mse: 0.8265\n",
      "Epoch 01520: saving model to Regression_Model/msle.linear-1520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8254 - val_loss: 0.0584 - val_mse: 0.7882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1521/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8304 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1522/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8241 - val_loss: 0.0584 - val_mse: 0.7892\n",
      "Epoch 1523/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8216 - val_loss: 0.0583 - val_mse: 0.7910\n",
      "Epoch 1524/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8229 - val_loss: 0.0584 - val_mse: 0.7890\n",
      "Epoch 1525/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8422 - val_loss: 0.0585 - val_mse: 0.7968\n",
      "Epoch 1526/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8227 - val_loss: 0.0584 - val_mse: 0.7942\n",
      "Epoch 1527/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8215 - val_loss: 0.0584 - val_mse: 0.7953\n",
      "Epoch 1528/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8322 - val_loss: 0.0584 - val_mse: 0.7961\n",
      "Epoch 1529/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8125 - val_loss: 0.0583 - val_mse: 0.7909\n",
      "Epoch 1530/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0643 - mse: 0.8190\n",
      "Epoch 01530: saving model to Regression_Model/msle.linear-1530.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0645 - mse: 0.8215 - val_loss: 0.0583 - val_mse: 0.7942\n",
      "Epoch 1531/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8169 - val_loss: 0.0583 - val_mse: 0.7897\n",
      "Epoch 1532/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8221 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1533/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8187 - val_loss: 0.0583 - val_mse: 0.7906\n",
      "Epoch 1534/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8275 - val_loss: 0.0583 - val_mse: 0.7909\n",
      "Epoch 1535/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8197 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1536/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0637 - mse: 0.8140 - val_loss: 0.0583 - val_mse: 0.7905\n",
      "Epoch 1537/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8196 - val_loss: 0.0583 - val_mse: 0.7915\n",
      "Epoch 1538/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0661 - mse: 0.8353 - val_loss: 0.0583 - val_mse: 0.7916\n",
      "Epoch 1539/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8210 - val_loss: 0.0583 - val_mse: 0.7884\n",
      "Epoch 1540/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0653 - mse: 0.8221\n",
      "Epoch 01540: saving model to Regression_Model/msle.linear-1540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8181 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1541/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8190 - val_loss: 0.0583 - val_mse: 0.7857\n",
      "Epoch 1542/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8157 - val_loss: 0.0584 - val_mse: 0.7948\n",
      "Epoch 1543/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8136 - val_loss: 0.0584 - val_mse: 0.7961\n",
      "Epoch 1544/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8216 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1545/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8208 - val_loss: 0.0583 - val_mse: 0.7933\n",
      "Epoch 1546/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8134 - val_loss: 0.0583 - val_mse: 0.7935\n",
      "Epoch 1547/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0635 - mse: 0.8184 - val_loss: 0.0583 - val_mse: 0.7937\n",
      "Epoch 1548/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8228 - val_loss: 0.0583 - val_mse: 0.7906\n",
      "Epoch 1549/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8288 - val_loss: 0.0583 - val_mse: 0.7900\n",
      "Epoch 1550/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0644 - mse: 0.8192\n",
      "Epoch 01550: saving model to Regression_Model/msle.linear-1550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8194 - val_loss: 0.0583 - val_mse: 0.7934\n",
      "Epoch 1551/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8253 - val_loss: 0.0583 - val_mse: 0.7932\n",
      "Epoch 1552/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8247 - val_loss: 0.0583 - val_mse: 0.7903\n",
      "Epoch 1553/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8205 - val_loss: 0.0583 - val_mse: 0.7927\n",
      "Epoch 1554/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8265 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1555/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8218 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1556/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8257 - val_loss: 0.0583 - val_mse: 0.7874\n",
      "Epoch 1557/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8100 - val_loss: 0.0583 - val_mse: 0.7941\n",
      "Epoch 1558/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8222 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1559/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8242 - val_loss: 0.0583 - val_mse: 0.7938\n",
      "Epoch 1560/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0656 - mse: 0.8265\n",
      "Epoch 01560: saving model to Regression_Model/msle.linear-1560.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.0655 - mse: 0.8249 - val_loss: 0.0583 - val_mse: 0.7947\n",
      "Epoch 1561/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0665 - mse: 0.8327 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1562/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8237 - val_loss: 0.0583 - val_mse: 0.7917\n",
      "Epoch 1563/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8209 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1564/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8220 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1565/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8262 - val_loss: 0.0584 - val_mse: 0.7948\n",
      "Epoch 1566/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8254 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1567/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8195 - val_loss: 0.0583 - val_mse: 0.7860\n",
      "Epoch 1568/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8264 - val_loss: 0.0583 - val_mse: 0.7945\n",
      "Epoch 1569/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8266 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1570/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0644 - mse: 0.8141\n",
      "Epoch 01570: saving model to Regression_Model/msle.linear-1570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8148 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1571/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8221 - val_loss: 0.0583 - val_mse: 0.7883\n",
      "Epoch 1572/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8244 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1573/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8178 - val_loss: 0.0583 - val_mse: 0.7904\n",
      "Epoch 1574/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8210 - val_loss: 0.0583 - val_mse: 0.7878\n",
      "Epoch 1575/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8287 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1576/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8436 - val_loss: 0.0584 - val_mse: 0.7965\n",
      "Epoch 1577/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8204 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1578/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8211 - val_loss: 0.0583 - val_mse: 0.7936\n",
      "Epoch 1579/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8227 - val_loss: 0.0583 - val_mse: 0.7949\n",
      "Epoch 1580/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0646 - mse: 0.8192\n",
      "Epoch 01580: saving model to Regression_Model/msle.linear-1580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8199 - val_loss: 0.0584 - val_mse: 0.7867\n",
      "Epoch 1581/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8168 - val_loss: 0.0583 - val_mse: 0.7933\n",
      "Epoch 1582/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8246 - val_loss: 0.0584 - val_mse: 0.7960\n",
      "Epoch 1583/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8189 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1584/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8167 - val_loss: 0.0583 - val_mse: 0.7874\n",
      "Epoch 1585/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8197 - val_loss: 0.0583 - val_mse: 0.7894\n",
      "Epoch 1586/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8153 - val_loss: 0.0583 - val_mse: 0.7934\n",
      "Epoch 1587/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8238 - val_loss: 0.0584 - val_mse: 0.7941\n",
      "Epoch 1588/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8226 - val_loss: 0.0583 - val_mse: 0.7941\n",
      "Epoch 1589/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8267 - val_loss: 0.0583 - val_mse: 0.7920\n",
      "Epoch 1590/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0649 - mse: 0.8176\n",
      "Epoch 01590: saving model to Regression_Model/msle.linear-1590.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.0648 - mse: 0.8214 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1591/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8214 - val_loss: 0.0583 - val_mse: 0.7911\n",
      "Epoch 1592/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8248 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1593/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8217 - val_loss: 0.0583 - val_mse: 0.7899\n",
      "Epoch 1594/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8304 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1595/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8184 - val_loss: 0.0583 - val_mse: 0.7908\n",
      "Epoch 1596/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8205 - val_loss: 0.0583 - val_mse: 0.7929\n",
      "Epoch 1597/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8444 - val_loss: 0.0583 - val_mse: 0.7920\n",
      "Epoch 1598/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8137 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1599/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8171 - val_loss: 0.0583 - val_mse: 0.7905\n",
      "Epoch 1600/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0640 - mse: 0.8159\n",
      "Epoch 01600: saving model to Regression_Model/msle.linear-1600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8132 - val_loss: 0.0583 - val_mse: 0.7908\n",
      "Epoch 1601/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8194 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1602/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8235 - val_loss: 0.0583 - val_mse: 0.7940\n",
      "Epoch 1603/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8227 - val_loss: 0.0582 - val_mse: 0.7904\n",
      "Epoch 1604/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0645 - mse: 0.8165 - val_loss: 0.0583 - val_mse: 0.7934\n",
      "Epoch 1605/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8249 - val_loss: 0.0583 - val_mse: 0.7929\n",
      "Epoch 1606/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8274 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1607/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8239 - val_loss: 0.0583 - val_mse: 0.7860\n",
      "Epoch 1608/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8139 - val_loss: 0.0582 - val_mse: 0.7927\n",
      "Epoch 1609/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0639 - mse: 0.8168 - val_loss: 0.0583 - val_mse: 0.7912\n",
      "Epoch 1610/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.0643 - mse: 0.8215\n",
      "Epoch 01610: saving model to Regression_Model/msle.linear-1610.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0644 - mse: 0.8220 - val_loss: 0.0583 - val_mse: 0.7930\n",
      "Epoch 1611/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8176 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1612/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8191 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1613/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8199 - val_loss: 0.0583 - val_mse: 0.7893\n",
      "Epoch 1614/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0643 - mse: 0.8132 - val_loss: 0.0583 - val_mse: 0.7934\n",
      "Epoch 1615/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0653 - mse: 0.8283 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1616/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8241 - val_loss: 0.0583 - val_mse: 0.7897\n",
      "Epoch 1617/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8138 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1618/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8152 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1619/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8217 - val_loss: 0.0583 - val_mse: 0.7907\n",
      "Epoch 1620/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0652 - mse: 0.8167\n",
      "Epoch 01620: saving model to Regression_Model/msle.linear-1620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8204 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1621/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8279 - val_loss: 0.0582 - val_mse: 0.7923\n",
      "Epoch 1622/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8170 - val_loss: 0.0583 - val_mse: 0.7888\n",
      "Epoch 1623/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8130 - val_loss: 0.0583 - val_mse: 0.7932\n",
      "Epoch 1624/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8310 - val_loss: 0.0583 - val_mse: 0.7929\n",
      "Epoch 1625/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8229 - val_loss: 0.0583 - val_mse: 0.7940\n",
      "Epoch 1626/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8221 - val_loss: 0.0583 - val_mse: 0.7913\n",
      "Epoch 1627/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8157 - val_loss: 0.0583 - val_mse: 0.7897\n",
      "Epoch 1628/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8186 - val_loss: 0.0583 - val_mse: 0.7932\n",
      "Epoch 1629/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0636 - mse: 0.8140 - val_loss: 0.0582 - val_mse: 0.7907\n",
      "Epoch 1630/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0650 - mse: 0.8201\n",
      "Epoch 01630: saving model to Regression_Model/msle.linear-1630.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0647 - mse: 0.8222 - val_loss: 0.0583 - val_mse: 0.7896\n",
      "Epoch 1631/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8126 - val_loss: 0.0583 - val_mse: 0.7930\n",
      "Epoch 1632/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8186 - val_loss: 0.0584 - val_mse: 0.7958\n",
      "Epoch 1633/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8307 - val_loss: 0.0583 - val_mse: 0.7898\n",
      "Epoch 1634/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8263 - val_loss: 0.0583 - val_mse: 0.7906\n",
      "Epoch 1635/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8222 - val_loss: 0.0583 - val_mse: 0.7909\n",
      "Epoch 1636/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8169 - val_loss: 0.0583 - val_mse: 0.7932\n",
      "Epoch 1637/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8244 - val_loss: 0.0583 - val_mse: 0.7918\n",
      "Epoch 1638/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0655 - mse: 0.8253 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1639/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0637 - mse: 0.8214 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1640/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0650 - mse: 0.8176\n",
      "Epoch 01640: saving model to Regression_Model/msle.linear-1640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8199 - val_loss: 0.0582 - val_mse: 0.7927\n",
      "Epoch 1641/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8177 - val_loss: 0.0583 - val_mse: 0.7937\n",
      "Epoch 1642/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8329 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1643/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8168 - val_loss: 0.0583 - val_mse: 0.7932\n",
      "Epoch 1644/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8203 - val_loss: 0.0583 - val_mse: 0.7885\n",
      "Epoch 1645/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8166 - val_loss: 0.0583 - val_mse: 0.7949\n",
      "Epoch 1646/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8188 - val_loss: 0.0583 - val_mse: 0.7932\n",
      "Epoch 1647/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8283 - val_loss: 0.0583 - val_mse: 0.7903\n",
      "Epoch 1648/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8274 - val_loss: 0.0582 - val_mse: 0.7911\n",
      "Epoch 1649/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8221 - val_loss: 0.0583 - val_mse: 0.7906\n",
      "Epoch 1650/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0645 - mse: 0.8140\n",
      "Epoch 01650: saving model to Regression_Model/msle.linear-1650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8145 - val_loss: 0.0583 - val_mse: 0.7875\n",
      "Epoch 1651/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8184 - val_loss: 0.0582 - val_mse: 0.7897\n",
      "Epoch 1652/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8221 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1653/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8227 - val_loss: 0.0583 - val_mse: 0.7887\n",
      "Epoch 1654/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8221 - val_loss: 0.0583 - val_mse: 0.7915\n",
      "Epoch 1655/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8180 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1656/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8145 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1657/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8259 - val_loss: 0.0582 - val_mse: 0.7907\n",
      "Epoch 1658/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8241 - val_loss: 0.0583 - val_mse: 0.7840\n",
      "Epoch 1659/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8234 - val_loss: 0.0583 - val_mse: 0.7937\n",
      "Epoch 1660/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.0644 - mse: 0.8219\n",
      "Epoch 01660: saving model to Regression_Model/msle.linear-1660.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0645 - mse: 0.8229 - val_loss: 0.0583 - val_mse: 0.7878\n",
      "Epoch 1661/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8244 - val_loss: 0.0582 - val_mse: 0.7913\n",
      "Epoch 1662/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8173 - val_loss: 0.0583 - val_mse: 0.7934\n",
      "Epoch 1663/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8221 - val_loss: 0.0582 - val_mse: 0.7923\n",
      "Epoch 1664/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8309 - val_loss: 0.0583 - val_mse: 0.7878\n",
      "Epoch 1665/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8197 - val_loss: 0.0582 - val_mse: 0.7923\n",
      "Epoch 1666/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0636 - mse: 0.8127 - val_loss: 0.0583 - val_mse: 0.7935\n",
      "Epoch 1667/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8171 - val_loss: 0.0583 - val_mse: 0.7855\n",
      "Epoch 1668/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8166 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1669/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8301 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1670/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0647 - mse: 0.8241\n",
      "Epoch 01670: saving model to Regression_Model/msle.linear-1670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8224 - val_loss: 0.0582 - val_mse: 0.7903\n",
      "Epoch 1671/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8218 - val_loss: 0.0582 - val_mse: 0.7909\n",
      "Epoch 1672/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8241 - val_loss: 0.0584 - val_mse: 0.7945\n",
      "Epoch 1673/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8232 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1674/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8231 - val_loss: 0.0582 - val_mse: 0.7894\n",
      "Epoch 1675/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8168 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1676/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8201 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1677/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8202 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1678/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8207 - val_loss: 0.0583 - val_mse: 0.7898\n",
      "Epoch 1679/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8319 - val_loss: 0.0582 - val_mse: 0.7925\n",
      "Epoch 1680/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.0645 - mse: 0.8222\n",
      "Epoch 01680: saving model to Regression_Model/msle.linear-1680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8219 - val_loss: 0.0583 - val_mse: 0.7852\n",
      "Epoch 1681/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8238 - val_loss: 0.0582 - val_mse: 0.7909\n",
      "Epoch 1682/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8178 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1683/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8220 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1684/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8159 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1685/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8238 - val_loss: 0.0582 - val_mse: 0.7898\n",
      "Epoch 1686/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8186 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1687/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8131 - val_loss: 0.0582 - val_mse: 0.7909\n",
      "Epoch 1688/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8210 - val_loss: 0.0582 - val_mse: 0.7924\n",
      "Epoch 1689/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8165 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1690/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0652 - mse: 0.8209\n",
      "Epoch 01690: saving model to Regression_Model/msle.linear-1690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8232 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1691/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8190 - val_loss: 0.0582 - val_mse: 0.7898\n",
      "Epoch 1692/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8248 - val_loss: 0.0583 - val_mse: 0.7888\n",
      "Epoch 1693/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8113 - val_loss: 0.0583 - val_mse: 0.7941\n",
      "Epoch 1694/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8170 - val_loss: 0.0583 - val_mse: 0.7940\n",
      "Epoch 1695/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8224 - val_loss: 0.0582 - val_mse: 0.7912\n",
      "Epoch 1696/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8218 - val_loss: 0.0582 - val_mse: 0.7908\n",
      "Epoch 1697/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8216 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1698/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8176 - val_loss: 0.0583 - val_mse: 0.7886\n",
      "Epoch 1699/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8243 - val_loss: 0.0582 - val_mse: 0.7905\n",
      "Epoch 1700/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0639 - mse: 0.8097\n",
      "Epoch 01700: saving model to Regression_Model/msle.linear-1700.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0637 - mse: 0.8138 - val_loss: 0.0583 - val_mse: 0.7914\n",
      "Epoch 1701/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8199 - val_loss: 0.0582 - val_mse: 0.7914\n",
      "Epoch 1702/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8338 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1703/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8207 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1704/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8211 - val_loss: 0.0583 - val_mse: 0.7916\n",
      "Epoch 1705/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0639 - mse: 0.8148 - val_loss: 0.0583 - val_mse: 0.7927\n",
      "Epoch 1706/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8248 - val_loss: 0.0583 - val_mse: 0.7936\n",
      "Epoch 1707/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8253 - val_loss: 0.0583 - val_mse: 0.7879\n",
      "Epoch 1708/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8258 - val_loss: 0.0583 - val_mse: 0.7886\n",
      "Epoch 1709/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8265 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1710/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0644 - mse: 0.8219\n",
      "Epoch 01710: saving model to Regression_Model/msle.linear-1710.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.0644 - mse: 0.8201 - val_loss: 0.0583 - val_mse: 0.7856\n",
      "Epoch 1711/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8158 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1712/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8175 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1713/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8243 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1714/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8169 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1715/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8204 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1716/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0637 - mse: 0.8104 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1717/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8363 - val_loss: 0.0583 - val_mse: 0.7932\n",
      "Epoch 1718/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8367 - val_loss: 0.0582 - val_mse: 0.7908\n",
      "Epoch 1719/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8228 - val_loss: 0.0582 - val_mse: 0.7908\n",
      "Epoch 1720/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0638 - mse: 0.8145\n",
      "Epoch 01720: saving model to Regression_Model/msle.linear-1720.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8152 - val_loss: 0.0582 - val_mse: 0.7889\n",
      "Epoch 1721/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0634 - mse: 0.8089 - val_loss: 0.0583 - val_mse: 0.7917\n",
      "Epoch 1722/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8189 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1723/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8410 - val_loss: 0.0582 - val_mse: 0.7908\n",
      "Epoch 1724/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8290 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1725/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8265 - val_loss: 0.0583 - val_mse: 0.7870\n",
      "Epoch 1726/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8158 - val_loss: 0.0582 - val_mse: 0.7925\n",
      "Epoch 1727/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8208 - val_loss: 0.0582 - val_mse: 0.7908\n",
      "Epoch 1728/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8266 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1729/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8203 - val_loss: 0.0582 - val_mse: 0.7898\n",
      "Epoch 1730/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.0645 - mse: 0.8200\n",
      "Epoch 01730: saving model to Regression_Model/msle.linear-1730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8205 - val_loss: 0.0582 - val_mse: 0.7899\n",
      "Epoch 1731/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8179 - val_loss: 0.0582 - val_mse: 0.7904\n",
      "Epoch 1732/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8179 - val_loss: 0.0583 - val_mse: 0.7929\n",
      "Epoch 1733/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8215 - val_loss: 0.0583 - val_mse: 0.7891\n",
      "Epoch 1734/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8218 - val_loss: 0.0582 - val_mse: 0.7921\n",
      "Epoch 1735/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8167 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1736/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0636 - mse: 0.8122 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1737/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8184 - val_loss: 0.0583 - val_mse: 0.7903\n",
      "Epoch 1738/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8172 - val_loss: 0.0583 - val_mse: 0.7885\n",
      "Epoch 1739/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8279 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1740/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0638 - mse: 0.8199\n",
      "Epoch 01740: saving model to Regression_Model/msle.linear-1740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8178 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1741/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8201 - val_loss: 0.0582 - val_mse: 0.7927\n",
      "Epoch 1742/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8337 - val_loss: 0.0583 - val_mse: 0.7927\n",
      "Epoch 1743/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8279 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1744/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8199 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1745/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8267 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1746/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8213 - val_loss: 0.0582 - val_mse: 0.7914\n",
      "Epoch 1747/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8211 - val_loss: 0.0582 - val_mse: 0.7898\n",
      "Epoch 1748/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8209 - val_loss: 0.0582 - val_mse: 0.7891\n",
      "Epoch 1749/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8181 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1750/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0645 - mse: 0.8251\n",
      "Epoch 01750: saving model to Regression_Model/msle.linear-1750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8276 - val_loss: 0.0582 - val_mse: 0.7888\n",
      "Epoch 1751/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8245 - val_loss: 0.0582 - val_mse: 0.7909\n",
      "Epoch 1752/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8157 - val_loss: 0.0582 - val_mse: 0.7888\n",
      "Epoch 1753/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8199 - val_loss: 0.0582 - val_mse: 0.7906\n",
      "Epoch 1754/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8192 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1755/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8190 - val_loss: 0.0582 - val_mse: 0.7910\n",
      "Epoch 1756/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8269 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1757/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8195 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1758/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8168 - val_loss: 0.0582 - val_mse: 0.7899\n",
      "Epoch 1759/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8204 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1760/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0641 - mse: 0.8142\n",
      "Epoch 01760: saving model to Regression_Model/msle.linear-1760.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0648 - mse: 0.8191 - val_loss: 0.0582 - val_mse: 0.7911\n",
      "Epoch 1761/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8150 - val_loss: 0.0582 - val_mse: 0.7904\n",
      "Epoch 1762/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8221 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1763/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8164 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1764/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8239 - val_loss: 0.0583 - val_mse: 0.7873\n",
      "Epoch 1765/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8199 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1766/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8197 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1767/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8189 - val_loss: 0.0582 - val_mse: 0.7907\n",
      "Epoch 1768/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8213 - val_loss: 0.0583 - val_mse: 0.7932\n",
      "Epoch 1769/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8176 - val_loss: 0.0583 - val_mse: 0.7917\n",
      "Epoch 1770/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.0641 - mse: 0.8236\n",
      "Epoch 01770: saving model to Regression_Model/msle.linear-1770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8198 - val_loss: 0.0582 - val_mse: 0.7905\n",
      "Epoch 1771/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8298 - val_loss: 0.0583 - val_mse: 0.7916\n",
      "Epoch 1772/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8160 - val_loss: 0.0582 - val_mse: 0.7923\n",
      "Epoch 1773/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8226 - val_loss: 0.0582 - val_mse: 0.7896\n",
      "Epoch 1774/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8227 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1775/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8181 - val_loss: 0.0583 - val_mse: 0.7929\n",
      "Epoch 1776/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8248 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1777/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8144 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1778/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8303 - val_loss: 0.0582 - val_mse: 0.7913\n",
      "Epoch 1779/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8298 - val_loss: 0.0583 - val_mse: 0.7900\n",
      "Epoch 1780/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0640 - mse: 0.8152\n",
      "Epoch 01780: saving model to Regression_Model/msle.linear-1780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8185 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1781/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8251 - val_loss: 0.0583 - val_mse: 0.7933\n",
      "Epoch 1782/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8282 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1783/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8303 - val_loss: 0.0582 - val_mse: 0.7921\n",
      "Epoch 1784/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8238 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1785/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8164 - val_loss: 0.0582 - val_mse: 0.7921\n",
      "Epoch 1786/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8269 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1787/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8165 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1788/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8251 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1789/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8257 - val_loss: 0.0583 - val_mse: 0.7933\n",
      "Epoch 1790/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.0649 - mse: 0.8254\n",
      "Epoch 01790: saving model to Regression_Model/msle.linear-1790.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8252 - val_loss: 0.0582 - val_mse: 0.7924\n",
      "Epoch 1791/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8156 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1792/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0641 - mse: 0.8177 - val_loss: 0.0583 - val_mse: 0.7920\n",
      "Epoch 1793/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8228 - val_loss: 0.0583 - val_mse: 0.7918\n",
      "Epoch 1794/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0637 - mse: 0.8165 - val_loss: 0.0583 - val_mse: 0.7906\n",
      "Epoch 1795/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8243 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1796/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8184 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1797/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8188 - val_loss: 0.0583 - val_mse: 0.7934\n",
      "Epoch 1798/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8217 - val_loss: 0.0583 - val_mse: 0.7868\n",
      "Epoch 1799/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8175 - val_loss: 0.0582 - val_mse: 0.7911\n",
      "Epoch 1800/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.0635 - mse: 0.8099\n",
      "Epoch 01800: saving model to Regression_Model/msle.linear-1800.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8134 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1801/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8169 - val_loss: 0.0582 - val_mse: 0.7927\n",
      "Epoch 1802/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0664 - mse: 0.8476 - val_loss: 0.0582 - val_mse: 0.7924\n",
      "Epoch 1803/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8164 - val_loss: 0.0583 - val_mse: 0.7919\n",
      "Epoch 1804/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8280 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1805/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8241 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1806/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8214 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1807/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8169 - val_loss: 0.0583 - val_mse: 0.7920\n",
      "Epoch 1808/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8204 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1809/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8140 - val_loss: 0.0583 - val_mse: 0.7883\n",
      "Epoch 1810/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0646 - mse: 0.8293\n",
      "Epoch 01810: saving model to Regression_Model/msle.linear-1810.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8279 - val_loss: 0.0583 - val_mse: 0.7889\n",
      "Epoch 1811/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8311 - val_loss: 0.0582 - val_mse: 0.7895\n",
      "Epoch 1812/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8254 - val_loss: 0.0582 - val_mse: 0.7923\n",
      "Epoch 1813/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8146 - val_loss: 0.0583 - val_mse: 0.7930\n",
      "Epoch 1814/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8164 - val_loss: 0.0582 - val_mse: 0.7921\n",
      "Epoch 1815/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8166 - val_loss: 0.0582 - val_mse: 0.7893\n",
      "Epoch 1816/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8272 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1817/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8198 - val_loss: 0.0582 - val_mse: 0.7926\n",
      "Epoch 1818/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0655 - mse: 0.8312 - val_loss: 0.0583 - val_mse: 0.7920\n",
      "Epoch 1819/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8168 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1820/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.0646 - mse: 0.8265\n",
      "Epoch 01820: saving model to Regression_Model/msle.linear-1820.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8214 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1821/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8245 - val_loss: 0.0582 - val_mse: 0.7914\n",
      "Epoch 1822/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8169 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1823/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8306 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1824/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8182 - val_loss: 0.0582 - val_mse: 0.7913\n",
      "Epoch 1825/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8249 - val_loss: 0.0582 - val_mse: 0.7905\n",
      "Epoch 1826/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8242 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1827/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8168 - val_loss: 0.0582 - val_mse: 0.7904\n",
      "Epoch 1828/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8270 - val_loss: 0.0582 - val_mse: 0.7902\n",
      "Epoch 1829/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8259 - val_loss: 0.0582 - val_mse: 0.7914\n",
      "Epoch 1830/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0642 - mse: 0.8235\n",
      "Epoch 01830: saving model to Regression_Model/msle.linear-1830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8219 - val_loss: 0.0582 - val_mse: 0.7897\n",
      "Epoch 1831/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8237 - val_loss: 0.0582 - val_mse: 0.7914\n",
      "Epoch 1832/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8252 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1833/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8389 - val_loss: 0.0582 - val_mse: 0.7905\n",
      "Epoch 1834/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8222 - val_loss: 0.0582 - val_mse: 0.7913\n",
      "Epoch 1835/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8239 - val_loss: 0.0582 - val_mse: 0.7898\n",
      "Epoch 1836/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8258 - val_loss: 0.0582 - val_mse: 0.7894\n",
      "Epoch 1837/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0646 - mse: 0.8183 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1838/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0645 - mse: 0.8185 - val_loss: 0.0582 - val_mse: 0.7909\n",
      "Epoch 1839/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8165 - val_loss: 0.0582 - val_mse: 0.7914\n",
      "Epoch 1840/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0650 - mse: 0.8248\n",
      "Epoch 01840: saving model to Regression_Model/msle.linear-1840.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8239 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1841/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8279 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1842/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8243 - val_loss: 0.0583 - val_mse: 0.7893\n",
      "Epoch 1843/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8172 - val_loss: 0.0583 - val_mse: 0.7875\n",
      "Epoch 1844/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8236 - val_loss: 0.0583 - val_mse: 0.7929\n",
      "Epoch 1845/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8190 - val_loss: 0.0583 - val_mse: 0.7881\n",
      "Epoch 1846/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8258 - val_loss: 0.0582 - val_mse: 0.7912\n",
      "Epoch 1847/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8199 - val_loss: 0.0583 - val_mse: 0.7891\n",
      "Epoch 1848/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8225 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1849/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8166 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1850/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0647 - mse: 0.8175\n",
      "Epoch 01850: saving model to Regression_Model/msle.linear-1850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8197 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1851/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8245 - val_loss: 0.0582 - val_mse: 0.7921\n",
      "Epoch 1852/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8330 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1853/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8190 - val_loss: 0.0582 - val_mse: 0.7912\n",
      "Epoch 1854/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8267 - val_loss: 0.0582 - val_mse: 0.7921\n",
      "Epoch 1855/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8208 - val_loss: 0.0583 - val_mse: 0.7907\n",
      "Epoch 1856/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8184 - val_loss: 0.0583 - val_mse: 0.7919\n",
      "Epoch 1857/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8222 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1858/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8327 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1859/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8165 - val_loss: 0.0583 - val_mse: 0.7883\n",
      "Epoch 1860/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.0655 - mse: 0.8370\n",
      "Epoch 01860: saving model to Regression_Model/msle.linear-1860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8357 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1861/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8137 - val_loss: 0.0583 - val_mse: 0.7881\n",
      "Epoch 1862/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8244 - val_loss: 0.0583 - val_mse: 0.7898\n",
      "Epoch 1863/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0646 - mse: 0.8253 - val_loss: 0.0583 - val_mse: 0.7908\n",
      "Epoch 1864/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8190 - val_loss: 0.0583 - val_mse: 0.7905\n",
      "Epoch 1865/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8229 - val_loss: 0.0583 - val_mse: 0.7919\n",
      "Epoch 1866/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0635 - mse: 0.8117 - val_loss: 0.0582 - val_mse: 0.7925\n",
      "Epoch 1867/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8239 - val_loss: 0.0583 - val_mse: 0.7909\n",
      "Epoch 1868/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8142 - val_loss: 0.0583 - val_mse: 0.7872\n",
      "Epoch 1869/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8269 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1870/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0644 - mse: 0.8196\n",
      "Epoch 01870: saving model to Regression_Model/msle.linear-1870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8195 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1871/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8233 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1872/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8171 - val_loss: 0.0583 - val_mse: 0.7912\n",
      "Epoch 1873/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8453 - val_loss: 0.0583 - val_mse: 0.7906\n",
      "Epoch 1874/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0654 - mse: 0.8222 - val_loss: 0.0583 - val_mse: 0.7920\n",
      "Epoch 1875/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8260 - val_loss: 0.0583 - val_mse: 0.7927\n",
      "Epoch 1876/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8244 - val_loss: 0.0583 - val_mse: 0.7909\n",
      "Epoch 1877/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0658 - mse: 0.8332 - val_loss: 0.0583 - val_mse: 0.7919\n",
      "Epoch 1878/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8252 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1879/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8360 - val_loss: 0.0583 - val_mse: 0.7913\n",
      "Epoch 1880/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0648 - mse: 0.8157\n",
      "Epoch 01880: saving model to Regression_Model/msle.linear-1880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8191 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1881/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8191 - val_loss: 0.0583 - val_mse: 0.7927\n",
      "Epoch 1882/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8230 - val_loss: 0.0583 - val_mse: 0.7913\n",
      "Epoch 1883/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8171 - val_loss: 0.0583 - val_mse: 0.7931\n",
      "Epoch 1884/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8175 - val_loss: 0.0583 - val_mse: 0.7927\n",
      "Epoch 1885/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8225 - val_loss: 0.0583 - val_mse: 0.7917\n",
      "Epoch 1886/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8238 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1887/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8220 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1888/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0646 - mse: 0.8212 - val_loss: 0.0583 - val_mse: 0.7920\n",
      "Epoch 1889/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8190 - val_loss: 0.0583 - val_mse: 0.7917\n",
      "Epoch 1890/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8215\n",
      "Epoch 01890: saving model to Regression_Model/msle.linear-1890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8225 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1891/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8246 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1892/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8174 - val_loss: 0.0583 - val_mse: 0.7927\n",
      "Epoch 1893/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8237 - val_loss: 0.0583 - val_mse: 0.7936\n",
      "Epoch 1894/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8194 - val_loss: 0.0583 - val_mse: 0.7905\n",
      "Epoch 1895/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8210 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1896/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8191 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1897/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8165 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1898/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8202 - val_loss: 0.0583 - val_mse: 0.7916\n",
      "Epoch 1899/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8320 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1900/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0660 - mse: 0.8234\n",
      "Epoch 01900: saving model to Regression_Model/msle.linear-1900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0656 - mse: 0.8234 - val_loss: 0.0583 - val_mse: 0.7918\n",
      "Epoch 1901/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8187 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1902/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8193 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1903/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0645 - mse: 0.8323 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1904/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8205 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1905/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8236 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1906/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8337 - val_loss: 0.0583 - val_mse: 0.7928\n",
      "Epoch 1907/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8208 - val_loss: 0.0582 - val_mse: 0.7913\n",
      "Epoch 1908/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8174 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1909/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8170 - val_loss: 0.0583 - val_mse: 0.7902\n",
      "Epoch 1910/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.0642 - mse: 0.8226\n",
      "Epoch 01910: saving model to Regression_Model/msle.linear-1910.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8225 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1911/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8196 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1912/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8166 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1913/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8266 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1914/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8139 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1915/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8236 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1916/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8253 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1917/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8169 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1918/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8191 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1919/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0659 - mse: 0.8395 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1920/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.0651 - mse: 0.8254\n",
      "Epoch 01920: saving model to Regression_Model/msle.linear-1920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8249 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1921/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0634 - mse: 0.8135 - val_loss: 0.0583 - val_mse: 0.7929\n",
      "Epoch 1922/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8240 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1923/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8162 - val_loss: 0.0582 - val_mse: 0.7921\n",
      "Epoch 1924/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8238 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1925/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8281 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1926/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8180 - val_loss: 0.0582 - val_mse: 0.7911\n",
      "Epoch 1927/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8295 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1928/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8302 - val_loss: 0.0582 - val_mse: 0.7905\n",
      "Epoch 1929/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8227 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1930/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.0652 - mse: 0.8262\n",
      "Epoch 01930: saving model to Regression_Model/msle.linear-1930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8250 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1931/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0639 - mse: 0.8145 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1932/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8163 - val_loss: 0.0582 - val_mse: 0.7921\n",
      "Epoch 1933/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8226 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1934/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8178 - val_loss: 0.0583 - val_mse: 0.7920\n",
      "Epoch 1935/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8170 - val_loss: 0.0582 - val_mse: 0.7913\n",
      "Epoch 1936/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8240 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 1937/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8206 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1938/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0644 - mse: 0.8159 - val_loss: 0.0582 - val_mse: 0.7911\n",
      "Epoch 1939/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8167 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1940/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0643 - mse: 0.8181\n",
      "Epoch 01940: saving model to Regression_Model/msle.linear-1940.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0643 - mse: 0.8172 - val_loss: 0.0583 - val_mse: 0.7905\n",
      "Epoch 1941/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8245 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1942/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8211 - val_loss: 0.0583 - val_mse: 0.7925\n",
      "Epoch 1943/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8213 - val_loss: 0.0582 - val_mse: 0.7905\n",
      "Epoch 1944/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8158 - val_loss: 0.0582 - val_mse: 0.7912\n",
      "Epoch 1945/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0648 - mse: 0.8197 - val_loss: 0.0582 - val_mse: 0.7903\n",
      "Epoch 1946/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8090 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1947/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8277 - val_loss: 0.0583 - val_mse: 0.7922\n",
      "Epoch 1948/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8188 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1949/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8214 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1950/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.0643 - mse: 0.8201\n",
      "Epoch 01950: saving model to Regression_Model/msle.linear-1950.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8194 - val_loss: 0.0582 - val_mse: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1951/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8230 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1952/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8205 - val_loss: 0.0582 - val_mse: 0.7896\n",
      "Epoch 1953/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8174 - val_loss: 0.0582 - val_mse: 0.7901\n",
      "Epoch 1954/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8204 - val_loss: 0.0583 - val_mse: 0.7875\n",
      "Epoch 1955/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8256 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1956/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8203 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1957/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0637 - mse: 0.8169 - val_loss: 0.0582 - val_mse: 0.7909\n",
      "Epoch 1958/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0638 - mse: 0.8149 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1959/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8209 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1960/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.0651 - mse: 0.8339\n",
      "Epoch 01960: saving model to Regression_Model/msle.linear-1960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8342 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1961/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8225 - val_loss: 0.0582 - val_mse: 0.7914\n",
      "Epoch 1962/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8165 - val_loss: 0.0583 - val_mse: 0.7879\n",
      "Epoch 1963/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0640 - mse: 0.8133 - val_loss: 0.0582 - val_mse: 0.7907\n",
      "Epoch 1964/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8327 - val_loss: 0.0582 - val_mse: 0.7912\n",
      "Epoch 1965/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0637 - mse: 0.8163 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1966/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8233 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1967/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8200 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1968/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0650 - mse: 0.8275 - val_loss: 0.0582 - val_mse: 0.7911\n",
      "Epoch 1969/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0643 - mse: 0.8183 - val_loss: 0.0582 - val_mse: 0.7911\n",
      "Epoch 1970/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.0645 - mse: 0.8130\n",
      "Epoch 01970: saving model to Regression_Model/msle.linear-1970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8163 - val_loss: 0.0582 - val_mse: 0.7911\n",
      "Epoch 1971/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8192 - val_loss: 0.0582 - val_mse: 0.7921\n",
      "Epoch 1972/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8224 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1973/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8248 - val_loss: 0.0582 - val_mse: 0.7913\n",
      "Epoch 1974/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8206 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1975/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0657 - mse: 0.8327 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1976/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0653 - mse: 0.8228 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1977/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8261 - val_loss: 0.0582 - val_mse: 0.7909\n",
      "Epoch 1978/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0646 - mse: 0.8242 - val_loss: 0.0582 - val_mse: 0.7913\n",
      "Epoch 1979/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0648 - mse: 0.8230 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1980/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.0645 - mse: 0.8142\n",
      "Epoch 01980: saving model to Regression_Model/msle.linear-1980.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.0642 - mse: 0.8126 - val_loss: 0.0582 - val_mse: 0.7920\n",
      "Epoch 1981/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8151 - val_loss: 0.0582 - val_mse: 0.7908\n",
      "Epoch 1982/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0650 - mse: 0.8208 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1983/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8258 - val_loss: 0.0583 - val_mse: 0.7921\n",
      "Epoch 1984/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8141 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1985/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8281 - val_loss: 0.0582 - val_mse: 0.7917\n",
      "Epoch 1986/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0647 - mse: 0.8189 - val_loss: 0.0582 - val_mse: 0.7913\n",
      "Epoch 1987/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0649 - mse: 0.8197 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1988/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8297 - val_loss: 0.0582 - val_mse: 0.7916\n",
      "Epoch 1989/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0651 - mse: 0.8253 - val_loss: 0.0583 - val_mse: 0.7923\n",
      "Epoch 1990/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.0643 - mse: 0.8243\n",
      "Epoch 01990: saving model to Regression_Model/msle.linear-1990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0641 - mse: 0.8215 - val_loss: 0.0582 - val_mse: 0.7904\n",
      "Epoch 1991/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0640 - mse: 0.8155 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1992/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0651 - mse: 0.8219 - val_loss: 0.0582 - val_mse: 0.7918\n",
      "Epoch 1993/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8215 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1994/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8199 - val_loss: 0.0582 - val_mse: 0.7915\n",
      "Epoch 1995/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0645 - mse: 0.8333 - val_loss: 0.0582 - val_mse: 0.7919\n",
      "Epoch 1996/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8216 - val_loss: 0.0582 - val_mse: 0.7922\n",
      "Epoch 1997/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0642 - mse: 0.8310 - val_loss: 0.0582 - val_mse: 0.7909\n",
      "Epoch 1998/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.0649 - mse: 0.8246 - val_loss: 0.0583 - val_mse: 0.7926\n",
      "Epoch 1999/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0647 - mse: 0.8207 - val_loss: 0.0583 - val_mse: 0.7924\n",
      "Epoch 2000/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.0653 - mse: 0.8341\n",
      "Epoch 02000: saving model to Regression_Model/msle.linear-2000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.0652 - mse: 0.8297 - val_loss: 0.0582 - val_mse: 0.7914\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=2000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "mse\n",
      "val_loss\n",
      "val_mse\n"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd9555ea828>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-0370.ckpt'\n",
    "    #MODEL_PATH  = 'Regression_Model/mle.linear-1500.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "testid='bl6.mle.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([492.], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
