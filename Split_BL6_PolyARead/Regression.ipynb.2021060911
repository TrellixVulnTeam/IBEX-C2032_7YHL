{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 14753\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.predict.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    #train_data  = train_data/300\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    #valid_data  = valid_data/300\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.47435 2.5292199\n",
      "5.729239 1.606415\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb1e28d748>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXzcdZ3H8ddnZnK0SXqkSdr0oE0PoOVogVhbbmxBW8GCBwusUF0UUUFR1wUX3WVddVkeiru6LFgVKcqhIkdtqxwVBZZypFDaQig96B3a9L7SnJ/9Y35JJyFHk5l2MjPv5+Mxj/x+v/n9Zr7fpjPvfI/f72fujoiIZK5QsgsgIiLJpSAQEclwCgIRkQynIBARyXAKAhGRDBdJdgF6oqioyEeNGpXsYoiIpJQlS5Zsd/fitttTMghGjRpFRUVFsoshIpJSzGx9e9vVNSQikuEUBCIiGU5BICKS4RQEIiIZTkEgIpLhFAQiIhlOQSAikuEUBEmyY38tTyzdnLDXq29s4sGXN1DX0JSw1+yt1u84wLNvb0t2MUTSRkqeUJbK3J1HX9vMN37/BgDnjitmYF52h/tX7alhwbIq/v6DI+mTHe5wv7kvruN7CyppaGrimqmjEl3sXuWSn77A3kMNAJw4pIAHPz+Fwk7+DUWkcxnVIrht3ptM+u5TrN62Pynv//jrmyn71sKWEADYebCuZXlR5Vaq99W2Oub2P73N9xZU8tRb7/H7io1Mv/NvHKpvfN9rv7llLwDrdxw8SqXvHWobGtl7qIHcrBAfPmkwb7+3L6EtK5FMlFEtgvJRA7nvxXU8/vpm/vHDJxzz9//jG1soKcjhxmnjGNo/l2vnVrDrQB0Uw7a9h7h2bgVlRXk8+4/nAzDtR39lTfUBAL768NKW1znxO39mYN8swqEQF59ayvjSAh57Pfpl+MsX3mXaiSWcObbomNfvWGgOvDsvn8SMk4dwwrf/zHt7DiW5VCKpLaNaBBefOpSxJfms3LovYa+5eXcNOw/Udb0jsKZ6P5PLCrl6ykiKC3IAWLF5Dxf/9Hkm/2ARAO9uP0Bjkwf7R0PgunNHY9b6tS4+dSgHahu478V13PyH5QAM6ZdLOGRc9YuXGXXLAh58eUMiqphUS9bvYvGaHTTfUvW19bsA+MCoQsyMwf1z+Pnza9EtV0V6LqNaBADHFfZl866ahL3eWbf/BYBzxhWREwlRlJ/DDy47hVCo9Td3Y5OzeXcNHzm5FIBxJQUMysvm9j+/zaH61gO8W/ceauki+uL5Y7j5Iydy0YTB3PfiOuYvqwLg3y89mVs/Op6dB+rYuPMgfzfnJa4/bzSHGpq4/U9vA/DPjy3nqg8el7C6Hmv3L17HvzzxJgDjSvK5ZcaJvLv9AP1yIxTlR8cEThsxkI07a9i4s4bjBvVNYmlFUlfGBUFJQQ7LN+8B4FB9IzmRENb2z+0j1PyXO8Dzq7a3LF8ycShntemaWfnePuobneMH5wPQJzvMbR87iV8vXk9ZUR7fmnkiL7+7ky/8egmbdtXwwMvRiwQW5UdbDuWjCikfVcj8ZQsY2j8XgNysMEMH9GHogD68eut0CvOyqdpTw0trd1CxbhcFuan963086O46c8wgXlyzg2vnRq84O7oor+V39vlzRjPvjS2s2LJHQSDSQ6n9TdEDxQU57Nhfy08WreLOp9/h7LFF/OZzH+zRa1XtibYsfnDZKZwxciCVVXu56bdLeeXdne8Lgne3R7t5Jgzt17LtkolDuWTi0Jb1k4f1B6Cyai9D+kW/7K+ZOrLV6/ztm+fTv09Wu/UCGD6wL/d9djLfeXwF85dt6VG9eoP1Ow7w2obdXF4+nDs+OZG339vL1377BpVVe1kb/FsCjCnJA+BLD7zGrTPH85e3t7G7pp6FXzm7xwEvkmkyaowAol+YTQ53Pv0OAC+s3s76HQe6OKq1zbtr2LjzIBuCGTqjBvXlhCEFXHraMIoLcti69/2DlzXBTJ++WR1n79D+uZT2z6Vi/S52HKijtH8uWeHWv6KRg/IY0LfrqZK5WSFqe/k5BRt3HuRQfSOrt+1n+/7Ws6VeWB1tYU0fPxiAE4f0Y/6NZwPwjQuPb9mvb3aEa88uA+D7CytZvHYHlVV7eWLplnZnV4nI+2Vci6Ak+MsZYHxpPyqr9vLs29v4zFllHR7j7tQ2NLF0427mvbGFx17b3PLFDlBWnNeyXNg3u9Xg8d5D9fzHwrepb4x+Kedmd5y9ZsbkskKeWLqFovxshgRdQD2REwn36iDYtu8Q59zxbEu3z4jCPjz3zQta/oq/9bEVAEwuK2w5Jhwy1t3+0fe91ncunsA3LjqeSd99uuWEupt+u5TPbhrFv15y0jGojUhqy7wg6Hf4y/U/Pn4KNz+yjLv+uobZZ45qtyuhtqGRS+96kcqqve2+3unHDaC0f5+W9YF5Wa3GC/5v1XYeeuXw7J3crI5PCgP4h7PKeGLpFrbvr+PCCUOOuF5t5URCNDY5DY1NRMK9q+H3o6dW8tO/rAbgxTU7ANi4s4Y9NfU8u3IbW/cebh201w3Wnr7ZEX5xTTm/fXUjN04by5d+8xqLg9cWkc5lXBBMHD6A7116MmeNLaKsKI9xg/OZv6yKyqp9VO2pYeHy9/jBx08mJxL9wn7w5Q1UVu3ljJED+cCoQu7525qW1youyOHHfzep1esP7pdLTf1O5r64jtlnjmrVnw2QG+k8CCaOGMDD101h6cbdrcYPuqs5cA41NJHfi4LA3XnolY0t61/50FieX72d1zfsZtJ3n27ZHgkZC75yTrf6+c89vphzj4/ejvXMsYP4zUsbaGxywiGNFYh0JuOCIBwyPj3l8ADstWeXMX9ZFVV7alpmpWzbd4hfXxsdQK5Yv4uSghweuX4qZsah+kaOK+zL1VNHvq//HqIDx08s3cKLa7YzdcwgfrJoFSMK+7BxZ3RgOSvc9ZfSlNGDmDJ6UFz1zI5Ey1a9r5b8nI5/zSs27+Gtqr186ozhx2Rw9bP3vcr2/bUM7Z/LJZOG8vWLTmDs4AJe3/B6yz7PfP1cSvrl0i/3yFoD7RkxMDqD6O9+tpjfB787EWlf7/lTMUma++Gr9hxq+ZJe+d7hE87WbT/A+NJ+LV8kt33sJP7h7LJ2QwAgLydC+ciB7DvUwDcfWUZtQxP/eNHhs5iP1RfSlt3R4PnhUys5WNfAhh0HW/rP3Z0tu2tYW72fi3/6Av/0yDIqghO1jpbKqr185lev8NeV1QA8/uWz+NaM8QBMGj4AiI4H9O+TxZji/LhCAOCqDx7H4H45VKzfxTtbk3NJEZFUkZAWgZl9BPhvIAz8wt1vb/P83wM3B6v7gS+6+xvBc+uAfUAj0ODu5Yko05Eqys/BDN7csof6Rqe4IIdt+2qpqWskHDJWbdvP1G7+dV6QG+HZ4Avvxg+NZdakYa0uEXEsXHPmKH723FryssN84u7FLWMc3/7oeF7bsIuFy99rtf//PruaOy+f1OkF8HpqwbIqfvbcGpZtip6/cc64olZjNccN6tvuIHA8CnKzuOuq0/nkPYup2lPDCUMKEvr6Iukk7iAwszBwF3AhsAl41czmuftbMbu9C5zn7rvMbAYwB4idvH+Bu28nCbLC0bOBm1sBE4cP4JnKrWzcdZCQGXUNTa3m/h+J5itjApx/QrTPesFXzm51AtrRNmxAH8pHDuR3FZtabf/egspW6+eMK+L5Vdt5dmU1X3xgCQ9fNzWh5ajeV8uXH3yt1bbrzxuT0PfoyOAgbHQtIpHOJaJraDKw2t3Xunsd8DAwK3YHd3/R3Zv7Hl4ChifgfRNmcL8cVgXdBycFX/obdhxk277oF8iQft2bxtn8hX/vZ8o5Y2Rh8Lr9OTXoAjlWbpw2jn7B2cUXTRjMlZNH8MNPTWy1z+ypo8gOurleWruThmCa64trtvPCqvizecPO1oPl08eXcMrw/nG/7pEo7Z9LUX42z69Oyt8YIikjEV1Dw4CNMeubaP3XflvXAn+KWXfgKTNz4GfuPicBZeqWcSUFrNgc7ToZHZwTsONALQfqojNvSvrldHhse+76+9PZsOMgU8fEN+Abr/OOL+aNf72IhcvfY9r4EnKzwtQ2NFJT18C4wQVU76tl2vgS7r92Mv9w36scrGvk+dXbGVucz1U/fxmA+Tee3XLGc3dt3HmQbz26vGX9c2eX8e2LJySkbkciEg4xZfQg5i+r4oYL9jK+tHstO5FMkYgWQXujn+32gZjZBUSD4OaYzWe5++nADODLZnZuB8deZ2YVZlZRXV0db5lbOWPkwJblEYXR2SYPvbKxpV9/2IDuXcNm2IA+SQ+BZmbGR08tbZlOmhMJc/XUUUwZPYhLJg7FzJgyehALvnIOADv217Ej5oS4v67c1uMrez6xdDPvbN3Ph04s4Zmvn8fNM06Mv0LdNCO4yF/ztZtE5P0SEQSbgBEx68OB913kxsxOBX4BzHL3ljN93H1L8HMb8BjRrqb3cfc57l7u7uXFxcUJKPZhl542rGV52IA+RELG0o27AZhQ2q/TO4OliwHBiVt/WLKJNTE37vnhU+/wP8HJX82Wb9rD029tpbah80s4VO+rpSA3wr2f+QBjS/I7nGl1NH301FJOGtqPv72T2D8eRNJJIj6ZrwLjzKzMzLKBK4B5sTuY2XHAo8DV7v5OzPY8MytoXgYuAlYkoEzdkp8T4W/fPJ85V5/B4H65jAyuYnnxqaXcf227uZR2mq9UunjtjlZ3UANYFlytdffBOv7tj29yyf+8wOfvr+DPK9573+tA9DyM2//0NnMXr6c4v3vdakfD0AHR8zju/uuarncWyUBxjxG4e4OZ3QA8SXT66L3u/qaZXR88fw/wL8Ag4H+DefTN00QHA48F2yLAg+7+53jL1BMjB+UxclB0fODRL53F9v21lA3Ke999BdJVe5ehmDK6kJfW7my5uN78ZVX86v/WtTy/Y3/7N+S59r6Klkt9D+7mQPvR8N1ZJ/H0W1v58TPvcP15o3VymUgbCWmru/tCdz/e3ce4+/eDbfcEIYC7f87dB7r7pOBRHmxf6+4Tg8dJzccmW/NJTZkSAs1umj6u1U3gf3rl6Vx7dhnrdhzgV//3Lt9+fAV52WFWfX8GAPsONTD73lc49bYnefqtrUD0ZLzlm/dwyrD+TDuxhK9OH5eUusQq7d+H71w8gbqGJvbU1Ce7OCK9TsZdYkI6dtP04zlU38Q9f1vDsAF9KMrPZkxxPrUNTfzbH6OnhfzHJ04lKxyiT1aY3TV1LX3vn7+/gt99YSo/fHIlAD+/pjyuq6cm2rAB0bK8/O5OPnxSzy/mJ5KOFATSynXnjmZsST4nD4teVuOy04bRNztMXWMTk0YM4PjB0TN0C3IjLTfbafaDhZXU1DUyorBPrwoBgMll0VlcNz70Ostvu6jlooIiomsNSRuFedl88ozhnDgkOue+T3aYS08bxuXlI1pCAKJXXm2+btBPrjyNovxslm7czdrt+5lS1jumzsYqzMvmC+eOpq6hidvmvZns4oj0KgoC6ZHmS2dA9Kzl7192CgD1jU6/I7yHwLF2y4wTKciJ8PjrunuZSCwFgfTIJ04fzsnD+nHfZz9AblaY0piuoHivHHq0mBk/veo0auob+cmiVckujkivoSCQHhldnM/8G8/h/BNKAFp1G505tvd1DTU7c0wRfbPD/HHZlh6fMS2SbhQEkhC5WWEe/NwHuXXmeD4wqrDrA5IkOxLin2eOZ+POGtZUH+j6AJEMoFlDkjBnji3izLFFyS5Gl5qvLfX2e3sZW5Kf5NKIJJ9aBJJxmi8hcsODr2vQWAQFgWSgvtkRPh5caPDqX76c5NKIJJ+CQDLSf37yVLIjId4Ibp8pkskUBJKRssIhvjb9eOoamjhQ29D1ASJpTEEgGasoP3qBvS/8egk3P7KMuoamJJdIJDkUBJKxJpcVcsbIgWzZU8NvKzayZP2urg8SSUMKAslYIwfl8YcvnsnvvzAVgLeq9ia5RCLJoSCQjFeYl01uVogl63cmuygiSaEgkIxnZuRlR/hTB7feFEl3CgIR4KKThuAOTU26/pBkHgWBCDC6KHq/6gN1mkoqmSchQWBmHzGzlWa22sxuaed5M7OfBM8vM7PTj/RYkWMhPzd62a39OqdAMlDcQWBmYeAuYAYwAbjSzCa02W0GMC54XAfc3Y1jRY66/JxoEOw+qJvbS+ZJRItgMrDa3de6ex3wMDCrzT6zgPs96iVggJmVHuGxIkddUX4OAH98Y0uSSyJy7CUiCIYBG2PWNwXbjmSfIzlW5Kj7YFn0HgoaK5ZMlIggsHa2tf04dbTPkRwbfQGz68yswswqqquru1lEkc6FQkb/Plm6LLVkpEQEwSZgRMz6cKBt+7qjfY7kWADcfY67l7t7eXFxcXu7iMSlT1aYmjoFgWSeRATBq8A4Myszs2zgCmBem33mAdcEs4emAHvcveoIjxU5Jvpkh6lRi0AyUNy3qnT3BjO7AXgSCAP3uvubZnZ98Pw9wEJgJrAaOAh8trNj4y2TSE/kZoXVNSQZKSH3LHb3hUS/7GO33ROz7MCXj/RYkWTIzQqpRSAZSWcWiwT6Zod5ftV23ZdAMo6CQCRwyrABANy/eB3z3tjC6m37k1sgkWNEQSASuHLyCMzgewsq+cpDr/OlB5Yku0gix4SCQCQwclAeL31rGs98/TyumTqSd7bu57+eeSfZxRI56hQEIjEG98tlbEk+nzh9OAD/9cwq6hs1ZiDpTUEg0o6JIwZw5+UTAVi/42CSSyNydCkIRDowpjgfgDXVGjSW9KYgEOlAWXH0ZjXrth9IcklEji4FgUgHCnIimMEB3axG0pyCQKQDZkZOJMQhnWAmaU5BINIJXX9IMoGCQKQTuREFgaQ/BYFIJ3KzQhyqV9eQpDcFgUgn1DUkmUBBINKJnKywBosl7SkIRDqRGwmpRSBpT0Eg0oncrDC1CgJJcwoCkU5osFgygYJApBO5WWEONahFIOktriAws0Ize9rMVgU/B7azzwgze9bMKs3sTTP7asxzt5nZZjNbGjxmxlMekUTTeQSSCeJtEdwCLHL3ccCiYL2tBuAb7j4emAJ82cwmxDz/Y3efFDx0E3vpVdQ1JJkg3iCYBcwNlucCl7bdwd2r3P21YHkfUAkMi/N9RY6JHJ1HIBkg3iAY7O5VEP3CB0o629nMRgGnAS/HbL7BzJaZ2b3tdS3FHHudmVWYWUV1dXWcxRY5MrmRELUNTbh7sosictR0GQRm9oyZrWjnMas7b2Rm+cAfgJvcfW+w+W5gDDAJqAJ+1NHx7j7H3cvdvby4uLg7by3SYzlZYQBqdVKZpLFIVzu4+/SOnjOzrWZW6u5VZlYKbOtgvyyiIfCAuz8a89pbY/b5OTC/O4UXOdpym4OgvqllWSTdxNs1NA+YHSzPBp5ou4OZGfBLoNLd72zzXGnM6mXAijjLI5JQuVnRj4imkEo6izcIbgcuNLNVwIXBOmY21MyaZwCdBVwNfKidaaJ3mNlyM1sGXAB8Lc7yiCRUbiTaCtCAsaSzLruGOuPuO4Bp7WzfAswMll8ArIPjr47n/UWOtubuIE0hlXSmM4tFOtHSNaQWgaQxBYFIJw63CBQEkr4UBCKdODxYrK4hSV8KApFO5ESap4+qRSDpS0Eg0olIODrPoaFJZxZL+lIQiHQiEop+ROob1TUk6UtBINKJrOYWQaNaBJK+FAQinYiEox+RRnUNSRpTEIh0IhKKtgjqm9Q1JOlLQSDSieYgUNeQpDMFgUgnmruGNFgs6UxBINKJ5sFijRFIOlMQiHSiefqoziOQdKYgEOlEy2CxuoYkjSkIRDoRChkh02CxpDcFgUgXIuGQuoYkrSkIRLqQFTIa1DUkaSyuO5SJZIJwyKhYv4v/fmZVq+1FBdlcNfk4orflFkldCgKRLpwwpIBX1+1i6cbd73vu3HHFjCjsm4RSiSROXEFgZoXAb4FRwDrgcnff1c5+64B9QCPQ4O7l3TleJJl+94WpeJshgqfeeo/rf/Maew/VJ6dQIgkU7xjBLcAidx8HLArWO3KBu09qDoEeHC+SFGYWnT0U8+iXmwXAvkMNSS6dSPziDYJZwNxgeS5w6TE+XiQp8nOjjen9CgJJA/EGwWB3rwIIfpZ0sJ8DT5nZEjO7rgfHY2bXmVmFmVVUV1fHWWyR+BQELYL9tQoCSX1djhGY2TPAkHaeurUb73OWu28xsxLgaTN7292f68bxuPscYA5AeXm5JnVLUuXnRD86+zRGIGmgyyBw9+kdPWdmW82s1N2rzKwU2NbBa2wJfm4zs8eAycBzwBEdL9LbFARdQ/vUIpA0EG/X0DxgdrA8G3ii7Q5mlmdmBc3LwEXAiiM9XqQ3yomEyAqbBoslLcQbBLcDF5rZKuDCYB0zG2pmC4N9BgMvmNkbwCvAAnf/c2fHi/R2ZkZ+TkSDxZIW4jqPwN13ANPa2b4FmBksrwUmdud4kVSQnxth4fIq/v3Sk5NdFJG46FpDIj3U1AR7ajRYLKlPQSDSQ7MmDU12EUQSQkEg0kNZweWpve31J0RSjIJApIea72dcr5vWSIpTEIj0UFa4+X7GuleBpDYFgUgPRYIgqG9Qi0BSm4JApIeyg66hOt29TFKcgkCkh9Q1JOlCQSDSQ+oaknShIBDpoZZZQ2oRSIpTEIj0UHPXUL3GCCTFKQhEeqhljEDnEUiKUxCI9FB2JPrxeW6V7pgnqU1BINJD5SMHAlBT15jkkojER0Eg0kN5ORGyg+sNiaQyBYFIHMIho1FBIClOQSASh0jINFgsKU9BIBKHcNho1HkEkuIUBCJxiIRMYwSS8uIKAjMrNLOnzWxV8HNgO/ucYGZLYx57zeym4LnbzGxzzHMz4ymPyLGmMQJJB/G2CG4BFrn7OGBRsN6Ku69090nuPgk4AzgIPBazy4+bn3f3hXGWR+SYioQ0a0hSX7xBMAuYGyzPBS7tYv9pwBp3Xx/n+4r0CmoRSDqINwgGu3sVQPCzpIv9rwAearPtBjNbZmb3tte11MzMrjOzCjOrqK7WmZzSO2iMQNJBl0FgZs+Y2Yp2HrO680Zmlg18DPh9zOa7gTHAJKAK+FFHx7v7HHcvd/fy4uLi7ry1yFETbRFo1pCktkhXO7j79I6eM7OtZlbq7lVmVgps6+SlZgCvufvWmNduWTaznwPzj6zYIr1DWOcRSBqIt2toHjA7WJ4NPNHJvlfSplsoCI9mlwEr4iyPyDEVCWuMQFJfvEFwO3Chma0CLgzWMbOhZtYyA8jM+gbPP9rm+DvMbLmZLQMuAL4WZ3lEjqmwZg1JGuiya6gz7r6D6Eygttu3ADNj1g8Cg9rZ7+p43l8k2SKaNSRpQGcWi8QhHDLdvF5SnoJAJA6RkFHboCCQ1KYgEIlDkzuvb9hNncJAUpiCQCQOZUV5ABysa0hySUR6TkEgEocJQ/sDUNeoFoGkLgWBSByywwagk8okpSkIROIQCUU/QvVqEUgKUxCIxCEroiCQ1KcgEIlDc9dQvbqGJIUpCETioK4hSQcKApE4HO4aUotAUpeCQCQOWaHmriG1CCR1KQhE4qDBYkkHCgKROGSFox8hnUcgqUxBIBKHSNA1tHjtDt7YuDvJpRHpGQWBSBwG5WdjBnOeW8sVc15KdnFEekRBIBKH0v59WHzLND495Thq6huTXRyRHlEQiMRpSP9cBuXlAOCusQJJPQoCkQQIWXSsQDkgqSiuIDCzT5nZm2bWZGblnez3ETNbaWarzeyWmO2FZva0ma0Kfg6MpzwiyRLkAE1KAklB8bYIVgAfB57raAczCwN3ATOACcCVZjYhePoWYJG7jwMWBesiKSeYPIRiQFJRXEHg7pXuvrKL3SYDq919rbvXAQ8Ds4LnZgFzg+W5wKXxlEckWSxoEqhFIKnoWIwRDAM2xqxvCrYBDHb3KoDgZ0lHL2Jm15lZhZlVVFdXH7XCivREc9eQckBSUaSrHczsGWBIO0/d6u5PHMF7WDvbuv1xcfc5wByA8vJyfdykVzE0WCypq8sgcPfpcb7HJmBEzPpwYEuwvNXMSt29ysxKgW1xvpdIUrS0CDRKICnoWHQNvQqMM7MyM8sGrgDmBc/NA2YHy7OBI2lhiPQ6oZZZQ8kth0hPxDt99DIz2wRMBRaY2ZPB9qFmthDA3RuAG4AngUrgd+7+ZvAStwMXmtkq4MJgXSTlHO4aUhJI6umya6gz7v4Y8Fg727cAM2PWFwIL29lvBzAtnjKI9Aam6aOSwnRmsUgCNE8fdd2WQFKQgkAkAUIaLJYUpiAQSYDmOdIaLJZUpCAQSYBQSIPFkroUBCIJoBaBpDIFgUgCtAwWa4xAUpCCQCQBdK0hSWUKApEE0I1pJJUpCEQS4PAYgZJAUo+CQCQBWloESS6HSE8oCEQSofmic5o2JClIQSCSAO3ddEMkVSgIRBIgpFtVSgpTEIgkgKaPSipTEIgkgAaLJZUpCEQSwFruUKYokNSjIBBJANMJZZLCFAQiCdA8a0hXH5VUpCAQSQCNEUgqi/fm9Z8yszfNrMnMyjvYZ4SZPWtmlcG+X4157jYz22xmS4PHzPZeQ6S30xiBpLK4bl4PrAA+Dvysk30agG+4+2tmVgAsMbOn3f2t4Pkfu/sP4yyHSFKFNH1UUlhcQeDulXB4oKyDfaqAqmB5n5lVAsOAtzo8SCTl6IQySV3HdIzAzEYBpwEvx2y+wcyWmdm9Zjawk2OvM7MKM6uorq4+yiUV6R61CCSVdRkEZvaMma1o5zGrO29kZvnAH4Cb3H1vsPluYAwwiWir4UcdHe/uc9y93N3Li4uLu/PWIkedpo9KKuuya8jdp8f7JmaWRTQEHnD3R2Nee2vMPj8H5sf7XiLJ0DJ9VPOGJAUd9a4hi/6p9Eug0t3vbPNcaczqZUQHn0VSTij4JOkq1JKK4p0+epmZbQKmAgvM7Mlg+1AzWxjsdhZwNfChdqaJ3mFmy81sGXAB8LV4yiOSLEZz15CSQFJPvLOGHgMea2f7FmBmsPwCHVyu3d2vjuf9RXqLw+cRJLccIj2hM4tFEuDwFGolgaQeBYFIAmj6qKQyBYFIAljLCWVJLohID+Sw7H4AAASvSURBVCgIRBLgcItASSCpR0EgkggaLJYUpiAQSYDDl6FWEkjqURCIJMDhG9MktRgiPRLvZahFBAgFgwT/9Mgy+maHk1waSWc/+PgpfGBUYUJfU0EgkgATSvtxeflw9tc2JLsokub6ZCX+Dw0FgUgC5OVEuOOTE5NdDJEe0RiBiEiGUxCIiGQ4BYGISIZTEIiIZDgFgYhIhlMQiIhkOAWBiEiGUxCIiGQ4S8XL5ppZNbC+h4cXAdsTWJzeJp3rp7qlrnSuXyrVbaS7F7fdmJJBEA8zq3D38mSX42hJ5/qpbqkrneuXDnVT15CISIZTEIiIZLhMDII5yS7AUZbO9VPdUlc61y/l65ZxYwQiItJaJrYIREQkhoJARCTDZVQQmNlHzGylma02s1uSXZ7uMrMRZvasmVWa2Ztm9tVge6GZPW1mq4KfA2OO+VZQ35Vm9uHklf7ImFnYzF43s/nBelrUzcwGmNkjZvZ28Pubmi51AzCzrwX/J1eY2UNmlpuq9TOze81sm5mtiNnW7bqY2Rlmtjx47idmZm3fq9dw94x4AGFgDTAayAbeACYku1zdrEMpcHqwXAC8A0wA7gBuCbbfAvxnsDwhqGcOUBbUP5zsenRRx68DDwLzg/W0qBswF/hcsJwNDEijug0D3gX6BOu/Az6TqvUDzgVOB1bEbOt2XYBXgKmAAX8CZiS7bh09MqlFMBlY7e5r3b0OeBiYleQydYu7V7n7a8HyPqCS6IdwFtEvGoKflwbLs4CH3b3W3d8FVhP9d+iVzGw48FHgFzGbU75uZtaP6JfLLwHcvc7dd5MGdYsRAfqYWQToC2whRevn7s8BO9ts7lZdzKwU6Ofuiz2aCvfHHNPrZFIQDAM2xqxvCralJDMbBZwGvAwMdvcqiIYFUBLslmp1/i/gn4CmmG3pULfRQDXwq6Db6xdmlkd61A133wz8ENgAVAF73P0p0qR+ge7WZViw3HZ7r5RJQdBe/1xKzp01s3zgD8BN7r63s13b2dYr62xmFwPb3H3JkR7SzrZeWTeify2fDtzt7qcBB4h2L3QklepG0F8+i2jXyFAgz8w+3dkh7WzrtfXrQkd1Sak6ZlIQbAJGxKwPJ9p8TSlmlkU0BB5w90eDzVuDpijBz23B9lSq81nAx8xsHdFuuw+Z2W9Ij7ptAja5+8vB+iNEgyEd6gYwHXjX3avdvR54FDiT9KkfdL8um4Llttt7pUwKgleBcWZWZmbZwBXAvCSXqVuCWQe/BCrd/c6Yp+YBs4Pl2cATMduvMLMcMysDxhEdwOp13P1b7j7c3UcR/d38xd0/TXrU7T1go5mdEGyaBrxFGtQtsAGYYmZ9g/+j04iOX6VL/aCbdQm6j/aZ2ZTg3+SamGN6n2SPVh/LBzCT6EybNcCtyS5PD8p/NtHm5TJgafCYCQwCFgGrgp+FMcfcGtR3Jb141kKbep7P4VlDaVE3YBJQEfzuHgcGpkvdgvL+G/A2sAL4NdFZNClZP+AhomMd9UT/sr+2J3UByoN/jzXA/xBcyaE3PnSJCRGRDJdJXUMiItIOBYGISIZTEIiIZDgFgYhIhlMQiIhkOAWBiEiGUxCIiGS4/weLnZWN0cRnDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb1e222da0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='bl6.mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 368 steps, validate for 368 steps\n",
      "Epoch 1/2000\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.7066 - mse: 0.7001 - val_loss: 0.5959 - val_mse: 0.5892\n",
      "Epoch 2/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.6034 - mse: 0.5968 - val_loss: 0.5308 - val_mse: 0.5242\n",
      "Epoch 3/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.6101 - mse: 0.6034 - val_loss: 0.5371 - val_mse: 0.5304\n",
      "Epoch 4/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5995 - mse: 0.5928 - val_loss: 0.5384 - val_mse: 0.5317\n",
      "Epoch 5/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5968 - mse: 0.5901 - val_loss: 0.5375 - val_mse: 0.5308\n",
      "Epoch 6/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5800 - mse: 0.5733 - val_loss: 0.5316 - val_mse: 0.5249\n",
      "Epoch 7/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5823 - mse: 0.5756 - val_loss: 0.5123 - val_mse: 0.5056\n",
      "Epoch 8/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5840 - mse: 0.5773 - val_loss: 0.5228 - val_mse: 0.5161\n",
      "Epoch 9/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5708 - mse: 0.5640 - val_loss: 0.5395 - val_mse: 0.5328\n",
      "Epoch 10/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5790 - mse: 0.5722\n",
      "Epoch 00010: saving model to Regression_Model/bl6.mle.linear-0010.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5782 - mse: 0.5715 - val_loss: 0.5210 - val_mse: 0.5142\n",
      "Epoch 11/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5783 - mse: 0.5716 - val_loss: 0.5309 - val_mse: 0.5242\n",
      "Epoch 12/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5709 - mse: 0.5642 - val_loss: 0.5134 - val_mse: 0.5066\n",
      "Epoch 13/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5654 - mse: 0.5587 - val_loss: 0.5121 - val_mse: 0.5054\n",
      "Epoch 14/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5641 - mse: 0.5573 - val_loss: 0.5116 - val_mse: 0.5048\n",
      "Epoch 15/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5741 - mse: 0.5673 - val_loss: 0.5016 - val_mse: 0.4949\n",
      "Epoch 16/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5807 - mse: 0.5739 - val_loss: 0.5308 - val_mse: 0.5241\n",
      "Epoch 17/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5559 - mse: 0.5492 - val_loss: 0.5333 - val_mse: 0.5266\n",
      "Epoch 18/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5548 - mse: 0.5481 - val_loss: 0.5088 - val_mse: 0.5021\n",
      "Epoch 19/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5635 - mse: 0.5567 - val_loss: 0.5199 - val_mse: 0.5132\n",
      "Epoch 20/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.5642 - mse: 0.5574\n",
      "Epoch 00020: saving model to Regression_Model/bl6.mle.linear-0020.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5646 - mse: 0.5579 - val_loss: 0.5085 - val_mse: 0.5018\n",
      "Epoch 21/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5638 - mse: 0.5570 - val_loss: 0.4941 - val_mse: 0.4874\n",
      "Epoch 22/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5497 - mse: 0.5430 - val_loss: 0.4960 - val_mse: 0.4892\n",
      "Epoch 23/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5580 - mse: 0.5512 - val_loss: 0.5010 - val_mse: 0.4942\n",
      "Epoch 24/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5535 - mse: 0.5467 - val_loss: 0.4989 - val_mse: 0.4922\n",
      "Epoch 25/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5520 - mse: 0.5452 - val_loss: 0.4931 - val_mse: 0.4863\n",
      "Epoch 26/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5488 - mse: 0.5421 - val_loss: 0.4983 - val_mse: 0.4915\n",
      "Epoch 27/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5540 - mse: 0.5473 - val_loss: 0.5014 - val_mse: 0.4946\n",
      "Epoch 28/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5584 - mse: 0.5516 - val_loss: 0.4953 - val_mse: 0.4886\n",
      "Epoch 29/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5448 - mse: 0.5380 - val_loss: 0.5002 - val_mse: 0.4935\n",
      "Epoch 30/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5460 - mse: 0.5392\n",
      "Epoch 00030: saving model to Regression_Model/bl6.mle.linear-0030.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5445 - mse: 0.5377 - val_loss: 0.4944 - val_mse: 0.4877\n",
      "Epoch 31/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5492 - mse: 0.5425 - val_loss: 0.4935 - val_mse: 0.4867\n",
      "Epoch 32/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5481 - mse: 0.5414 - val_loss: 0.4865 - val_mse: 0.4798\n",
      "Epoch 33/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5437 - mse: 0.5369 - val_loss: 0.4882 - val_mse: 0.4815\n",
      "Epoch 34/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5540 - mse: 0.5472 - val_loss: 0.4874 - val_mse: 0.4806\n",
      "Epoch 35/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5460 - mse: 0.5392 - val_loss: 0.4912 - val_mse: 0.4845\n",
      "Epoch 36/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5475 - mse: 0.5407 - val_loss: 0.4922 - val_mse: 0.4854\n",
      "Epoch 37/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5442 - mse: 0.5374 - val_loss: 0.4781 - val_mse: 0.4713\n",
      "Epoch 38/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5435 - mse: 0.5367 - val_loss: 0.4977 - val_mse: 0.4910\n",
      "Epoch 39/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5469 - mse: 0.5401 - val_loss: 0.4956 - val_mse: 0.4888\n",
      "Epoch 40/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5543 - mse: 0.5475\n",
      "Epoch 00040: saving model to Regression_Model/bl6.mle.linear-0040.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.5547 - mse: 0.5480 - val_loss: 0.5101 - val_mse: 0.5033\n",
      "Epoch 41/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5401 - mse: 0.5333 - val_loss: 0.4865 - val_mse: 0.4798\n",
      "Epoch 42/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5463 - mse: 0.5395 - val_loss: 0.4896 - val_mse: 0.4828\n",
      "Epoch 43/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5382 - mse: 0.5315 - val_loss: 0.4760 - val_mse: 0.4693\n",
      "Epoch 44/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5341 - mse: 0.5273 - val_loss: 0.4786 - val_mse: 0.4719\n",
      "Epoch 45/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5407 - mse: 0.5340 - val_loss: 0.5024 - val_mse: 0.4956\n",
      "Epoch 46/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5463 - mse: 0.5396 - val_loss: 0.4716 - val_mse: 0.4648\n",
      "Epoch 47/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5435 - mse: 0.5368 - val_loss: 0.5036 - val_mse: 0.4969\n",
      "Epoch 48/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5444 - mse: 0.5377 - val_loss: 0.5225 - val_mse: 0.5157\n",
      "Epoch 49/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5317 - mse: 0.5249 - val_loss: 0.4823 - val_mse: 0.4756\n",
      "Epoch 50/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5445 - mse: 0.5377\n",
      "Epoch 00050: saving model to Regression_Model/bl6.mle.linear-0050.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.5450 - mse: 0.5383 - val_loss: 0.4743 - val_mse: 0.4675\n",
      "Epoch 51/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5348 - mse: 0.5281 - val_loss: 0.4821 - val_mse: 0.4753\n",
      "Epoch 52/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5359 - mse: 0.5291 - val_loss: 0.4869 - val_mse: 0.4802\n",
      "Epoch 53/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5372 - mse: 0.5305 - val_loss: 0.4809 - val_mse: 0.4742\n",
      "Epoch 54/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5395 - mse: 0.5327 - val_loss: 0.4862 - val_mse: 0.4795\n",
      "Epoch 55/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5498 - mse: 0.5430 - val_loss: 0.4755 - val_mse: 0.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5404 - mse: 0.5337 - val_loss: 0.4895 - val_mse: 0.4828\n",
      "Epoch 57/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5401 - mse: 0.5334 - val_loss: 0.4895 - val_mse: 0.4827\n",
      "Epoch 58/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5397 - mse: 0.5330 - val_loss: 0.4786 - val_mse: 0.4719\n",
      "Epoch 59/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5422 - mse: 0.5354 - val_loss: 0.4715 - val_mse: 0.4648\n",
      "Epoch 60/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5439 - mse: 0.5372\n",
      "Epoch 00060: saving model to Regression_Model/bl6.mle.linear-0060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5447 - mse: 0.5379 - val_loss: 0.4918 - val_mse: 0.4850\n",
      "Epoch 61/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5428 - mse: 0.5361 - val_loss: 0.4869 - val_mse: 0.4802\n",
      "Epoch 62/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5378 - mse: 0.5310 - val_loss: 0.4806 - val_mse: 0.4739\n",
      "Epoch 63/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5384 - mse: 0.5316 - val_loss: 0.4719 - val_mse: 0.4651\n",
      "Epoch 64/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5373 - mse: 0.5306 - val_loss: 0.4736 - val_mse: 0.4669\n",
      "Epoch 65/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5342 - mse: 0.5275 - val_loss: 0.4681 - val_mse: 0.4613\n",
      "Epoch 66/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5377 - mse: 0.5309 - val_loss: 0.4750 - val_mse: 0.4682\n",
      "Epoch 67/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5286 - mse: 0.5219 - val_loss: 0.4625 - val_mse: 0.4558\n",
      "Epoch 68/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5404 - mse: 0.5337 - val_loss: 0.4891 - val_mse: 0.4824\n",
      "Epoch 69/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5382 - mse: 0.5314 - val_loss: 0.4707 - val_mse: 0.4640\n",
      "Epoch 70/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5329 - mse: 0.5262\n",
      "Epoch 00070: saving model to Regression_Model/bl6.mle.linear-0070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5336 - mse: 0.5269 - val_loss: 0.4788 - val_mse: 0.4721\n",
      "Epoch 71/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5321 - mse: 0.5254 - val_loss: 0.4711 - val_mse: 0.4644\n",
      "Epoch 72/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5325 - mse: 0.5258 - val_loss: 0.4667 - val_mse: 0.4600\n",
      "Epoch 73/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5383 - mse: 0.5316 - val_loss: 0.4779 - val_mse: 0.4712\n",
      "Epoch 74/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5270 - mse: 0.5203 - val_loss: 0.4719 - val_mse: 0.4652\n",
      "Epoch 75/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5390 - mse: 0.5322 - val_loss: 0.4709 - val_mse: 0.4642\n",
      "Epoch 76/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5353 - mse: 0.5285 - val_loss: 0.4673 - val_mse: 0.4606\n",
      "Epoch 77/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5299 - mse: 0.5232 - val_loss: 0.4973 - val_mse: 0.4906\n",
      "Epoch 78/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5278 - mse: 0.5211 - val_loss: 0.4671 - val_mse: 0.4604\n",
      "Epoch 79/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5270 - mse: 0.5203 - val_loss: 0.4677 - val_mse: 0.4610\n",
      "Epoch 80/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5225 - mse: 0.5158\n",
      "Epoch 00080: saving model to Regression_Model/bl6.mle.linear-0080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5251 - mse: 0.5183 - val_loss: 0.4693 - val_mse: 0.4626\n",
      "Epoch 81/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5259 - mse: 0.5192 - val_loss: 0.4651 - val_mse: 0.4584\n",
      "Epoch 82/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5371 - mse: 0.5304 - val_loss: 0.4709 - val_mse: 0.4642\n",
      "Epoch 83/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5318 - mse: 0.5250 - val_loss: 0.4790 - val_mse: 0.4723\n",
      "Epoch 84/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5329 - mse: 0.5262 - val_loss: 0.4681 - val_mse: 0.4614\n",
      "Epoch 85/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5188 - val_loss: 0.4689 - val_mse: 0.4622\n",
      "Epoch 86/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5296 - mse: 0.5229 - val_loss: 0.4678 - val_mse: 0.4611\n",
      "Epoch 87/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5196 - mse: 0.5129 - val_loss: 0.4731 - val_mse: 0.4664\n",
      "Epoch 88/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5177 - mse: 0.5110 - val_loss: 0.4673 - val_mse: 0.4606\n",
      "Epoch 89/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5266 - mse: 0.5199 - val_loss: 0.4733 - val_mse: 0.4667\n",
      "Epoch 90/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.5262 - mse: 0.5195\n",
      "Epoch 00090: saving model to Regression_Model/bl6.mle.linear-0090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5256 - mse: 0.5189 - val_loss: 0.4749 - val_mse: 0.4682\n",
      "Epoch 91/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5292 - mse: 0.5225 - val_loss: 0.4731 - val_mse: 0.4664\n",
      "Epoch 92/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5216 - mse: 0.5149 - val_loss: 0.4607 - val_mse: 0.4540\n",
      "Epoch 93/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5311 - mse: 0.5244 - val_loss: 0.4620 - val_mse: 0.4553\n",
      "Epoch 94/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5282 - mse: 0.5216 - val_loss: 0.4965 - val_mse: 0.4898\n",
      "Epoch 95/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5305 - mse: 0.5238 - val_loss: 0.4808 - val_mse: 0.4741\n",
      "Epoch 96/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5272 - mse: 0.5205 - val_loss: 0.4709 - val_mse: 0.4642\n",
      "Epoch 97/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5186 - mse: 0.5119 - val_loss: 0.4633 - val_mse: 0.4567\n",
      "Epoch 98/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5229 - mse: 0.5162 - val_loss: 0.4750 - val_mse: 0.4683\n",
      "Epoch 99/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5322 - mse: 0.5255 - val_loss: 0.4699 - val_mse: 0.4632\n",
      "Epoch 100/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.5237 - mse: 0.5170\n",
      "Epoch 00100: saving model to Regression_Model/bl6.mle.linear-0100.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5230 - mse: 0.5163 - val_loss: 0.4624 - val_mse: 0.4557\n",
      "Epoch 101/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5188 - val_loss: 0.4685 - val_mse: 0.4619\n",
      "Epoch 102/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5285 - mse: 0.5219 - val_loss: 0.4704 - val_mse: 0.4637\n",
      "Epoch 103/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5234 - mse: 0.5167 - val_loss: 0.4784 - val_mse: 0.4717\n",
      "Epoch 104/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5196 - mse: 0.5129 - val_loss: 0.4600 - val_mse: 0.4534\n",
      "Epoch 105/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5277 - mse: 0.5211 - val_loss: 0.4612 - val_mse: 0.4545\n",
      "Epoch 106/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5289 - mse: 0.5222 - val_loss: 0.4682 - val_mse: 0.4615\n",
      "Epoch 107/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5258 - mse: 0.5191 - val_loss: 0.4763 - val_mse: 0.4697\n",
      "Epoch 108/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5212 - mse: 0.5145 - val_loss: 0.4806 - val_mse: 0.4739\n",
      "Epoch 109/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5325 - mse: 0.5258 - val_loss: 0.4708 - val_mse: 0.4641\n",
      "Epoch 110/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5265 - mse: 0.5199\n",
      "Epoch 00110: saving model to Regression_Model/bl6.mle.linear-0110.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5235 - mse: 0.5168 - val_loss: 0.4578 - val_mse: 0.4511\n",
      "Epoch 111/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5193 - mse: 0.5126 - val_loss: 0.4612 - val_mse: 0.4545\n",
      "Epoch 112/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5218 - mse: 0.5151 - val_loss: 0.4585 - val_mse: 0.4518\n",
      "Epoch 113/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5205 - mse: 0.5138 - val_loss: 0.4608 - val_mse: 0.4541\n",
      "Epoch 114/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5126 - mse: 0.5059 - val_loss: 0.4556 - val_mse: 0.4489\n",
      "Epoch 115/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5222 - mse: 0.5155 - val_loss: 0.4637 - val_mse: 0.4571\n",
      "Epoch 116/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5198 - mse: 0.5131 - val_loss: 0.4600 - val_mse: 0.4534\n",
      "Epoch 117/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5327 - mse: 0.5260 - val_loss: 0.4746 - val_mse: 0.4680\n",
      "Epoch 118/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5234 - mse: 0.5167 - val_loss: 0.4616 - val_mse: 0.4549\n",
      "Epoch 119/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5217 - mse: 0.5150 - val_loss: 0.4750 - val_mse: 0.4683\n",
      "Epoch 120/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5217 - mse: 0.5151\n",
      "Epoch 00120: saving model to Regression_Model/bl6.mle.linear-0120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5228 - mse: 0.5161 - val_loss: 0.4603 - val_mse: 0.4537\n",
      "Epoch 121/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5229 - mse: 0.5162 - val_loss: 0.4701 - val_mse: 0.4635\n",
      "Epoch 122/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5225 - mse: 0.5159 - val_loss: 0.4625 - val_mse: 0.4559\n",
      "Epoch 123/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5219 - mse: 0.5152 - val_loss: 0.4633 - val_mse: 0.4567\n",
      "Epoch 124/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5279 - mse: 0.5213 - val_loss: 0.4661 - val_mse: 0.4595\n",
      "Epoch 125/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5268 - mse: 0.5202 - val_loss: 0.4710 - val_mse: 0.4643\n",
      "Epoch 126/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5200 - mse: 0.5134 - val_loss: 0.4656 - val_mse: 0.4589\n",
      "Epoch 127/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5281 - mse: 0.5215 - val_loss: 0.4677 - val_mse: 0.4610\n",
      "Epoch 128/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5148 - mse: 0.5082 - val_loss: 0.4532 - val_mse: 0.4465\n",
      "Epoch 129/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5093 - val_loss: 0.4593 - val_mse: 0.4526\n",
      "Epoch 130/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5254 - mse: 0.5187\n",
      "Epoch 00130: saving model to Regression_Model/bl6.mle.linear-0130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5246 - mse: 0.5179 - val_loss: 0.4615 - val_mse: 0.4548\n",
      "Epoch 131/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5257 - mse: 0.5191 - val_loss: 0.4676 - val_mse: 0.4609\n",
      "Epoch 132/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5195 - mse: 0.5128 - val_loss: 0.4648 - val_mse: 0.4581\n",
      "Epoch 133/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5232 - mse: 0.5165 - val_loss: 0.4558 - val_mse: 0.4491\n",
      "Epoch 134/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5225 - mse: 0.5159 - val_loss: 0.4529 - val_mse: 0.4463\n",
      "Epoch 135/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5098 - mse: 0.5031 - val_loss: 0.4526 - val_mse: 0.4459\n",
      "Epoch 136/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5069 - val_loss: 0.4518 - val_mse: 0.4452\n",
      "Epoch 137/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5209 - mse: 0.5142 - val_loss: 0.4541 - val_mse: 0.4474\n",
      "Epoch 138/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5215 - mse: 0.5149 - val_loss: 0.4620 - val_mse: 0.4553\n",
      "Epoch 139/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5248 - mse: 0.5182 - val_loss: 0.4569 - val_mse: 0.4503\n",
      "Epoch 140/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5223 - mse: 0.5157\n",
      "Epoch 00140: saving model to Regression_Model/bl6.mle.linear-0140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5234 - mse: 0.5168 - val_loss: 0.4694 - val_mse: 0.4627\n",
      "Epoch 141/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5202 - mse: 0.5135 - val_loss: 0.4525 - val_mse: 0.4458\n",
      "Epoch 142/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5191 - mse: 0.5124 - val_loss: 0.4530 - val_mse: 0.4463\n",
      "Epoch 143/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5208 - mse: 0.5141 - val_loss: 0.4568 - val_mse: 0.4501\n",
      "Epoch 144/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5228 - mse: 0.5161 - val_loss: 0.4626 - val_mse: 0.4559\n",
      "Epoch 145/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5197 - mse: 0.5131 - val_loss: 0.4570 - val_mse: 0.4504\n",
      "Epoch 146/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5140 - val_loss: 0.4594 - val_mse: 0.4528\n",
      "Epoch 147/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5183 - mse: 0.5116 - val_loss: 0.4514 - val_mse: 0.4448\n",
      "Epoch 148/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5144 - mse: 0.5078 - val_loss: 0.4581 - val_mse: 0.4514\n",
      "Epoch 149/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5185 - mse: 0.5118 - val_loss: 0.4513 - val_mse: 0.4447\n",
      "Epoch 150/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5162 - mse: 0.5095\n",
      "Epoch 00150: saving model to Regression_Model/bl6.mle.linear-0150.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.5182 - mse: 0.5115 - val_loss: 0.4635 - val_mse: 0.4568\n",
      "Epoch 151/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5228 - mse: 0.5161 - val_loss: 0.4502 - val_mse: 0.4436\n",
      "Epoch 152/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5190 - mse: 0.5123 - val_loss: 0.4475 - val_mse: 0.4408\n",
      "Epoch 153/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5111 - mse: 0.5045 - val_loss: 0.4567 - val_mse: 0.4500\n",
      "Epoch 154/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5176 - mse: 0.5110 - val_loss: 0.4476 - val_mse: 0.4409\n",
      "Epoch 155/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5206 - mse: 0.5140 - val_loss: 0.4549 - val_mse: 0.4482\n",
      "Epoch 156/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5241 - mse: 0.5174 - val_loss: 0.4655 - val_mse: 0.4588\n",
      "Epoch 157/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5162 - mse: 0.5095 - val_loss: 0.4458 - val_mse: 0.4392\n",
      "Epoch 158/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5143 - mse: 0.5077 - val_loss: 0.4635 - val_mse: 0.4568\n",
      "Epoch 159/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5205 - mse: 0.5139 - val_loss: 0.4910 - val_mse: 0.4844\n",
      "Epoch 160/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5166 - mse: 0.5100\n",
      "Epoch 00160: saving model to Regression_Model/bl6.mle.linear-0160.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5158 - mse: 0.5092 - val_loss: 0.4680 - val_mse: 0.4613\n",
      "Epoch 161/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5043 - val_loss: 0.4528 - val_mse: 0.4462\n",
      "Epoch 162/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5117 - mse: 0.5050 - val_loss: 0.4565 - val_mse: 0.4499\n",
      "Epoch 163/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5157 - mse: 0.5090 - val_loss: 0.4559 - val_mse: 0.4492\n",
      "Epoch 164/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5189 - mse: 0.5122 - val_loss: 0.4639 - val_mse: 0.4573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5154 - mse: 0.5088 - val_loss: 0.4511 - val_mse: 0.4444\n",
      "Epoch 166/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5198 - mse: 0.5132 - val_loss: 0.4489 - val_mse: 0.4423\n",
      "Epoch 167/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5086 - mse: 0.5020 - val_loss: 0.4471 - val_mse: 0.4404\n",
      "Epoch 168/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5208 - mse: 0.5141 - val_loss: 0.4493 - val_mse: 0.4426\n",
      "Epoch 169/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5150 - mse: 0.5083 - val_loss: 0.4505 - val_mse: 0.4439\n",
      "Epoch 170/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5152 - mse: 0.5085\n",
      "Epoch 00170: saving model to Regression_Model/bl6.mle.linear-0170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5074 - val_loss: 0.4530 - val_mse: 0.4463\n",
      "Epoch 171/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5138 - mse: 0.5071 - val_loss: 0.4470 - val_mse: 0.4403\n",
      "Epoch 172/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5173 - mse: 0.5106 - val_loss: 0.4624 - val_mse: 0.4557\n",
      "Epoch 173/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5008 - val_loss: 0.4492 - val_mse: 0.4426\n",
      "Epoch 174/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5140 - mse: 0.5074 - val_loss: 0.4459 - val_mse: 0.4393\n",
      "Epoch 175/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5068 - val_loss: 0.4467 - val_mse: 0.4400\n",
      "Epoch 176/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5191 - mse: 0.5124 - val_loss: 0.4574 - val_mse: 0.4508\n",
      "Epoch 177/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5144 - mse: 0.5077 - val_loss: 0.4686 - val_mse: 0.4620\n",
      "Epoch 178/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5208 - mse: 0.5141 - val_loss: 0.4553 - val_mse: 0.4486\n",
      "Epoch 179/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5185 - mse: 0.5118 - val_loss: 0.4595 - val_mse: 0.4529\n",
      "Epoch 180/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.5161 - mse: 0.5094\n",
      "Epoch 00180: saving model to Regression_Model/bl6.mle.linear-0180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5151 - mse: 0.5084 - val_loss: 0.4472 - val_mse: 0.4405\n",
      "Epoch 181/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5058 - val_loss: 0.4583 - val_mse: 0.4517\n",
      "Epoch 182/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5163 - mse: 0.5097 - val_loss: 0.4538 - val_mse: 0.4472\n",
      "Epoch 183/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5103 - mse: 0.5036 - val_loss: 0.4655 - val_mse: 0.4588\n",
      "Epoch 184/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5255 - mse: 0.5189 - val_loss: 0.4666 - val_mse: 0.4599\n",
      "Epoch 185/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5057 - val_loss: 0.4551 - val_mse: 0.4485\n",
      "Epoch 186/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5101 - mse: 0.5035 - val_loss: 0.4628 - val_mse: 0.4562\n",
      "Epoch 187/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5152 - mse: 0.5086 - val_loss: 0.4629 - val_mse: 0.4562\n",
      "Epoch 188/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5149 - mse: 0.5082 - val_loss: 0.4484 - val_mse: 0.4417\n",
      "Epoch 189/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5151 - mse: 0.5084 - val_loss: 0.4518 - val_mse: 0.4451\n",
      "Epoch 190/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.5177 - mse: 0.5111\n",
      "Epoch 00190: saving model to Regression_Model/bl6.mle.linear-0190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5178 - mse: 0.5111 - val_loss: 0.4561 - val_mse: 0.4494\n",
      "Epoch 191/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5145 - mse: 0.5079 - val_loss: 0.4444 - val_mse: 0.4377\n",
      "Epoch 192/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5112 - mse: 0.5046 - val_loss: 0.4482 - val_mse: 0.4416\n",
      "Epoch 193/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5178 - mse: 0.5111 - val_loss: 0.4575 - val_mse: 0.4508\n",
      "Epoch 194/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5160 - mse: 0.5094 - val_loss: 0.4551 - val_mse: 0.4484\n",
      "Epoch 195/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5141 - mse: 0.5075 - val_loss: 0.4467 - val_mse: 0.4400\n",
      "Epoch 196/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5160 - mse: 0.5094 - val_loss: 0.4528 - val_mse: 0.4461\n",
      "Epoch 197/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5144 - mse: 0.5077 - val_loss: 0.4557 - val_mse: 0.4490\n",
      "Epoch 198/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5130 - mse: 0.5063 - val_loss: 0.4459 - val_mse: 0.4393\n",
      "Epoch 199/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5196 - mse: 0.5130 - val_loss: 0.4661 - val_mse: 0.4595\n",
      "Epoch 200/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.5153 - mse: 0.5086\n",
      "Epoch 00200: saving model to Regression_Model/bl6.mle.linear-0200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5142 - mse: 0.5076 - val_loss: 0.4464 - val_mse: 0.4398\n",
      "Epoch 201/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5043 - val_loss: 0.4479 - val_mse: 0.4412\n",
      "Epoch 202/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5159 - mse: 0.5093 - val_loss: 0.4436 - val_mse: 0.4370\n",
      "Epoch 203/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5017 - val_loss: 0.4496 - val_mse: 0.4429\n",
      "Epoch 204/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5124 - mse: 0.5058 - val_loss: 0.4559 - val_mse: 0.4493\n",
      "Epoch 205/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5136 - mse: 0.5070 - val_loss: 0.4419 - val_mse: 0.4353\n",
      "Epoch 206/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4948 - val_loss: 0.4503 - val_mse: 0.4436\n",
      "Epoch 207/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5042 - val_loss: 0.4506 - val_mse: 0.4440\n",
      "Epoch 208/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5151 - mse: 0.5084 - val_loss: 0.4667 - val_mse: 0.4601\n",
      "Epoch 209/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5138 - mse: 0.5071 - val_loss: 0.4516 - val_mse: 0.4449\n",
      "Epoch 210/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5115 - mse: 0.5048\n",
      "Epoch 00210: saving model to Regression_Model/bl6.mle.linear-0210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5127 - mse: 0.5061 - val_loss: 0.4462 - val_mse: 0.4396\n",
      "Epoch 211/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5144 - mse: 0.5077 - val_loss: 0.4463 - val_mse: 0.4396\n",
      "Epoch 212/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.4998 - val_loss: 0.4429 - val_mse: 0.4362\n",
      "Epoch 213/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5132 - mse: 0.5065 - val_loss: 0.4481 - val_mse: 0.4414\n",
      "Epoch 214/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5035 - mse: 0.4968 - val_loss: 0.4426 - val_mse: 0.4359\n",
      "Epoch 215/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5109 - mse: 0.5042 - val_loss: 0.4478 - val_mse: 0.4411\n",
      "Epoch 216/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5065 - mse: 0.4998 - val_loss: 0.4420 - val_mse: 0.4353\n",
      "Epoch 217/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5089 - mse: 0.5022 - val_loss: 0.4423 - val_mse: 0.4356\n",
      "Epoch 218/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5105 - mse: 0.5038 - val_loss: 0.4512 - val_mse: 0.4445\n",
      "Epoch 219/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5102 - mse: 0.5035 - val_loss: 0.4480 - val_mse: 0.4413\n",
      "Epoch 220/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5214 - mse: 0.5147\n",
      "Epoch 00220: saving model to Regression_Model/bl6.mle.linear-0220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5204 - mse: 0.5137 - val_loss: 0.4456 - val_mse: 0.4389\n",
      "Epoch 221/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5114 - mse: 0.5048 - val_loss: 0.4543 - val_mse: 0.4476\n",
      "Epoch 222/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5002 - mse: 0.4935 - val_loss: 0.4466 - val_mse: 0.4399\n",
      "Epoch 223/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5092 - mse: 0.5025 - val_loss: 0.4450 - val_mse: 0.4383\n",
      "Epoch 224/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5006 - val_loss: 0.4504 - val_mse: 0.4437\n",
      "Epoch 225/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5087 - mse: 0.5020 - val_loss: 0.4579 - val_mse: 0.4512\n",
      "Epoch 226/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5180 - mse: 0.5113 - val_loss: 0.4462 - val_mse: 0.4395\n",
      "Epoch 227/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5076 - mse: 0.5009 - val_loss: 0.4424 - val_mse: 0.4357\n",
      "Epoch 228/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4990 - val_loss: 0.4489 - val_mse: 0.4422\n",
      "Epoch 229/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5165 - mse: 0.5098 - val_loss: 0.4427 - val_mse: 0.4360\n",
      "Epoch 230/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.5019 - mse: 0.4952\n",
      "Epoch 00230: saving model to Regression_Model/bl6.mle.linear-0230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5032 - mse: 0.4966 - val_loss: 0.4419 - val_mse: 0.4352\n",
      "Epoch 231/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5038 - mse: 0.4971 - val_loss: 0.4497 - val_mse: 0.4430\n",
      "Epoch 232/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5081 - mse: 0.5014 - val_loss: 0.4450 - val_mse: 0.4384\n",
      "Epoch 233/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5153 - mse: 0.5086 - val_loss: 0.4466 - val_mse: 0.4399\n",
      "Epoch 234/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5070 - mse: 0.5003 - val_loss: 0.4489 - val_mse: 0.4422\n",
      "Epoch 235/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5108 - mse: 0.5041 - val_loss: 0.4432 - val_mse: 0.4366\n",
      "Epoch 236/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5073 - mse: 0.5006 - val_loss: 0.4589 - val_mse: 0.4522\n",
      "Epoch 237/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5109 - mse: 0.5042 - val_loss: 0.4491 - val_mse: 0.4425\n",
      "Epoch 238/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5037 - mse: 0.4970 - val_loss: 0.4435 - val_mse: 0.4368\n",
      "Epoch 239/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5072 - mse: 0.5005 - val_loss: 0.4593 - val_mse: 0.4526\n",
      "Epoch 240/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5134 - mse: 0.5068\n",
      "Epoch 00240: saving model to Regression_Model/bl6.mle.linear-0240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5135 - mse: 0.5068 - val_loss: 0.4468 - val_mse: 0.4401\n",
      "Epoch 241/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5019 - mse: 0.4953 - val_loss: 0.4401 - val_mse: 0.4334\n",
      "Epoch 242/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5046 - mse: 0.4980 - val_loss: 0.4581 - val_mse: 0.4514\n",
      "Epoch 243/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5051 - mse: 0.4984 - val_loss: 0.4453 - val_mse: 0.4387\n",
      "Epoch 244/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5005 - mse: 0.4939 - val_loss: 0.4457 - val_mse: 0.4390\n",
      "Epoch 245/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5124 - mse: 0.5058 - val_loss: 0.4404 - val_mse: 0.4337\n",
      "Epoch 246/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5078 - mse: 0.5012 - val_loss: 0.4551 - val_mse: 0.4484\n",
      "Epoch 247/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5021 - val_loss: 0.4499 - val_mse: 0.4432\n",
      "Epoch 248/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5040 - mse: 0.4973 - val_loss: 0.4463 - val_mse: 0.4396\n",
      "Epoch 249/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5050 - mse: 0.4983 - val_loss: 0.4458 - val_mse: 0.4391\n",
      "Epoch 250/2000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.5049 - mse: 0.4982\n",
      "Epoch 00250: saving model to Regression_Model/bl6.mle.linear-0250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5061 - mse: 0.4994 - val_loss: 0.4525 - val_mse: 0.4458\n",
      "Epoch 251/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5044 - mse: 0.4977 - val_loss: 0.4415 - val_mse: 0.4348\n",
      "Epoch 252/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5039 - mse: 0.4973 - val_loss: 0.4397 - val_mse: 0.4330\n",
      "Epoch 253/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5007 - mse: 0.4940 - val_loss: 0.4441 - val_mse: 0.4374\n",
      "Epoch 254/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4952 - val_loss: 0.4539 - val_mse: 0.4472\n",
      "Epoch 255/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5003 - val_loss: 0.4360 - val_mse: 0.4293\n",
      "Epoch 256/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5017 - val_loss: 0.4621 - val_mse: 0.4554\n",
      "Epoch 257/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4950 - val_loss: 0.4398 - val_mse: 0.4331\n",
      "Epoch 258/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5083 - mse: 0.5016 - val_loss: 0.4448 - val_mse: 0.4381\n",
      "Epoch 259/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4924 - val_loss: 0.4399 - val_mse: 0.4333\n",
      "Epoch 260/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.5126 - mse: 0.5059\n",
      "Epoch 00260: saving model to Regression_Model/bl6.mle.linear-0260.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5128 - mse: 0.5061 - val_loss: 0.4512 - val_mse: 0.4445\n",
      "Epoch 261/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5066 - mse: 0.5000 - val_loss: 0.4431 - val_mse: 0.4364\n",
      "Epoch 262/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4948 - val_loss: 0.4420 - val_mse: 0.4353\n",
      "Epoch 263/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5042 - mse: 0.4976 - val_loss: 0.4423 - val_mse: 0.4356\n",
      "Epoch 264/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5096 - mse: 0.5029 - val_loss: 0.4414 - val_mse: 0.4348\n",
      "Epoch 265/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5084 - mse: 0.5017 - val_loss: 0.4550 - val_mse: 0.4483\n",
      "Epoch 266/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5172 - mse: 0.5106 - val_loss: 0.4371 - val_mse: 0.4305\n",
      "Epoch 267/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5093 - mse: 0.5027 - val_loss: 0.4380 - val_mse: 0.4314\n",
      "Epoch 268/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5066 - mse: 0.4999 - val_loss: 0.4389 - val_mse: 0.4323\n",
      "Epoch 269/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5031 - mse: 0.4964 - val_loss: 0.4384 - val_mse: 0.4318\n",
      "Epoch 270/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5024 - mse: 0.4957\n",
      "Epoch 00270: saving model to Regression_Model/bl6.mle.linear-0270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5043 - mse: 0.4976 - val_loss: 0.4498 - val_mse: 0.4431\n",
      "Epoch 271/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5056 - mse: 0.4990 - val_loss: 0.4382 - val_mse: 0.4316\n",
      "Epoch 272/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5053 - mse: 0.4986 - val_loss: 0.4446 - val_mse: 0.4379\n",
      "Epoch 273/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5001 - mse: 0.4934 - val_loss: 0.4364 - val_mse: 0.4297\n",
      "Epoch 274/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5005 - val_loss: 0.4351 - val_mse: 0.4284\n",
      "Epoch 275/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4928 - val_loss: 0.4402 - val_mse: 0.4335\n",
      "Epoch 276/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5000 - mse: 0.4933 - val_loss: 0.4480 - val_mse: 0.4413\n",
      "Epoch 277/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5024 - mse: 0.4957 - val_loss: 0.4377 - val_mse: 0.4310\n",
      "Epoch 278/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5054 - mse: 0.4987 - val_loss: 0.4431 - val_mse: 0.4364\n",
      "Epoch 279/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.4997 - val_loss: 0.4395 - val_mse: 0.4328\n",
      "Epoch 280/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.5049 - mse: 0.4982\n",
      "Epoch 00280: saving model to Regression_Model/bl6.mle.linear-0280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5064 - mse: 0.4997 - val_loss: 0.4442 - val_mse: 0.4376\n",
      "Epoch 281/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5049 - mse: 0.4982 - val_loss: 0.4364 - val_mse: 0.4297\n",
      "Epoch 282/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5057 - mse: 0.4990 - val_loss: 0.4381 - val_mse: 0.4314\n",
      "Epoch 283/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5020 - mse: 0.4953 - val_loss: 0.4468 - val_mse: 0.4401\n",
      "Epoch 284/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5115 - mse: 0.5048 - val_loss: 0.4452 - val_mse: 0.4385\n",
      "Epoch 285/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5037 - mse: 0.4970 - val_loss: 0.4339 - val_mse: 0.4272\n",
      "Epoch 286/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5088 - mse: 0.5021 - val_loss: 0.4452 - val_mse: 0.4385\n",
      "Epoch 287/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5084 - mse: 0.5018 - val_loss: 0.4399 - val_mse: 0.4332\n",
      "Epoch 288/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5072 - mse: 0.5005 - val_loss: 0.4555 - val_mse: 0.4488\n",
      "Epoch 289/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5000 - mse: 0.4933 - val_loss: 0.4457 - val_mse: 0.4390\n",
      "Epoch 290/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5067 - mse: 0.5000\n",
      "Epoch 00290: saving model to Regression_Model/bl6.mle.linear-0290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5069 - mse: 0.5002 - val_loss: 0.4368 - val_mse: 0.4301\n",
      "Epoch 291/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5028 - mse: 0.4961 - val_loss: 0.4468 - val_mse: 0.4401\n",
      "Epoch 292/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4983 - mse: 0.4917 - val_loss: 0.4371 - val_mse: 0.4304\n",
      "Epoch 293/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5046 - mse: 0.4979 - val_loss: 0.4381 - val_mse: 0.4314\n",
      "Epoch 294/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5036 - mse: 0.4969 - val_loss: 0.4450 - val_mse: 0.4383\n",
      "Epoch 295/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5025 - mse: 0.4958 - val_loss: 0.4419 - val_mse: 0.4352\n",
      "Epoch 296/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5051 - mse: 0.4984 - val_loss: 0.4418 - val_mse: 0.4352\n",
      "Epoch 297/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4956 - val_loss: 0.4479 - val_mse: 0.4412\n",
      "Epoch 298/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5011 - mse: 0.4944 - val_loss: 0.4416 - val_mse: 0.4349\n",
      "Epoch 299/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5122 - mse: 0.5055 - val_loss: 0.4382 - val_mse: 0.4315\n",
      "Epoch 300/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.5018 - mse: 0.4952\n",
      "Epoch 00300: saving model to Regression_Model/bl6.mle.linear-0300.ckpt\n",
      "368/368 [==============================] - 4s 11ms/step - loss: 0.5010 - mse: 0.4943 - val_loss: 0.4431 - val_mse: 0.4365\n",
      "Epoch 301/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4943 - val_loss: 0.4368 - val_mse: 0.4302\n",
      "Epoch 302/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5092 - mse: 0.5025 - val_loss: 0.4500 - val_mse: 0.4433\n",
      "Epoch 303/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4938 - val_loss: 0.4440 - val_mse: 0.4373\n",
      "Epoch 304/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4994 - mse: 0.4927 - val_loss: 0.4474 - val_mse: 0.4408\n",
      "Epoch 305/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4926 - val_loss: 0.4504 - val_mse: 0.4437\n",
      "Epoch 306/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5040 - mse: 0.4973 - val_loss: 0.4493 - val_mse: 0.4426\n",
      "Epoch 307/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5030 - mse: 0.4963 - val_loss: 0.4340 - val_mse: 0.4273\n",
      "Epoch 308/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4989 - mse: 0.4922 - val_loss: 0.4395 - val_mse: 0.4328\n",
      "Epoch 309/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5047 - mse: 0.4980 - val_loss: 0.4345 - val_mse: 0.4278\n",
      "Epoch 310/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5010 - mse: 0.4943\n",
      "Epoch 00310: saving model to Regression_Model/bl6.mle.linear-0310.ckpt\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.5043 - mse: 0.4976 - val_loss: 0.4384 - val_mse: 0.4317\n",
      "Epoch 311/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5018 - mse: 0.4951 - val_loss: 0.4404 - val_mse: 0.4337\n",
      "Epoch 312/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4964 - val_loss: 0.4403 - val_mse: 0.4336\n",
      "Epoch 313/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4991 - mse: 0.4924 - val_loss: 0.4364 - val_mse: 0.4297\n",
      "Epoch 314/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4988 - mse: 0.4921 - val_loss: 0.4333 - val_mse: 0.4266\n",
      "Epoch 315/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5130 - mse: 0.5063 - val_loss: 0.4373 - val_mse: 0.4306\n",
      "Epoch 316/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4937 - val_loss: 0.4325 - val_mse: 0.4258\n",
      "Epoch 317/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4914 - mse: 0.4847 - val_loss: 0.4425 - val_mse: 0.4358\n",
      "Epoch 318/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5024 - mse: 0.4957 - val_loss: 0.4389 - val_mse: 0.4323\n",
      "Epoch 319/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4995 - mse: 0.4928 - val_loss: 0.4375 - val_mse: 0.4308\n",
      "Epoch 320/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.5082 - mse: 0.5015\n",
      "Epoch 00320: saving model to Regression_Model/bl6.mle.linear-0320.ckpt\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.5084 - mse: 0.5017 - val_loss: 0.4388 - val_mse: 0.4321\n",
      "Epoch 321/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4928 - val_loss: 0.4339 - val_mse: 0.4272\n",
      "Epoch 322/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4926 - val_loss: 0.4354 - val_mse: 0.4287\n",
      "Epoch 323/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5013 - mse: 0.4946 - val_loss: 0.4344 - val_mse: 0.4277\n",
      "Epoch 324/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4942 - mse: 0.4875 - val_loss: 0.4363 - val_mse: 0.4296\n",
      "Epoch 325/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5052 - mse: 0.4985 - val_loss: 0.4406 - val_mse: 0.4339\n",
      "Epoch 326/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5055 - mse: 0.4988 - val_loss: 0.4387 - val_mse: 0.4320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4970 - mse: 0.4903 - val_loss: 0.4322 - val_mse: 0.4255\n",
      "Epoch 328/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4947 - val_loss: 0.4352 - val_mse: 0.4285\n",
      "Epoch 329/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4995 - mse: 0.4928 - val_loss: 0.4362 - val_mse: 0.4295\n",
      "Epoch 330/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.5047 - mse: 0.4980\n",
      "Epoch 00330: saving model to Regression_Model/bl6.mle.linear-0330.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5063 - mse: 0.4996 - val_loss: 0.4424 - val_mse: 0.4357\n",
      "Epoch 331/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4941 - val_loss: 0.4330 - val_mse: 0.4263\n",
      "Epoch 332/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5005 - mse: 0.4939 - val_loss: 0.4330 - val_mse: 0.4263\n",
      "Epoch 333/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5025 - mse: 0.4958 - val_loss: 0.4453 - val_mse: 0.4386\n",
      "Epoch 334/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5019 - mse: 0.4952 - val_loss: 0.4362 - val_mse: 0.4295\n",
      "Epoch 335/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5014 - mse: 0.4947 - val_loss: 0.4315 - val_mse: 0.4249\n",
      "Epoch 336/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5013 - mse: 0.4946 - val_loss: 0.4363 - val_mse: 0.4296\n",
      "Epoch 337/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5028 - mse: 0.4961 - val_loss: 0.4397 - val_mse: 0.4330\n",
      "Epoch 338/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4992 - mse: 0.4925 - val_loss: 0.4355 - val_mse: 0.4288\n",
      "Epoch 339/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4980 - mse: 0.4913 - val_loss: 0.4357 - val_mse: 0.4290\n",
      "Epoch 340/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.5005 - mse: 0.4938\n",
      "Epoch 00340: saving model to Regression_Model/bl6.mle.linear-0340.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 0.5013 - mse: 0.4946 - val_loss: 0.4391 - val_mse: 0.4324\n",
      "Epoch 341/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4975 - val_loss: 0.4428 - val_mse: 0.4361\n",
      "Epoch 342/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5032 - mse: 0.4965 - val_loss: 0.4351 - val_mse: 0.4284\n",
      "Epoch 343/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4930 - mse: 0.4863 - val_loss: 0.4354 - val_mse: 0.4287\n",
      "Epoch 344/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5048 - mse: 0.4982 - val_loss: 0.4391 - val_mse: 0.4324\n",
      "Epoch 345/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5042 - mse: 0.4975 - val_loss: 0.4331 - val_mse: 0.4264\n",
      "Epoch 346/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4846 - val_loss: 0.4431 - val_mse: 0.4364\n",
      "Epoch 347/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5031 - mse: 0.4964 - val_loss: 0.4362 - val_mse: 0.4296\n",
      "Epoch 348/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4973 - mse: 0.4906 - val_loss: 0.4389 - val_mse: 0.4322\n",
      "Epoch 349/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5009 - mse: 0.4942 - val_loss: 0.4313 - val_mse: 0.4246\n",
      "Epoch 350/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.5013 - mse: 0.4946\n",
      "Epoch 00350: saving model to Regression_Model/bl6.mle.linear-0350.ckpt\n",
      "368/368 [==============================] - 5s 14ms/step - loss: 0.5021 - mse: 0.4954 - val_loss: 0.4452 - val_mse: 0.4385\n",
      "Epoch 351/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4938 - val_loss: 0.4379 - val_mse: 0.4312\n",
      "Epoch 352/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4970 - mse: 0.4903 - val_loss: 0.4430 - val_mse: 0.4363\n",
      "Epoch 353/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4963 - mse: 0.4896 - val_loss: 0.4341 - val_mse: 0.4274\n",
      "Epoch 354/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5062 - mse: 0.4995 - val_loss: 0.4354 - val_mse: 0.4287\n",
      "Epoch 355/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4980 - mse: 0.4913 - val_loss: 0.4383 - val_mse: 0.4316\n",
      "Epoch 356/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4930 - val_loss: 0.4474 - val_mse: 0.4408\n",
      "Epoch 357/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5034 - mse: 0.4967 - val_loss: 0.4341 - val_mse: 0.4274\n",
      "Epoch 358/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4974 - mse: 0.4907 - val_loss: 0.4345 - val_mse: 0.4278\n",
      "Epoch 359/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4948 - val_loss: 0.4385 - val_mse: 0.4318\n",
      "Epoch 360/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.5018 - mse: 0.4951\n",
      "Epoch 00360: saving model to Regression_Model/bl6.mle.linear-0360.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.5032 - mse: 0.4966 - val_loss: 0.4381 - val_mse: 0.4314\n",
      "Epoch 361/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4950 - mse: 0.4883 - val_loss: 0.4327 - val_mse: 0.4261\n",
      "Epoch 362/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5035 - mse: 0.4968 - val_loss: 0.4457 - val_mse: 0.4390\n",
      "Epoch 363/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5015 - mse: 0.4949 - val_loss: 0.4445 - val_mse: 0.4378\n",
      "Epoch 364/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5020 - mse: 0.4953 - val_loss: 0.4317 - val_mse: 0.4250\n",
      "Epoch 365/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4994 - mse: 0.4927 - val_loss: 0.4377 - val_mse: 0.4310\n",
      "Epoch 366/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4998 - mse: 0.4932 - val_loss: 0.4306 - val_mse: 0.4239\n",
      "Epoch 367/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5075 - mse: 0.5009 - val_loss: 0.4365 - val_mse: 0.4298\n",
      "Epoch 368/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5037 - mse: 0.4971 - val_loss: 0.4303 - val_mse: 0.4236\n",
      "Epoch 369/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4959 - val_loss: 0.4465 - val_mse: 0.4398\n",
      "Epoch 370/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5004 - mse: 0.4937\n",
      "Epoch 00370: saving model to Regression_Model/bl6.mle.linear-0370.ckpt\n",
      "368/368 [==============================] - 4s 11ms/step - loss: 0.5000 - mse: 0.4933 - val_loss: 0.4309 - val_mse: 0.4242\n",
      "Epoch 371/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4935 - mse: 0.4868 - val_loss: 0.4315 - val_mse: 0.4248\n",
      "Epoch 372/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4361 - val_mse: 0.4294\n",
      "Epoch 373/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5033 - mse: 0.4966 - val_loss: 0.4300 - val_mse: 0.4233\n",
      "Epoch 374/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4942 - val_loss: 0.4383 - val_mse: 0.4316\n",
      "Epoch 375/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4989 - mse: 0.4922 - val_loss: 0.4312 - val_mse: 0.4245\n",
      "Epoch 376/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5009 - mse: 0.4942 - val_loss: 0.4469 - val_mse: 0.4402\n",
      "Epoch 377/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4994 - mse: 0.4927 - val_loss: 0.4410 - val_mse: 0.4343\n",
      "Epoch 378/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4974 - mse: 0.4907 - val_loss: 0.4343 - val_mse: 0.4276\n",
      "Epoch 379/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4964 - mse: 0.4897 - val_loss: 0.4467 - val_mse: 0.4400\n",
      "Epoch 380/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.4977 - mse: 0.4911\n",
      "Epoch 00380: saving model to Regression_Model/bl6.mle.linear-0380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4925 - val_loss: 0.4367 - val_mse: 0.4300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4931 - mse: 0.4865 - val_loss: 0.4427 - val_mse: 0.4361\n",
      "Epoch 382/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4972 - mse: 0.4905 - val_loss: 0.4376 - val_mse: 0.4310\n",
      "Epoch 383/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5008 - mse: 0.4941 - val_loss: 0.4409 - val_mse: 0.4342\n",
      "Epoch 384/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5012 - mse: 0.4946 - val_loss: 0.4307 - val_mse: 0.4240\n",
      "Epoch 385/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5041 - mse: 0.4974 - val_loss: 0.4392 - val_mse: 0.4326\n",
      "Epoch 386/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4977 - mse: 0.4910 - val_loss: 0.4311 - val_mse: 0.4244\n",
      "Epoch 387/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5014 - mse: 0.4947 - val_loss: 0.4368 - val_mse: 0.4301\n",
      "Epoch 388/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4927 - mse: 0.4860 - val_loss: 0.4360 - val_mse: 0.4293\n",
      "Epoch 389/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4976 - mse: 0.4909 - val_loss: 0.4355 - val_mse: 0.4288\n",
      "Epoch 390/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4986 - mse: 0.4919\n",
      "Epoch 00390: saving model to Regression_Model/bl6.mle.linear-0390.ckpt\n",
      "368/368 [==============================] - 8s 22ms/step - loss: 0.4987 - mse: 0.4920 - val_loss: 0.4343 - val_mse: 0.4276\n",
      "Epoch 391/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4926 - mse: 0.4860 - val_loss: 0.4417 - val_mse: 0.4350\n",
      "Epoch 392/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4996 - mse: 0.4929 - val_loss: 0.4288 - val_mse: 0.4221\n",
      "Epoch 393/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5003 - mse: 0.4936 - val_loss: 0.4353 - val_mse: 0.4287\n",
      "Epoch 394/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4937 - val_loss: 0.4403 - val_mse: 0.4336\n",
      "Epoch 395/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4968 - mse: 0.4901 - val_loss: 0.4346 - val_mse: 0.4279\n",
      "Epoch 396/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4997 - mse: 0.4930 - val_loss: 0.4335 - val_mse: 0.4268\n",
      "Epoch 397/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5094 - mse: 0.5027 - val_loss: 0.4360 - val_mse: 0.4294\n",
      "Epoch 398/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4985 - mse: 0.4918 - val_loss: 0.4391 - val_mse: 0.4324\n",
      "Epoch 399/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4954 - mse: 0.4887 - val_loss: 0.4333 - val_mse: 0.4266\n",
      "Epoch 400/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4891 - mse: 0.4824\n",
      "Epoch 00400: saving model to Regression_Model/bl6.mle.linear-0400.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4890 - mse: 0.4823 - val_loss: 0.4289 - val_mse: 0.4222\n",
      "Epoch 401/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4967 - mse: 0.4900 - val_loss: 0.4336 - val_mse: 0.4269\n",
      "Epoch 402/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5026 - mse: 0.4959 - val_loss: 0.4286 - val_mse: 0.4219\n",
      "Epoch 403/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4989 - mse: 0.4922 - val_loss: 0.4287 - val_mse: 0.4220\n",
      "Epoch 404/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5029 - mse: 0.4962 - val_loss: 0.4287 - val_mse: 0.4220\n",
      "Epoch 405/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4922 - mse: 0.4855 - val_loss: 0.4391 - val_mse: 0.4324\n",
      "Epoch 406/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4991 - mse: 0.4924 - val_loss: 0.4349 - val_mse: 0.4282\n",
      "Epoch 407/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4952 - mse: 0.4885 - val_loss: 0.4354 - val_mse: 0.4287\n",
      "Epoch 408/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4992 - mse: 0.4925 - val_loss: 0.4296 - val_mse: 0.4229\n",
      "Epoch 409/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4910 - val_loss: 0.4329 - val_mse: 0.4262\n",
      "Epoch 410/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4937 - mse: 0.4870\n",
      "Epoch 00410: saving model to Regression_Model/bl6.mle.linear-0410.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.4942 - mse: 0.4876 - val_loss: 0.4307 - val_mse: 0.4241\n",
      "Epoch 411/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4871 - val_loss: 0.4348 - val_mse: 0.4281\n",
      "Epoch 412/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4978 - mse: 0.4911 - val_loss: 0.4413 - val_mse: 0.4347\n",
      "Epoch 413/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5029 - mse: 0.4962 - val_loss: 0.4492 - val_mse: 0.4425\n",
      "Epoch 414/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5017 - mse: 0.4950 - val_loss: 0.4292 - val_mse: 0.4225\n",
      "Epoch 415/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4915 - mse: 0.4848 - val_loss: 0.4400 - val_mse: 0.4333\n",
      "Epoch 416/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4940 - val_loss: 0.4387 - val_mse: 0.4320\n",
      "Epoch 417/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4941 - mse: 0.4874 - val_loss: 0.4339 - val_mse: 0.4272\n",
      "Epoch 418/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4960 - mse: 0.4893 - val_loss: 0.4304 - val_mse: 0.4237\n",
      "Epoch 419/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4939 - mse: 0.4872 - val_loss: 0.4365 - val_mse: 0.4298\n",
      "Epoch 420/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.5029 - mse: 0.4963\n",
      "Epoch 00420: saving model to Regression_Model/bl6.mle.linear-0420.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.5027 - mse: 0.4960 - val_loss: 0.4393 - val_mse: 0.4326\n",
      "Epoch 421/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4993 - mse: 0.4926 - val_loss: 0.4271 - val_mse: 0.4204\n",
      "Epoch 422/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4962 - mse: 0.4895 - val_loss: 0.4317 - val_mse: 0.4250\n",
      "Epoch 423/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5023 - mse: 0.4957 - val_loss: 0.4357 - val_mse: 0.4290\n",
      "Epoch 424/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4984 - mse: 0.4917 - val_loss: 0.4420 - val_mse: 0.4353\n",
      "Epoch 425/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5004 - mse: 0.4938 - val_loss: 0.4341 - val_mse: 0.4274\n",
      "Epoch 426/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4981 - mse: 0.4914 - val_loss: 0.4344 - val_mse: 0.4277\n",
      "Epoch 427/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4897 - mse: 0.4830 - val_loss: 0.4295 - val_mse: 0.4228\n",
      "Epoch 428/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5019 - mse: 0.4952 - val_loss: 0.4334 - val_mse: 0.4267\n",
      "Epoch 429/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4977 - mse: 0.4911 - val_loss: 0.4287 - val_mse: 0.4220\n",
      "Epoch 430/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4970 - mse: 0.4904\n",
      "Epoch 00430: saving model to Regression_Model/bl6.mle.linear-0430.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 0.4963 - mse: 0.4896 - val_loss: 0.4325 - val_mse: 0.4258\n",
      "Epoch 431/2000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4972 - mse: 0.4905 - val_loss: 0.4316 - val_mse: 0.4249\n",
      "Epoch 432/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4871 - val_loss: 0.4315 - val_mse: 0.4248\n",
      "Epoch 433/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4970 - mse: 0.4903 - val_loss: 0.4341 - val_mse: 0.4274\n",
      "Epoch 434/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4948 - mse: 0.4881 - val_loss: 0.4257 - val_mse: 0.4190\n",
      "Epoch 435/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4866 - val_loss: 0.4294 - val_mse: 0.4227\n",
      "Epoch 436/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4815 - val_loss: 0.4317 - val_mse: 0.4250\n",
      "Epoch 437/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4985 - mse: 0.4918 - val_loss: 0.4282 - val_mse: 0.4215\n",
      "Epoch 438/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4975 - mse: 0.4908 - val_loss: 0.4359 - val_mse: 0.4292\n",
      "Epoch 439/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4987 - mse: 0.4920 - val_loss: 0.4301 - val_mse: 0.4234\n",
      "Epoch 440/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4935 - mse: 0.4869\n",
      "Epoch 00440: saving model to Regression_Model/bl6.mle.linear-0440.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4937 - mse: 0.4870 - val_loss: 0.4293 - val_mse: 0.4226\n",
      "Epoch 441/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4901 - mse: 0.4835 - val_loss: 0.4361 - val_mse: 0.4294\n",
      "Epoch 442/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.5006 - mse: 0.4939 - val_loss: 0.4280 - val_mse: 0.4213\n",
      "Epoch 443/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4985 - mse: 0.4918 - val_loss: 0.4292 - val_mse: 0.4226\n",
      "Epoch 444/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4982 - mse: 0.4915 - val_loss: 0.4396 - val_mse: 0.4329\n",
      "Epoch 445/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4829 - val_loss: 0.4304 - val_mse: 0.4238\n",
      "Epoch 446/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4989 - mse: 0.4923 - val_loss: 0.4265 - val_mse: 0.4198\n",
      "Epoch 447/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4986 - mse: 0.4920 - val_loss: 0.4348 - val_mse: 0.4281\n",
      "Epoch 448/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4955 - mse: 0.4888 - val_loss: 0.4333 - val_mse: 0.4266\n",
      "Epoch 449/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4941 - mse: 0.4874 - val_loss: 0.4282 - val_mse: 0.4216\n",
      "Epoch 450/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4942 - mse: 0.4875\n",
      "Epoch 00450: saving model to Regression_Model/bl6.mle.linear-0450.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4962 - mse: 0.4895 - val_loss: 0.4279 - val_mse: 0.4212\n",
      "Epoch 451/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4990 - mse: 0.4923 - val_loss: 0.4312 - val_mse: 0.4245\n",
      "Epoch 452/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4953 - mse: 0.4887 - val_loss: 0.4336 - val_mse: 0.4269\n",
      "Epoch 453/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4876 - val_loss: 0.4285 - val_mse: 0.4218\n",
      "Epoch 454/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4903 - val_loss: 0.4310 - val_mse: 0.4244\n",
      "Epoch 455/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4947 - mse: 0.4881 - val_loss: 0.4342 - val_mse: 0.4275\n",
      "Epoch 456/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4965 - mse: 0.4899 - val_loss: 0.4291 - val_mse: 0.4224\n",
      "Epoch 457/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4920 - mse: 0.4854 - val_loss: 0.4285 - val_mse: 0.4219\n",
      "Epoch 458/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4923 - mse: 0.4856 - val_loss: 0.4327 - val_mse: 0.4260\n",
      "Epoch 459/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4946 - mse: 0.4879 - val_loss: 0.4288 - val_mse: 0.4222\n",
      "Epoch 460/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4991 - mse: 0.4924\n",
      "Epoch 00460: saving model to Regression_Model/bl6.mle.linear-0460.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.4971 - mse: 0.4905 - val_loss: 0.4392 - val_mse: 0.4325\n",
      "Epoch 461/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4894 - val_loss: 0.4384 - val_mse: 0.4318\n",
      "Epoch 462/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4964 - mse: 0.4898 - val_loss: 0.4243 - val_mse: 0.4177\n",
      "Epoch 463/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4852 - val_loss: 0.4345 - val_mse: 0.4279\n",
      "Epoch 464/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4828 - val_loss: 0.4263 - val_mse: 0.4196\n",
      "Epoch 465/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4925 - mse: 0.4858 - val_loss: 0.4346 - val_mse: 0.4280\n",
      "Epoch 466/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4958 - mse: 0.4892 - val_loss: 0.4280 - val_mse: 0.4213\n",
      "Epoch 467/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4939 - mse: 0.4872 - val_loss: 0.4259 - val_mse: 0.4193\n",
      "Epoch 468/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4869 - mse: 0.4803 - val_loss: 0.4308 - val_mse: 0.4242\n",
      "Epoch 469/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4944 - mse: 0.4878 - val_loss: 0.4259 - val_mse: 0.4192\n",
      "Epoch 470/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4938 - mse: 0.4871\n",
      "Epoch 00470: saving model to Regression_Model/bl6.mle.linear-0470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4935 - mse: 0.4869 - val_loss: 0.4263 - val_mse: 0.4196\n",
      "Epoch 471/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4841 - val_loss: 0.4336 - val_mse: 0.4269\n",
      "Epoch 472/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4917 - mse: 0.4850 - val_loss: 0.4339 - val_mse: 0.4273\n",
      "Epoch 473/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4898 - mse: 0.4832 - val_loss: 0.4280 - val_mse: 0.4214\n",
      "Epoch 474/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4902 - val_loss: 0.4238 - val_mse: 0.4171\n",
      "Epoch 475/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4946 - mse: 0.4879 - val_loss: 0.4268 - val_mse: 0.4202\n",
      "Epoch 476/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4877 - val_loss: 0.4278 - val_mse: 0.4211\n",
      "Epoch 477/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4942 - mse: 0.4876 - val_loss: 0.4343 - val_mse: 0.4276\n",
      "Epoch 478/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4893 - mse: 0.4826 - val_loss: 0.4281 - val_mse: 0.4214\n",
      "Epoch 479/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4893 - mse: 0.4827 - val_loss: 0.4258 - val_mse: 0.4191\n",
      "Epoch 480/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4962 - mse: 0.4896\n",
      "Epoch 00480: saving model to Regression_Model/bl6.mle.linear-0480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4959 - mse: 0.4893 - val_loss: 0.4304 - val_mse: 0.4237\n",
      "Epoch 481/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4951 - mse: 0.4884 - val_loss: 0.4323 - val_mse: 0.4256\n",
      "Epoch 482/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4904 - mse: 0.4837 - val_loss: 0.4282 - val_mse: 0.4215\n",
      "Epoch 483/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4980 - mse: 0.4913 - val_loss: 0.4278 - val_mse: 0.4212\n",
      "Epoch 484/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4954 - mse: 0.4887 - val_loss: 0.4281 - val_mse: 0.4214\n",
      "Epoch 485/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4971 - mse: 0.4904 - val_loss: 0.4319 - val_mse: 0.4252\n",
      "Epoch 486/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4938 - mse: 0.4872 - val_loss: 0.4276 - val_mse: 0.4209\n",
      "Epoch 487/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4905 - mse: 0.4838 - val_loss: 0.4282 - val_mse: 0.4216\n",
      "Epoch 488/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4891 - mse: 0.4824 - val_loss: 0.4318 - val_mse: 0.4251\n",
      "Epoch 489/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4855 - mse: 0.4788 - val_loss: 0.4307 - val_mse: 0.4241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4966 - mse: 0.4899\n",
      "Epoch 00490: saving model to Regression_Model/bl6.mle.linear-0490.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4959 - mse: 0.4892 - val_loss: 0.4306 - val_mse: 0.4240\n",
      "Epoch 491/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4827 - val_loss: 0.4292 - val_mse: 0.4226\n",
      "Epoch 492/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4921 - mse: 0.4854 - val_loss: 0.4299 - val_mse: 0.4232\n",
      "Epoch 493/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4983 - mse: 0.4917 - val_loss: 0.4343 - val_mse: 0.4277\n",
      "Epoch 494/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4935 - mse: 0.4869 - val_loss: 0.4265 - val_mse: 0.4198\n",
      "Epoch 495/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4833 - val_loss: 0.4316 - val_mse: 0.4250\n",
      "Epoch 496/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4934 - mse: 0.4867 - val_loss: 0.4291 - val_mse: 0.4225\n",
      "Epoch 497/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4924 - mse: 0.4857 - val_loss: 0.4288 - val_mse: 0.4222\n",
      "Epoch 498/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4923 - mse: 0.4856 - val_loss: 0.4246 - val_mse: 0.4180\n",
      "Epoch 499/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4911 - mse: 0.4844 - val_loss: 0.4238 - val_mse: 0.4171\n",
      "Epoch 500/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4885 - mse: 0.4818\n",
      "Epoch 00500: saving model to Regression_Model/bl6.mle.linear-0500.ckpt\n",
      "368/368 [==============================] - 5s 13ms/step - loss: 0.4885 - mse: 0.4818 - val_loss: 0.4266 - val_mse: 0.4200\n",
      "Epoch 501/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4985 - mse: 0.4918 - val_loss: 0.4211 - val_mse: 0.4145\n",
      "Epoch 502/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4886 - mse: 0.4819 - val_loss: 0.4261 - val_mse: 0.4195\n",
      "Epoch 503/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4928 - mse: 0.4862 - val_loss: 0.4251 - val_mse: 0.4185\n",
      "Epoch 504/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4883 - mse: 0.4816 - val_loss: 0.4243 - val_mse: 0.4177\n",
      "Epoch 505/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4979 - mse: 0.4912 - val_loss: 0.4269 - val_mse: 0.4202\n",
      "Epoch 506/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4934 - mse: 0.4867 - val_loss: 0.4223 - val_mse: 0.4157\n",
      "Epoch 507/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4895 - mse: 0.4829 - val_loss: 0.4262 - val_mse: 0.4196\n",
      "Epoch 508/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4902 - mse: 0.4836 - val_loss: 0.4293 - val_mse: 0.4226\n",
      "Epoch 509/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4909 - mse: 0.4842 - val_loss: 0.4273 - val_mse: 0.4207\n",
      "Epoch 510/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4962 - mse: 0.4895\n",
      "Epoch 00510: saving model to Regression_Model/bl6.mle.linear-0510.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.4970 - mse: 0.4903 - val_loss: 0.4290 - val_mse: 0.4223\n",
      "Epoch 511/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4877 - val_loss: 0.4352 - val_mse: 0.4285\n",
      "Epoch 512/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4930 - mse: 0.4863 - val_loss: 0.4282 - val_mse: 0.4215\n",
      "Epoch 513/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4911 - mse: 0.4845 - val_loss: 0.4296 - val_mse: 0.4230\n",
      "Epoch 514/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4897 - mse: 0.4831 - val_loss: 0.4327 - val_mse: 0.4261\n",
      "Epoch 515/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4981 - mse: 0.4915 - val_loss: 0.4255 - val_mse: 0.4189\n",
      "Epoch 516/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4938 - mse: 0.4872 - val_loss: 0.4258 - val_mse: 0.4192\n",
      "Epoch 517/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4926 - mse: 0.4859 - val_loss: 0.4277 - val_mse: 0.4210\n",
      "Epoch 518/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4965 - mse: 0.4898 - val_loss: 0.4330 - val_mse: 0.4264\n",
      "Epoch 519/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4882 - mse: 0.4815 - val_loss: 0.4253 - val_mse: 0.4187\n",
      "Epoch 520/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4915 - mse: 0.4848\n",
      "Epoch 00520: saving model to Regression_Model/bl6.mle.linear-0520.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4914 - mse: 0.4847 - val_loss: 0.4319 - val_mse: 0.4252\n",
      "Epoch 521/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4859 - mse: 0.4793 - val_loss: 0.4254 - val_mse: 0.4188\n",
      "Epoch 522/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4948 - mse: 0.4881 - val_loss: 0.4241 - val_mse: 0.4175\n",
      "Epoch 523/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4907 - mse: 0.4841 - val_loss: 0.4311 - val_mse: 0.4245\n",
      "Epoch 524/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4943 - mse: 0.4877 - val_loss: 0.4235 - val_mse: 0.4168\n",
      "Epoch 525/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4911 - mse: 0.4844 - val_loss: 0.4256 - val_mse: 0.4190\n",
      "Epoch 526/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4849 - val_loss: 0.4268 - val_mse: 0.4202\n",
      "Epoch 527/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4942 - mse: 0.4876 - val_loss: 0.4314 - val_mse: 0.4248\n",
      "Epoch 528/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4898 - mse: 0.4831 - val_loss: 0.4264 - val_mse: 0.4198\n",
      "Epoch 529/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4966 - mse: 0.4900 - val_loss: 0.4294 - val_mse: 0.4227\n",
      "Epoch 530/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4956 - mse: 0.4889\n",
      "Epoch 00530: saving model to Regression_Model/bl6.mle.linear-0530.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4969 - mse: 0.4903 - val_loss: 0.4224 - val_mse: 0.4157\n",
      "Epoch 531/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4849 - val_loss: 0.4299 - val_mse: 0.4232\n",
      "Epoch 532/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4920 - mse: 0.4854 - val_loss: 0.4276 - val_mse: 0.4210\n",
      "Epoch 533/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4905 - mse: 0.4838 - val_loss: 0.4309 - val_mse: 0.4243\n",
      "Epoch 534/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4837 - mse: 0.4770 - val_loss: 0.4296 - val_mse: 0.4229\n",
      "Epoch 535/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4898 - mse: 0.4832 - val_loss: 0.4219 - val_mse: 0.4153\n",
      "Epoch 536/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4929 - mse: 0.4862 - val_loss: 0.4351 - val_mse: 0.4285\n",
      "Epoch 537/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4947 - mse: 0.4880 - val_loss: 0.4249 - val_mse: 0.4182\n",
      "Epoch 538/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5000 - mse: 0.4933 - val_loss: 0.4282 - val_mse: 0.4215\n",
      "Epoch 539/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4886 - mse: 0.4819 - val_loss: 0.4224 - val_mse: 0.4158\n",
      "Epoch 540/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4939 - mse: 0.4873\n",
      "Epoch 00540: saving model to Regression_Model/bl6.mle.linear-0540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4938 - mse: 0.4871 - val_loss: 0.4274 - val_mse: 0.4208\n",
      "Epoch 541/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4971 - mse: 0.4905 - val_loss: 0.4224 - val_mse: 0.4158\n",
      "Epoch 542/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4920 - mse: 0.4853 - val_loss: 0.4289 - val_mse: 0.4223\n",
      "Epoch 543/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4942 - mse: 0.4876 - val_loss: 0.4252 - val_mse: 0.4186\n",
      "Epoch 544/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4898 - mse: 0.4832 - val_loss: 0.4266 - val_mse: 0.4199\n",
      "Epoch 545/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4910 - mse: 0.4844 - val_loss: 0.4315 - val_mse: 0.4249\n",
      "Epoch 546/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4964 - mse: 0.4897 - val_loss: 0.4268 - val_mse: 0.4202\n",
      "Epoch 547/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4812 - val_loss: 0.4265 - val_mse: 0.4198\n",
      "Epoch 548/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4956 - mse: 0.4889 - val_loss: 0.4263 - val_mse: 0.4196\n",
      "Epoch 549/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4961 - mse: 0.4895 - val_loss: 0.4268 - val_mse: 0.4202\n",
      "Epoch 550/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4895 - mse: 0.4828\n",
      "Epoch 00550: saving model to Regression_Model/bl6.mle.linear-0550.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.4897 - mse: 0.4830 - val_loss: 0.4318 - val_mse: 0.4252\n",
      "Epoch 551/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4850 - val_loss: 0.4241 - val_mse: 0.4175\n",
      "Epoch 552/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4781 - val_loss: 0.4228 - val_mse: 0.4162\n",
      "Epoch 553/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4939 - mse: 0.4872 - val_loss: 0.4290 - val_mse: 0.4224\n",
      "Epoch 554/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4918 - mse: 0.4852 - val_loss: 0.4297 - val_mse: 0.4231\n",
      "Epoch 555/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4901 - mse: 0.4835 - val_loss: 0.4236 - val_mse: 0.4170\n",
      "Epoch 556/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.5023 - mse: 0.4957 - val_loss: 0.4299 - val_mse: 0.4233\n",
      "Epoch 557/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4853 - mse: 0.4787 - val_loss: 0.4291 - val_mse: 0.4224\n",
      "Epoch 558/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4925 - mse: 0.4859 - val_loss: 0.4240 - val_mse: 0.4174\n",
      "Epoch 559/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4900 - mse: 0.4833 - val_loss: 0.4267 - val_mse: 0.4200\n",
      "Epoch 560/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4906 - mse: 0.4839\n",
      "Epoch 00560: saving model to Regression_Model/bl6.mle.linear-0560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4922 - mse: 0.4856 - val_loss: 0.4222 - val_mse: 0.4156\n",
      "Epoch 561/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4903 - mse: 0.4837 - val_loss: 0.4249 - val_mse: 0.4183\n",
      "Epoch 562/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4938 - mse: 0.4872 - val_loss: 0.4265 - val_mse: 0.4199\n",
      "Epoch 563/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4926 - mse: 0.4860 - val_loss: 0.4219 - val_mse: 0.4153\n",
      "Epoch 564/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4933 - mse: 0.4866 - val_loss: 0.4218 - val_mse: 0.4152\n",
      "Epoch 565/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4876 - mse: 0.4809 - val_loss: 0.4253 - val_mse: 0.4187\n",
      "Epoch 566/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4875 - mse: 0.4808 - val_loss: 0.4306 - val_mse: 0.4239\n",
      "Epoch 567/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4878 - mse: 0.4812 - val_loss: 0.4226 - val_mse: 0.4160\n",
      "Epoch 568/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4936 - mse: 0.4870 - val_loss: 0.4317 - val_mse: 0.4251\n",
      "Epoch 569/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4932 - mse: 0.4866 - val_loss: 0.4283 - val_mse: 0.4217\n",
      "Epoch 570/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4902 - mse: 0.4836\n",
      "Epoch 00570: saving model to Regression_Model/bl6.mle.linear-0570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4917 - mse: 0.4850 - val_loss: 0.4223 - val_mse: 0.4156\n",
      "Epoch 571/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4886 - mse: 0.4820 - val_loss: 0.4272 - val_mse: 0.4206\n",
      "Epoch 572/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4821 - val_loss: 0.4273 - val_mse: 0.4206\n",
      "Epoch 573/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4922 - mse: 0.4855 - val_loss: 0.4261 - val_mse: 0.4194\n",
      "Epoch 574/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4906 - mse: 0.4840 - val_loss: 0.4209 - val_mse: 0.4143\n",
      "Epoch 575/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4829 - val_loss: 0.4254 - val_mse: 0.4188\n",
      "Epoch 576/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4925 - mse: 0.4858 - val_loss: 0.4244 - val_mse: 0.4178\n",
      "Epoch 577/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4807 - val_loss: 0.4255 - val_mse: 0.4189\n",
      "Epoch 578/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4827 - mse: 0.4761 - val_loss: 0.4275 - val_mse: 0.4209\n",
      "Epoch 579/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4843 - mse: 0.4777 - val_loss: 0.4227 - val_mse: 0.4161\n",
      "Epoch 580/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4850 - mse: 0.4784\n",
      "Epoch 00580: saving model to Regression_Model/bl6.mle.linear-0580.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4853 - mse: 0.4787 - val_loss: 0.4240 - val_mse: 0.4174\n",
      "Epoch 581/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4897 - mse: 0.4831 - val_loss: 0.4282 - val_mse: 0.4216\n",
      "Epoch 582/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4855 - mse: 0.4789 - val_loss: 0.4196 - val_mse: 0.4130\n",
      "Epoch 583/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4939 - mse: 0.4873 - val_loss: 0.4211 - val_mse: 0.4145\n",
      "Epoch 584/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4906 - mse: 0.4840 - val_loss: 0.4264 - val_mse: 0.4198\n",
      "Epoch 585/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4919 - mse: 0.4853 - val_loss: 0.4245 - val_mse: 0.4179\n",
      "Epoch 586/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4918 - mse: 0.4852 - val_loss: 0.4229 - val_mse: 0.4163\n",
      "Epoch 587/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4902 - mse: 0.4836 - val_loss: 0.4234 - val_mse: 0.4168\n",
      "Epoch 588/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4923 - mse: 0.4857 - val_loss: 0.4248 - val_mse: 0.4181\n",
      "Epoch 589/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4898 - mse: 0.4832 - val_loss: 0.4261 - val_mse: 0.4195\n",
      "Epoch 590/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4850 - mse: 0.4784\n",
      "Epoch 00590: saving model to Regression_Model/bl6.mle.linear-0590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4797 - val_loss: 0.4226 - val_mse: 0.4160\n",
      "Epoch 591/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4961 - mse: 0.4895 - val_loss: 0.4300 - val_mse: 0.4234\n",
      "Epoch 592/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4852 - val_loss: 0.4269 - val_mse: 0.4203\n",
      "Epoch 593/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4851 - mse: 0.4785 - val_loss: 0.4266 - val_mse: 0.4200\n",
      "Epoch 594/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4907 - mse: 0.4841 - val_loss: 0.4353 - val_mse: 0.4287\n",
      "Epoch 595/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4841 - val_loss: 0.4227 - val_mse: 0.4160\n",
      "Epoch 596/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4982 - mse: 0.4916 - val_loss: 0.4213 - val_mse: 0.4147\n",
      "Epoch 597/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4953 - mse: 0.4887 - val_loss: 0.4274 - val_mse: 0.4208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4848 - mse: 0.4782 - val_loss: 0.4246 - val_mse: 0.4180\n",
      "Epoch 599/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4859 - mse: 0.4793 - val_loss: 0.4273 - val_mse: 0.4207\n",
      "Epoch 600/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4953 - mse: 0.4887\n",
      "Epoch 00600: saving model to Regression_Model/bl6.mle.linear-0600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4947 - mse: 0.4881 - val_loss: 0.4250 - val_mse: 0.4184\n",
      "Epoch 601/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4783 - val_loss: 0.4189 - val_mse: 0.4123\n",
      "Epoch 602/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4844 - val_loss: 0.4228 - val_mse: 0.4162\n",
      "Epoch 603/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4811 - val_loss: 0.4248 - val_mse: 0.4182\n",
      "Epoch 604/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4883 - mse: 0.4817 - val_loss: 0.4240 - val_mse: 0.4174\n",
      "Epoch 605/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4964 - mse: 0.4898 - val_loss: 0.4276 - val_mse: 0.4210\n",
      "Epoch 606/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4972 - mse: 0.4906 - val_loss: 0.4247 - val_mse: 0.4181\n",
      "Epoch 607/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4870 - mse: 0.4804 - val_loss: 0.4260 - val_mse: 0.4194\n",
      "Epoch 608/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4903 - mse: 0.4837 - val_loss: 0.4239 - val_mse: 0.4173\n",
      "Epoch 609/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4814 - val_loss: 0.4229 - val_mse: 0.4163\n",
      "Epoch 610/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4917 - mse: 0.4851\n",
      "Epoch 00610: saving model to Regression_Model/bl6.mle.linear-0610.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4918 - mse: 0.4852 - val_loss: 0.4232 - val_mse: 0.4166\n",
      "Epoch 611/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4808 - val_loss: 0.4243 - val_mse: 0.4177\n",
      "Epoch 612/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4865 - mse: 0.4799 - val_loss: 0.4242 - val_mse: 0.4177\n",
      "Epoch 613/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4903 - mse: 0.4838 - val_loss: 0.4244 - val_mse: 0.4179\n",
      "Epoch 614/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4855 - mse: 0.4789 - val_loss: 0.4251 - val_mse: 0.4185\n",
      "Epoch 615/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4890 - mse: 0.4824 - val_loss: 0.4228 - val_mse: 0.4162\n",
      "Epoch 616/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4900 - mse: 0.4834 - val_loss: 0.4255 - val_mse: 0.4189\n",
      "Epoch 617/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4908 - mse: 0.4843 - val_loss: 0.4264 - val_mse: 0.4199\n",
      "Epoch 618/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4823 - val_loss: 0.4241 - val_mse: 0.4175\n",
      "Epoch 619/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4883 - mse: 0.4817 - val_loss: 0.4235 - val_mse: 0.4169\n",
      "Epoch 620/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4949 - mse: 0.4883\n",
      "Epoch 00620: saving model to Regression_Model/bl6.mle.linear-0620.ckpt\n",
      "368/368 [==============================] - 4s 11ms/step - loss: 0.4928 - mse: 0.4862 - val_loss: 0.4182 - val_mse: 0.4116\n",
      "Epoch 621/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4951 - mse: 0.4885 - val_loss: 0.4290 - val_mse: 0.4224\n",
      "Epoch 622/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4879 - mse: 0.4813 - val_loss: 0.4240 - val_mse: 0.4174\n",
      "Epoch 623/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4836 - val_loss: 0.4326 - val_mse: 0.4260\n",
      "Epoch 624/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4926 - mse: 0.4860 - val_loss: 0.4270 - val_mse: 0.4204\n",
      "Epoch 625/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4896 - mse: 0.4830 - val_loss: 0.4198 - val_mse: 0.4132\n",
      "Epoch 626/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4836 - val_loss: 0.4219 - val_mse: 0.4154\n",
      "Epoch 627/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4909 - mse: 0.4844 - val_loss: 0.4236 - val_mse: 0.4171\n",
      "Epoch 628/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4790 - val_loss: 0.4211 - val_mse: 0.4145\n",
      "Epoch 629/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4944 - mse: 0.4878 - val_loss: 0.4221 - val_mse: 0.4155\n",
      "Epoch 630/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4825 - mse: 0.4760\n",
      "Epoch 00630: saving model to Regression_Model/bl6.mle.linear-0630.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4767 - val_loss: 0.4191 - val_mse: 0.4125\n",
      "Epoch 631/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4853 - val_loss: 0.4207 - val_mse: 0.4141\n",
      "Epoch 632/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4900 - mse: 0.4834 - val_loss: 0.4208 - val_mse: 0.4142\n",
      "Epoch 633/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4787 - val_loss: 0.4196 - val_mse: 0.4130\n",
      "Epoch 634/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4911 - mse: 0.4845 - val_loss: 0.4223 - val_mse: 0.4158\n",
      "Epoch 635/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4919 - mse: 0.4854 - val_loss: 0.4232 - val_mse: 0.4166\n",
      "Epoch 636/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4893 - mse: 0.4827 - val_loss: 0.4268 - val_mse: 0.4202\n",
      "Epoch 637/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4933 - mse: 0.4867 - val_loss: 0.4250 - val_mse: 0.4184\n",
      "Epoch 638/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4836 - mse: 0.4770 - val_loss: 0.4214 - val_mse: 0.4148\n",
      "Epoch 639/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4867 - mse: 0.4801 - val_loss: 0.4208 - val_mse: 0.4143\n",
      "Epoch 640/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4919 - mse: 0.4853\n",
      "Epoch 00640: saving model to Regression_Model/bl6.mle.linear-0640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4853 - val_loss: 0.4199 - val_mse: 0.4134\n",
      "Epoch 641/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4760 - val_loss: 0.4262 - val_mse: 0.4196\n",
      "Epoch 642/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4900 - mse: 0.4835 - val_loss: 0.4218 - val_mse: 0.4153\n",
      "Epoch 643/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4918 - mse: 0.4852 - val_loss: 0.4320 - val_mse: 0.4254\n",
      "Epoch 644/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4766 - val_loss: 0.4217 - val_mse: 0.4151\n",
      "Epoch 645/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4900 - mse: 0.4834 - val_loss: 0.4192 - val_mse: 0.4127\n",
      "Epoch 646/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4826 - val_loss: 0.4237 - val_mse: 0.4171\n",
      "Epoch 647/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4894 - mse: 0.4828 - val_loss: 0.4206 - val_mse: 0.4140\n",
      "Epoch 648/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4833 - val_loss: 0.4199 - val_mse: 0.4134\n",
      "Epoch 649/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4908 - mse: 0.4842 - val_loss: 0.4229 - val_mse: 0.4164\n",
      "Epoch 650/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4857 - mse: 0.4791\n",
      "Epoch 00650: saving model to Regression_Model/bl6.mle.linear-0650.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.4874 - mse: 0.4808 - val_loss: 0.4188 - val_mse: 0.4122\n",
      "Epoch 651/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4797 - val_loss: 0.4220 - val_mse: 0.4155\n",
      "Epoch 652/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4790 - val_loss: 0.4243 - val_mse: 0.4177\n",
      "Epoch 653/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4769 - val_loss: 0.4207 - val_mse: 0.4142\n",
      "Epoch 654/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4851 - mse: 0.4785 - val_loss: 0.4214 - val_mse: 0.4148\n",
      "Epoch 655/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4913 - mse: 0.4847 - val_loss: 0.4278 - val_mse: 0.4212\n",
      "Epoch 656/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4830 - val_loss: 0.4226 - val_mse: 0.4160\n",
      "Epoch 657/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4890 - mse: 0.4825 - val_loss: 0.4269 - val_mse: 0.4204\n",
      "Epoch 658/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4879 - mse: 0.4813 - val_loss: 0.4255 - val_mse: 0.4189\n",
      "Epoch 659/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4776 - val_loss: 0.4228 - val_mse: 0.4162\n",
      "Epoch 660/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4867 - mse: 0.4802\n",
      "Epoch 00660: saving model to Regression_Model/bl6.mle.linear-0660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4802 - val_loss: 0.4245 - val_mse: 0.4180\n",
      "Epoch 661/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4874 - mse: 0.4808 - val_loss: 0.4210 - val_mse: 0.4144\n",
      "Epoch 662/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4921 - mse: 0.4855 - val_loss: 0.4194 - val_mse: 0.4128\n",
      "Epoch 663/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4915 - mse: 0.4849 - val_loss: 0.4186 - val_mse: 0.4120\n",
      "Epoch 664/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4823 - mse: 0.4758 - val_loss: 0.4198 - val_mse: 0.4133\n",
      "Epoch 665/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4912 - mse: 0.4846 - val_loss: 0.4224 - val_mse: 0.4159\n",
      "Epoch 666/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4823 - val_loss: 0.4241 - val_mse: 0.4176\n",
      "Epoch 667/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4886 - mse: 0.4821 - val_loss: 0.4197 - val_mse: 0.4132\n",
      "Epoch 668/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4880 - mse: 0.4815 - val_loss: 0.4256 - val_mse: 0.4191\n",
      "Epoch 669/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4909 - mse: 0.4843 - val_loss: 0.4254 - val_mse: 0.4189\n",
      "Epoch 670/2000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.4839 - mse: 0.4773\n",
      "Epoch 00670: saving model to Regression_Model/bl6.mle.linear-0670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4860 - mse: 0.4794 - val_loss: 0.4192 - val_mse: 0.4127\n",
      "Epoch 671/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4748 - val_loss: 0.4328 - val_mse: 0.4263\n",
      "Epoch 672/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4908 - mse: 0.4843 - val_loss: 0.4237 - val_mse: 0.4171\n",
      "Epoch 673/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4859 - mse: 0.4794 - val_loss: 0.4227 - val_mse: 0.4162\n",
      "Epoch 674/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4755 - val_loss: 0.4260 - val_mse: 0.4195\n",
      "Epoch 675/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4910 - mse: 0.4844 - val_loss: 0.4319 - val_mse: 0.4254\n",
      "Epoch 676/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4912 - mse: 0.4847 - val_loss: 0.4213 - val_mse: 0.4148\n",
      "Epoch 677/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4888 - mse: 0.4823 - val_loss: 0.4208 - val_mse: 0.4142\n",
      "Epoch 678/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4934 - mse: 0.4868 - val_loss: 0.4209 - val_mse: 0.4144\n",
      "Epoch 679/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4886 - mse: 0.4821 - val_loss: 0.4239 - val_mse: 0.4174\n",
      "Epoch 680/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4901 - mse: 0.4836\n",
      "Epoch 00680: saving model to Regression_Model/bl6.mle.linear-0680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4830 - val_loss: 0.4255 - val_mse: 0.4189\n",
      "Epoch 681/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4882 - mse: 0.4817 - val_loss: 0.4266 - val_mse: 0.4201\n",
      "Epoch 682/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4860 - mse: 0.4795 - val_loss: 0.4212 - val_mse: 0.4146\n",
      "Epoch 683/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4945 - mse: 0.4880 - val_loss: 0.4248 - val_mse: 0.4182\n",
      "Epoch 684/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4786 - val_loss: 0.4233 - val_mse: 0.4167\n",
      "Epoch 685/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4753 - val_loss: 0.4178 - val_mse: 0.4112\n",
      "Epoch 686/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4907 - mse: 0.4841 - val_loss: 0.4296 - val_mse: 0.4231\n",
      "Epoch 687/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4862 - mse: 0.4796 - val_loss: 0.4212 - val_mse: 0.4147\n",
      "Epoch 688/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4894 - mse: 0.4828 - val_loss: 0.4267 - val_mse: 0.4201\n",
      "Epoch 689/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4877 - mse: 0.4812 - val_loss: 0.4272 - val_mse: 0.4206\n",
      "Epoch 690/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4892 - mse: 0.4826\n",
      "Epoch 00690: saving model to Regression_Model/bl6.mle.linear-0690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4819 - val_loss: 0.4263 - val_mse: 0.4198\n",
      "Epoch 691/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4917 - mse: 0.4852 - val_loss: 0.4216 - val_mse: 0.4151\n",
      "Epoch 692/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4798 - val_loss: 0.4198 - val_mse: 0.4133\n",
      "Epoch 693/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4772 - val_loss: 0.4216 - val_mse: 0.4151\n",
      "Epoch 694/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4915 - mse: 0.4850 - val_loss: 0.4255 - val_mse: 0.4189\n",
      "Epoch 695/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4884 - mse: 0.4819 - val_loss: 0.4194 - val_mse: 0.4129\n",
      "Epoch 696/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4759 - val_loss: 0.4233 - val_mse: 0.4168\n",
      "Epoch 697/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4844 - mse: 0.4779 - val_loss: 0.4222 - val_mse: 0.4157\n",
      "Epoch 698/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4923 - mse: 0.4858 - val_loss: 0.4194 - val_mse: 0.4128\n",
      "Epoch 699/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4771 - val_loss: 0.4211 - val_mse: 0.4146\n",
      "Epoch 700/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4783 - mse: 0.4717\n",
      "Epoch 00700: saving model to Regression_Model/bl6.mle.linear-0700.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4739 - val_loss: 0.4173 - val_mse: 0.4108\n",
      "Epoch 701/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4818 - val_loss: 0.4232 - val_mse: 0.4167\n",
      "Epoch 702/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4892 - mse: 0.4826 - val_loss: 0.4253 - val_mse: 0.4187\n",
      "Epoch 703/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4891 - mse: 0.4826 - val_loss: 0.4218 - val_mse: 0.4152\n",
      "Epoch 704/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4829 - val_loss: 0.4216 - val_mse: 0.4150\n",
      "Epoch 705/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4936 - mse: 0.4871 - val_loss: 0.4234 - val_mse: 0.4169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 706/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4909 - mse: 0.4844 - val_loss: 0.4220 - val_mse: 0.4155\n",
      "Epoch 707/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4744 - val_loss: 0.4238 - val_mse: 0.4173\n",
      "Epoch 708/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4950 - mse: 0.4885 - val_loss: 0.4243 - val_mse: 0.4178\n",
      "Epoch 709/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4725 - val_loss: 0.4188 - val_mse: 0.4123\n",
      "Epoch 710/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4908 - mse: 0.4843\n",
      "Epoch 00710: saving model to Regression_Model/bl6.mle.linear-0710.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4818 - val_loss: 0.4265 - val_mse: 0.4200\n",
      "Epoch 711/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4777 - val_loss: 0.4196 - val_mse: 0.4131\n",
      "Epoch 712/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4835 - mse: 0.4769 - val_loss: 0.4228 - val_mse: 0.4163\n",
      "Epoch 713/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4855 - mse: 0.4790 - val_loss: 0.4200 - val_mse: 0.4135\n",
      "Epoch 714/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4915 - mse: 0.4850 - val_loss: 0.4218 - val_mse: 0.4153\n",
      "Epoch 715/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4895 - mse: 0.4829 - val_loss: 0.4213 - val_mse: 0.4148\n",
      "Epoch 716/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4863 - mse: 0.4798 - val_loss: 0.4213 - val_mse: 0.4148\n",
      "Epoch 717/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4871 - mse: 0.4806 - val_loss: 0.4211 - val_mse: 0.4146\n",
      "Epoch 718/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4750 - val_loss: 0.4235 - val_mse: 0.4169\n",
      "Epoch 719/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4850 - mse: 0.4785 - val_loss: 0.4187 - val_mse: 0.4122\n",
      "Epoch 720/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4838 - mse: 0.4773\n",
      "Epoch 00720: saving model to Regression_Model/bl6.mle.linear-0720.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4865 - mse: 0.4800 - val_loss: 0.4224 - val_mse: 0.4159\n",
      "Epoch 721/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4817 - mse: 0.4752 - val_loss: 0.4206 - val_mse: 0.4141\n",
      "Epoch 722/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4820 - mse: 0.4755 - val_loss: 0.4188 - val_mse: 0.4122\n",
      "Epoch 723/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4785 - val_loss: 0.4184 - val_mse: 0.4119\n",
      "Epoch 724/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4899 - mse: 0.4834 - val_loss: 0.4213 - val_mse: 0.4148\n",
      "Epoch 725/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4826 - val_loss: 0.4229 - val_mse: 0.4164\n",
      "Epoch 726/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4798 - val_loss: 0.4226 - val_mse: 0.4161\n",
      "Epoch 727/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4860 - mse: 0.4795 - val_loss: 0.4195 - val_mse: 0.4130\n",
      "Epoch 728/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4850 - mse: 0.4785 - val_loss: 0.4212 - val_mse: 0.4147\n",
      "Epoch 729/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4892 - mse: 0.4827 - val_loss: 0.4200 - val_mse: 0.4135\n",
      "Epoch 730/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4808 - mse: 0.4743\n",
      "Epoch 00730: saving model to Regression_Model/bl6.mle.linear-0730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4753 - val_loss: 0.4205 - val_mse: 0.4139\n",
      "Epoch 731/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4808 - mse: 0.4742 - val_loss: 0.4204 - val_mse: 0.4139\n",
      "Epoch 732/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4815 - val_loss: 0.4200 - val_mse: 0.4135\n",
      "Epoch 733/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4848 - mse: 0.4783 - val_loss: 0.4194 - val_mse: 0.4129\n",
      "Epoch 734/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4863 - mse: 0.4798 - val_loss: 0.4227 - val_mse: 0.4162\n",
      "Epoch 735/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4862 - mse: 0.4796 - val_loss: 0.4208 - val_mse: 0.4143\n",
      "Epoch 736/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4905 - mse: 0.4840 - val_loss: 0.4193 - val_mse: 0.4128\n",
      "Epoch 737/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4857 - mse: 0.4791 - val_loss: 0.4208 - val_mse: 0.4143\n",
      "Epoch 738/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4861 - mse: 0.4795 - val_loss: 0.4211 - val_mse: 0.4145\n",
      "Epoch 739/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4841 - mse: 0.4776 - val_loss: 0.4194 - val_mse: 0.4129\n",
      "Epoch 740/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4833 - mse: 0.4768\n",
      "Epoch 00740: saving model to Regression_Model/bl6.mle.linear-0740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4767 - val_loss: 0.4196 - val_mse: 0.4131\n",
      "Epoch 741/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4879 - mse: 0.4814 - val_loss: 0.4258 - val_mse: 0.4193\n",
      "Epoch 742/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4886 - mse: 0.4821 - val_loss: 0.4230 - val_mse: 0.4165\n",
      "Epoch 743/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4798 - val_loss: 0.4246 - val_mse: 0.4181\n",
      "Epoch 744/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4871 - mse: 0.4806 - val_loss: 0.4198 - val_mse: 0.4133\n",
      "Epoch 745/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4869 - mse: 0.4804 - val_loss: 0.4228 - val_mse: 0.4163\n",
      "Epoch 746/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4970 - mse: 0.4904 - val_loss: 0.4198 - val_mse: 0.4133\n",
      "Epoch 747/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4852 - mse: 0.4787 - val_loss: 0.4183 - val_mse: 0.4118\n",
      "Epoch 748/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4785 - val_loss: 0.4176 - val_mse: 0.4111\n",
      "Epoch 749/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4754 - val_loss: 0.4167 - val_mse: 0.4102\n",
      "Epoch 750/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4839 - mse: 0.4774\n",
      "Epoch 00750: saving model to Regression_Model/bl6.mle.linear-0750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4769 - val_loss: 0.4220 - val_mse: 0.4155\n",
      "Epoch 751/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4803 - val_loss: 0.4220 - val_mse: 0.4155\n",
      "Epoch 752/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4885 - mse: 0.4820 - val_loss: 0.4169 - val_mse: 0.4104\n",
      "Epoch 753/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4839 - mse: 0.4774 - val_loss: 0.4173 - val_mse: 0.4108\n",
      "Epoch 754/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4824 - mse: 0.4759 - val_loss: 0.4184 - val_mse: 0.4119\n",
      "Epoch 755/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4823 - mse: 0.4758 - val_loss: 0.4171 - val_mse: 0.4106\n",
      "Epoch 756/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4833 - mse: 0.4768 - val_loss: 0.4187 - val_mse: 0.4122\n",
      "Epoch 757/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4816 - mse: 0.4751 - val_loss: 0.4181 - val_mse: 0.4116\n",
      "Epoch 758/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4802 - mse: 0.4737 - val_loss: 0.4201 - val_mse: 0.4136\n",
      "Epoch 759/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4866 - mse: 0.4801 - val_loss: 0.4212 - val_mse: 0.4147\n",
      "Epoch 760/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/368 [============================>.] - ETA: 0s - loss: 0.4907 - mse: 0.4842\n",
      "Epoch 00760: saving model to Regression_Model/bl6.mle.linear-0760.ckpt\n",
      "368/368 [==============================] - 4s 11ms/step - loss: 0.4921 - mse: 0.4856 - val_loss: 0.4176 - val_mse: 0.4111\n",
      "Epoch 761/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4866 - mse: 0.4801 - val_loss: 0.4197 - val_mse: 0.4132\n",
      "Epoch 762/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4772 - val_loss: 0.4221 - val_mse: 0.4156\n",
      "Epoch 763/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4861 - mse: 0.4796 - val_loss: 0.4192 - val_mse: 0.4127\n",
      "Epoch 764/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4881 - mse: 0.4816 - val_loss: 0.4177 - val_mse: 0.4112\n",
      "Epoch 765/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4799 - val_loss: 0.4219 - val_mse: 0.4154\n",
      "Epoch 766/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4830 - mse: 0.4765 - val_loss: 0.4185 - val_mse: 0.4120\n",
      "Epoch 767/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4791 - val_loss: 0.4205 - val_mse: 0.4140\n",
      "Epoch 768/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4861 - mse: 0.4796 - val_loss: 0.4210 - val_mse: 0.4145\n",
      "Epoch 769/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4796 - mse: 0.4731 - val_loss: 0.4168 - val_mse: 0.4103\n",
      "Epoch 770/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4860 - mse: 0.4796\n",
      "Epoch 00770: saving model to Regression_Model/bl6.mle.linear-0770.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4860 - mse: 0.4795 - val_loss: 0.4209 - val_mse: 0.4144\n",
      "Epoch 771/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4751 - val_loss: 0.4178 - val_mse: 0.4113\n",
      "Epoch 772/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4912 - mse: 0.4847 - val_loss: 0.4194 - val_mse: 0.4129\n",
      "Epoch 773/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4879 - mse: 0.4814 - val_loss: 0.4214 - val_mse: 0.4149\n",
      "Epoch 774/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4822 - mse: 0.4757 - val_loss: 0.4184 - val_mse: 0.4119\n",
      "Epoch 775/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4769 - val_loss: 0.4215 - val_mse: 0.4150\n",
      "Epoch 776/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4857 - mse: 0.4792 - val_loss: 0.4203 - val_mse: 0.4138\n",
      "Epoch 777/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4831 - val_loss: 0.4207 - val_mse: 0.4142\n",
      "Epoch 778/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4873 - mse: 0.4808 - val_loss: 0.4240 - val_mse: 0.4175\n",
      "Epoch 779/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4755 - val_loss: 0.4191 - val_mse: 0.4126\n",
      "Epoch 780/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4854 - mse: 0.4789\n",
      "Epoch 00780: saving model to Regression_Model/bl6.mle.linear-0780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4846 - mse: 0.4781 - val_loss: 0.4201 - val_mse: 0.4136\n",
      "Epoch 781/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4780 - val_loss: 0.4173 - val_mse: 0.4108\n",
      "Epoch 782/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4756 - val_loss: 0.4176 - val_mse: 0.4111\n",
      "Epoch 783/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4899 - mse: 0.4834 - val_loss: 0.4197 - val_mse: 0.4132\n",
      "Epoch 784/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4865 - mse: 0.4800 - val_loss: 0.4217 - val_mse: 0.4152\n",
      "Epoch 785/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4764 - val_loss: 0.4202 - val_mse: 0.4138\n",
      "Epoch 786/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4864 - mse: 0.4799 - val_loss: 0.4174 - val_mse: 0.4109\n",
      "Epoch 787/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4791 - val_loss: 0.4269 - val_mse: 0.4204\n",
      "Epoch 788/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4877 - mse: 0.4812 - val_loss: 0.4194 - val_mse: 0.4129\n",
      "Epoch 789/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4907 - mse: 0.4842 - val_loss: 0.4214 - val_mse: 0.4149\n",
      "Epoch 790/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4827 - mse: 0.4762\n",
      "Epoch 00790: saving model to Regression_Model/bl6.mle.linear-0790.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4807 - mse: 0.4742 - val_loss: 0.4172 - val_mse: 0.4107\n",
      "Epoch 791/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4756 - val_loss: 0.4171 - val_mse: 0.4106\n",
      "Epoch 792/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4827 - mse: 0.4762 - val_loss: 0.4184 - val_mse: 0.4119\n",
      "Epoch 793/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4811 - val_loss: 0.4197 - val_mse: 0.4133\n",
      "Epoch 794/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4873 - mse: 0.4809 - val_loss: 0.4193 - val_mse: 0.4128\n",
      "Epoch 795/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4916 - mse: 0.4851 - val_loss: 0.4178 - val_mse: 0.4113\n",
      "Epoch 796/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4852 - mse: 0.4787 - val_loss: 0.4185 - val_mse: 0.4121\n",
      "Epoch 797/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4796 - mse: 0.4731 - val_loss: 0.4170 - val_mse: 0.4106\n",
      "Epoch 798/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4806 - val_loss: 0.4203 - val_mse: 0.4138\n",
      "Epoch 799/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4823 - val_loss: 0.4185 - val_mse: 0.4120\n",
      "Epoch 800/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4844 - mse: 0.4779\n",
      "Epoch 00800: saving model to Regression_Model/bl6.mle.linear-0800.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4843 - mse: 0.4778 - val_loss: 0.4172 - val_mse: 0.4107\n",
      "Epoch 801/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4793 - val_loss: 0.4200 - val_mse: 0.4135\n",
      "Epoch 802/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4763 - val_loss: 0.4195 - val_mse: 0.4130\n",
      "Epoch 803/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4769 - val_loss: 0.4170 - val_mse: 0.4105\n",
      "Epoch 804/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4759 - val_loss: 0.4215 - val_mse: 0.4151\n",
      "Epoch 805/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4858 - mse: 0.4793 - val_loss: 0.4172 - val_mse: 0.4107\n",
      "Epoch 806/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4881 - mse: 0.4816 - val_loss: 0.4176 - val_mse: 0.4112\n",
      "Epoch 807/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4878 - mse: 0.4813 - val_loss: 0.4182 - val_mse: 0.4117\n",
      "Epoch 808/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4824 - val_loss: 0.4161 - val_mse: 0.4096\n",
      "Epoch 809/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4776 - val_loss: 0.4183 - val_mse: 0.4119\n",
      "Epoch 810/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4902 - mse: 0.4837\n",
      "Epoch 00810: saving model to Regression_Model/bl6.mle.linear-0810.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4819 - val_loss: 0.4188 - val_mse: 0.4123\n",
      "Epoch 811/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4908 - mse: 0.4844 - val_loss: 0.4199 - val_mse: 0.4135\n",
      "Epoch 812/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4905 - mse: 0.4841 - val_loss: 0.4201 - val_mse: 0.4137\n",
      "Epoch 813/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4874 - mse: 0.4809 - val_loss: 0.4229 - val_mse: 0.4164\n",
      "Epoch 814/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4820 - mse: 0.4756 - val_loss: 0.4187 - val_mse: 0.4122\n",
      "Epoch 815/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4754 - val_loss: 0.4191 - val_mse: 0.4127\n",
      "Epoch 816/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4735 - val_loss: 0.4182 - val_mse: 0.4118\n",
      "Epoch 817/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4880 - mse: 0.4815 - val_loss: 0.4215 - val_mse: 0.4150\n",
      "Epoch 818/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4854 - mse: 0.4789 - val_loss: 0.4177 - val_mse: 0.4113\n",
      "Epoch 819/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4856 - mse: 0.4791 - val_loss: 0.4159 - val_mse: 0.4094\n",
      "Epoch 820/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4849 - mse: 0.4784\n",
      "Epoch 00820: saving model to Regression_Model/bl6.mle.linear-0820.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4777 - val_loss: 0.4209 - val_mse: 0.4144\n",
      "Epoch 821/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4769 - mse: 0.4705 - val_loss: 0.4169 - val_mse: 0.4105\n",
      "Epoch 822/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4771 - val_loss: 0.4191 - val_mse: 0.4126\n",
      "Epoch 823/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4800 - mse: 0.4735 - val_loss: 0.4175 - val_mse: 0.4111\n",
      "Epoch 824/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4765 - val_loss: 0.4153 - val_mse: 0.4088\n",
      "Epoch 825/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4843 - mse: 0.4779 - val_loss: 0.4182 - val_mse: 0.4117\n",
      "Epoch 826/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4755 - val_loss: 0.4163 - val_mse: 0.4099\n",
      "Epoch 827/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4844 - mse: 0.4779 - val_loss: 0.4157 - val_mse: 0.4092\n",
      "Epoch 828/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4882 - mse: 0.4817 - val_loss: 0.4218 - val_mse: 0.4153\n",
      "Epoch 829/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4911 - mse: 0.4846 - val_loss: 0.4189 - val_mse: 0.4124\n",
      "Epoch 830/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4810 - mse: 0.4745\n",
      "Epoch 00830: saving model to Regression_Model/bl6.mle.linear-0830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4738 - val_loss: 0.4181 - val_mse: 0.4116\n",
      "Epoch 831/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4881 - mse: 0.4816 - val_loss: 0.4198 - val_mse: 0.4134\n",
      "Epoch 832/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4707 - val_loss: 0.4168 - val_mse: 0.4103\n",
      "Epoch 833/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4763 - val_loss: 0.4222 - val_mse: 0.4157\n",
      "Epoch 834/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4764 - val_loss: 0.4195 - val_mse: 0.4130\n",
      "Epoch 835/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4736 - val_loss: 0.4160 - val_mse: 0.4095\n",
      "Epoch 836/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4720 - val_loss: 0.4208 - val_mse: 0.4143\n",
      "Epoch 837/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4786 - val_loss: 0.4143 - val_mse: 0.4078\n",
      "Epoch 838/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4783 - val_loss: 0.4190 - val_mse: 0.4125\n",
      "Epoch 839/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4811 - mse: 0.4747 - val_loss: 0.4181 - val_mse: 0.4116\n",
      "Epoch 840/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4841 - mse: 0.4776\n",
      "Epoch 00840: saving model to Regression_Model/bl6.mle.linear-0840.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4766 - val_loss: 0.4242 - val_mse: 0.4177\n",
      "Epoch 841/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4753 - val_loss: 0.4161 - val_mse: 0.4097\n",
      "Epoch 842/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4755 - val_loss: 0.4166 - val_mse: 0.4101\n",
      "Epoch 843/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4912 - mse: 0.4847 - val_loss: 0.4180 - val_mse: 0.4115\n",
      "Epoch 844/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4890 - mse: 0.4825 - val_loss: 0.4182 - val_mse: 0.4117\n",
      "Epoch 845/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4830 - val_loss: 0.4201 - val_mse: 0.4136\n",
      "Epoch 846/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4889 - mse: 0.4824 - val_loss: 0.4206 - val_mse: 0.4141\n",
      "Epoch 847/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4781 - val_loss: 0.4158 - val_mse: 0.4094\n",
      "Epoch 848/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4798 - val_loss: 0.4152 - val_mse: 0.4088\n",
      "Epoch 849/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4854 - mse: 0.4789 - val_loss: 0.4203 - val_mse: 0.4139\n",
      "Epoch 850/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4840 - mse: 0.4776\n",
      "Epoch 00850: saving model to Regression_Model/bl6.mle.linear-0850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4771 - val_loss: 0.4158 - val_mse: 0.4093\n",
      "Epoch 851/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4788 - val_loss: 0.4172 - val_mse: 0.4107\n",
      "Epoch 852/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4801 - mse: 0.4737 - val_loss: 0.4173 - val_mse: 0.4109\n",
      "Epoch 853/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4893 - mse: 0.4829 - val_loss: 0.4231 - val_mse: 0.4167\n",
      "Epoch 854/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4871 - mse: 0.4807 - val_loss: 0.4212 - val_mse: 0.4147\n",
      "Epoch 855/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4798 - val_loss: 0.4193 - val_mse: 0.4129\n",
      "Epoch 856/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4855 - mse: 0.4791 - val_loss: 0.4149 - val_mse: 0.4084\n",
      "Epoch 857/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4753 - mse: 0.4689 - val_loss: 0.4170 - val_mse: 0.4106\n",
      "Epoch 858/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4830 - val_loss: 0.4162 - val_mse: 0.4098\n",
      "Epoch 859/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4803 - val_loss: 0.4203 - val_mse: 0.4138\n",
      "Epoch 860/2000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.4778 - mse: 0.4714\n",
      "Epoch 00860: saving model to Regression_Model/bl6.mle.linear-0860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4730 - val_loss: 0.4166 - val_mse: 0.4102\n",
      "Epoch 861/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4700 - val_loss: 0.4170 - val_mse: 0.4106\n",
      "Epoch 862/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4859 - mse: 0.4795 - val_loss: 0.4234 - val_mse: 0.4169\n",
      "Epoch 863/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4866 - mse: 0.4802 - val_loss: 0.4213 - val_mse: 0.4149\n",
      "Epoch 864/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4822 - mse: 0.4757 - val_loss: 0.4206 - val_mse: 0.4141\n",
      "Epoch 865/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4847 - mse: 0.4782 - val_loss: 0.4150 - val_mse: 0.4086\n",
      "Epoch 866/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4812 - mse: 0.4748 - val_loss: 0.4178 - val_mse: 0.4114\n",
      "Epoch 867/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4739 - val_loss: 0.4189 - val_mse: 0.4124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4848 - mse: 0.4784 - val_loss: 0.4197 - val_mse: 0.4132\n",
      "Epoch 869/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4837 - val_loss: 0.4156 - val_mse: 0.4091\n",
      "Epoch 870/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4781 - mse: 0.4716\n",
      "Epoch 00870: saving model to Regression_Model/bl6.mle.linear-0870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4747 - val_loss: 0.4214 - val_mse: 0.4149\n",
      "Epoch 871/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4775 - val_loss: 0.4174 - val_mse: 0.4110\n",
      "Epoch 872/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4842 - mse: 0.4778 - val_loss: 0.4188 - val_mse: 0.4124\n",
      "Epoch 873/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4852 - mse: 0.4788 - val_loss: 0.4163 - val_mse: 0.4099\n",
      "Epoch 874/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4752 - mse: 0.4688 - val_loss: 0.4168 - val_mse: 0.4104\n",
      "Epoch 875/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4748 - val_loss: 0.4188 - val_mse: 0.4123\n",
      "Epoch 876/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4840 - mse: 0.4775 - val_loss: 0.4175 - val_mse: 0.4110\n",
      "Epoch 877/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4872 - mse: 0.4808 - val_loss: 0.4213 - val_mse: 0.4148\n",
      "Epoch 878/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4902 - mse: 0.4838 - val_loss: 0.4239 - val_mse: 0.4175\n",
      "Epoch 879/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4702 - val_loss: 0.4171 - val_mse: 0.4107\n",
      "Epoch 880/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4817 - mse: 0.4753\n",
      "Epoch 00880: saving model to Regression_Model/bl6.mle.linear-0880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4743 - val_loss: 0.4207 - val_mse: 0.4142\n",
      "Epoch 881/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4909 - mse: 0.4844 - val_loss: 0.4209 - val_mse: 0.4145\n",
      "Epoch 882/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4709 - val_loss: 0.4156 - val_mse: 0.4091\n",
      "Epoch 883/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4703 - val_loss: 0.4151 - val_mse: 0.4087\n",
      "Epoch 884/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4743 - val_loss: 0.4164 - val_mse: 0.4100\n",
      "Epoch 885/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4840 - mse: 0.4775 - val_loss: 0.4172 - val_mse: 0.4107\n",
      "Epoch 886/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4724 - val_loss: 0.4148 - val_mse: 0.4083\n",
      "Epoch 887/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4870 - mse: 0.4806 - val_loss: 0.4198 - val_mse: 0.4134\n",
      "Epoch 888/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4789 - mse: 0.4725 - val_loss: 0.4206 - val_mse: 0.4142\n",
      "Epoch 889/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4769 - val_loss: 0.4168 - val_mse: 0.4104\n",
      "Epoch 890/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4854 - mse: 0.4789\n",
      "Epoch 00890: saving model to Regression_Model/bl6.mle.linear-0890.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4836 - mse: 0.4771 - val_loss: 0.4183 - val_mse: 0.4118\n",
      "Epoch 891/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4749 - val_loss: 0.4202 - val_mse: 0.4138\n",
      "Epoch 892/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4763 - val_loss: 0.4193 - val_mse: 0.4129\n",
      "Epoch 893/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4771 - val_loss: 0.4169 - val_mse: 0.4104\n",
      "Epoch 894/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4726 - val_loss: 0.4186 - val_mse: 0.4122\n",
      "Epoch 895/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4833 - mse: 0.4768 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 896/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4783 - mse: 0.4719 - val_loss: 0.4189 - val_mse: 0.4124\n",
      "Epoch 897/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4780 - mse: 0.4715 - val_loss: 0.4180 - val_mse: 0.4115\n",
      "Epoch 898/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4776 - mse: 0.4711 - val_loss: 0.4192 - val_mse: 0.4128\n",
      "Epoch 899/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4718 - val_loss: 0.4169 - val_mse: 0.4104\n",
      "Epoch 900/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4850 - mse: 0.4786\n",
      "Epoch 00900: saving model to Regression_Model/bl6.mle.linear-0900.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4857 - mse: 0.4793 - val_loss: 0.4199 - val_mse: 0.4134\n",
      "Epoch 901/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4817 - mse: 0.4752 - val_loss: 0.4135 - val_mse: 0.4071\n",
      "Epoch 902/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4800 - val_loss: 0.4165 - val_mse: 0.4101\n",
      "Epoch 903/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4789 - val_loss: 0.4138 - val_mse: 0.4074\n",
      "Epoch 904/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4818 - mse: 0.4754 - val_loss: 0.4175 - val_mse: 0.4111\n",
      "Epoch 905/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4827 - mse: 0.4763 - val_loss: 0.4156 - val_mse: 0.4092\n",
      "Epoch 906/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4854 - mse: 0.4789 - val_loss: 0.4140 - val_mse: 0.4076\n",
      "Epoch 907/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4866 - mse: 0.4802 - val_loss: 0.4195 - val_mse: 0.4130\n",
      "Epoch 908/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4813 - mse: 0.4749 - val_loss: 0.4173 - val_mse: 0.4109\n",
      "Epoch 909/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4817 - mse: 0.4753 - val_loss: 0.4179 - val_mse: 0.4115\n",
      "Epoch 910/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4848 - mse: 0.4784\n",
      "Epoch 00910: saving model to Regression_Model/bl6.mle.linear-0910.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4865 - mse: 0.4800 - val_loss: 0.4136 - val_mse: 0.4071\n",
      "Epoch 911/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4894 - mse: 0.4829 - val_loss: 0.4166 - val_mse: 0.4102\n",
      "Epoch 912/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4761 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 913/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4767 - val_loss: 0.4149 - val_mse: 0.4085\n",
      "Epoch 914/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4836 - mse: 0.4771 - val_loss: 0.4176 - val_mse: 0.4112\n",
      "Epoch 915/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4826 - mse: 0.4762 - val_loss: 0.4169 - val_mse: 0.4105\n",
      "Epoch 916/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4850 - mse: 0.4786 - val_loss: 0.4153 - val_mse: 0.4088\n",
      "Epoch 917/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4739 - mse: 0.4674 - val_loss: 0.4177 - val_mse: 0.4113\n",
      "Epoch 918/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4827 - mse: 0.4763 - val_loss: 0.4182 - val_mse: 0.4118\n",
      "Epoch 919/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4817 - mse: 0.4752 - val_loss: 0.4159 - val_mse: 0.4095\n",
      "Epoch 920/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4865 - mse: 0.4801\n",
      "Epoch 00920: saving model to Regression_Model/bl6.mle.linear-0920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4804 - val_loss: 0.4124 - val_mse: 0.4059\n",
      "Epoch 921/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4872 - mse: 0.4807 - val_loss: 0.4158 - val_mse: 0.4094\n",
      "Epoch 922/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4747 - val_loss: 0.4143 - val_mse: 0.4079\n",
      "Epoch 923/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4799 - val_loss: 0.4162 - val_mse: 0.4098\n",
      "Epoch 924/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4853 - mse: 0.4788 - val_loss: 0.4181 - val_mse: 0.4117\n",
      "Epoch 925/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4899 - mse: 0.4835 - val_loss: 0.4151 - val_mse: 0.4087\n",
      "Epoch 926/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4848 - mse: 0.4784 - val_loss: 0.4152 - val_mse: 0.4088\n",
      "Epoch 927/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4769 - val_loss: 0.4160 - val_mse: 0.4096\n",
      "Epoch 928/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4778 - mse: 0.4713 - val_loss: 0.4166 - val_mse: 0.4102\n",
      "Epoch 929/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4787 - val_loss: 0.4162 - val_mse: 0.4097\n",
      "Epoch 930/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4849 - mse: 0.4784\n",
      "Epoch 00930: saving model to Regression_Model/bl6.mle.linear-0930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4781 - val_loss: 0.4153 - val_mse: 0.4088\n",
      "Epoch 931/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4787 - val_loss: 0.4176 - val_mse: 0.4112\n",
      "Epoch 932/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4730 - val_loss: 0.4183 - val_mse: 0.4119\n",
      "Epoch 933/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4847 - mse: 0.4783 - val_loss: 0.4144 - val_mse: 0.4080\n",
      "Epoch 934/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4871 - mse: 0.4807 - val_loss: 0.4171 - val_mse: 0.4107\n",
      "Epoch 935/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4702 - val_loss: 0.4140 - val_mse: 0.4076\n",
      "Epoch 936/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4778 - mse: 0.4714 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 937/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4820 - mse: 0.4756 - val_loss: 0.4163 - val_mse: 0.4099\n",
      "Epoch 938/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4743 - val_loss: 0.4157 - val_mse: 0.4093\n",
      "Epoch 939/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4735 - val_loss: 0.4142 - val_mse: 0.4078\n",
      "Epoch 940/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4834 - mse: 0.4770\n",
      "Epoch 00940: saving model to Regression_Model/bl6.mle.linear-0940.ckpt\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.4811 - mse: 0.4747 - val_loss: 0.4167 - val_mse: 0.4103\n",
      "Epoch 941/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4736 - val_loss: 0.4151 - val_mse: 0.4087\n",
      "Epoch 942/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4842 - mse: 0.4778 - val_loss: 0.4136 - val_mse: 0.4072\n",
      "Epoch 943/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4821 - mse: 0.4757 - val_loss: 0.4145 - val_mse: 0.4081\n",
      "Epoch 944/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4747 - val_loss: 0.4160 - val_mse: 0.4096\n",
      "Epoch 945/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4776 - mse: 0.4712 - val_loss: 0.4167 - val_mse: 0.4103\n",
      "Epoch 946/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4735 - val_loss: 0.4156 - val_mse: 0.4092\n",
      "Epoch 947/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4733 - val_loss: 0.4165 - val_mse: 0.4101\n",
      "Epoch 948/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4833 - mse: 0.4769 - val_loss: 0.4183 - val_mse: 0.4118\n",
      "Epoch 949/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4757 - val_loss: 0.4191 - val_mse: 0.4127\n",
      "Epoch 950/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4854 - mse: 0.4790\n",
      "Epoch 00950: saving model to Regression_Model/bl6.mle.linear-0950.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4864 - mse: 0.4800 - val_loss: 0.4157 - val_mse: 0.4093\n",
      "Epoch 951/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4766 - val_loss: 0.4155 - val_mse: 0.4091\n",
      "Epoch 952/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4927 - mse: 0.4863 - val_loss: 0.4153 - val_mse: 0.4089\n",
      "Epoch 953/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4801 - mse: 0.4737 - val_loss: 0.4188 - val_mse: 0.4124\n",
      "Epoch 954/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4730 - val_loss: 0.4130 - val_mse: 0.4066\n",
      "Epoch 955/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4755 - val_loss: 0.4150 - val_mse: 0.4086\n",
      "Epoch 956/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4842 - mse: 0.4778 - val_loss: 0.4201 - val_mse: 0.4137\n",
      "Epoch 957/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4869 - mse: 0.4805 - val_loss: 0.4152 - val_mse: 0.4088\n",
      "Epoch 958/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4770 - val_loss: 0.4171 - val_mse: 0.4107\n",
      "Epoch 959/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4779 - val_loss: 0.4162 - val_mse: 0.4098\n",
      "Epoch 960/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4825 - mse: 0.4761\n",
      "Epoch 00960: saving model to Regression_Model/bl6.mle.linear-0960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4768 - val_loss: 0.4158 - val_mse: 0.4094\n",
      "Epoch 961/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4745 - val_loss: 0.4133 - val_mse: 0.4069\n",
      "Epoch 962/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4797 - mse: 0.4733 - val_loss: 0.4153 - val_mse: 0.4089\n",
      "Epoch 963/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4846 - mse: 0.4782 - val_loss: 0.4191 - val_mse: 0.4127\n",
      "Epoch 964/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4789 - mse: 0.4725 - val_loss: 0.4148 - val_mse: 0.4084\n",
      "Epoch 965/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4871 - mse: 0.4807 - val_loss: 0.4145 - val_mse: 0.4081\n",
      "Epoch 966/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4768 - mse: 0.4704 - val_loss: 0.4181 - val_mse: 0.4117\n",
      "Epoch 967/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4766 - val_loss: 0.4154 - val_mse: 0.4090\n",
      "Epoch 968/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4739 - val_loss: 0.4167 - val_mse: 0.4103\n",
      "Epoch 969/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4821 - mse: 0.4757 - val_loss: 0.4152 - val_mse: 0.4088\n",
      "Epoch 970/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4863 - mse: 0.4799\n",
      "Epoch 00970: saving model to Regression_Model/bl6.mle.linear-0970.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4875 - mse: 0.4811 - val_loss: 0.4181 - val_mse: 0.4117\n",
      "Epoch 971/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4786 - val_loss: 0.4169 - val_mse: 0.4105\n",
      "Epoch 972/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4756 - mse: 0.4692 - val_loss: 0.4153 - val_mse: 0.4089\n",
      "Epoch 973/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4896 - mse: 0.4833 - val_loss: 0.4188 - val_mse: 0.4124\n",
      "Epoch 974/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4786 - val_loss: 0.4166 - val_mse: 0.4102\n",
      "Epoch 975/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4846 - mse: 0.4782 - val_loss: 0.4133 - val_mse: 0.4069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4844 - mse: 0.4780 - val_loss: 0.4145 - val_mse: 0.4081\n",
      "Epoch 977/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4740 - val_loss: 0.4170 - val_mse: 0.4106\n",
      "Epoch 978/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4720 - val_loss: 0.4142 - val_mse: 0.4078\n",
      "Epoch 979/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4871 - mse: 0.4807 - val_loss: 0.4149 - val_mse: 0.4085\n",
      "Epoch 980/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4757 - mse: 0.4693\n",
      "Epoch 00980: saving model to Regression_Model/bl6.mle.linear-0980.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4756 - mse: 0.4692 - val_loss: 0.4199 - val_mse: 0.4135\n",
      "Epoch 981/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4767 - val_loss: 0.4183 - val_mse: 0.4119\n",
      "Epoch 982/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4760 - val_loss: 0.4205 - val_mse: 0.4141\n",
      "Epoch 983/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4736 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 984/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4829 - mse: 0.4765 - val_loss: 0.4172 - val_mse: 0.4108\n",
      "Epoch 985/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4766 - mse: 0.4702 - val_loss: 0.4142 - val_mse: 0.4078\n",
      "Epoch 986/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4835 - mse: 0.4771 - val_loss: 0.4159 - val_mse: 0.4096\n",
      "Epoch 987/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4747 - mse: 0.4683 - val_loss: 0.4143 - val_mse: 0.4080\n",
      "Epoch 988/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4809 - mse: 0.4745 - val_loss: 0.4200 - val_mse: 0.4136\n",
      "Epoch 989/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4824 - mse: 0.4760 - val_loss: 0.4170 - val_mse: 0.4106\n",
      "Epoch 990/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4819 - mse: 0.4755\n",
      "Epoch 00990: saving model to Regression_Model/bl6.mle.linear-0990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4717 - val_loss: 0.4169 - val_mse: 0.4105\n",
      "Epoch 991/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4161 - val_mse: 0.4097\n",
      "Epoch 992/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4706 - mse: 0.4642 - val_loss: 0.4142 - val_mse: 0.4079\n",
      "Epoch 993/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4834 - mse: 0.4770 - val_loss: 0.4156 - val_mse: 0.4092\n",
      "Epoch 994/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4750 - val_loss: 0.4185 - val_mse: 0.4121\n",
      "Epoch 995/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4861 - mse: 0.4797 - val_loss: 0.4167 - val_mse: 0.4103\n",
      "Epoch 996/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4797 - mse: 0.4733 - val_loss: 0.4153 - val_mse: 0.4089\n",
      "Epoch 997/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4818 - mse: 0.4754 - val_loss: 0.4165 - val_mse: 0.4101\n",
      "Epoch 998/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4736 - val_loss: 0.4168 - val_mse: 0.4104\n",
      "Epoch 999/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4761 - mse: 0.4697 - val_loss: 0.4153 - val_mse: 0.4089\n",
      "Epoch 1000/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4741 - mse: 0.4677\n",
      "Epoch 01000: saving model to Regression_Model/bl6.mle.linear-1000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4708 - val_loss: 0.4162 - val_mse: 0.4098\n",
      "Epoch 1001/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4762 - val_loss: 0.4153 - val_mse: 0.4089\n",
      "Epoch 1002/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4775 - val_loss: 0.4163 - val_mse: 0.4099\n",
      "Epoch 1003/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4849 - mse: 0.4785 - val_loss: 0.4143 - val_mse: 0.4079\n",
      "Epoch 1004/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4739 - val_loss: 0.4206 - val_mse: 0.4142\n",
      "Epoch 1005/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4796 - mse: 0.4732 - val_loss: 0.4150 - val_mse: 0.4087\n",
      "Epoch 1006/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4817 - mse: 0.4753 - val_loss: 0.4164 - val_mse: 0.4100\n",
      "Epoch 1007/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4823 - mse: 0.4759 - val_loss: 0.4157 - val_mse: 0.4094\n",
      "Epoch 1008/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4830 - mse: 0.4766 - val_loss: 0.4154 - val_mse: 0.4090\n",
      "Epoch 1009/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4807 - mse: 0.4743 - val_loss: 0.4178 - val_mse: 0.4114\n",
      "Epoch 1010/2000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 0.4792 - mse: 0.4728\n",
      "Epoch 01010: saving model to Regression_Model/bl6.mle.linear-1010.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4810 - mse: 0.4746 - val_loss: 0.4147 - val_mse: 0.4083\n",
      "Epoch 1011/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4762 - mse: 0.4698 - val_loss: 0.4133 - val_mse: 0.4069\n",
      "Epoch 1012/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4748 - mse: 0.4685 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1013/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4806 - mse: 0.4743 - val_loss: 0.4166 - val_mse: 0.4102\n",
      "Epoch 1014/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4829 - mse: 0.4765 - val_loss: 0.4142 - val_mse: 0.4078\n",
      "Epoch 1015/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4817 - mse: 0.4753 - val_loss: 0.4152 - val_mse: 0.4088\n",
      "Epoch 1016/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4773 - mse: 0.4710 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1017/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4862 - mse: 0.4798 - val_loss: 0.4183 - val_mse: 0.4120\n",
      "Epoch 1018/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4848 - mse: 0.4785 - val_loss: 0.4159 - val_mse: 0.4096\n",
      "Epoch 1019/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4758 - val_loss: 0.4165 - val_mse: 0.4101\n",
      "Epoch 1020/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4795 - mse: 0.4732\n",
      "Epoch 01020: saving model to Regression_Model/bl6.mle.linear-1020.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4153 - val_mse: 0.4089\n",
      "Epoch 1021/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4711 - val_loss: 0.4136 - val_mse: 0.4073\n",
      "Epoch 1022/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4808 - mse: 0.4745 - val_loss: 0.4138 - val_mse: 0.4074\n",
      "Epoch 1023/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4739 - val_loss: 0.4143 - val_mse: 0.4079\n",
      "Epoch 1024/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4821 - mse: 0.4757 - val_loss: 0.4163 - val_mse: 0.4099\n",
      "Epoch 1025/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4800 - mse: 0.4736 - val_loss: 0.4147 - val_mse: 0.4084\n",
      "Epoch 1026/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4714 - val_loss: 0.4155 - val_mse: 0.4091\n",
      "Epoch 1027/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4839 - mse: 0.4775 - val_loss: 0.4136 - val_mse: 0.4072\n",
      "Epoch 1028/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4872 - mse: 0.4808 - val_loss: 0.4154 - val_mse: 0.4090\n",
      "Epoch 1029/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4796 - mse: 0.4732 - val_loss: 0.4138 - val_mse: 0.4074\n",
      "Epoch 1030/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/368 [============================>.] - ETA: 0s - loss: 0.4759 - mse: 0.4695\n",
      "Epoch 01030: saving model to Regression_Model/bl6.mle.linear-1030.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4706 - val_loss: 0.4138 - val_mse: 0.4074\n",
      "Epoch 1031/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4764 - val_loss: 0.4135 - val_mse: 0.4071\n",
      "Epoch 1032/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4810 - mse: 0.4747 - val_loss: 0.4133 - val_mse: 0.4069\n",
      "Epoch 1033/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4691 - val_loss: 0.4150 - val_mse: 0.4086\n",
      "Epoch 1034/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4696 - val_loss: 0.4151 - val_mse: 0.4087\n",
      "Epoch 1035/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4783 - mse: 0.4719 - val_loss: 0.4164 - val_mse: 0.4101\n",
      "Epoch 1036/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4856 - mse: 0.4792 - val_loss: 0.4149 - val_mse: 0.4085\n",
      "Epoch 1037/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4724 - mse: 0.4660 - val_loss: 0.4138 - val_mse: 0.4074\n",
      "Epoch 1038/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4142 - val_mse: 0.4079\n",
      "Epoch 1039/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4798 - mse: 0.4735 - val_loss: 0.4141 - val_mse: 0.4078\n",
      "Epoch 1040/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4839 - mse: 0.4775\n",
      "Epoch 01040: saving model to Regression_Model/bl6.mle.linear-1040.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.4844 - mse: 0.4780 - val_loss: 0.4169 - val_mse: 0.4105\n",
      "Epoch 1041/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4832 - val_loss: 0.4155 - val_mse: 0.4091\n",
      "Epoch 1042/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4134 - val_mse: 0.4070\n",
      "Epoch 1043/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4799 - mse: 0.4735 - val_loss: 0.4154 - val_mse: 0.4090\n",
      "Epoch 1044/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4752 - mse: 0.4688 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 1045/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4784 - mse: 0.4720 - val_loss: 0.4153 - val_mse: 0.4090\n",
      "Epoch 1046/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4773 - val_loss: 0.4152 - val_mse: 0.4089\n",
      "Epoch 1047/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4789 - mse: 0.4726 - val_loss: 0.4153 - val_mse: 0.4090\n",
      "Epoch 1048/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4740 - val_loss: 0.4153 - val_mse: 0.4090\n",
      "Epoch 1049/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4738 - val_loss: 0.4160 - val_mse: 0.4096\n",
      "Epoch 1050/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4847 - mse: 0.4783\n",
      "Epoch 01050: saving model to Regression_Model/bl6.mle.linear-1050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4831 - mse: 0.4767 - val_loss: 0.4154 - val_mse: 0.4090\n",
      "Epoch 1051/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4826 - mse: 0.4762 - val_loss: 0.4157 - val_mse: 0.4094\n",
      "Epoch 1052/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4795 - mse: 0.4731 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1053/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4826 - mse: 0.4762 - val_loss: 0.4157 - val_mse: 0.4094\n",
      "Epoch 1054/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4760 - mse: 0.4696 - val_loss: 0.4154 - val_mse: 0.4090\n",
      "Epoch 1055/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4825 - mse: 0.4762 - val_loss: 0.4125 - val_mse: 0.4061\n",
      "Epoch 1056/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4765 - mse: 0.4701 - val_loss: 0.4141 - val_mse: 0.4077\n",
      "Epoch 1057/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4825 - mse: 0.4761 - val_loss: 0.4124 - val_mse: 0.4060\n",
      "Epoch 1058/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4852 - mse: 0.4789 - val_loss: 0.4187 - val_mse: 0.4123\n",
      "Epoch 1059/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4853 - mse: 0.4790 - val_loss: 0.4133 - val_mse: 0.4069\n",
      "Epoch 1060/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4811 - mse: 0.4748\n",
      "Epoch 01060: saving model to Regression_Model/bl6.mle.linear-1060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4741 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1061/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4895 - mse: 0.4831 - val_loss: 0.4166 - val_mse: 0.4102\n",
      "Epoch 1062/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4778 - val_loss: 0.4163 - val_mse: 0.4099\n",
      "Epoch 1063/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4739 - val_loss: 0.4134 - val_mse: 0.4071\n",
      "Epoch 1064/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4849 - mse: 0.4785 - val_loss: 0.4152 - val_mse: 0.4088\n",
      "Epoch 1065/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4854 - mse: 0.4790 - val_loss: 0.4144 - val_mse: 0.4080\n",
      "Epoch 1066/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4809 - mse: 0.4745 - val_loss: 0.4152 - val_mse: 0.4089\n",
      "Epoch 1067/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4789 - mse: 0.4726 - val_loss: 0.4156 - val_mse: 0.4092\n",
      "Epoch 1068/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4820 - mse: 0.4756 - val_loss: 0.4161 - val_mse: 0.4098\n",
      "Epoch 1069/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4747 - mse: 0.4684 - val_loss: 0.4134 - val_mse: 0.4070\n",
      "Epoch 1070/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4849 - mse: 0.4786\n",
      "Epoch 01070: saving model to Regression_Model/bl6.mle.linear-1070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4887 - mse: 0.4823 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 1071/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4903 - mse: 0.4839 - val_loss: 0.4170 - val_mse: 0.4106\n",
      "Epoch 1072/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4848 - mse: 0.4784 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1073/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4146 - val_mse: 0.4083\n",
      "Epoch 1074/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4752 - mse: 0.4688 - val_loss: 0.4171 - val_mse: 0.4107\n",
      "Epoch 1075/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4123 - val_mse: 0.4059\n",
      "Epoch 1076/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4799 - val_loss: 0.4145 - val_mse: 0.4081\n",
      "Epoch 1077/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4811 - mse: 0.4748 - val_loss: 0.4160 - val_mse: 0.4096\n",
      "Epoch 1078/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4821 - mse: 0.4758 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 1079/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4701 - val_loss: 0.4145 - val_mse: 0.4081\n",
      "Epoch 1080/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4764 - mse: 0.4700\n",
      "Epoch 01080: saving model to Regression_Model/bl6.mle.linear-1080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4705 - val_loss: 0.4144 - val_mse: 0.4080\n",
      "Epoch 1081/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4840 - mse: 0.4777 - val_loss: 0.4139 - val_mse: 0.4076\n",
      "Epoch 1082/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4765 - val_loss: 0.4150 - val_mse: 0.4087\n",
      "Epoch 1083/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4824 - mse: 0.4760 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1084/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4743 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 1085/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4801 - mse: 0.4737 - val_loss: 0.4119 - val_mse: 0.4055\n",
      "Epoch 1086/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4746 - mse: 0.4683 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1087/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4855 - mse: 0.4791 - val_loss: 0.4143 - val_mse: 0.4079\n",
      "Epoch 1088/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4804 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1089/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4786 - mse: 0.4722 - val_loss: 0.4145 - val_mse: 0.4082\n",
      "Epoch 1090/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4802 - mse: 0.4739\n",
      "Epoch 01090: saving model to Regression_Model/bl6.mle.linear-1090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4776 - val_loss: 0.4150 - val_mse: 0.4087\n",
      "Epoch 1091/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4779 - val_loss: 0.4123 - val_mse: 0.4059\n",
      "Epoch 1092/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4743 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1093/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4782 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 1094/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4768 - mse: 0.4704 - val_loss: 0.4185 - val_mse: 0.4122\n",
      "Epoch 1095/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4728 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1096/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4763 - val_loss: 0.4150 - val_mse: 0.4087\n",
      "Epoch 1097/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4765 - val_loss: 0.4143 - val_mse: 0.4080\n",
      "Epoch 1098/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4891 - mse: 0.4827 - val_loss: 0.4140 - val_mse: 0.4076\n",
      "Epoch 1099/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4863 - mse: 0.4799 - val_loss: 0.4142 - val_mse: 0.4079\n",
      "Epoch 1100/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4833 - mse: 0.4769\n",
      "Epoch 01100: saving model to Regression_Model/bl6.mle.linear-1100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4769 - val_loss: 0.4156 - val_mse: 0.4092\n",
      "Epoch 1101/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4844 - mse: 0.4780 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1102/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4763 - mse: 0.4700 - val_loss: 0.4159 - val_mse: 0.4095\n",
      "Epoch 1103/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4772 - val_loss: 0.4139 - val_mse: 0.4075\n",
      "Epoch 1104/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4154 - val_mse: 0.4090\n",
      "Epoch 1105/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4871 - mse: 0.4808 - val_loss: 0.4151 - val_mse: 0.4087\n",
      "Epoch 1106/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4807 - mse: 0.4744 - val_loss: 0.4154 - val_mse: 0.4090\n",
      "Epoch 1107/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4822 - mse: 0.4758 - val_loss: 0.4180 - val_mse: 0.4117\n",
      "Epoch 1108/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4856 - mse: 0.4792 - val_loss: 0.4151 - val_mse: 0.4087\n",
      "Epoch 1109/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4847 - mse: 0.4783 - val_loss: 0.4164 - val_mse: 0.4100\n",
      "Epoch 1110/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4762 - mse: 0.4698\n",
      "Epoch 01110: saving model to Regression_Model/bl6.mle.linear-1110.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.4761 - mse: 0.4698 - val_loss: 0.4149 - val_mse: 0.4086\n",
      "Epoch 1111/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4884 - mse: 0.4820 - val_loss: 0.4142 - val_mse: 0.4079\n",
      "Epoch 1112/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4843 - mse: 0.4779 - val_loss: 0.4169 - val_mse: 0.4106\n",
      "Epoch 1113/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4119 - val_mse: 0.4055\n",
      "Epoch 1114/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4804 - mse: 0.4741 - val_loss: 0.4144 - val_mse: 0.4080\n",
      "Epoch 1115/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4737 - mse: 0.4674 - val_loss: 0.4166 - val_mse: 0.4103\n",
      "Epoch 1116/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4788 - mse: 0.4724 - val_loss: 0.4138 - val_mse: 0.4074\n",
      "Epoch 1117/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4160 - val_mse: 0.4096\n",
      "Epoch 1118/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4827 - mse: 0.4763 - val_loss: 0.4158 - val_mse: 0.4095\n",
      "Epoch 1119/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4818 - mse: 0.4755 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1120/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4763 - mse: 0.4700\n",
      "Epoch 01120: saving model to Regression_Model/bl6.mle.linear-1120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4763 - mse: 0.4700 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 1121/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4755 - val_loss: 0.4137 - val_mse: 0.4073\n",
      "Epoch 1122/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4836 - mse: 0.4773 - val_loss: 0.4169 - val_mse: 0.4105\n",
      "Epoch 1123/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4774 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1124/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4733 - mse: 0.4670 - val_loss: 0.4156 - val_mse: 0.4093\n",
      "Epoch 1125/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4142 - val_mse: 0.4078\n",
      "Epoch 1126/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4873 - mse: 0.4809 - val_loss: 0.4153 - val_mse: 0.4089\n",
      "Epoch 1127/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4160 - val_mse: 0.4097\n",
      "Epoch 1128/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4786 - mse: 0.4722 - val_loss: 0.4138 - val_mse: 0.4074\n",
      "Epoch 1129/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4838 - mse: 0.4775 - val_loss: 0.4157 - val_mse: 0.4094\n",
      "Epoch 1130/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4818 - mse: 0.4754\n",
      "Epoch 01130: saving model to Regression_Model/bl6.mle.linear-1130.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 0.4785 - mse: 0.4722 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1131/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4751 - val_loss: 0.4140 - val_mse: 0.4077\n",
      "Epoch 1132/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4814 - mse: 0.4750 - val_loss: 0.4137 - val_mse: 0.4074\n",
      "Epoch 1133/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4155 - val_mse: 0.4092\n",
      "Epoch 1134/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1135/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4809 - mse: 0.4746 - val_loss: 0.4127 - val_mse: 0.4063\n",
      "Epoch 1136/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4806 - mse: 0.4743 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1137/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4815 - mse: 0.4751 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1138/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4808 - mse: 0.4744 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1139/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4790 - mse: 0.4726 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1140/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4828 - mse: 0.4765\n",
      "Epoch 01140: saving model to Regression_Model/bl6.mle.linear-1140.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4829 - mse: 0.4765 - val_loss: 0.4144 - val_mse: 0.4081\n",
      "Epoch 1141/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4780 - val_loss: 0.4128 - val_mse: 0.4064\n",
      "Epoch 1142/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4825 - mse: 0.4762 - val_loss: 0.4152 - val_mse: 0.4088\n",
      "Epoch 1143/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4803 - mse: 0.4740 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1144/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4830 - mse: 0.4767 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1145/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4818 - mse: 0.4755 - val_loss: 0.4119 - val_mse: 0.4055\n",
      "Epoch 1146/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4748 - mse: 0.4685 - val_loss: 0.4133 - val_mse: 0.4069\n",
      "Epoch 1147/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4763 - mse: 0.4700 - val_loss: 0.4115 - val_mse: 0.4051\n",
      "Epoch 1148/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4789 - mse: 0.4726 - val_loss: 0.4134 - val_mse: 0.4071\n",
      "Epoch 1149/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4818 - mse: 0.4755 - val_loss: 0.4142 - val_mse: 0.4079\n",
      "Epoch 1150/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4794 - mse: 0.4731\n",
      "Epoch 01150: saving model to Regression_Model/bl6.mle.linear-1150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4732 - val_loss: 0.4159 - val_mse: 0.4096\n",
      "Epoch 1151/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4778 - val_loss: 0.4148 - val_mse: 0.4085\n",
      "Epoch 1152/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4805 - mse: 0.4741 - val_loss: 0.4156 - val_mse: 0.4093\n",
      "Epoch 1153/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4752 - mse: 0.4689 - val_loss: 0.4164 - val_mse: 0.4101\n",
      "Epoch 1154/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4775 - mse: 0.4711 - val_loss: 0.4120 - val_mse: 0.4056\n",
      "Epoch 1155/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4133 - val_mse: 0.4070\n",
      "Epoch 1156/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4809 - mse: 0.4746 - val_loss: 0.4140 - val_mse: 0.4076\n",
      "Epoch 1157/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4833 - mse: 0.4770 - val_loss: 0.4141 - val_mse: 0.4078\n",
      "Epoch 1158/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4800 - mse: 0.4737 - val_loss: 0.4151 - val_mse: 0.4088\n",
      "Epoch 1159/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4810 - mse: 0.4747 - val_loss: 0.4140 - val_mse: 0.4077\n",
      "Epoch 1160/2000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 0.4816 - mse: 0.4753\n",
      "Epoch 01160: saving model to Regression_Model/bl6.mle.linear-1160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4743 - val_loss: 0.4134 - val_mse: 0.4070\n",
      "Epoch 1161/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4691 - val_loss: 0.4123 - val_mse: 0.4059\n",
      "Epoch 1162/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4831 - mse: 0.4768 - val_loss: 0.4125 - val_mse: 0.4061\n",
      "Epoch 1163/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4842 - mse: 0.4779 - val_loss: 0.4154 - val_mse: 0.4091\n",
      "Epoch 1164/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4851 - mse: 0.4788 - val_loss: 0.4165 - val_mse: 0.4102\n",
      "Epoch 1165/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4724 - val_loss: 0.4128 - val_mse: 0.4064\n",
      "Epoch 1166/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4889 - mse: 0.4826 - val_loss: 0.4134 - val_mse: 0.4071\n",
      "Epoch 1167/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4854 - mse: 0.4791 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1168/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4847 - mse: 0.4784 - val_loss: 0.4143 - val_mse: 0.4080\n",
      "Epoch 1169/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4158 - val_mse: 0.4095\n",
      "Epoch 1170/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4780 - mse: 0.4717\n",
      "Epoch 01170: saving model to Regression_Model/bl6.mle.linear-1170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4720 - val_loss: 0.4155 - val_mse: 0.4092\n",
      "Epoch 1171/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4860 - mse: 0.4797 - val_loss: 0.4139 - val_mse: 0.4075\n",
      "Epoch 1172/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4146 - val_mse: 0.4083\n",
      "Epoch 1173/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4798 - mse: 0.4734 - val_loss: 0.4157 - val_mse: 0.4093\n",
      "Epoch 1174/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4878 - mse: 0.4815 - val_loss: 0.4133 - val_mse: 0.4070\n",
      "Epoch 1175/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4836 - mse: 0.4772 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1176/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4767 - mse: 0.4704 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1177/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4766 - mse: 0.4703 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1178/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4766 - mse: 0.4703 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1179/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4770 - mse: 0.4707 - val_loss: 0.4129 - val_mse: 0.4066\n",
      "Epoch 1180/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4757 - mse: 0.4694\n",
      "Epoch 01180: saving model to Regression_Model/bl6.mle.linear-1180.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.4746 - mse: 0.4683 - val_loss: 0.4113 - val_mse: 0.4049\n",
      "Epoch 1181/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4862 - mse: 0.4799 - val_loss: 0.4149 - val_mse: 0.4086\n",
      "Epoch 1182/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4793 - mse: 0.4730 - val_loss: 0.4134 - val_mse: 0.4071\n",
      "Epoch 1183/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4133 - val_mse: 0.4070\n",
      "Epoch 1184/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4779 - mse: 0.4716 - val_loss: 0.4161 - val_mse: 0.4098\n",
      "Epoch 1185/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4776 - mse: 0.4713 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1186/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4818 - mse: 0.4755 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1187/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4838 - mse: 0.4774 - val_loss: 0.4146 - val_mse: 0.4082\n",
      "Epoch 1188/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4765 - mse: 0.4702 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1189/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4758 - mse: 0.4694 - val_loss: 0.4124 - val_mse: 0.4060\n",
      "Epoch 1190/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4770 - mse: 0.4706\n",
      "Epoch 01190: saving model to Regression_Model/bl6.mle.linear-1190.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4139 - val_mse: 0.4076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1191/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4766 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1192/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4778 - mse: 0.4715 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1193/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4786 - mse: 0.4723 - val_loss: 0.4140 - val_mse: 0.4077\n",
      "Epoch 1194/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4741 - mse: 0.4678 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1195/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4782 - mse: 0.4719 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1196/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4807 - mse: 0.4744 - val_loss: 0.4134 - val_mse: 0.4071\n",
      "Epoch 1197/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4722 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1198/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4764 - mse: 0.4701 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1199/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4850 - mse: 0.4787 - val_loss: 0.4145 - val_mse: 0.4082\n",
      "Epoch 1200/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4763 - mse: 0.4700\n",
      "Epoch 01200: saving model to Regression_Model/bl6.mle.linear-1200.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4762 - mse: 0.4699 - val_loss: 0.4129 - val_mse: 0.4066\n",
      "Epoch 1201/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4836 - mse: 0.4772 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1202/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4813 - mse: 0.4749 - val_loss: 0.4134 - val_mse: 0.4071\n",
      "Epoch 1203/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4760 - mse: 0.4697 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1204/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4823 - mse: 0.4760 - val_loss: 0.4131 - val_mse: 0.4067\n",
      "Epoch 1205/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4810 - mse: 0.4746 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1206/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4131 - val_mse: 0.4067\n",
      "Epoch 1207/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1208/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4797 - mse: 0.4734 - val_loss: 0.4143 - val_mse: 0.4080\n",
      "Epoch 1209/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4739 - mse: 0.4675 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1210/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4852 - mse: 0.4789\n",
      "Epoch 01210: saving model to Regression_Model/bl6.mle.linear-1210.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4831 - mse: 0.4768 - val_loss: 0.4138 - val_mse: 0.4074\n",
      "Epoch 1211/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4743 - mse: 0.4680 - val_loss: 0.4152 - val_mse: 0.4089\n",
      "Epoch 1212/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4140 - val_mse: 0.4077\n",
      "Epoch 1213/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4800 - mse: 0.4737 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1214/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4823 - mse: 0.4760 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1215/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4803 - mse: 0.4740 - val_loss: 0.4142 - val_mse: 0.4079\n",
      "Epoch 1216/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4808 - mse: 0.4745 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1217/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4728 - mse: 0.4665 - val_loss: 0.4141 - val_mse: 0.4078\n",
      "Epoch 1218/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4836 - mse: 0.4773 - val_loss: 0.4155 - val_mse: 0.4092\n",
      "Epoch 1219/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4831 - mse: 0.4768 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1220/2000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.4839 - mse: 0.4776\n",
      "Epoch 01220: saving model to Regression_Model/bl6.mle.linear-1220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4762 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1221/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4736 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1222/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4801 - mse: 0.4738 - val_loss: 0.4142 - val_mse: 0.4078\n",
      "Epoch 1223/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4805 - mse: 0.4742 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1224/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4762 - val_loss: 0.4146 - val_mse: 0.4083\n",
      "Epoch 1225/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4740 - val_loss: 0.4127 - val_mse: 0.4063\n",
      "Epoch 1226/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4782 - mse: 0.4718 - val_loss: 0.4128 - val_mse: 0.4064\n",
      "Epoch 1227/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4811 - mse: 0.4748 - val_loss: 0.4120 - val_mse: 0.4057\n",
      "Epoch 1228/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4824 - mse: 0.4761 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1229/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4844 - mse: 0.4781 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1230/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4781 - mse: 0.4717\n",
      "Epoch 01230: saving model to Regression_Model/bl6.mle.linear-1230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4796 - mse: 0.4732 - val_loss: 0.4148 - val_mse: 0.4085\n",
      "Epoch 1231/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4712 - val_loss: 0.4127 - val_mse: 0.4063\n",
      "Epoch 1232/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4780 - mse: 0.4717 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1233/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4142 - val_mse: 0.4079\n",
      "Epoch 1234/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4849 - mse: 0.4786 - val_loss: 0.4136 - val_mse: 0.4073\n",
      "Epoch 1235/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4810 - mse: 0.4747 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1236/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4754 - mse: 0.4691 - val_loss: 0.4129 - val_mse: 0.4066\n",
      "Epoch 1237/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4828 - mse: 0.4764 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1238/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4752 - mse: 0.4689 - val_loss: 0.4129 - val_mse: 0.4066\n",
      "Epoch 1239/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4803 - mse: 0.4740 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1240/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4761 - mse: 0.4698\n",
      "Epoch 01240: saving model to Regression_Model/bl6.mle.linear-1240.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.4759 - mse: 0.4696 - val_loss: 0.4137 - val_mse: 0.4074\n",
      "Epoch 1241/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4777 - mse: 0.4714 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1242/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4735 - mse: 0.4672 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1243/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4808 - mse: 0.4745 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1244/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1245/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4147 - val_mse: 0.4084\n",
      "Epoch 1246/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4782 - mse: 0.4719 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1247/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4789 - mse: 0.4726 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1248/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4835 - mse: 0.4772 - val_loss: 0.4140 - val_mse: 0.4077\n",
      "Epoch 1249/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4764 - mse: 0.4701 - val_loss: 0.4136 - val_mse: 0.4073\n",
      "Epoch 1250/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4801 - mse: 0.4737\n",
      "Epoch 01250: saving model to Regression_Model/bl6.mle.linear-1250.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4800 - mse: 0.4737 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1251/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4743 - mse: 0.4679 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1252/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1253/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4139 - val_mse: 0.4076\n",
      "Epoch 1254/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4765 - mse: 0.4701 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1255/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4139 - val_mse: 0.4076\n",
      "Epoch 1256/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4766 - mse: 0.4703 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1257/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4751 - val_loss: 0.4133 - val_mse: 0.4070\n",
      "Epoch 1258/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4706 - val_loss: 0.4133 - val_mse: 0.4070\n",
      "Epoch 1259/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4793 - mse: 0.4730 - val_loss: 0.4118 - val_mse: 0.4054\n",
      "Epoch 1260/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4820 - mse: 0.4757\n",
      "Epoch 01260: saving model to Regression_Model/bl6.mle.linear-1260.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4753 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1261/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4702 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1262/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4760 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1263/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4735 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1264/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4751 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1265/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4799 - mse: 0.4736 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1266/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4697 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1267/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4734 - val_loss: 0.4147 - val_mse: 0.4084\n",
      "Epoch 1268/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4740 - val_loss: 0.4139 - val_mse: 0.4076\n",
      "Epoch 1269/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4731 - mse: 0.4667 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1270/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4824 - mse: 0.4761\n",
      "Epoch 01270: saving model to Regression_Model/bl6.mle.linear-1270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4763 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1271/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4752 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1272/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4740 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1273/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4785 - mse: 0.4722 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1274/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4890 - mse: 0.4827 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1275/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4838 - mse: 0.4775 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1276/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1277/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4752 - mse: 0.4689 - val_loss: 0.4152 - val_mse: 0.4089\n",
      "Epoch 1278/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4872 - mse: 0.4809 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1279/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4837 - mse: 0.4774 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1280/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4812 - mse: 0.4749\n",
      "Epoch 01280: saving model to Regression_Model/bl6.mle.linear-1280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4742 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1281/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4732 - val_loss: 0.4118 - val_mse: 0.4055\n",
      "Epoch 1282/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4759 - mse: 0.4696 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1283/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4140 - val_mse: 0.4077\n",
      "Epoch 1284/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4718 - mse: 0.4655 - val_loss: 0.4118 - val_mse: 0.4054\n",
      "Epoch 1285/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4763 - val_loss: 0.4148 - val_mse: 0.4085\n",
      "Epoch 1286/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4782 - val_loss: 0.4134 - val_mse: 0.4071\n",
      "Epoch 1287/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4818 - mse: 0.4755 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1288/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4875 - mse: 0.4812 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1289/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4704 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1290/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4806 - mse: 0.4743\n",
      "Epoch 01290: saving model to Regression_Model/bl6.mle.linear-1290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4760 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1291/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1292/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4791 - mse: 0.4728 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1293/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4742 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1294/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4753 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1295/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4722 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1296/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4766 - mse: 0.4703 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1297/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4727 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1298/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4841 - mse: 0.4778 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1299/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4699 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1300/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4818 - mse: 0.4755\n",
      "Epoch 01300: saving model to Regression_Model/bl6.mle.linear-1300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4751 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1301/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4780 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1302/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4778 - mse: 0.4715 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1303/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4810 - mse: 0.4747 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1304/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4750 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1305/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4747 - mse: 0.4684 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1306/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4704 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1307/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1308/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4808 - mse: 0.4745 - val_loss: 0.4137 - val_mse: 0.4074\n",
      "Epoch 1309/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1310/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4804 - mse: 0.4741\n",
      "Epoch 01310: saving model to Regression_Model/bl6.mle.linear-1310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4748 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1311/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4742 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1312/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4761 - mse: 0.4698 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1313/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4865 - mse: 0.4802 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1314/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4762 - mse: 0.4699 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1315/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1316/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4756 - mse: 0.4693 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1317/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4763 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1318/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4706 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1319/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4786 - mse: 0.4723 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1320/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4827 - mse: 0.4764\n",
      "Epoch 01320: saving model to Regression_Model/bl6.mle.linear-1320.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4818 - mse: 0.4755 - val_loss: 0.4136 - val_mse: 0.4073\n",
      "Epoch 1321/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4760 - val_loss: 0.4139 - val_mse: 0.4077\n",
      "Epoch 1322/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4800 - mse: 0.4737 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1323/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4744 - mse: 0.4681 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1324/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4808 - mse: 0.4745 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1325/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4120 - val_mse: 0.4057\n",
      "Epoch 1326/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4885 - mse: 0.4822 - val_loss: 0.4144 - val_mse: 0.4081\n",
      "Epoch 1327/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4743 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1328/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4852 - mse: 0.4790 - val_loss: 0.4143 - val_mse: 0.4080\n",
      "Epoch 1329/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4721 - val_loss: 0.4145 - val_mse: 0.4082\n",
      "Epoch 1330/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4884 - mse: 0.4821\n",
      "Epoch 01330: saving model to Regression_Model/bl6.mle.linear-1330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4880 - mse: 0.4817 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1331/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4822 - mse: 0.4759 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1332/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4797 - mse: 0.4734 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1333/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4788 - mse: 0.4725 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1334/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4725 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1335/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4795 - mse: 0.4732 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1336/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4712 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1337/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4741 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1338/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4806 - mse: 0.4743 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1339/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4817 - mse: 0.4754 - val_loss: 0.4137 - val_mse: 0.4074\n",
      "Epoch 1340/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4783 - mse: 0.4720\n",
      "Epoch 01340: saving model to Regression_Model/bl6.mle.linear-1340.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4144 - val_mse: 0.4081\n",
      "Epoch 1341/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4725 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1342/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4770 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1343/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4807 - mse: 0.4744 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1344/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4751 - mse: 0.4688 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1345/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4800 - mse: 0.4737 - val_loss: 0.4131 - val_mse: 0.4068\n",
      "Epoch 1346/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4740 - val_loss: 0.4136 - val_mse: 0.4073\n",
      "Epoch 1347/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4790 - mse: 0.4727 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1348/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4734 - mse: 0.4671 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1349/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4811 - mse: 0.4748 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1350/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4829 - mse: 0.4767\n",
      "Epoch 01350: saving model to Regression_Model/bl6.mle.linear-1350.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.4809 - mse: 0.4746 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1351/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4731 - mse: 0.4669 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1352/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4763 - mse: 0.4700 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1353/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4783 - mse: 0.4720 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1354/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4702 - val_loss: 0.4144 - val_mse: 0.4081\n",
      "Epoch 1355/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4748 - mse: 0.4685 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1356/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4792 - mse: 0.4729 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1357/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4714 - mse: 0.4651 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1358/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4843 - mse: 0.4780 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1359/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4706 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1360/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4789 - mse: 0.4726\n",
      "Epoch 01360: saving model to Regression_Model/bl6.mle.linear-1360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4697 - val_loss: 0.4122 - val_mse: 0.4060\n",
      "Epoch 1361/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1362/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4776 - mse: 0.4714 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1363/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4764 - mse: 0.4701 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1364/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4720 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1365/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4845 - mse: 0.4782 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1366/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4758 - val_loss: 0.4142 - val_mse: 0.4079\n",
      "Epoch 1367/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4730 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1368/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4728 - mse: 0.4665 - val_loss: 0.4138 - val_mse: 0.4075\n",
      "Epoch 1369/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4798 - mse: 0.4735 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1370/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4724 - mse: 0.4661\n",
      "Epoch 01370: saving model to Regression_Model/bl6.mle.linear-1370.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4726 - mse: 0.4663 - val_loss: 0.4124 - val_mse: 0.4062\n",
      "Epoch 1371/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4135 - val_mse: 0.4073\n",
      "Epoch 1372/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4751 - mse: 0.4688 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1373/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4749 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1374/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4848 - mse: 0.4785 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1375/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4735 - mse: 0.4672 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1376/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4757 - mse: 0.4694 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1377/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4764 - mse: 0.4701 - val_loss: 0.4119 - val_mse: 0.4057\n",
      "Epoch 1378/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4745 - mse: 0.4682 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1379/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4767 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1380/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4785 - mse: 0.4723\n",
      "Epoch 01380: saving model to Regression_Model/bl6.mle.linear-1380.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4778 - mse: 0.4715 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1381/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4744 - val_loss: 0.4132 - val_mse: 0.4069\n",
      "Epoch 1382/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4744 - mse: 0.4681 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1383/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4730 - val_loss: 0.4129 - val_mse: 0.4066\n",
      "Epoch 1384/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4737 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1385/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4818 - mse: 0.4756 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1386/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4137 - val_mse: 0.4074\n",
      "Epoch 1387/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4736 - mse: 0.4673 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1388/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4697 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1389/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4868 - mse: 0.4805 - val_loss: 0.4123 - val_mse: 0.4061\n",
      "Epoch 1390/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4749 - mse: 0.4686\n",
      "Epoch 01390: saving model to Regression_Model/bl6.mle.linear-1390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4739 - mse: 0.4677 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1391/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1392/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4705 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1393/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4753 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1394/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4720 - mse: 0.4657 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1395/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4748 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1396/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1397/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4742 - mse: 0.4680 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1398/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4722 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1399/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4703 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1400/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4786 - mse: 0.4723\n",
      "Epoch 01400: saving model to Regression_Model/bl6.mle.linear-1400.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4801 - mse: 0.4738 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1401/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4850 - mse: 0.4787 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1402/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4769 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1403/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1404/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4707 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1405/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4824 - mse: 0.4761 - val_loss: 0.4120 - val_mse: 0.4057\n",
      "Epoch 1406/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4692 - val_loss: 0.4105 - val_mse: 0.4042\n",
      "Epoch 1407/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4737 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1408/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4833 - mse: 0.4771 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1409/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1410/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4781 - mse: 0.4718\n",
      "Epoch 01410: saving model to Regression_Model/bl6.mle.linear-1410.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.4771 - mse: 0.4709 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1411/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4755 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1412/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4766 - mse: 0.4703 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1413/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4782 - mse: 0.4719 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1414/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4751 - mse: 0.4688 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1415/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4751 - val_loss: 0.4132 - val_mse: 0.4070\n",
      "Epoch 1416/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4742 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1417/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4810 - mse: 0.4747 - val_loss: 0.4139 - val_mse: 0.4076\n",
      "Epoch 1418/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4780 - mse: 0.4718 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1419/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4123 - val_mse: 0.4061\n",
      "Epoch 1420/2000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4815 - mse: 0.4752\n",
      "Epoch 01420: saving model to Regression_Model/bl6.mle.linear-1420.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4758 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1421/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4722 - mse: 0.4659 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1422/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4730 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1423/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4733 - mse: 0.4670 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1424/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4808 - mse: 0.4746 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1425/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1426/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4736 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1427/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4744 - mse: 0.4681 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1428/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4720 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1429/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4705 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1430/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4755 - mse: 0.4693\n",
      "Epoch 01430: saving model to Regression_Model/bl6.mle.linear-1430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4776 - mse: 0.4713 - val_loss: 0.4118 - val_mse: 0.4056\n",
      "Epoch 1431/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4742 - mse: 0.4679 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1432/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4746 - mse: 0.4683 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1433/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4749 - mse: 0.4686 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1434/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4704 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1435/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4793 - mse: 0.4730 - val_loss: 0.4105 - val_mse: 0.4042\n",
      "Epoch 1436/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4760 - mse: 0.4697 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1437/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4748 - mse: 0.4685 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1438/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4862 - mse: 0.4799 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1439/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1440/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4826 - mse: 0.4763\n",
      "Epoch 01440: saving model to Regression_Model/bl6.mle.linear-1440.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.4813 - mse: 0.4750 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1441/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4732 - mse: 0.4670 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1442/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4746 - mse: 0.4683 - val_loss: 0.4118 - val_mse: 0.4055\n",
      "Epoch 1443/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4808 - mse: 0.4745 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1444/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4737 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1445/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4744 - mse: 0.4681 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1446/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4799 - mse: 0.4737 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1447/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4779 - mse: 0.4716 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1448/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4836 - mse: 0.4773 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1449/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4795 - mse: 0.4732 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1450/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4772 - mse: 0.4709\n",
      "Epoch 01450: saving model to Regression_Model/bl6.mle.linear-1450.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4789 - mse: 0.4726 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1451/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1452/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4788 - mse: 0.4726 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1453/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4853 - mse: 0.4790 - val_loss: 0.4123 - val_mse: 0.4061\n",
      "Epoch 1454/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4746 - mse: 0.4683 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1455/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4778 - mse: 0.4715 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1456/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4726 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1457/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4753 - mse: 0.4690 - val_loss: 0.4121 - val_mse: 0.4059\n",
      "Epoch 1458/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4713 - val_loss: 0.4124 - val_mse: 0.4062\n",
      "Epoch 1459/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4129 - val_mse: 0.4066\n",
      "Epoch 1460/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4740 - mse: 0.4677\n",
      "Epoch 01460: saving model to Regression_Model/bl6.mle.linear-1460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4729 - mse: 0.4666 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1461/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4704 - mse: 0.4642 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1462/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4703 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1463/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4766 - mse: 0.4703 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1464/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4730 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1465/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4738 - mse: 0.4676 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1466/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4807 - mse: 0.4744 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1467/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4747 - mse: 0.4684 - val_loss: 0.4126 - val_mse: 0.4063\n",
      "Epoch 1468/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4762 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1469/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4737 - val_loss: 0.4123 - val_mse: 0.4061\n",
      "Epoch 1470/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4815 - mse: 0.4752\n",
      "Epoch 01470: saving model to Regression_Model/bl6.mle.linear-1470.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4808 - mse: 0.4745 - val_loss: 0.4119 - val_mse: 0.4057\n",
      "Epoch 1471/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4746 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1472/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4861 - mse: 0.4799 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1473/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4127 - val_mse: 0.4065\n",
      "Epoch 1474/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4741 - val_loss: 0.4123 - val_mse: 0.4060\n",
      "Epoch 1475/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4736 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1476/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4764 - mse: 0.4701 - val_loss: 0.4124 - val_mse: 0.4062\n",
      "Epoch 1477/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4786 - mse: 0.4723 - val_loss: 0.4122 - val_mse: 0.4060\n",
      "Epoch 1478/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4796 - mse: 0.4733 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1479/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4120 - val_mse: 0.4057\n",
      "Epoch 1480/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4758 - mse: 0.4695\n",
      "Epoch 01480: saving model to Regression_Model/bl6.mle.linear-1480.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.4774 - mse: 0.4711 - val_loss: 0.4118 - val_mse: 0.4055\n",
      "Epoch 1481/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4743 - val_loss: 0.4135 - val_mse: 0.4072\n",
      "Epoch 1482/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4744 - val_loss: 0.4117 - val_mse: 0.4055\n",
      "Epoch 1483/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1484/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4722 - val_loss: 0.4118 - val_mse: 0.4055\n",
      "Epoch 1485/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4743 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1486/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4840 - mse: 0.4777 - val_loss: 0.4127 - val_mse: 0.4064\n",
      "Epoch 1487/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4811 - mse: 0.4748 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1488/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4841 - mse: 0.4779 - val_loss: 0.4117 - val_mse: 0.4055\n",
      "Epoch 1489/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4706 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1490/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4778 - mse: 0.4715\n",
      "Epoch 01490: saving model to Regression_Model/bl6.mle.linear-1490.ckpt\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4775 - mse: 0.4713 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1491/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4732 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1492/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4812 - mse: 0.4749 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1493/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4771 - val_loss: 0.4124 - val_mse: 0.4062\n",
      "Epoch 1494/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4759 - val_loss: 0.4136 - val_mse: 0.4073\n",
      "Epoch 1495/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4786 - mse: 0.4724 - val_loss: 0.4124 - val_mse: 0.4062\n",
      "Epoch 1496/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4739 - mse: 0.4676 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1497/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4757 - mse: 0.4694 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1498/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4710 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1499/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1500/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4828 - mse: 0.4765\n",
      "Epoch 01500: saving model to Regression_Model/bl6.mle.linear-1500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4762 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1501/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4720 - val_loss: 0.4120 - val_mse: 0.4057\n",
      "Epoch 1502/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4779 - mse: 0.4716 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1503/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4751 - mse: 0.4688 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1504/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4735 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1505/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4694 - mse: 0.4631 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1506/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4719 - mse: 0.4656 - val_loss: 0.4120 - val_mse: 0.4057\n",
      "Epoch 1507/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4688 - mse: 0.4625 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1508/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4765 - mse: 0.4703 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1509/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4752 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1510/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4771 - mse: 0.4709\n",
      "Epoch 01510: saving model to Regression_Model/bl6.mle.linear-1510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4776 - mse: 0.4713 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1511/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4706 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1512/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4779 - mse: 0.4716 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1513/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4832 - mse: 0.4769 - val_loss: 0.4128 - val_mse: 0.4065\n",
      "Epoch 1514/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4764 - mse: 0.4701 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1515/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4788 - mse: 0.4726 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1516/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4735 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1517/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4705 - val_loss: 0.4120 - val_mse: 0.4058\n",
      "Epoch 1518/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4761 - mse: 0.4698 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1519/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4708 - val_loss: 0.4117 - val_mse: 0.4055\n",
      "Epoch 1520/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4764 - mse: 0.4701\n",
      "Epoch 01520: saving model to Regression_Model/bl6.mle.linear-1520.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4764 - mse: 0.4701 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1521/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4854 - mse: 0.4792 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1522/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4839 - mse: 0.4777 - val_loss: 0.4130 - val_mse: 0.4067\n",
      "Epoch 1523/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4758 - mse: 0.4695 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1524/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4131 - val_mse: 0.4069\n",
      "Epoch 1525/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4721 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1526/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4707 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1527/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4752 - mse: 0.4689 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1528/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4788 - mse: 0.4725 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1529/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4826 - mse: 0.4763 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1530/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4805 - mse: 0.4742\n",
      "Epoch 01530: saving model to Regression_Model/bl6.mle.linear-1530.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4807 - mse: 0.4744 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1531/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4761 - val_loss: 0.4124 - val_mse: 0.4061\n",
      "Epoch 1532/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1533/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4730 - mse: 0.4668 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1534/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1535/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4822 - mse: 0.4760 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1536/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4775 - mse: 0.4712 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1537/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4761 - mse: 0.4699 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1538/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4764 - mse: 0.4701 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1539/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4760 - mse: 0.4698 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1540/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4763 - mse: 0.4701\n",
      "Epoch 01540: saving model to Regression_Model/bl6.mle.linear-1540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4763 - mse: 0.4700 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1541/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4707 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1542/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4800 - mse: 0.4738 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1543/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4834 - mse: 0.4771 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1544/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4839 - mse: 0.4777 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1545/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4789 - mse: 0.4727 - val_loss: 0.4119 - val_mse: 0.4057\n",
      "Epoch 1546/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4718 - mse: 0.4655 - val_loss: 0.4119 - val_mse: 0.4057\n",
      "Epoch 1547/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4719 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1548/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4762 - mse: 0.4700 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1549/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4749 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1550/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4716 - mse: 0.4653\n",
      "Epoch 01550: saving model to Regression_Model/bl6.mle.linear-1550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4726 - mse: 0.4663 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1551/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4729 - mse: 0.4667 - val_loss: 0.4117 - val_mse: 0.4055\n",
      "Epoch 1552/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4713 - mse: 0.4651 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1553/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4780 - mse: 0.4718 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1554/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4786 - mse: 0.4723 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1555/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4729 - mse: 0.4667 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1556/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4735 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1557/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4743 - mse: 0.4680 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1558/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4780 - mse: 0.4717 - val_loss: 0.4118 - val_mse: 0.4056\n",
      "Epoch 1559/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4801 - mse: 0.4738 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1560/2000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 0.4771 - mse: 0.4708\n",
      "Epoch 01560: saving model to Regression_Model/bl6.mle.linear-1560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4752 - mse: 0.4689 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1561/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4743 - mse: 0.4681 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1562/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1563/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4792 - mse: 0.4730 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1564/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4741 - mse: 0.4678 - val_loss: 0.4118 - val_mse: 0.4055\n",
      "Epoch 1565/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4840 - mse: 0.4778 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1566/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4728 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1567/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4719 - val_loss: 0.4119 - val_mse: 0.4057\n",
      "Epoch 1568/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4702 - val_loss: 0.4118 - val_mse: 0.4056\n",
      "Epoch 1569/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4703 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1570/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4764 - mse: 0.4701\n",
      "Epoch 01570: saving model to Regression_Model/bl6.mle.linear-1570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4709 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1571/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4761 - mse: 0.4698 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1572/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4823 - mse: 0.4760 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1573/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4716 - mse: 0.4653 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1574/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4763 - mse: 0.4700 - val_loss: 0.4120 - val_mse: 0.4057\n",
      "Epoch 1575/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4123 - val_mse: 0.4061\n",
      "Epoch 1576/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1577/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4771 - mse: 0.4708 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1578/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4843 - mse: 0.4781 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1579/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4738 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1580/2000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.4871 - mse: 0.4808\n",
      "Epoch 01580: saving model to Regression_Model/bl6.mle.linear-1580.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4863 - mse: 0.4800 - val_loss: 0.4119 - val_mse: 0.4057\n",
      "Epoch 1581/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4759 - mse: 0.4696 - val_loss: 0.4125 - val_mse: 0.4062\n",
      "Epoch 1582/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4120 - val_mse: 0.4058\n",
      "Epoch 1583/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4721 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1584/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4731 - mse: 0.4669 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1585/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4806 - mse: 0.4744 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1586/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4732 - mse: 0.4669 - val_loss: 0.4118 - val_mse: 0.4055\n",
      "Epoch 1587/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4789 - mse: 0.4727 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1588/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4771 - mse: 0.4709 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1589/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4729 - mse: 0.4667 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1590/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4776 - mse: 0.4713\n",
      "Epoch 01590: saving model to Regression_Model/bl6.mle.linear-1590.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4768 - mse: 0.4705 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1591/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1592/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4720 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1593/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4821 - mse: 0.4759 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1594/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4774 - mse: 0.4712 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1595/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4777 - mse: 0.4715 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1596/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4801 - mse: 0.4739 - val_loss: 0.4118 - val_mse: 0.4056\n",
      "Epoch 1597/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4834 - mse: 0.4771 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1598/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4764 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1599/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4817 - mse: 0.4755 - val_loss: 0.4117 - val_mse: 0.4055\n",
      "Epoch 1600/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4763 - mse: 0.4700\n",
      "Epoch 01600: saving model to Regression_Model/bl6.mle.linear-1600.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4751 - mse: 0.4689 - val_loss: 0.4120 - val_mse: 0.4057\n",
      "Epoch 1601/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4777 - mse: 0.4715 - val_loss: 0.4126 - val_mse: 0.4064\n",
      "Epoch 1602/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4707 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1603/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4837 - mse: 0.4774 - val_loss: 0.4124 - val_mse: 0.4062\n",
      "Epoch 1604/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1605/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4650 - mse: 0.4588 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1606/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4774 - mse: 0.4711 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1607/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4796 - mse: 0.4733 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1608/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4797 - mse: 0.4735 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1609/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4786 - mse: 0.4723 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1610/2000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 0.4873 - mse: 0.4811\n",
      "Epoch 01610: saving model to Regression_Model/bl6.mle.linear-1610.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4864 - mse: 0.4802 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1611/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4845 - mse: 0.4783 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1612/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4762 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1613/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4756 - val_loss: 0.4119 - val_mse: 0.4057\n",
      "Epoch 1614/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1615/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4776 - mse: 0.4713 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1616/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4769 - mse: 0.4706 - val_loss: 0.4120 - val_mse: 0.4057\n",
      "Epoch 1617/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4781 - mse: 0.4719 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1618/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4786 - mse: 0.4724 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1619/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4780 - mse: 0.4717 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1620/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4771 - mse: 0.4709\n",
      "Epoch 01620: saving model to Regression_Model/bl6.mle.linear-1620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4764 - mse: 0.4702 - val_loss: 0.4114 - val_mse: 0.4051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1621/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1622/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4835 - mse: 0.4772 - val_loss: 0.4117 - val_mse: 0.4055\n",
      "Epoch 1623/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4720 - val_loss: 0.4120 - val_mse: 0.4058\n",
      "Epoch 1624/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4820 - mse: 0.4757 - val_loss: 0.4124 - val_mse: 0.4062\n",
      "Epoch 1625/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4733 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1626/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4755 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1627/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4780 - mse: 0.4717 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1628/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4774 - mse: 0.4712 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1629/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4710 - mse: 0.4647 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1630/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4849 - mse: 0.4786\n",
      "Epoch 01630: saving model to Regression_Model/bl6.mle.linear-1630.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4779 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1631/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4744 - mse: 0.4682 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1632/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4822 - mse: 0.4759 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1633/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4737 - val_loss: 0.4119 - val_mse: 0.4057\n",
      "Epoch 1634/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4122 - val_mse: 0.4060\n",
      "Epoch 1635/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4743 - mse: 0.4681 - val_loss: 0.4121 - val_mse: 0.4058\n",
      "Epoch 1636/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4776 - mse: 0.4713 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1637/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4712 - mse: 0.4650 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1638/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4814 - mse: 0.4752 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1639/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4768 - mse: 0.4706 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1640/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4780 - mse: 0.4717\n",
      "Epoch 01640: saving model to Regression_Model/bl6.mle.linear-1640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4780 - mse: 0.4717 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1641/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4723 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1642/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4738 - mse: 0.4675 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1643/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4727 - mse: 0.4664 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1644/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4862 - mse: 0.4799 - val_loss: 0.4104 - val_mse: 0.4041\n",
      "Epoch 1645/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4731 - mse: 0.4669 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1646/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4835 - mse: 0.4772 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1647/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4815 - mse: 0.4752 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1648/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4812 - mse: 0.4750 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1649/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4764 - mse: 0.4702 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1650/2000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 0.4764 - mse: 0.4702\n",
      "Epoch 01650: saving model to Regression_Model/bl6.mle.linear-1650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4723 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1651/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4722 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1652/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4743 - mse: 0.4680 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1653/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4836 - mse: 0.4774 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1654/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4719 - mse: 0.4656 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1655/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4722 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1656/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4118 - val_mse: 0.4055\n",
      "Epoch 1657/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4709 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1658/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4713 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1659/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4710 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1660/2000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 0.4776 - mse: 0.4713\n",
      "Epoch 01660: saving model to Regression_Model/bl6.mle.linear-1660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4711 - val_loss: 0.4104 - val_mse: 0.4041\n",
      "Epoch 1661/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4816 - mse: 0.4753 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1662/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4761 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1663/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4767 - mse: 0.4705 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1664/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1665/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4701 - mse: 0.4639 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1666/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4710 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1667/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4699 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1668/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1669/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4811 - mse: 0.4748 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1670/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4753 - mse: 0.4690\n",
      "Epoch 01670: saving model to Regression_Model/bl6.mle.linear-1670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4754 - mse: 0.4691 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1671/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4701 - mse: 0.4639 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1672/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4725 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1673/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4703 - val_loss: 0.4103 - val_mse: 0.4040\n",
      "Epoch 1674/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4740 - val_loss: 0.4104 - val_mse: 0.4042\n",
      "Epoch 1675/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4743 - mse: 0.4681 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1676/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4703 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1677/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4744 - mse: 0.4681 - val_loss: 0.4105 - val_mse: 0.4042\n",
      "Epoch 1678/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1679/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4833 - mse: 0.4770 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1680/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4790 - mse: 0.4727\n",
      "Epoch 01680: saving model to Regression_Model/bl6.mle.linear-1680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4726 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1681/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4723 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1682/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4769 - mse: 0.4707 - val_loss: 0.4122 - val_mse: 0.4059\n",
      "Epoch 1683/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4807 - mse: 0.4744 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1684/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4822 - mse: 0.4760 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1685/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4721 - mse: 0.4659 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1686/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4734 - mse: 0.4672 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1687/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4756 - mse: 0.4694 - val_loss: 0.4120 - val_mse: 0.4058\n",
      "Epoch 1688/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1689/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4816 - mse: 0.4753 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1690/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4797 - mse: 0.4734\n",
      "Epoch 01690: saving model to Regression_Model/bl6.mle.linear-1690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4793 - mse: 0.4731 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1691/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4765 - mse: 0.4702 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1692/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4751 - mse: 0.4688 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1693/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4707 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1694/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4729 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1695/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4782 - mse: 0.4719 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1696/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4734 - mse: 0.4671 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1697/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4724 - mse: 0.4661 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1698/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4738 - mse: 0.4675 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1699/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4738 - mse: 0.4675 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1700/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4750 - mse: 0.4687\n",
      "Epoch 01700: saving model to Regression_Model/bl6.mle.linear-1700.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4752 - mse: 0.4690 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1701/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4752 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1702/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4708 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1703/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4764 - mse: 0.4702 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1704/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4757 - val_loss: 0.4119 - val_mse: 0.4056\n",
      "Epoch 1705/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4700 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1706/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4710 - mse: 0.4648 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1707/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4836 - mse: 0.4773 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1708/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4728 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1709/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4805 - mse: 0.4743 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1710/2000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 0.4753 - mse: 0.4690\n",
      "Epoch 01710: saving model to Regression_Model/bl6.mle.linear-1710.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4712 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1711/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4727 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1712/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4710 - mse: 0.4647 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1713/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4729 - mse: 0.4666 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1714/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4104 - val_mse: 0.4042\n",
      "Epoch 1715/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4692 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1716/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4755 - mse: 0.4693 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1717/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4817 - mse: 0.4755 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1718/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4752 - mse: 0.4689 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1719/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4837 - mse: 0.4775 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1720/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4888 - mse: 0.4825\n",
      "Epoch 01720: saving model to Regression_Model/bl6.mle.linear-1720.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4888 - mse: 0.4825 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1721/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4118 - val_mse: 0.4055\n",
      "Epoch 1722/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4746 - mse: 0.4684 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1723/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4720 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1724/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4774 - mse: 0.4712 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1725/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4754 - mse: 0.4691 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1726/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4839 - mse: 0.4777 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1727/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4812 - mse: 0.4749 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1728/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4689 - mse: 0.4627 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1729/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4728 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1730/2000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 0.4768 - mse: 0.4705\n",
      "Epoch 01730: saving model to Regression_Model/bl6.mle.linear-1730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4730 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1731/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4763 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1732/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4741 - mse: 0.4679 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1733/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4774 - mse: 0.4712 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1734/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4691 - mse: 0.4629 - val_loss: 0.4116 - val_mse: 0.4053\n",
      "Epoch 1735/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4120 - val_mse: 0.4058\n",
      "Epoch 1736/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4748 - mse: 0.4686 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1737/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4825 - mse: 0.4762 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1738/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4805 - mse: 0.4742 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1739/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4774 - mse: 0.4712 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1740/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4750 - mse: 0.4687\n",
      "Epoch 01740: saving model to Regression_Model/bl6.mle.linear-1740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4744 - mse: 0.4682 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1741/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4711 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1742/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4772 - mse: 0.4709 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1743/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4708 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1744/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4721 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1745/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4785 - mse: 0.4723 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1746/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4758 - mse: 0.4696 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1747/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4817 - mse: 0.4754 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1748/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4741 - mse: 0.4678 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1749/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4798 - mse: 0.4735 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1750/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4780 - mse: 0.4718\n",
      "Epoch 01750: saving model to Regression_Model/bl6.mle.linear-1750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4764 - mse: 0.4702 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1751/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4759 - mse: 0.4696 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1752/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4728 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1753/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4750 - mse: 0.4688 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1754/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4822 - mse: 0.4759 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1755/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4713 - mse: 0.4651 - val_loss: 0.4103 - val_mse: 0.4040\n",
      "Epoch 1756/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4748 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1757/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4790 - mse: 0.4728 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1758/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1759/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4739 - mse: 0.4677 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1760/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4762 - mse: 0.4700\n",
      "Epoch 01760: saving model to Regression_Model/bl6.mle.linear-1760.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 0.4762 - mse: 0.4699 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1761/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4795 - mse: 0.4733 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1762/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4734 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1763/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4727 - mse: 0.4665 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1764/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4765 - mse: 0.4703 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1765/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4767 - mse: 0.4704 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1766/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4736 - val_loss: 0.4103 - val_mse: 0.4040\n",
      "Epoch 1767/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4753 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1768/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4735 - mse: 0.4672 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1769/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4736 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1770/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4853 - mse: 0.4791\n",
      "Epoch 01770: saving model to Regression_Model/bl6.mle.linear-1770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4788 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1771/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4741 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1772/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4833 - mse: 0.4771 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1773/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4746 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1774/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4752 - mse: 0.4690 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1775/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4720 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1776/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4838 - mse: 0.4775 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1777/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4811 - mse: 0.4748 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1778/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4706 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1779/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4734 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1780/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4800 - mse: 0.4738\n",
      "Epoch 01780: saving model to Regression_Model/bl6.mle.linear-1780.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 0.4798 - mse: 0.4735 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1781/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4702 - mse: 0.4639 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1782/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4700 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1783/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4704 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1784/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4813 - mse: 0.4751 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1785/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4788 - mse: 0.4726 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1786/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4761 - mse: 0.4698 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1787/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4777 - mse: 0.4715 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1788/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4708 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1789/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4697 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1790/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4790 - mse: 0.4728\n",
      "Epoch 01790: saving model to Regression_Model/bl6.mle.linear-1790.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4747 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1791/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4815 - mse: 0.4753 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1792/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4758 - mse: 0.4696 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1793/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4740 - val_loss: 0.4118 - val_mse: 0.4055\n",
      "Epoch 1794/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4824 - mse: 0.4762 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1795/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4738 - mse: 0.4675 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1796/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4747 - mse: 0.4684 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1797/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4779 - mse: 0.4717 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1798/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4740 - mse: 0.4678 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1799/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4809 - mse: 0.4746 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1800/2000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 0.4775 - mse: 0.4712\n",
      "Epoch 01800: saving model to Regression_Model/bl6.mle.linear-1800.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4771 - mse: 0.4709 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1801/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4775 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1802/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4826 - mse: 0.4763 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1803/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4782 - mse: 0.4719 - val_loss: 0.4117 - val_mse: 0.4055\n",
      "Epoch 1804/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4788 - mse: 0.4726 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1805/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4792 - mse: 0.4730 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1806/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4793 - mse: 0.4731 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1807/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4723 - mse: 0.4660 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1808/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4795 - mse: 0.4733 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1809/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4804 - mse: 0.4742 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1810/2000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 0.4803 - mse: 0.4741\n",
      "Epoch 01810: saving model to Regression_Model/bl6.mle.linear-1810.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4781 - mse: 0.4718 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1811/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4731 - mse: 0.4669 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1812/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4722 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1813/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4814 - mse: 0.4751 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1814/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4731 - val_loss: 0.4105 - val_mse: 0.4042\n",
      "Epoch 1815/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4766 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1816/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4752 - mse: 0.4689 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1817/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4869 - mse: 0.4806 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1818/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4720 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1819/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4807 - mse: 0.4745 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1820/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4786 - mse: 0.4724\n",
      "Epoch 01820: saving model to Regression_Model/bl6.mle.linear-1820.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4783 - mse: 0.4721 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1821/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4748 - mse: 0.4685 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1822/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4816 - mse: 0.4754 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1823/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4742 - mse: 0.4679 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1824/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4815 - mse: 0.4753 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1825/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4746 - mse: 0.4683 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1826/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4814 - mse: 0.4751 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1827/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4799 - mse: 0.4736 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1828/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4730 - mse: 0.4668 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1829/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4891 - mse: 0.4829 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1830/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4711 - mse: 0.4648\n",
      "Epoch 01830: saving model to Regression_Model/bl6.mle.linear-1830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4712 - mse: 0.4650 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1831/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4740 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1832/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4776 - mse: 0.4713 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1833/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4774 - mse: 0.4712 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1834/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4827 - mse: 0.4765 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1835/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4777 - mse: 0.4714 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1836/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4730 - mse: 0.4667 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1837/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1838/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4828 - mse: 0.4765 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1839/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4780 - mse: 0.4718 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1840/2000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 0.4787 - mse: 0.4725\n",
      "Epoch 01840: saving model to Regression_Model/bl6.mle.linear-1840.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4788 - mse: 0.4726 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1841/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4793 - mse: 0.4730 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1842/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1843/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4797 - mse: 0.4734 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1844/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4828 - mse: 0.4765 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1845/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4825 - mse: 0.4762 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1846/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4753 - mse: 0.4691 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1847/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4799 - mse: 0.4737 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1848/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4789 - mse: 0.4727 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1849/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4731 - mse: 0.4668 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1850/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4804 - mse: 0.4741\n",
      "Epoch 01850: saving model to Regression_Model/bl6.mle.linear-1850.ckpt\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.4811 - mse: 0.4749 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1851/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4761 - mse: 0.4698 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1852/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4748 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1853/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4729 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1854/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4805 - mse: 0.4742 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1855/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4726 - mse: 0.4664 - val_loss: 0.4104 - val_mse: 0.4042\n",
      "Epoch 1856/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4743 - mse: 0.4680 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1857/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1858/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4779 - mse: 0.4717 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1859/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4699 - mse: 0.4636 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1860/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4743 - mse: 0.4681\n",
      "Epoch 01860: saving model to Regression_Model/bl6.mle.linear-1860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4744 - mse: 0.4682 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1861/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4731 - mse: 0.4669 - val_loss: 0.4104 - val_mse: 0.4042\n",
      "Epoch 1862/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4829 - mse: 0.4766 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1863/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4794 - mse: 0.4732 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1864/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4730 - mse: 0.4668 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1865/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4742 - mse: 0.4679 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1866/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4826 - mse: 0.4764 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1867/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4776 - mse: 0.4713 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1868/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4800 - mse: 0.4738 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1869/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4742 - mse: 0.4680 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1870/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4758 - mse: 0.4696\n",
      "Epoch 01870: saving model to Regression_Model/bl6.mle.linear-1870.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 0.4752 - mse: 0.4690 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1871/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4755 - mse: 0.4693 - val_loss: 0.4104 - val_mse: 0.4041\n",
      "Epoch 1872/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4771 - mse: 0.4709 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1873/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4723 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1874/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4757 - mse: 0.4694 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1875/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4720 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1876/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4775 - mse: 0.4712 - val_loss: 0.4104 - val_mse: 0.4041\n",
      "Epoch 1877/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4774 - mse: 0.4711 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1878/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4722 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1879/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4698 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1880/2000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 0.4795 - mse: 0.4733\n",
      "Epoch 01880: saving model to Regression_Model/bl6.mle.linear-1880.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 0.4831 - mse: 0.4769 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1881/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4842 - mse: 0.4779 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1882/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4858 - mse: 0.4796 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1883/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4757 - mse: 0.4695 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1884/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4720 - mse: 0.4658 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1885/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1886/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4812 - mse: 0.4750 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1887/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4809 - mse: 0.4747 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1888/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4756 - mse: 0.4694 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1889/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4722 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1890/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/368 [===========================>..] - ETA: 0s - loss: 0.4789 - mse: 0.4727\n",
      "Epoch 01890: saving model to Regression_Model/bl6.mle.linear-1890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4782 - mse: 0.4719 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1891/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4708 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1892/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4734 - mse: 0.4672 - val_loss: 0.4104 - val_mse: 0.4041\n",
      "Epoch 1893/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4797 - mse: 0.4735 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1894/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4723 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1895/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4726 - mse: 0.4663 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1896/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4795 - mse: 0.4733 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1897/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4737 - mse: 0.4674 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1898/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4700 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1899/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4740 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1900/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4794 - mse: 0.4731\n",
      "Epoch 01900: saving model to Regression_Model/bl6.mle.linear-1900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4793 - mse: 0.4730 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1901/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4751 - mse: 0.4689 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1902/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4683 - mse: 0.4621 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1903/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4778 - mse: 0.4716 - val_loss: 0.4103 - val_mse: 0.4040\n",
      "Epoch 1904/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4776 - mse: 0.4713 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1905/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4742 - mse: 0.4680 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1906/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1907/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4757 - mse: 0.4694 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1908/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4797 - mse: 0.4734 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1909/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4788 - mse: 0.4726 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1910/2000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 0.4776 - mse: 0.4713\n",
      "Epoch 01910: saving model to Regression_Model/bl6.mle.linear-1910.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4777 - mse: 0.4715 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1911/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4851 - mse: 0.4789 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1912/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4759 - mse: 0.4696 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1913/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4833 - mse: 0.4771 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1914/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4716 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1915/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4777 - mse: 0.4715 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1916/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4767 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1917/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4791 - mse: 0.4729 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1918/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4805 - mse: 0.4743 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1919/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4788 - mse: 0.4725 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1920/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4787 - mse: 0.4725\n",
      "Epoch 01920: saving model to Regression_Model/bl6.mle.linear-1920.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 0.4787 - mse: 0.4724 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1921/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4811 - mse: 0.4748 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1922/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4750 - mse: 0.4687 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1923/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4797 - mse: 0.4735 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1924/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4806 - mse: 0.4744 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1925/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4711 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1926/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4779 - mse: 0.4716 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1927/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4803 - mse: 0.4741 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1928/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4770 - mse: 0.4708 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1929/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4747 - mse: 0.4685 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1930/2000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 0.4804 - mse: 0.4742\n",
      "Epoch 01930: saving model to Regression_Model/bl6.mle.linear-1930.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4816 - mse: 0.4753 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1931/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4760 - mse: 0.4697 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1932/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4819 - mse: 0.4756 - val_loss: 0.4113 - val_mse: 0.4050\n",
      "Epoch 1933/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4799 - mse: 0.4736 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1934/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4791 - mse: 0.4729 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1935/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4785 - mse: 0.4722 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1936/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4721 - mse: 0.4658 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1937/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4764 - mse: 0.4702 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1938/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4804 - mse: 0.4741 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1939/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4838 - mse: 0.4776 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1940/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4735 - mse: 0.4673\n",
      "Epoch 01940: saving model to Regression_Model/bl6.mle.linear-1940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4735 - mse: 0.4673 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1941/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4766 - mse: 0.4704 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1942/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4732 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1943/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4767 - mse: 0.4705 - val_loss: 0.4108 - val_mse: 0.4045\n",
      "Epoch 1944/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4829 - mse: 0.4766 - val_loss: 0.4110 - val_mse: 0.4048\n",
      "Epoch 1945/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4830 - mse: 0.4768 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1946/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4817 - mse: 0.4754 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1947/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4751 - mse: 0.4688 - val_loss: 0.4115 - val_mse: 0.4052\n",
      "Epoch 1948/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4791 - mse: 0.4729 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1949/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4756 - mse: 0.4693 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1950/2000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 0.4724 - mse: 0.4661\n",
      "Epoch 01950: saving model to Regression_Model/bl6.mle.linear-1950.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4734 - mse: 0.4672 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1951/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4710 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1952/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4785 - mse: 0.4722 - val_loss: 0.4116 - val_mse: 0.4054\n",
      "Epoch 1953/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4782 - mse: 0.4719 - val_loss: 0.4117 - val_mse: 0.4054\n",
      "Epoch 1954/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4763 - mse: 0.4700 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1955/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4798 - mse: 0.4736 - val_loss: 0.4114 - val_mse: 0.4051\n",
      "Epoch 1956/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4762 - mse: 0.4700 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1957/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4790 - mse: 0.4728 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1958/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4811 - mse: 0.4748 - val_loss: 0.4114 - val_mse: 0.4052\n",
      "Epoch 1959/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4769 - mse: 0.4706 - val_loss: 0.4115 - val_mse: 0.4053\n",
      "Epoch 1960/2000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 0.4767 - mse: 0.4705\n",
      "Epoch 01960: saving model to Regression_Model/bl6.mle.linear-1960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4757 - mse: 0.4694 - val_loss: 0.4113 - val_mse: 0.4051\n",
      "Epoch 1961/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4759 - mse: 0.4697 - val_loss: 0.4111 - val_mse: 0.4049\n",
      "Epoch 1962/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4747 - val_loss: 0.4112 - val_mse: 0.4049\n",
      "Epoch 1963/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4783 - mse: 0.4721 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1964/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4735 - mse: 0.4672 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1965/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4727 - mse: 0.4664 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1966/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4828 - mse: 0.4766 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1967/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4808 - mse: 0.4745 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1968/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4771 - mse: 0.4708 - val_loss: 0.4111 - val_mse: 0.4048\n",
      "Epoch 1969/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4773 - mse: 0.4711 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1970/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4730 - mse: 0.4667\n",
      "Epoch 01970: saving model to Regression_Model/bl6.mle.linear-1970.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 0.4723 - mse: 0.4660 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1971/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4734 - mse: 0.4672 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1972/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4708 - mse: 0.4646 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1973/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4818 - mse: 0.4756 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1974/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4819 - mse: 0.4757 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1975/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4849 - mse: 0.4787 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1976/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4843 - mse: 0.4780 - val_loss: 0.4110 - val_mse: 0.4047\n",
      "Epoch 1977/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4781 - mse: 0.4719 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1978/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4815 - mse: 0.4752 - val_loss: 0.4107 - val_mse: 0.4044\n",
      "Epoch 1979/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4743 - mse: 0.4681 - val_loss: 0.4106 - val_mse: 0.4043\n",
      "Epoch 1980/2000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.4785 - mse: 0.4723\n",
      "Epoch 01980: saving model to Regression_Model/bl6.mle.linear-1980.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4784 - mse: 0.4721 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1981/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4810 - mse: 0.4748 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1982/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4778 - mse: 0.4716 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1983/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4763 - mse: 0.4701 - val_loss: 0.4104 - val_mse: 0.4042\n",
      "Epoch 1984/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4729 - mse: 0.4666 - val_loss: 0.4105 - val_mse: 0.4042\n",
      "Epoch 1985/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4824 - mse: 0.4761 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1986/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4865 - mse: 0.4803 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1987/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4774 - mse: 0.4711 - val_loss: 0.4112 - val_mse: 0.4050\n",
      "Epoch 1988/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4729 - mse: 0.4667 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1989/2000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 0.4765 - mse: 0.4703 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1990/2000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 0.4722 - mse: 0.4660\n",
      "Epoch 01990: saving model to Regression_Model/bl6.mle.linear-1990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4735 - mse: 0.4673 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1991/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4809 - mse: 0.4747 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1992/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4747 - mse: 0.4684 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1993/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4802 - mse: 0.4739 - val_loss: 0.4105 - val_mse: 0.4043\n",
      "Epoch 1994/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4757 - mse: 0.4694 - val_loss: 0.4106 - val_mse: 0.4044\n",
      "Epoch 1995/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4751 - mse: 0.4689 - val_loss: 0.4109 - val_mse: 0.4047\n",
      "Epoch 1996/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4724 - mse: 0.4662 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 1997/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4794 - mse: 0.4732 - val_loss: 0.4109 - val_mse: 0.4046\n",
      "Epoch 1998/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4740 - mse: 0.4678 - val_loss: 0.4107 - val_mse: 0.4045\n",
      "Epoch 1999/2000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 0.4738 - mse: 0.4676 - val_loss: 0.4108 - val_mse: 0.4046\n",
      "Epoch 2000/2000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 0.4856 - mse: 0.4794\n",
      "Epoch 02000: saving model to Regression_Model/bl6.mle.linear-2000.ckpt\n",
      "368/368 [==============================] - 5s 13ms/step - loss: 0.4855 - mse: 0.4793 - val_loss: 0.4110 - val_mse: 0.4048\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=2000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "mse\n",
      "val_loss\n",
      "val_mse\n"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb1d9e5710>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-1990.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "testid='bl6.mle.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight success\n"
     ]
    }
   ],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([492.], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3736844"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
