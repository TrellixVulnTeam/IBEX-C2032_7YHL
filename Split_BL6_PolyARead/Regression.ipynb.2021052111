{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 55918\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.regression.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    train_data = (train_data-data_mean)/data_std\n",
    "    #train_data = train_data/data_max\n",
    "    train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    #valid_data    = valid_data/data_max\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3861275 2.4915485\n",
      "3.8266706 1.8094194\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2ab8f225c0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2ab8e9a0f0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='bl6.mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1397 steps, validate for 1397 steps\n",
      "Epoch 1/3000\n",
      "1397/1397 [==============================] - 8s 5ms/step - loss: 0.7098 - mse: 0.7032 - val_loss: 0.6005 - val_mse: 0.5939\n",
      "Epoch 2/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6563 - mse: 0.6496 - val_loss: 0.6447 - val_mse: 0.6380\n",
      "Epoch 3/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6486 - mse: 0.6419 - val_loss: 0.5787 - val_mse: 0.5718\n",
      "Epoch 4/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6399 - mse: 0.6331 - val_loss: 0.5732 - val_mse: 0.5663\n",
      "Epoch 5/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6306 - mse: 0.6238 - val_loss: 0.5691 - val_mse: 0.5622\n",
      "Epoch 6/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6278 - mse: 0.6209 - val_loss: 0.5772 - val_mse: 0.5702\n",
      "Epoch 7/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6256 - mse: 0.6187 - val_loss: 0.5567 - val_mse: 0.5497\n",
      "Epoch 8/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6222 - mse: 0.6152 - val_loss: 0.5625 - val_mse: 0.5555\n",
      "Epoch 9/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6151 - mse: 0.6080 - val_loss: 0.5446 - val_mse: 0.5376\n",
      "Epoch 10/3000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.6139 - mse: 0.6068\n",
      "Epoch 00010: saving model to Regression_Model/bl6.mle.linear-0010.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6143 - mse: 0.6072 - val_loss: 0.5858 - val_mse: 0.5788\n",
      "Epoch 11/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.6097 - mse: 0.6026 - val_loss: 0.5425 - val_mse: 0.5353\n",
      "Epoch 12/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6067 - mse: 0.5996 - val_loss: 0.5541 - val_mse: 0.5469\n",
      "Epoch 13/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6111 - mse: 0.6038 - val_loss: 0.5702 - val_mse: 0.5630\n",
      "Epoch 14/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6029 - mse: 0.5956 - val_loss: 0.5333 - val_mse: 0.5260\n",
      "Epoch 15/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.6051 - mse: 0.5977 - val_loss: 0.5395 - val_mse: 0.5321\n",
      "Epoch 16/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6055 - mse: 0.5981 - val_loss: 0.5475 - val_mse: 0.5400\n",
      "Epoch 17/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.6078 - mse: 0.6003 - val_loss: 0.5412 - val_mse: 0.5337\n",
      "Epoch 18/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5999 - mse: 0.5924 - val_loss: 0.5249 - val_mse: 0.5174\n",
      "Epoch 19/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5968 - mse: 0.5893 - val_loss: 0.5307 - val_mse: 0.5232\n",
      "Epoch 20/3000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5967 - mse: 0.5892\n",
      "Epoch 00020: saving model to Regression_Model/bl6.mle.linear-0020.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5966 - mse: 0.5891 - val_loss: 0.5291 - val_mse: 0.5216\n",
      "Epoch 21/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5937 - mse: 0.5862 - val_loss: 0.5540 - val_mse: 0.5464\n",
      "Epoch 22/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5932 - mse: 0.5856 - val_loss: 0.5238 - val_mse: 0.5162\n",
      "Epoch 23/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5915 - mse: 0.5838 - val_loss: 0.5231 - val_mse: 0.5155\n",
      "Epoch 24/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5904 - mse: 0.5828 - val_loss: 0.5227 - val_mse: 0.5151\n",
      "Epoch 25/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5926 - mse: 0.5850 - val_loss: 0.5298 - val_mse: 0.5221\n",
      "Epoch 26/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5908 - mse: 0.5831 - val_loss: 0.5243 - val_mse: 0.5166\n",
      "Epoch 27/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5882 - mse: 0.5805 - val_loss: 0.5155 - val_mse: 0.5078\n",
      "Epoch 28/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5862 - mse: 0.5784 - val_loss: 0.5185 - val_mse: 0.5108\n",
      "Epoch 29/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5886 - mse: 0.5808 - val_loss: 0.5735 - val_mse: 0.5658\n",
      "Epoch 30/3000\n",
      "1382/1397 [============================>.] - ETA: 0s - loss: 0.5883 - mse: 0.5805\n",
      "Epoch 00030: saving model to Regression_Model/bl6.mle.linear-0030.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5883 - mse: 0.5805 - val_loss: 0.5220 - val_mse: 0.5143\n",
      "Epoch 31/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5842 - mse: 0.5764 - val_loss: 0.5305 - val_mse: 0.5228\n",
      "Epoch 32/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5816 - mse: 0.5738 - val_loss: 0.5224 - val_mse: 0.5146\n",
      "Epoch 33/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5850 - mse: 0.5772 - val_loss: 0.5360 - val_mse: 0.5282\n",
      "Epoch 34/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5825 - mse: 0.5747 - val_loss: 0.5353 - val_mse: 0.5275\n",
      "Epoch 35/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5839 - mse: 0.5762 - val_loss: 0.5109 - val_mse: 0.5031\n",
      "Epoch 36/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5817 - mse: 0.5739 - val_loss: 0.5133 - val_mse: 0.5055\n",
      "Epoch 37/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5876 - mse: 0.5798 - val_loss: 0.5572 - val_mse: 0.5495\n",
      "Epoch 38/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5846 - mse: 0.5768 - val_loss: 0.5125 - val_mse: 0.5048\n",
      "Epoch 39/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5798 - mse: 0.5720 - val_loss: 0.5253 - val_mse: 0.5176\n",
      "Epoch 40/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5825 - mse: 0.5747\n",
      "Epoch 00040: saving model to Regression_Model/bl6.mle.linear-0040.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5820 - mse: 0.5742 - val_loss: 0.5119 - val_mse: 0.5041\n",
      "Epoch 41/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5833 - mse: 0.5756 - val_loss: 0.5200 - val_mse: 0.5122\n",
      "Epoch 42/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5793 - mse: 0.5715 - val_loss: 0.5171 - val_mse: 0.5093\n",
      "Epoch 43/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5811 - mse: 0.5733 - val_loss: 0.5109 - val_mse: 0.5031\n",
      "Epoch 44/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5788 - mse: 0.5710 - val_loss: 0.5236 - val_mse: 0.5159\n",
      "Epoch 45/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5763 - mse: 0.5685 - val_loss: 0.5180 - val_mse: 0.5102\n",
      "Epoch 46/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5761 - mse: 0.5683 - val_loss: 0.5073 - val_mse: 0.4995\n",
      "Epoch 47/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5775 - mse: 0.5697 - val_loss: 0.5220 - val_mse: 0.5142\n",
      "Epoch 48/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5758 - mse: 0.5681 - val_loss: 0.5066 - val_mse: 0.4989\n",
      "Epoch 49/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5809 - mse: 0.5731 - val_loss: 0.5074 - val_mse: 0.4997\n",
      "Epoch 50/3000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5789 - mse: 0.5712\n",
      "Epoch 00050: saving model to Regression_Model/bl6.mle.linear-0050.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5788 - mse: 0.5710 - val_loss: 0.5059 - val_mse: 0.4981\n",
      "Epoch 51/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5766 - mse: 0.5688 - val_loss: 0.5254 - val_mse: 0.5176\n",
      "Epoch 52/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5775 - mse: 0.5698 - val_loss: 0.5133 - val_mse: 0.5055\n",
      "Epoch 53/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5748 - mse: 0.5671 - val_loss: 0.5079 - val_mse: 0.5001\n",
      "Epoch 54/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5740 - mse: 0.5662 - val_loss: 0.5034 - val_mse: 0.4956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5763 - mse: 0.5686 - val_loss: 0.5110 - val_mse: 0.5032\n",
      "Epoch 56/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5727 - mse: 0.5650 - val_loss: 0.5056 - val_mse: 0.4978\n",
      "Epoch 57/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5760 - mse: 0.5682 - val_loss: 0.5099 - val_mse: 0.5021\n",
      "Epoch 58/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5745 - mse: 0.5667 - val_loss: 0.5180 - val_mse: 0.5102\n",
      "Epoch 59/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5712 - mse: 0.5634 - val_loss: 0.5103 - val_mse: 0.5026\n",
      "Epoch 60/3000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5726 - mse: 0.5648\n",
      "Epoch 00060: saving model to Regression_Model/bl6.mle.linear-0060.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5721 - mse: 0.5643 - val_loss: 0.5114 - val_mse: 0.5036\n",
      "Epoch 61/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5741 - mse: 0.5663 - val_loss: 0.5097 - val_mse: 0.5019\n",
      "Epoch 62/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5744 - mse: 0.5666 - val_loss: 0.5028 - val_mse: 0.4950\n",
      "Epoch 63/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5742 - mse: 0.5664 - val_loss: 0.5050 - val_mse: 0.4972\n",
      "Epoch 64/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5750 - mse: 0.5673 - val_loss: 0.5137 - val_mse: 0.5059\n",
      "Epoch 65/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5712 - mse: 0.5634 - val_loss: 0.5072 - val_mse: 0.4995\n",
      "Epoch 66/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5738 - mse: 0.5660 - val_loss: 0.5027 - val_mse: 0.4949\n",
      "Epoch 67/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5705 - mse: 0.5627 - val_loss: 0.5040 - val_mse: 0.4962\n",
      "Epoch 68/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5726 - mse: 0.5649 - val_loss: 0.5032 - val_mse: 0.4954\n",
      "Epoch 69/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5744 - mse: 0.5666 - val_loss: 0.5040 - val_mse: 0.4962\n",
      "Epoch 70/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5732 - mse: 0.5654\n",
      "Epoch 00070: saving model to Regression_Model/bl6.mle.linear-0070.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5734 - mse: 0.5656 - val_loss: 0.5247 - val_mse: 0.5170\n",
      "Epoch 71/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5734 - mse: 0.5656 - val_loss: 0.5105 - val_mse: 0.5028\n",
      "Epoch 72/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5693 - mse: 0.5616 - val_loss: 0.5059 - val_mse: 0.4982\n",
      "Epoch 73/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5705 - mse: 0.5627 - val_loss: 0.5028 - val_mse: 0.4950\n",
      "Epoch 74/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5703 - mse: 0.5626 - val_loss: 0.5235 - val_mse: 0.5158\n",
      "Epoch 75/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5658 - mse: 0.5581 - val_loss: 0.5029 - val_mse: 0.4952\n",
      "Epoch 76/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5684 - mse: 0.5607 - val_loss: 0.5157 - val_mse: 0.5079\n",
      "Epoch 77/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5704 - mse: 0.5626 - val_loss: 0.5105 - val_mse: 0.5028\n",
      "Epoch 78/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5724 - mse: 0.5646 - val_loss: 0.5046 - val_mse: 0.4968\n",
      "Epoch 79/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5704 - mse: 0.5627 - val_loss: 0.5076 - val_mse: 0.4998\n",
      "Epoch 80/3000\n",
      "1386/1397 [============================>.] - ETA: 0s - loss: 0.5652 - mse: 0.5574\n",
      "Epoch 00080: saving model to Regression_Model/bl6.mle.linear-0080.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5654 - mse: 0.5576 - val_loss: 0.5020 - val_mse: 0.4943\n",
      "Epoch 81/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5669 - mse: 0.5592 - val_loss: 0.5168 - val_mse: 0.5091\n",
      "Epoch 82/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5658 - mse: 0.5580 - val_loss: 0.5056 - val_mse: 0.4978\n",
      "Epoch 83/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5661 - mse: 0.5584 - val_loss: 0.5010 - val_mse: 0.4933\n",
      "Epoch 84/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5683 - mse: 0.5606 - val_loss: 0.4986 - val_mse: 0.4908\n",
      "Epoch 85/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5691 - mse: 0.5613 - val_loss: 0.5021 - val_mse: 0.4944\n",
      "Epoch 86/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5705 - mse: 0.5628 - val_loss: 0.5043 - val_mse: 0.4966\n",
      "Epoch 87/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5676 - mse: 0.5599 - val_loss: 0.4977 - val_mse: 0.4900\n",
      "Epoch 88/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5669 - mse: 0.5592 - val_loss: 0.4995 - val_mse: 0.4918\n",
      "Epoch 89/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5675 - mse: 0.5598 - val_loss: 0.5067 - val_mse: 0.4990\n",
      "Epoch 90/3000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.5652 - mse: 0.5575\n",
      "Epoch 00090: saving model to Regression_Model/bl6.mle.linear-0090.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5651 - mse: 0.5574 - val_loss: 0.4999 - val_mse: 0.4922\n",
      "Epoch 91/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5670 - mse: 0.5593 - val_loss: 0.5141 - val_mse: 0.5064\n",
      "Epoch 92/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5637 - mse: 0.5560 - val_loss: 0.4976 - val_mse: 0.4899\n",
      "Epoch 93/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5668 - mse: 0.5591 - val_loss: 0.5111 - val_mse: 0.5034\n",
      "Epoch 94/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5639 - mse: 0.5562 - val_loss: 0.5006 - val_mse: 0.4929\n",
      "Epoch 95/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5670 - mse: 0.5593 - val_loss: 0.5026 - val_mse: 0.4949\n",
      "Epoch 96/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5682 - mse: 0.5605 - val_loss: 0.4980 - val_mse: 0.4903\n",
      "Epoch 97/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5629 - mse: 0.5553 - val_loss: 0.4952 - val_mse: 0.4875\n",
      "Epoch 98/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5621 - mse: 0.5544 - val_loss: 0.5199 - val_mse: 0.5122\n",
      "Epoch 99/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5661 - mse: 0.5584 - val_loss: 0.5010 - val_mse: 0.4934\n",
      "Epoch 100/3000\n",
      "1387/1397 [============================>.] - ETA: 0s - loss: 0.5661 - mse: 0.5584\n",
      "Epoch 00100: saving model to Regression_Model/bl6.mle.linear-0100.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5665 - mse: 0.5588 - val_loss: 0.4989 - val_mse: 0.4913\n",
      "Epoch 101/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5666 - mse: 0.5590 - val_loss: 0.5006 - val_mse: 0.4929\n",
      "Epoch 102/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5630 - mse: 0.5554 - val_loss: 0.5001 - val_mse: 0.4925\n",
      "Epoch 103/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5630 - mse: 0.5554 - val_loss: 0.5012 - val_mse: 0.4936\n",
      "Epoch 104/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5648 - mse: 0.5572 - val_loss: 0.4991 - val_mse: 0.4915\n",
      "Epoch 105/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5635 - mse: 0.5559 - val_loss: 0.4951 - val_mse: 0.4874\n",
      "Epoch 106/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5627 - mse: 0.5550 - val_loss: 0.4974 - val_mse: 0.4898\n",
      "Epoch 107/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5577 - mse: 0.5501 - val_loss: 0.5008 - val_mse: 0.4932\n",
      "Epoch 108/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5626 - mse: 0.5550 - val_loss: 0.5364 - val_mse: 0.5288\n",
      "Epoch 109/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5635 - mse: 0.5559 - val_loss: 0.5005 - val_mse: 0.4929\n",
      "Epoch 110/3000\n",
      "1386/1397 [============================>.] - ETA: 0s - loss: 0.5609 - mse: 0.5534\n",
      "Epoch 00110: saving model to Regression_Model/bl6.mle.linear-0110.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5611 - mse: 0.5535 - val_loss: 0.5024 - val_mse: 0.4948\n",
      "Epoch 111/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5625 - mse: 0.5549 - val_loss: 0.4944 - val_mse: 0.4869\n",
      "Epoch 112/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5603 - mse: 0.5528 - val_loss: 0.5052 - val_mse: 0.4977\n",
      "Epoch 113/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5594 - mse: 0.5518 - val_loss: 0.5031 - val_mse: 0.4955\n",
      "Epoch 114/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5638 - mse: 0.5562 - val_loss: 0.4994 - val_mse: 0.4918\n",
      "Epoch 115/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5614 - mse: 0.5538 - val_loss: 0.5046 - val_mse: 0.4970\n",
      "Epoch 116/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5632 - mse: 0.5556 - val_loss: 0.4969 - val_mse: 0.4894\n",
      "Epoch 117/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5603 - mse: 0.5527 - val_loss: 0.5000 - val_mse: 0.4925\n",
      "Epoch 118/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5575 - mse: 0.5500 - val_loss: 0.4934 - val_mse: 0.4858\n",
      "Epoch 119/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5610 - mse: 0.5534 - val_loss: 0.5010 - val_mse: 0.4935\n",
      "Epoch 120/3000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5604 - mse: 0.5528\n",
      "Epoch 00120: saving model to Regression_Model/bl6.mle.linear-0120.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5603 - mse: 0.5528 - val_loss: 0.4915 - val_mse: 0.4840\n",
      "Epoch 121/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5603 - mse: 0.5528 - val_loss: 0.5002 - val_mse: 0.4927\n",
      "Epoch 122/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5598 - mse: 0.5523 - val_loss: 0.4981 - val_mse: 0.4906\n",
      "Epoch 123/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5607 - mse: 0.5532 - val_loss: 0.4962 - val_mse: 0.4887\n",
      "Epoch 124/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5581 - mse: 0.5506 - val_loss: 0.5059 - val_mse: 0.4984\n",
      "Epoch 125/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5625 - mse: 0.5550 - val_loss: 0.4992 - val_mse: 0.4917\n",
      "Epoch 126/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5625 - mse: 0.5549 - val_loss: 0.4953 - val_mse: 0.4878\n",
      "Epoch 127/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5587 - mse: 0.5512 - val_loss: 0.4931 - val_mse: 0.4856\n",
      "Epoch 128/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5566 - mse: 0.5491 - val_loss: 0.4935 - val_mse: 0.4860\n",
      "Epoch 129/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5589 - mse: 0.5514 - val_loss: 0.4986 - val_mse: 0.4911\n",
      "Epoch 130/3000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5606 - mse: 0.5531\n",
      "Epoch 00130: saving model to Regression_Model/bl6.mle.linear-0130.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5605 - mse: 0.5530 - val_loss: 0.5012 - val_mse: 0.4937\n",
      "Epoch 131/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5615 - mse: 0.5540 - val_loss: 0.4971 - val_mse: 0.4896\n",
      "Epoch 132/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5561 - mse: 0.5486 - val_loss: 0.4954 - val_mse: 0.4879\n",
      "Epoch 133/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5624 - mse: 0.5550 - val_loss: 0.4920 - val_mse: 0.4845\n",
      "Epoch 134/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5571 - mse: 0.5496 - val_loss: 0.5016 - val_mse: 0.4942\n",
      "Epoch 135/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5599 - mse: 0.5524 - val_loss: 0.4993 - val_mse: 0.4918\n",
      "Epoch 136/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5583 - mse: 0.5508 - val_loss: 0.4923 - val_mse: 0.4849\n",
      "Epoch 137/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5567 - mse: 0.5493 - val_loss: 0.4947 - val_mse: 0.4873\n",
      "Epoch 138/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5589 - mse: 0.5515 - val_loss: 0.4926 - val_mse: 0.4852\n",
      "Epoch 139/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5579 - mse: 0.5504 - val_loss: 0.4976 - val_mse: 0.4902\n",
      "Epoch 140/3000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5571 - mse: 0.5497\n",
      "Epoch 00140: saving model to Regression_Model/bl6.mle.linear-0140.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5567 - mse: 0.5493 - val_loss: 0.5071 - val_mse: 0.4997\n",
      "Epoch 141/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5575 - mse: 0.5501 - val_loss: 0.4925 - val_mse: 0.4850\n",
      "Epoch 142/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5566 - mse: 0.5492 - val_loss: 0.4946 - val_mse: 0.4871\n",
      "Epoch 143/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5561 - mse: 0.5487 - val_loss: 0.4996 - val_mse: 0.4922\n",
      "Epoch 144/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5541 - mse: 0.5466 - val_loss: 0.5000 - val_mse: 0.4926\n",
      "Epoch 145/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5547 - mse: 0.5473 - val_loss: 0.4997 - val_mse: 0.4924\n",
      "Epoch 146/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5611 - mse: 0.5537 - val_loss: 0.4931 - val_mse: 0.4857\n",
      "Epoch 147/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5560 - mse: 0.5487 - val_loss: 0.4999 - val_mse: 0.4925\n",
      "Epoch 148/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5570 - mse: 0.5496 - val_loss: 0.4895 - val_mse: 0.4821\n",
      "Epoch 149/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5574 - mse: 0.5501 - val_loss: 0.4910 - val_mse: 0.4837\n",
      "Epoch 150/3000\n",
      "1383/1397 [============================>.] - ETA: 0s - loss: 0.5563 - mse: 0.5489\n",
      "Epoch 00150: saving model to Regression_Model/bl6.mle.linear-0150.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5562 - mse: 0.5488 - val_loss: 0.4973 - val_mse: 0.4899\n",
      "Epoch 151/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5579 - mse: 0.5505 - val_loss: 0.4975 - val_mse: 0.4902\n",
      "Epoch 152/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5556 - mse: 0.5482 - val_loss: 0.4905 - val_mse: 0.4832\n",
      "Epoch 153/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5572 - mse: 0.5499 - val_loss: 0.4950 - val_mse: 0.4876\n",
      "Epoch 154/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5601 - mse: 0.5528 - val_loss: 0.4951 - val_mse: 0.4878\n",
      "Epoch 155/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5583 - mse: 0.5510 - val_loss: 0.4919 - val_mse: 0.4846\n",
      "Epoch 156/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5572 - mse: 0.5498 - val_loss: 0.4976 - val_mse: 0.4902\n",
      "Epoch 157/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5550 - mse: 0.5477 - val_loss: 0.4908 - val_mse: 0.4834\n",
      "Epoch 158/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5526 - mse: 0.5453 - val_loss: 0.4889 - val_mse: 0.4815\n",
      "Epoch 159/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5537 - mse: 0.5464 - val_loss: 0.4958 - val_mse: 0.4885\n",
      "Epoch 160/3000\n",
      "1378/1397 [============================>.] - ETA: 0s - loss: 0.5536 - mse: 0.5463\n",
      "Epoch 00160: saving model to Regression_Model/bl6.mle.linear-0160.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5537 - mse: 0.5464 - val_loss: 0.4943 - val_mse: 0.4870\n",
      "Epoch 161/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5581 - mse: 0.5508 - val_loss: 0.4912 - val_mse: 0.4839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5539 - mse: 0.5466 - val_loss: 0.4903 - val_mse: 0.4830\n",
      "Epoch 163/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5566 - mse: 0.5494 - val_loss: 0.4956 - val_mse: 0.4883\n",
      "Epoch 164/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5571 - mse: 0.5498 - val_loss: 0.4883 - val_mse: 0.4810\n",
      "Epoch 165/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5556 - mse: 0.5484 - val_loss: 0.4903 - val_mse: 0.4831\n",
      "Epoch 166/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5556 - mse: 0.5483 - val_loss: 0.4959 - val_mse: 0.4886\n",
      "Epoch 167/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5550 - mse: 0.5477 - val_loss: 0.4876 - val_mse: 0.4803\n",
      "Epoch 168/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5559 - mse: 0.5486 - val_loss: 0.4985 - val_mse: 0.4913\n",
      "Epoch 169/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5549 - mse: 0.5476 - val_loss: 0.4896 - val_mse: 0.4824\n",
      "Epoch 170/3000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5561 - mse: 0.5488\n",
      "Epoch 00170: saving model to Regression_Model/bl6.mle.linear-0170.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5561 - mse: 0.5489 - val_loss: 0.4885 - val_mse: 0.4813\n",
      "Epoch 171/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5523 - mse: 0.5450 - val_loss: 0.4921 - val_mse: 0.4848\n",
      "Epoch 172/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5561 - mse: 0.5488 - val_loss: 0.4949 - val_mse: 0.4877\n",
      "Epoch 173/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5526 - mse: 0.5453 - val_loss: 0.4970 - val_mse: 0.4898\n",
      "Epoch 174/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5526 - mse: 0.5453 - val_loss: 0.4897 - val_mse: 0.4825\n",
      "Epoch 175/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5512 - mse: 0.5440 - val_loss: 0.4960 - val_mse: 0.4888\n",
      "Epoch 176/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5567 - mse: 0.5495 - val_loss: 0.4919 - val_mse: 0.4847\n",
      "Epoch 177/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5535 - mse: 0.5463 - val_loss: 0.4953 - val_mse: 0.4881\n",
      "Epoch 178/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5558 - mse: 0.5486 - val_loss: 0.4939 - val_mse: 0.4867\n",
      "Epoch 179/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5554 - mse: 0.5482 - val_loss: 0.4899 - val_mse: 0.4827\n",
      "Epoch 180/3000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.5560 - mse: 0.5488\n",
      "Epoch 00180: saving model to Regression_Model/bl6.mle.linear-0180.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5557 - mse: 0.5485 - val_loss: 0.4889 - val_mse: 0.4817\n",
      "Epoch 181/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5552 - mse: 0.5480 - val_loss: 0.4960 - val_mse: 0.4888\n",
      "Epoch 182/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5547 - mse: 0.5476 - val_loss: 0.4928 - val_mse: 0.4856\n",
      "Epoch 183/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5528 - mse: 0.5456 - val_loss: 0.4912 - val_mse: 0.4840\n",
      "Epoch 184/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5563 - mse: 0.5491 - val_loss: 0.4898 - val_mse: 0.4826\n",
      "Epoch 185/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5528 - mse: 0.5456 - val_loss: 0.4911 - val_mse: 0.4839\n",
      "Epoch 186/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5535 - mse: 0.5463 - val_loss: 0.4916 - val_mse: 0.4844\n",
      "Epoch 187/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5525 - mse: 0.5453 - val_loss: 0.4886 - val_mse: 0.4814\n",
      "Epoch 188/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5538 - mse: 0.5466 - val_loss: 0.4918 - val_mse: 0.4846\n",
      "Epoch 189/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5511 - mse: 0.5439 - val_loss: 0.4875 - val_mse: 0.4804\n",
      "Epoch 190/3000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5503 - mse: 0.5432\n",
      "Epoch 00190: saving model to Regression_Model/bl6.mle.linear-0190.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5507 - mse: 0.5435 - val_loss: 0.4896 - val_mse: 0.4824\n",
      "Epoch 191/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5536 - mse: 0.5465 - val_loss: 0.4906 - val_mse: 0.4835\n",
      "Epoch 192/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5512 - mse: 0.5440 - val_loss: 0.4902 - val_mse: 0.4831\n",
      "Epoch 193/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5518 - mse: 0.5447 - val_loss: 0.5000 - val_mse: 0.4928\n",
      "Epoch 194/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5516 - mse: 0.5445 - val_loss: 0.4883 - val_mse: 0.4812\n",
      "Epoch 195/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5496 - mse: 0.5425 - val_loss: 0.4864 - val_mse: 0.4793\n",
      "Epoch 196/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5523 - mse: 0.5452 - val_loss: 0.4882 - val_mse: 0.4811\n",
      "Epoch 197/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5520 - mse: 0.5449 - val_loss: 0.4906 - val_mse: 0.4834\n",
      "Epoch 198/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5512 - mse: 0.5441 - val_loss: 0.4907 - val_mse: 0.4836\n",
      "Epoch 199/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5513 - mse: 0.5442 - val_loss: 0.4915 - val_mse: 0.4844\n",
      "Epoch 200/3000\n",
      "1383/1397 [============================>.] - ETA: 0s - loss: 0.5526 - mse: 0.5455\n",
      "Epoch 00200: saving model to Regression_Model/bl6.mle.linear-0200.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5527 - mse: 0.5456 - val_loss: 0.4882 - val_mse: 0.4811\n",
      "Epoch 201/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5509 - mse: 0.5438 - val_loss: 0.4902 - val_mse: 0.4831\n",
      "Epoch 202/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5536 - mse: 0.5465 - val_loss: 0.4882 - val_mse: 0.4811\n",
      "Epoch 203/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5535 - mse: 0.5464 - val_loss: 0.4883 - val_mse: 0.4812\n",
      "Epoch 204/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5536 - mse: 0.5465 - val_loss: 0.4891 - val_mse: 0.4820\n",
      "Epoch 205/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5504 - mse: 0.5433 - val_loss: 0.4902 - val_mse: 0.4831\n",
      "Epoch 206/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5529 - mse: 0.5458 - val_loss: 0.4892 - val_mse: 0.4822\n",
      "Epoch 207/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5527 - mse: 0.5457 - val_loss: 0.4933 - val_mse: 0.4862\n",
      "Epoch 208/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5533 - mse: 0.5463 - val_loss: 0.4887 - val_mse: 0.4817\n",
      "Epoch 209/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5507 - mse: 0.5437 - val_loss: 0.4917 - val_mse: 0.4847\n",
      "Epoch 210/3000\n",
      "1381/1397 [============================>.] - ETA: 0s - loss: 0.5481 - mse: 0.5410\n",
      "Epoch 00210: saving model to Regression_Model/bl6.mle.linear-0210.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5482 - mse: 0.5412 - val_loss: 0.4894 - val_mse: 0.4823\n",
      "Epoch 211/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5494 - mse: 0.5423 - val_loss: 0.4932 - val_mse: 0.4861\n",
      "Epoch 212/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5522 - mse: 0.5451 - val_loss: 0.4901 - val_mse: 0.4830\n",
      "Epoch 213/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5512 - mse: 0.5442 - val_loss: 0.4863 - val_mse: 0.4793\n",
      "Epoch 214/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5503 - mse: 0.5432 - val_loss: 0.4878 - val_mse: 0.4807\n",
      "Epoch 215/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5494 - mse: 0.5423 - val_loss: 0.4883 - val_mse: 0.4812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5519 - mse: 0.5448 - val_loss: 0.4897 - val_mse: 0.4827\n",
      "Epoch 217/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5528 - mse: 0.5458 - val_loss: 0.4873 - val_mse: 0.4803\n",
      "Epoch 218/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5527 - mse: 0.5456 - val_loss: 0.4905 - val_mse: 0.4835\n",
      "Epoch 219/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5507 - mse: 0.5437 - val_loss: 0.4905 - val_mse: 0.4835\n",
      "Epoch 220/3000\n",
      "1382/1397 [============================>.] - ETA: 0s - loss: 0.5505 - mse: 0.5435\n",
      "Epoch 00220: saving model to Regression_Model/bl6.mle.linear-0220.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5503 - mse: 0.5433 - val_loss: 0.4876 - val_mse: 0.4806\n",
      "Epoch 221/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5533 - mse: 0.5463 - val_loss: 0.4867 - val_mse: 0.4797\n",
      "Epoch 222/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5505 - mse: 0.5434 - val_loss: 0.4923 - val_mse: 0.4852\n",
      "Epoch 223/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5525 - mse: 0.5455 - val_loss: 0.4875 - val_mse: 0.4805\n",
      "Epoch 224/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5534 - mse: 0.5464 - val_loss: 0.4933 - val_mse: 0.4862\n",
      "Epoch 225/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5495 - mse: 0.5425 - val_loss: 0.4888 - val_mse: 0.4818\n",
      "Epoch 226/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5510 - mse: 0.5440 - val_loss: 0.4879 - val_mse: 0.4809\n",
      "Epoch 227/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5525 - mse: 0.5455 - val_loss: 0.4908 - val_mse: 0.4838\n",
      "Epoch 228/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5516 - mse: 0.5446 - val_loss: 0.4876 - val_mse: 0.4806\n",
      "Epoch 229/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5519 - mse: 0.5450 - val_loss: 0.4902 - val_mse: 0.4832\n",
      "Epoch 230/3000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.5470 - mse: 0.5400\n",
      "Epoch 00230: saving model to Regression_Model/bl6.mle.linear-0230.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5470 - mse: 0.5400 - val_loss: 0.4882 - val_mse: 0.4812\n",
      "Epoch 231/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5498 - mse: 0.5428 - val_loss: 0.4862 - val_mse: 0.4792\n",
      "Epoch 232/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5484 - mse: 0.5414 - val_loss: 0.4908 - val_mse: 0.4838\n",
      "Epoch 233/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5499 - mse: 0.5430 - val_loss: 0.4941 - val_mse: 0.4871\n",
      "Epoch 234/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5528 - mse: 0.5458 - val_loss: 0.4917 - val_mse: 0.4847\n",
      "Epoch 235/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5504 - mse: 0.5434 - val_loss: 0.4896 - val_mse: 0.4826\n",
      "Epoch 236/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5489 - mse: 0.5420 - val_loss: 0.4853 - val_mse: 0.4784\n",
      "Epoch 237/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5519 - mse: 0.5449 - val_loss: 0.4876 - val_mse: 0.4807\n",
      "Epoch 238/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5512 - mse: 0.5442 - val_loss: 0.4916 - val_mse: 0.4847\n",
      "Epoch 239/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5498 - mse: 0.5429 - val_loss: 0.4884 - val_mse: 0.4814\n",
      "Epoch 240/3000\n",
      "1386/1397 [============================>.] - ETA: 0s - loss: 0.5490 - mse: 0.5421\n",
      "Epoch 00240: saving model to Regression_Model/bl6.mle.linear-0240.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5492 - mse: 0.5423 - val_loss: 0.4881 - val_mse: 0.4811\n",
      "Epoch 241/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5493 - mse: 0.5424 - val_loss: 0.4868 - val_mse: 0.4799\n",
      "Epoch 242/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5546 - mse: 0.5476 - val_loss: 0.4870 - val_mse: 0.4801\n",
      "Epoch 243/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5503 - mse: 0.5433 - val_loss: 0.4880 - val_mse: 0.4810\n",
      "Epoch 244/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5498 - mse: 0.5429 - val_loss: 0.4988 - val_mse: 0.4919\n",
      "Epoch 245/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5503 - mse: 0.5434 - val_loss: 0.4882 - val_mse: 0.4813\n",
      "Epoch 246/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5495 - mse: 0.5425 - val_loss: 0.4883 - val_mse: 0.4814\n",
      "Epoch 247/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5469 - mse: 0.5399 - val_loss: 0.4836 - val_mse: 0.4767\n",
      "Epoch 248/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5469 - mse: 0.5399 - val_loss: 0.4856 - val_mse: 0.4786\n",
      "Epoch 249/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5502 - mse: 0.5433 - val_loss: 0.4834 - val_mse: 0.4765\n",
      "Epoch 250/3000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5461 - mse: 0.5392\n",
      "Epoch 00250: saving model to Regression_Model/bl6.mle.linear-0250.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5456 - mse: 0.5387 - val_loss: 0.4873 - val_mse: 0.4803\n",
      "Epoch 251/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5491 - mse: 0.5422 - val_loss: 0.4858 - val_mse: 0.4789\n",
      "Epoch 252/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5500 - mse: 0.5431 - val_loss: 0.4863 - val_mse: 0.4794\n",
      "Epoch 253/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5487 - mse: 0.5418 - val_loss: 0.4835 - val_mse: 0.4766\n",
      "Epoch 254/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5493 - mse: 0.5424 - val_loss: 0.4843 - val_mse: 0.4774\n",
      "Epoch 255/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5533 - mse: 0.5464 - val_loss: 0.4850 - val_mse: 0.4781\n",
      "Epoch 256/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5492 - mse: 0.5422 - val_loss: 0.4850 - val_mse: 0.4781\n",
      "Epoch 257/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5482 - mse: 0.5413 - val_loss: 0.4867 - val_mse: 0.4798\n",
      "Epoch 258/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5411 - val_loss: 0.4892 - val_mse: 0.4823\n",
      "Epoch 259/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5391 - val_loss: 0.4889 - val_mse: 0.4820\n",
      "Epoch 260/3000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5486 - mse: 0.5417\n",
      "Epoch 00260: saving model to Regression_Model/bl6.mle.linear-0260.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5482 - mse: 0.5413 - val_loss: 0.4841 - val_mse: 0.4772\n",
      "Epoch 261/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5481 - mse: 0.5412 - val_loss: 0.4868 - val_mse: 0.4799\n",
      "Epoch 262/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5475 - mse: 0.5406 - val_loss: 0.4877 - val_mse: 0.4808\n",
      "Epoch 263/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5484 - mse: 0.5415 - val_loss: 0.4881 - val_mse: 0.4812\n",
      "Epoch 264/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5489 - mse: 0.5420 - val_loss: 0.4889 - val_mse: 0.4820\n",
      "Epoch 265/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5378 - val_loss: 0.4842 - val_mse: 0.4773\n",
      "Epoch 266/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5387 - val_loss: 0.4872 - val_mse: 0.4803\n",
      "Epoch 267/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5501 - mse: 0.5432 - val_loss: 0.4878 - val_mse: 0.4809\n",
      "Epoch 268/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5405 - val_loss: 0.4844 - val_mse: 0.4775\n",
      "Epoch 269/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5509 - mse: 0.5440 - val_loss: 0.4838 - val_mse: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/3000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.5482 - mse: 0.5414\n",
      "Epoch 00270: saving model to Regression_Model/bl6.mle.linear-0270.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5483 - mse: 0.5414 - val_loss: 0.4843 - val_mse: 0.4775\n",
      "Epoch 271/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5469 - mse: 0.5401 - val_loss: 0.4872 - val_mse: 0.4803\n",
      "Epoch 272/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5489 - mse: 0.5420 - val_loss: 0.4837 - val_mse: 0.4769\n",
      "Epoch 273/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5478 - mse: 0.5409 - val_loss: 0.4875 - val_mse: 0.4807\n",
      "Epoch 274/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5485 - mse: 0.5416 - val_loss: 0.4824 - val_mse: 0.4755\n",
      "Epoch 275/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5497 - mse: 0.5428 - val_loss: 0.4873 - val_mse: 0.4804\n",
      "Epoch 276/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5505 - mse: 0.5436 - val_loss: 0.4851 - val_mse: 0.4782\n",
      "Epoch 277/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5499 - mse: 0.5430 - val_loss: 0.4872 - val_mse: 0.4803\n",
      "Epoch 278/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5530 - mse: 0.5461 - val_loss: 0.4847 - val_mse: 0.4778\n",
      "Epoch 279/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5455 - mse: 0.5386 - val_loss: 0.4862 - val_mse: 0.4794\n",
      "Epoch 280/3000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5454 - mse: 0.5385\n",
      "Epoch 00280: saving model to Regression_Model/bl6.mle.linear-0280.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5451 - mse: 0.5383 - val_loss: 0.4816 - val_mse: 0.4747\n",
      "Epoch 281/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5496 - mse: 0.5428 - val_loss: 0.4844 - val_mse: 0.4775\n",
      "Epoch 282/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5486 - mse: 0.5417 - val_loss: 0.4863 - val_mse: 0.4795\n",
      "Epoch 283/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5492 - mse: 0.5424 - val_loss: 0.4892 - val_mse: 0.4824\n",
      "Epoch 284/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5385 - val_loss: 0.4854 - val_mse: 0.4786\n",
      "Epoch 285/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5503 - mse: 0.5435 - val_loss: 0.4840 - val_mse: 0.4771\n",
      "Epoch 286/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5482 - mse: 0.5414 - val_loss: 0.4843 - val_mse: 0.4775\n",
      "Epoch 287/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5393 - val_loss: 0.4836 - val_mse: 0.4768\n",
      "Epoch 288/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5509 - mse: 0.5441 - val_loss: 0.4893 - val_mse: 0.4825\n",
      "Epoch 289/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5473 - mse: 0.5405 - val_loss: 0.4836 - val_mse: 0.4767\n",
      "Epoch 290/3000\n",
      "1387/1397 [============================>.] - ETA: 0s - loss: 0.5471 - mse: 0.5403\n",
      "Epoch 00290: saving model to Regression_Model/bl6.mle.linear-0290.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5412 - val_loss: 0.4873 - val_mse: 0.4805\n",
      "Epoch 291/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5489 - mse: 0.5420 - val_loss: 0.4863 - val_mse: 0.4795\n",
      "Epoch 292/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5508 - mse: 0.5440 - val_loss: 0.4946 - val_mse: 0.4878\n",
      "Epoch 293/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5481 - mse: 0.5413 - val_loss: 0.4832 - val_mse: 0.4764\n",
      "Epoch 294/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5488 - mse: 0.5420 - val_loss: 0.4854 - val_mse: 0.4786\n",
      "Epoch 295/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5467 - mse: 0.5399 - val_loss: 0.4875 - val_mse: 0.4806\n",
      "Epoch 296/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5478 - mse: 0.5410 - val_loss: 0.4864 - val_mse: 0.4796\n",
      "Epoch 297/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5403 - val_loss: 0.4870 - val_mse: 0.4802\n",
      "Epoch 298/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5520 - mse: 0.5452 - val_loss: 0.4868 - val_mse: 0.4800\n",
      "Epoch 299/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5492 - mse: 0.5424 - val_loss: 0.4902 - val_mse: 0.4834\n",
      "Epoch 300/3000\n",
      "1377/1397 [============================>.] - ETA: 0s - loss: 0.5437 - mse: 0.5369\n",
      "Epoch 00300: saving model to Regression_Model/bl6.mle.linear-0300.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5434 - mse: 0.5366 - val_loss: 0.4830 - val_mse: 0.4762\n",
      "Epoch 301/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5467 - mse: 0.5398 - val_loss: 0.4836 - val_mse: 0.4768\n",
      "Epoch 302/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5390 - val_loss: 0.4878 - val_mse: 0.4810\n",
      "Epoch 303/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5380 - val_loss: 0.4841 - val_mse: 0.4774\n",
      "Epoch 304/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5400 - val_loss: 0.4909 - val_mse: 0.4841\n",
      "Epoch 305/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5485 - mse: 0.5417 - val_loss: 0.4868 - val_mse: 0.4800\n",
      "Epoch 306/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5384 - val_loss: 0.4842 - val_mse: 0.4774\n",
      "Epoch 307/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5375 - val_loss: 0.4882 - val_mse: 0.4814\n",
      "Epoch 308/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5486 - mse: 0.5418 - val_loss: 0.4828 - val_mse: 0.4760\n",
      "Epoch 309/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5477 - mse: 0.5409 - val_loss: 0.4836 - val_mse: 0.4768\n",
      "Epoch 310/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5446 - mse: 0.5378\n",
      "Epoch 00310: saving model to Regression_Model/bl6.mle.linear-0310.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5445 - mse: 0.5378 - val_loss: 0.4829 - val_mse: 0.4761\n",
      "Epoch 311/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5460 - mse: 0.5392 - val_loss: 0.4860 - val_mse: 0.4792\n",
      "Epoch 312/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4841 - val_mse: 0.4773\n",
      "Epoch 313/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5399 - val_loss: 0.4863 - val_mse: 0.4795\n",
      "Epoch 314/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5460 - mse: 0.5392 - val_loss: 0.4842 - val_mse: 0.4775\n",
      "Epoch 315/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4857 - val_mse: 0.4790\n",
      "Epoch 316/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5485 - mse: 0.5418 - val_loss: 0.4827 - val_mse: 0.4759\n",
      "Epoch 317/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5450 - mse: 0.5382 - val_loss: 0.4856 - val_mse: 0.4788\n",
      "Epoch 318/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5400 - val_loss: 0.4862 - val_mse: 0.4794\n",
      "Epoch 319/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5507 - mse: 0.5440 - val_loss: 0.4857 - val_mse: 0.4789\n",
      "Epoch 320/3000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.5458 - mse: 0.5390\n",
      "Epoch 00320: saving model to Regression_Model/bl6.mle.linear-0320.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5458 - mse: 0.5390 - val_loss: 0.4860 - val_mse: 0.4792\n",
      "Epoch 321/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5425 - mse: 0.5357 - val_loss: 0.4848 - val_mse: 0.4780\n",
      "Epoch 322/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5388 - val_loss: 0.4824 - val_mse: 0.4756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5399 - val_loss: 0.4831 - val_mse: 0.4763\n",
      "Epoch 324/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5493 - mse: 0.5425 - val_loss: 0.4855 - val_mse: 0.4788\n",
      "Epoch 325/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5393 - val_loss: 0.4840 - val_mse: 0.4772\n",
      "Epoch 326/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4873 - val_mse: 0.4806\n",
      "Epoch 327/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5467 - mse: 0.5399 - val_loss: 0.4846 - val_mse: 0.4779\n",
      "Epoch 328/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5378 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 329/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4860 - val_mse: 0.4792\n",
      "Epoch 330/3000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5444 - mse: 0.5377\n",
      "Epoch 00330: saving model to Regression_Model/bl6.mle.linear-0330.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5377 - val_loss: 0.4877 - val_mse: 0.4809\n",
      "Epoch 331/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5480 - mse: 0.5412 - val_loss: 0.4840 - val_mse: 0.4772\n",
      "Epoch 332/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5484 - mse: 0.5417 - val_loss: 0.4842 - val_mse: 0.4774\n",
      "Epoch 333/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5401 - val_loss: 0.4840 - val_mse: 0.4773\n",
      "Epoch 334/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4838 - val_mse: 0.4771\n",
      "Epoch 335/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5483 - mse: 0.5416 - val_loss: 0.4847 - val_mse: 0.4780\n",
      "Epoch 336/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5397 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 337/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5386 - val_loss: 0.4845 - val_mse: 0.4777\n",
      "Epoch 338/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5454 - mse: 0.5386 - val_loss: 0.4827 - val_mse: 0.4759\n",
      "Epoch 339/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5396 - val_loss: 0.4840 - val_mse: 0.4773\n",
      "Epoch 340/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5430 - mse: 0.5363\n",
      "Epoch 00340: saving model to Regression_Model/bl6.mle.linear-0340.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5367 - val_loss: 0.4847 - val_mse: 0.4780\n",
      "Epoch 341/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5425 - mse: 0.5357 - val_loss: 0.4863 - val_mse: 0.4795\n",
      "Epoch 342/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5460 - mse: 0.5392 - val_loss: 0.4849 - val_mse: 0.4782\n",
      "Epoch 343/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4855 - val_mse: 0.4788\n",
      "Epoch 344/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5394 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 345/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5406 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 346/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5476 - mse: 0.5408 - val_loss: 0.4850 - val_mse: 0.4783\n",
      "Epoch 347/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5457 - mse: 0.5390 - val_loss: 0.4838 - val_mse: 0.4771\n",
      "Epoch 348/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5407 - val_loss: 0.4846 - val_mse: 0.4778\n",
      "Epoch 349/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5395 - val_loss: 0.4876 - val_mse: 0.4809\n",
      "Epoch 350/3000\n",
      "1383/1397 [============================>.] - ETA: 0s - loss: 0.5468 - mse: 0.5401\n",
      "Epoch 00350: saving model to Regression_Model/bl6.mle.linear-0350.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 351/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5457 - mse: 0.5390 - val_loss: 0.4822 - val_mse: 0.4755\n",
      "Epoch 352/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5386 - val_loss: 0.4827 - val_mse: 0.4760\n",
      "Epoch 353/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5387 - val_loss: 0.4826 - val_mse: 0.4758\n",
      "Epoch 354/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5377 - val_loss: 0.4845 - val_mse: 0.4778\n",
      "Epoch 355/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5388 - val_loss: 0.4858 - val_mse: 0.4791\n",
      "Epoch 356/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5408 - val_loss: 0.4845 - val_mse: 0.4778\n",
      "Epoch 357/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5360 - val_loss: 0.4854 - val_mse: 0.4787\n",
      "Epoch 358/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5489 - mse: 0.5422 - val_loss: 0.4861 - val_mse: 0.4793\n",
      "Epoch 359/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5455 - mse: 0.5388 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 360/3000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.5464 - mse: 0.5397\n",
      "Epoch 00360: saving model to Regression_Model/bl6.mle.linear-0360.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5468 - mse: 0.5401 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 361/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5460 - mse: 0.5393 - val_loss: 0.4856 - val_mse: 0.4788\n",
      "Epoch 362/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5365 - val_loss: 0.4854 - val_mse: 0.4787\n",
      "Epoch 363/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5457 - mse: 0.5389 - val_loss: 0.4867 - val_mse: 0.4799\n",
      "Epoch 364/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5397 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 365/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5381 - val_loss: 0.4844 - val_mse: 0.4777\n",
      "Epoch 366/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5472 - mse: 0.5404 - val_loss: 0.4842 - val_mse: 0.4775\n",
      "Epoch 367/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5392 - val_loss: 0.4824 - val_mse: 0.4756\n",
      "Epoch 368/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5486 - mse: 0.5419 - val_loss: 0.4868 - val_mse: 0.4800\n",
      "Epoch 369/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 370/3000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5434 - mse: 0.5366\n",
      "Epoch 00370: saving model to Regression_Model/bl6.mle.linear-0370.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5438 - mse: 0.5370 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 371/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5477 - mse: 0.5410 - val_loss: 0.4824 - val_mse: 0.4756\n",
      "Epoch 372/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5487 - mse: 0.5420 - val_loss: 0.4860 - val_mse: 0.4793\n",
      "Epoch 373/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5480 - mse: 0.5413 - val_loss: 0.4842 - val_mse: 0.4775\n",
      "Epoch 374/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5475 - mse: 0.5408 - val_loss: 0.4873 - val_mse: 0.4806\n",
      "Epoch 375/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5470 - mse: 0.5403 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 376/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5479 - mse: 0.5412 - val_loss: 0.4842 - val_mse: 0.4775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 378/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 379/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5454 - mse: 0.5387 - val_loss: 0.4845 - val_mse: 0.4778\n",
      "Epoch 380/3000\n",
      "1393/1397 [============================>.] - ETA: 0s - loss: 0.5456 - mse: 0.5389\n",
      "Epoch 00380: saving model to Regression_Model/bl6.mle.linear-0380.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5455 - mse: 0.5388 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 381/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5478 - mse: 0.5411 - val_loss: 0.4846 - val_mse: 0.4779\n",
      "Epoch 382/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5450 - mse: 0.5383 - val_loss: 0.4859 - val_mse: 0.4792\n",
      "Epoch 383/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4829 - val_mse: 0.4762\n",
      "Epoch 384/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4850 - val_mse: 0.4783\n",
      "Epoch 385/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5396 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 386/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4865 - val_mse: 0.4798\n",
      "Epoch 387/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5395 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 388/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 389/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5391 - val_loss: 0.4843 - val_mse: 0.4776\n",
      "Epoch 390/3000\n",
      "1377/1397 [============================>.] - ETA: 0s - loss: 0.5467 - mse: 0.5400\n",
      "Epoch 00390: saving model to Regression_Model/bl6.mle.linear-0390.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5397 - val_loss: 0.4858 - val_mse: 0.4792\n",
      "Epoch 391/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5404 - mse: 0.5337 - val_loss: 0.4829 - val_mse: 0.4762\n",
      "Epoch 392/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5501 - mse: 0.5434 - val_loss: 0.4840 - val_mse: 0.4773\n",
      "Epoch 393/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4828 - val_mse: 0.4761\n",
      "Epoch 394/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5476 - mse: 0.5409 - val_loss: 0.4841 - val_mse: 0.4774\n",
      "Epoch 395/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5374 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 396/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5396 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 397/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5373 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 398/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5403 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 399/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5433 - mse: 0.5366 - val_loss: 0.4818 - val_mse: 0.4751\n",
      "Epoch 400/3000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.5436 - mse: 0.5369\n",
      "Epoch 00400: saving model to Regression_Model/bl6.mle.linear-0400.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5370 - val_loss: 0.4844 - val_mse: 0.4777\n",
      "Epoch 401/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5449 - mse: 0.5382 - val_loss: 0.4849 - val_mse: 0.4783\n",
      "Epoch 402/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5495 - mse: 0.5428 - val_loss: 0.4863 - val_mse: 0.4796\n",
      "Epoch 403/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5378 - val_loss: 0.4840 - val_mse: 0.4773\n",
      "Epoch 404/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5494 - mse: 0.5427 - val_loss: 0.4844 - val_mse: 0.4777\n",
      "Epoch 405/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5392 - val_loss: 0.4845 - val_mse: 0.4778\n",
      "Epoch 406/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5401 - val_loss: 0.4845 - val_mse: 0.4778\n",
      "Epoch 407/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 408/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 409/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5430 - mse: 0.5363 - val_loss: 0.4828 - val_mse: 0.4762\n",
      "Epoch 410/3000\n",
      "1393/1397 [============================>.] - ETA: 0s - loss: 0.5452 - mse: 0.5385\n",
      "Epoch 00410: saving model to Regression_Model/bl6.mle.linear-0410.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5454 - mse: 0.5387 - val_loss: 0.4829 - val_mse: 0.4762\n",
      "Epoch 411/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 412/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5444 - mse: 0.5377 - val_loss: 0.4826 - val_mse: 0.4759\n",
      "Epoch 413/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5482 - mse: 0.5416 - val_loss: 0.4838 - val_mse: 0.4771\n",
      "Epoch 414/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5476 - mse: 0.5410 - val_loss: 0.4828 - val_mse: 0.4761\n",
      "Epoch 415/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5469 - mse: 0.5402 - val_loss: 0.4844 - val_mse: 0.4777\n",
      "Epoch 416/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5499 - mse: 0.5432 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 417/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5430 - mse: 0.5364 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 418/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5388 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 419/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5488 - mse: 0.5421 - val_loss: 0.4847 - val_mse: 0.4780\n",
      "Epoch 420/3000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5419 - mse: 0.5352\n",
      "Epoch 00420: saving model to Regression_Model/bl6.mle.linear-0420.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5418 - mse: 0.5352 - val_loss: 0.4838 - val_mse: 0.4771\n",
      "Epoch 421/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5360 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 422/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4842 - val_mse: 0.4775\n",
      "Epoch 423/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5458 - mse: 0.5391 - val_loss: 0.4844 - val_mse: 0.4777\n",
      "Epoch 424/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5484 - mse: 0.5417 - val_loss: 0.4846 - val_mse: 0.4779\n",
      "Epoch 425/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5374 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 426/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 427/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5473 - mse: 0.5407 - val_loss: 0.4825 - val_mse: 0.4758\n",
      "Epoch 428/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5483 - mse: 0.5417 - val_loss: 0.4842 - val_mse: 0.4775\n",
      "Epoch 429/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5389 - val_loss: 0.4846 - val_mse: 0.4780\n",
      "Epoch 430/3000\n",
      "1392/1397 [============================>.] - ETA: 0s - loss: 0.5484 - mse: 0.5417\n",
      "Epoch 00430: saving model to Regression_Model/bl6.mle.linear-0430.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5483 - mse: 0.5417 - val_loss: 0.4842 - val_mse: 0.4775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5373 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 432/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5372 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 433/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5423 - mse: 0.5356 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 434/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 435/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5441 - mse: 0.5374 - val_loss: 0.4837 - val_mse: 0.4771\n",
      "Epoch 436/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5376 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 437/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4821 - val_mse: 0.4755\n",
      "Epoch 438/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5473 - mse: 0.5407 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 439/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5408 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 440/3000\n",
      "1381/1397 [============================>.] - ETA: 0s - loss: 0.5463 - mse: 0.5397\n",
      "Epoch 00440: saving model to Regression_Model/bl6.mle.linear-0440.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5464 - mse: 0.5397 - val_loss: 0.4842 - val_mse: 0.4775\n",
      "Epoch 441/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5485 - mse: 0.5418 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 442/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5370 - val_loss: 0.4850 - val_mse: 0.4783\n",
      "Epoch 443/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 444/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5395 - val_loss: 0.4843 - val_mse: 0.4776\n",
      "Epoch 445/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5456 - mse: 0.5389 - val_loss: 0.4844 - val_mse: 0.4777\n",
      "Epoch 446/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5486 - mse: 0.5420 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 447/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4827 - val_mse: 0.4760\n",
      "Epoch 448/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5408 - val_loss: 0.4843 - val_mse: 0.4777\n",
      "Epoch 449/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5478 - mse: 0.5411 - val_loss: 0.4839 - val_mse: 0.4773\n",
      "Epoch 450/3000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5471 - mse: 0.5404\n",
      "Epoch 00450: saving model to Regression_Model/bl6.mle.linear-0450.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 451/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5453 - mse: 0.5386 - val_loss: 0.4842 - val_mse: 0.4775\n",
      "Epoch 452/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5369 - val_loss: 0.4823 - val_mse: 0.4756\n",
      "Epoch 453/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5422 - mse: 0.5355 - val_loss: 0.4825 - val_mse: 0.4759\n",
      "Epoch 454/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5417 - mse: 0.5350 - val_loss: 0.4825 - val_mse: 0.4758\n",
      "Epoch 455/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5469 - mse: 0.5402 - val_loss: 0.4826 - val_mse: 0.4759\n",
      "Epoch 456/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 457/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5469 - mse: 0.5402 - val_loss: 0.4840 - val_mse: 0.4774\n",
      "Epoch 458/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5436 - mse: 0.5370 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 459/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5426 - mse: 0.5360 - val_loss: 0.4838 - val_mse: 0.4771\n",
      "Epoch 460/3000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.5464 - mse: 0.5397\n",
      "Epoch 00460: saving model to Regression_Model/bl6.mle.linear-0460.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5400 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 461/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5377 - val_loss: 0.4837 - val_mse: 0.4771\n",
      "Epoch 462/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4840 - val_mse: 0.4774\n",
      "Epoch 463/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4840 - val_mse: 0.4773\n",
      "Epoch 464/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5454 - mse: 0.5387 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 465/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5402 - mse: 0.5336 - val_loss: 0.4840 - val_mse: 0.4773\n",
      "Epoch 466/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5415 - mse: 0.5348 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 467/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4852 - val_mse: 0.4786\n",
      "Epoch 468/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4840 - val_mse: 0.4774\n",
      "Epoch 469/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4841 - val_mse: 0.4774\n",
      "Epoch 470/3000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5475 - mse: 0.5408\n",
      "Epoch 00470: saving model to Regression_Model/bl6.mle.linear-0470.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5476 - mse: 0.5409 - val_loss: 0.4837 - val_mse: 0.4771\n",
      "Epoch 471/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5397 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 472/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5408 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 473/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4842 - val_mse: 0.4776\n",
      "Epoch 474/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5478 - mse: 0.5412 - val_loss: 0.4837 - val_mse: 0.4771\n",
      "Epoch 475/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5419 - mse: 0.5353 - val_loss: 0.4828 - val_mse: 0.4761\n",
      "Epoch 476/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5360 - val_loss: 0.4829 - val_mse: 0.4762\n",
      "Epoch 477/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5478 - mse: 0.5411 - val_loss: 0.4848 - val_mse: 0.4781\n",
      "Epoch 478/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5381 - val_loss: 0.4838 - val_mse: 0.4771\n",
      "Epoch 479/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 480/3000\n",
      "1392/1397 [============================>.] - ETA: 0s - loss: 0.5465 - mse: 0.5399\n",
      "Epoch 00480: saving model to Regression_Model/bl6.mle.linear-0480.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5398 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 481/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4838 - val_mse: 0.4772\n",
      "Epoch 482/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5387 - val_loss: 0.4842 - val_mse: 0.4776\n",
      "Epoch 483/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5374 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 484/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5457 - mse: 0.5390 - val_loss: 0.4828 - val_mse: 0.4762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 486/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5382 - val_loss: 0.4846 - val_mse: 0.4779\n",
      "Epoch 487/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5401 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 488/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5403 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 489/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5376 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 490/3000\n",
      "1394/1397 [============================>.] - ETA: 0s - loss: 0.5454 - mse: 0.5388\n",
      "Epoch 00490: saving model to Regression_Model/bl6.mle.linear-0490.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5386 - val_loss: 0.4840 - val_mse: 0.4774\n",
      "Epoch 491/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 492/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5479 - mse: 0.5413 - val_loss: 0.4837 - val_mse: 0.4771\n",
      "Epoch 493/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5473 - mse: 0.5406 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 494/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5393 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 495/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5397 - val_loss: 0.4841 - val_mse: 0.4774\n",
      "Epoch 496/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4842 - val_mse: 0.4775\n",
      "Epoch 497/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 498/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5404 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 499/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5429 - mse: 0.5363 - val_loss: 0.4829 - val_mse: 0.4762\n",
      "Epoch 500/3000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5451 - mse: 0.5385\n",
      "Epoch 00500: saving model to Regression_Model/bl6.mle.linear-0500.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5451 - mse: 0.5384 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 501/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5391 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 502/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5405 - val_loss: 0.4844 - val_mse: 0.4778\n",
      "Epoch 503/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5429 - mse: 0.5362 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 504/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5385 - val_loss: 0.4822 - val_mse: 0.4756\n",
      "Epoch 505/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5400 - val_loss: 0.4828 - val_mse: 0.4762\n",
      "Epoch 506/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4828 - val_mse: 0.4762\n",
      "Epoch 507/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5472 - mse: 0.5405 - val_loss: 0.4840 - val_mse: 0.4773\n",
      "Epoch 508/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4828 - val_mse: 0.4761\n",
      "Epoch 509/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5361 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 510/3000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5471 - mse: 0.5405\n",
      "Epoch 00510: saving model to Regression_Model/bl6.mle.linear-0510.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5469 - mse: 0.5402 - val_loss: 0.4838 - val_mse: 0.4772\n",
      "Epoch 511/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5402 - mse: 0.5335 - val_loss: 0.4826 - val_mse: 0.4760\n",
      "Epoch 512/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5398 - val_loss: 0.4828 - val_mse: 0.4762\n",
      "Epoch 513/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5416 - mse: 0.5349 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 514/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5368 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 515/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5456 - mse: 0.5389 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 516/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5397 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 517/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5387 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 518/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 519/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5370 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 520/3000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5407 - mse: 0.5340\n",
      "Epoch 00520: saving model to Regression_Model/bl6.mle.linear-0520.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5406 - mse: 0.5340 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 521/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 522/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 523/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 524/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5400 - val_loss: 0.4841 - val_mse: 0.4775\n",
      "Epoch 525/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5498 - mse: 0.5432 - val_loss: 0.4842 - val_mse: 0.4776\n",
      "Epoch 526/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5427 - mse: 0.5361 - val_loss: 0.4840 - val_mse: 0.4773\n",
      "Epoch 527/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5500 - mse: 0.5433 - val_loss: 0.4839 - val_mse: 0.4773\n",
      "Epoch 528/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5451 - mse: 0.5384 - val_loss: 0.4841 - val_mse: 0.4775\n",
      "Epoch 529/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4844 - val_mse: 0.4777\n",
      "Epoch 530/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5454 - mse: 0.5388\n",
      "Epoch 00530: saving model to Regression_Model/bl6.mle.linear-0530.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5450 - mse: 0.5383 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 531/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 532/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4839 - val_mse: 0.4773\n",
      "Epoch 533/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4829 - val_mse: 0.4763\n",
      "Epoch 534/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5393 - val_loss: 0.4829 - val_mse: 0.4762\n",
      "Epoch 535/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4838 - val_mse: 0.4772\n",
      "Epoch 536/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5457 - mse: 0.5391 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 537/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 538/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4840 - val_mse: 0.4773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4841 - val_mse: 0.4775\n",
      "Epoch 540/3000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.5428 - mse: 0.5361\n",
      "Epoch 00540: saving model to Regression_Model/bl6.mle.linear-0540.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5418 - mse: 0.5352 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 541/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 542/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 543/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5472 - mse: 0.5406 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 544/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 545/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5367 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 546/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 547/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5408 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 548/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 549/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5495 - mse: 0.5428 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 550/3000\n",
      "1394/1397 [============================>.] - ETA: 0s - loss: 0.5456 - mse: 0.5389\n",
      "Epoch 00550: saving model to Regression_Model/bl6.mle.linear-0550.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5388 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 551/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4838 - val_mse: 0.4771\n",
      "Epoch 552/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5383 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 553/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5417 - mse: 0.5350 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 554/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5478 - mse: 0.5411 - val_loss: 0.4839 - val_mse: 0.4773\n",
      "Epoch 555/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 556/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5369 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 557/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 558/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5396 - mse: 0.5330 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 559/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 560/3000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5438 - mse: 0.5371\n",
      "Epoch 00560: saving model to Regression_Model/bl6.mle.linear-0560.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 561/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4828 - val_mse: 0.4762\n",
      "Epoch 562/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 563/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5367 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 564/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5502 - mse: 0.5435 - val_loss: 0.4843 - val_mse: 0.4776\n",
      "Epoch 565/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 566/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 567/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5368 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 568/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5416 - mse: 0.5350 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 569/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5422 - mse: 0.5356 - val_loss: 0.4829 - val_mse: 0.4763\n",
      "Epoch 570/3000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5427 - mse: 0.5360\n",
      "Epoch 00570: saving model to Regression_Model/bl6.mle.linear-0570.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5432 - mse: 0.5365 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 571/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5431 - mse: 0.5364 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 572/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 573/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 574/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 575/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5376 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 576/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 577/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5428 - mse: 0.5361 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 578/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 579/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5451 - mse: 0.5384 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 580/3000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5467 - mse: 0.5400\n",
      "Epoch 00580: saving model to Regression_Model/bl6.mle.linear-0580.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5467 - mse: 0.5400 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 581/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5477 - mse: 0.5411 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 582/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5475 - mse: 0.5409 - val_loss: 0.4838 - val_mse: 0.4772\n",
      "Epoch 583/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 584/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 585/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 586/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5372 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 587/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 588/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5382 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 589/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5397 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 590/3000\n",
      "1378/1397 [============================>.] - ETA: 0s - loss: 0.5454 - mse: 0.5388\n",
      "Epoch 00590: saving model to Regression_Model/bl6.mle.linear-0590.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5457 - mse: 0.5390 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 591/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5463 - mse: 0.5397 - val_loss: 0.4836 - val_mse: 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 592/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5404 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 593/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 594/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5442 - mse: 0.5375 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 595/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5469 - mse: 0.5403 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 596/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5431 - mse: 0.5364 - val_loss: 0.4837 - val_mse: 0.4771\n",
      "Epoch 597/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5369 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 598/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5472 - mse: 0.5406 - val_loss: 0.4837 - val_mse: 0.4771\n",
      "Epoch 599/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5481 - mse: 0.5414 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 600/3000\n",
      "1381/1397 [============================>.] - ETA: 0s - loss: 0.5451 - mse: 0.5385\n",
      "Epoch 00600: saving model to Regression_Model/bl6.mle.linear-0600.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5451 - mse: 0.5384 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 601/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 602/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 603/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5489 - mse: 0.5423 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 604/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5368 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 605/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5485 - mse: 0.5419 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 606/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5373 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 607/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5376 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 608/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5496 - mse: 0.5430 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 609/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5382 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 610/3000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5477 - mse: 0.5410\n",
      "Epoch 00610: saving model to Regression_Model/bl6.mle.linear-0610.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5476 - mse: 0.5410 - val_loss: 0.4842 - val_mse: 0.4775\n",
      "Epoch 611/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4840 - val_mse: 0.4774\n",
      "Epoch 612/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5365 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 613/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 614/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5428 - mse: 0.5362 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 615/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5396 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 616/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5374 - val_loss: 0.4839 - val_mse: 0.4772\n",
      "Epoch 617/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5416 - mse: 0.5349 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 618/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 619/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5411 - mse: 0.5344 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 620/3000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.5483 - mse: 0.5416\n",
      "Epoch 00620: saving model to Regression_Model/bl6.mle.linear-0620.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5484 - mse: 0.5417 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 621/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 622/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5393 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 623/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 624/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5451 - mse: 0.5385 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 625/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5455 - mse: 0.5388 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 626/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5404 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 627/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 628/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5378 - val_loss: 0.4837 - val_mse: 0.4770\n",
      "Epoch 629/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5419 - mse: 0.5352 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 630/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5441 - mse: 0.5375\n",
      "Epoch 00630: saving model to Regression_Model/bl6.mle.linear-0630.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 631/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5461 - mse: 0.5394 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 632/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 633/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 634/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 635/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5377 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 636/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5451 - mse: 0.5385 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 637/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 638/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5417 - mse: 0.5351 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 639/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 640/3000\n",
      "1393/1397 [============================>.] - ETA: 0s - loss: 0.5452 - mse: 0.5386\n",
      "Epoch 00640: saving model to Regression_Model/bl6.mle.linear-0640.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5460 - mse: 0.5393 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 641/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 642/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 643/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5369 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 644/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5427 - mse: 0.5360 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 645/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4832 - val_mse: 0.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 646/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5369 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 647/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5372 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 648/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5420 - mse: 0.5354 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 649/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 650/3000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.5438 - mse: 0.5371\n",
      "Epoch 00650: saving model to Regression_Model/bl6.mle.linear-0650.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5436 - mse: 0.5370 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 651/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 652/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 653/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5507 - mse: 0.5440 - val_loss: 0.4836 - val_mse: 0.4769\n",
      "Epoch 654/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 655/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4836 - val_mse: 0.4770\n",
      "Epoch 656/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 657/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 658/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5429 - mse: 0.5362 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 659/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5432 - mse: 0.5366 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 660/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5440 - mse: 0.5373\n",
      "Epoch 00660: saving model to Regression_Model/bl6.mle.linear-0660.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5445 - mse: 0.5378 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 661/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5424 - mse: 0.5358 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 662/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5401 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 663/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 664/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5428 - mse: 0.5362 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 665/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5397 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 666/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5385 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 667/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 668/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 669/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5388 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 670/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5433 - mse: 0.5367\n",
      "Epoch 00670: saving model to Regression_Model/bl6.mle.linear-0670.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 671/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5469 - mse: 0.5402 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 672/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5463 - mse: 0.5396 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 673/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 674/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5430 - mse: 0.5364 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 675/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5396 - mse: 0.5330 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 676/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5415 - mse: 0.5348 - val_loss: 0.4830 - val_mse: 0.4763\n",
      "Epoch 677/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 678/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5477 - mse: 0.5410 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 679/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5444 - mse: 0.5377 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 680/3000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5449 - mse: 0.5383\n",
      "Epoch 00680: saving model to Regression_Model/bl6.mle.linear-0680.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 681/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5405 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 682/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5454 - mse: 0.5388 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 683/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 684/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5424 - mse: 0.5358 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 685/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 686/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5430 - mse: 0.5364 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 687/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 688/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5424 - mse: 0.5357 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 689/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5404 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 690/3000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5436 - mse: 0.5370\n",
      "Epoch 00690: saving model to Regression_Model/bl6.mle.linear-0690.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5433 - mse: 0.5366 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 691/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5431 - mse: 0.5365 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 692/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 693/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 694/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5366 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 695/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5436 - mse: 0.5369 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 696/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5415 - mse: 0.5348 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 697/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 698/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 699/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5396 - val_loss: 0.4831 - val_mse: 0.4765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700/3000\n",
      "1386/1397 [============================>.] - ETA: 0s - loss: 0.5441 - mse: 0.5375\n",
      "Epoch 00700: saving model to Regression_Model/bl6.mle.linear-0700.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 701/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5466 - mse: 0.5400 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 702/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 703/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5372 - val_loss: 0.4831 - val_mse: 0.4764\n",
      "Epoch 704/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4830 - val_mse: 0.4764\n",
      "Epoch 705/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 706/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 707/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5412 - mse: 0.5346 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 708/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 709/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5430 - mse: 0.5364 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 710/3000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.5428 - mse: 0.5361\n",
      "Epoch 00710: saving model to Regression_Model/bl6.mle.linear-0710.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5428 - mse: 0.5362 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 711/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5396 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 712/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 713/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5478 - mse: 0.5412 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 714/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5501 - mse: 0.5435 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 715/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5360 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 716/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5395 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 717/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5369 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 718/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5387 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 719/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5424 - mse: 0.5358 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 720/3000\n",
      "1394/1397 [============================>.] - ETA: 0s - loss: 0.5420 - mse: 0.5354\n",
      "Epoch 00720: saving model to Regression_Model/bl6.mle.linear-0720.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5422 - mse: 0.5356 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 721/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 722/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5400 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 723/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 724/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5413 - mse: 0.5347 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 725/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5397 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 726/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 727/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5480 - mse: 0.5414 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 728/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 729/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 730/3000\n",
      "1385/1397 [============================>.] - ETA: 0s - loss: 0.5462 - mse: 0.5396\n",
      "Epoch 00730: saving model to Regression_Model/bl6.mle.linear-0730.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 731/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5365 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 732/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 733/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5395 - mse: 0.5329 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 734/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 735/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5433 - mse: 0.5367 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 736/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5368 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 737/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5470 - mse: 0.5404 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 738/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5451 - mse: 0.5385 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 739/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5372 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 740/3000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5446 - mse: 0.5379\n",
      "Epoch 00740: saving model to Regression_Model/bl6.mle.linear-0740.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 741/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5423 - mse: 0.5357 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 742/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5372 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 743/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5413 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 744/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5411 - mse: 0.5345 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 745/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5486 - mse: 0.5419 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 746/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 747/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 748/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5426 - mse: 0.5360 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 749/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5492 - mse: 0.5426 - val_loss: 0.4835 - val_mse: 0.4769\n",
      "Epoch 750/3000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.5425 - mse: 0.5359\n",
      "Epoch 00750: saving model to Regression_Model/bl6.mle.linear-0750.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5426 - mse: 0.5360 - val_loss: 0.4835 - val_mse: 0.4768\n",
      "Epoch 751/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 752/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4834 - val_mse: 0.4768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 753/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5472 - mse: 0.5406 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 754/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5392 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 755/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5479 - mse: 0.5412 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 756/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5401 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 757/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 758/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 759/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4834 - val_mse: 0.4768\n",
      "Epoch 760/3000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.5468 - mse: 0.5402\n",
      "Epoch 00760: saving model to Regression_Model/bl6.mle.linear-0760.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4834 - val_mse: 0.4767\n",
      "Epoch 761/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5433 - mse: 0.5367 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 762/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5438 - mse: 0.5371 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 763/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5369 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 764/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5433 - mse: 0.5367 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 765/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5375 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 766/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5416 - mse: 0.5350 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 767/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5479 - mse: 0.5413 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 768/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 769/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5484 - mse: 0.5418 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 770/3000\n",
      "1387/1397 [============================>.] - ETA: 0s - loss: 0.5408 - mse: 0.5342\n",
      "Epoch 00770: saving model to Regression_Model/bl6.mle.linear-0770.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5409 - mse: 0.5343 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 771/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5433 - mse: 0.5366 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 772/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5405 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 773/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5454 - mse: 0.5388 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 774/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5449 - mse: 0.5382 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 775/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 776/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5392 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 777/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 778/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5392 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 779/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5471 - mse: 0.5405 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 780/3000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.5487 - mse: 0.5421\n",
      "Epoch 00780: saving model to Regression_Model/bl6.mle.linear-0780.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5493 - mse: 0.5427 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 781/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5377 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 782/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5381 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 783/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5367 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 784/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5399 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 785/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 786/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 787/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5470 - mse: 0.5404 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 788/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5418 - mse: 0.5351 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 789/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 790/3000\n",
      "1392/1397 [============================>.] - ETA: 0s - loss: 0.5468 - mse: 0.5402\n",
      "Epoch 00790: saving model to Regression_Model/bl6.mle.linear-0790.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5467 - mse: 0.5401 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 791/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5454 - mse: 0.5387 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 792/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5397 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 793/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5361 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 794/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5361 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 795/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 796/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5420 - mse: 0.5354 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 797/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5415 - mse: 0.5348 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 798/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 799/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 800/3000\n",
      "1396/1397 [============================>.] - ETA: 0s - loss: 0.5467 - mse: 0.5401\n",
      "Epoch 00800: saving model to Regression_Model/bl6.mle.linear-0800.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5401 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 801/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5457 - mse: 0.5390 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 802/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5405 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 803/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 804/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5388 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 805/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5361 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 806/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5404 - val_loss: 0.4833 - val_mse: 0.4767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 807/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5417 - mse: 0.5350 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 808/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5421 - mse: 0.5354 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 809/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5414 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 810/3000\n",
      "1381/1397 [============================>.] - ETA: 0s - loss: 0.5447 - mse: 0.5380\n",
      "Epoch 00810: saving model to Regression_Model/bl6.mle.linear-0810.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 811/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5413 - mse: 0.5346 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 812/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5404 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 813/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5419 - mse: 0.5353 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 814/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5372 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 815/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 816/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5391 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 817/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5417 - mse: 0.5351 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 818/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5473 - mse: 0.5407 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 819/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 820/3000\n",
      "1387/1397 [============================>.] - ETA: 0s - loss: 0.5443 - mse: 0.5377\n",
      "Epoch 00820: saving model to Regression_Model/bl6.mle.linear-0820.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5437 - mse: 0.5371 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 821/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 822/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 823/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5436 - mse: 0.5369 - val_loss: 0.4832 - val_mse: 0.4765\n",
      "Epoch 824/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 825/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5429 - mse: 0.5362 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 826/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 827/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4831 - val_mse: 0.4765\n",
      "Epoch 828/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5479 - mse: 0.5413 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 829/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 830/3000\n",
      "1382/1397 [============================>.] - ETA: 0s - loss: 0.5450 - mse: 0.5384\n",
      "Epoch 00830: saving model to Regression_Model/bl6.mle.linear-0830.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5385 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 831/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 832/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 833/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5433 - mse: 0.5366 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 834/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5394 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 835/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5368 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 836/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5467 - mse: 0.5401 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 837/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5453 - mse: 0.5387 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 838/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5445 - mse: 0.5378 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 839/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5469 - mse: 0.5402 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 840/3000\n",
      "1383/1397 [============================>.] - ETA: 0s - loss: 0.5466 - mse: 0.5400\n",
      "Epoch 00840: saving model to Regression_Model/bl6.mle.linear-0840.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5457 - mse: 0.5391 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 841/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5460 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 842/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 843/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 844/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5495 - mse: 0.5428 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 845/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5426 - mse: 0.5360 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 846/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5451 - mse: 0.5385 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 847/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5386 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 848/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5457 - mse: 0.5390 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 849/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5430 - mse: 0.5364 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 850/3000\n",
      "1378/1397 [============================>.] - ETA: 0s - loss: 0.5425 - mse: 0.5359\n",
      "Epoch 00850: saving model to Regression_Model/bl6.mle.linear-0850.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5361 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 851/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5370 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 852/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5429 - mse: 0.5362 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 853/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5429 - mse: 0.5363 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 854/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5478 - mse: 0.5411 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 855/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 856/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5457 - mse: 0.5391 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 857/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5399 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 858/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 859/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5433 - mse: 0.5367 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 860/3000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5443 - mse: 0.5377\n",
      "Epoch 00860: saving model to Regression_Model/bl6.mle.linear-0860.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4832 - val_mse: 0.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 861/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 862/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5458 - mse: 0.5391 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 863/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 864/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5493 - mse: 0.5427 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 865/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5445 - mse: 0.5378 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 866/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 867/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5428 - mse: 0.5362 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 868/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5369 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 869/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 870/3000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5425 - mse: 0.5358\n",
      "Epoch 00870: saving model to Regression_Model/bl6.mle.linear-0870.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5422 - mse: 0.5356 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 871/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5436 - mse: 0.5369 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 872/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5387 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 873/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5482 - mse: 0.5415 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 874/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5469 - mse: 0.5402 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 875/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5457 - mse: 0.5391 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 876/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 877/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5366 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 878/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5404 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 879/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 880/3000\n",
      "1391/1397 [============================>.] - ETA: 0s - loss: 0.5462 - mse: 0.5395\n",
      "Epoch 00880: saving model to Regression_Model/bl6.mle.linear-0880.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 881/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5435 - mse: 0.5369 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 882/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 883/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 884/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5431 - mse: 0.5365 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 885/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5439 - mse: 0.5372 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 886/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5399 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 887/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5376 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 888/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5394 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 889/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5457 - mse: 0.5390 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 890/3000\n",
      "1379/1397 [============================>.] - ETA: 0s - loss: 0.5438 - mse: 0.5372\n",
      "Epoch 00890: saving model to Regression_Model/bl6.mle.linear-0890.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5445 - mse: 0.5378 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 891/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5482 - mse: 0.5415 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 892/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5385 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 893/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5429 - mse: 0.5363 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 894/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5428 - mse: 0.5362 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 895/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5370 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 896/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5421 - mse: 0.5355 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 897/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 898/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5370 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 899/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5429 - mse: 0.5363 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 900/3000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.5463 - mse: 0.5397\n",
      "Epoch 00900: saving model to Regression_Model/bl6.mle.linear-0900.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 901/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 902/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 903/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5471 - mse: 0.5404 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 904/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 905/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 906/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 907/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 908/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5478 - mse: 0.5411 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 909/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5452 - mse: 0.5385 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 910/3000\n",
      "1392/1397 [============================>.] - ETA: 0s - loss: 0.5444 - mse: 0.5378\n",
      "Epoch 00910: saving model to Regression_Model/bl6.mle.linear-0910.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 911/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5464 - mse: 0.5397 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 912/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 913/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5383 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 914/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4832 - val_mse: 0.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 915/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5361 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 916/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5398 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 917/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5427 - mse: 0.5360 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 918/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5485 - mse: 0.5419 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 919/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5473 - mse: 0.5407 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 920/3000\n",
      "1384/1397 [============================>.] - ETA: 0s - loss: 0.5445 - mse: 0.5378\n",
      "Epoch 00920: saving model to Regression_Model/bl6.mle.linear-0920.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 921/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5450 - mse: 0.5383 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 922/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 923/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 924/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5365 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 925/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5408 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 926/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 927/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5427 - mse: 0.5361 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 928/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5434 - mse: 0.5368 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 929/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 930/3000\n",
      "1382/1397 [============================>.] - ETA: 0s - loss: 0.5404 - mse: 0.5338\n",
      "Epoch 00930: saving model to Regression_Model/bl6.mle.linear-0930.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5411 - mse: 0.5345 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 931/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 932/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5384 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 933/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 934/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5392 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 935/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5431 - mse: 0.5364 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 936/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5370 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 937/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 938/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 939/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 940/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5441 - mse: 0.5375\n",
      "Epoch 00940: saving model to Regression_Model/bl6.mle.linear-0940.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5375 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 941/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5423 - mse: 0.5357 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 942/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5433 - mse: 0.5366 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 943/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4833 - val_mse: 0.4767\n",
      "Epoch 944/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5431 - mse: 0.5364 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 945/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5428 - mse: 0.5362 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 946/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5392 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 947/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5371 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 948/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5423 - mse: 0.5356 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 949/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5453 - mse: 0.5386 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 950/3000\n",
      "1388/1397 [============================>.] - ETA: 0s - loss: 0.5447 - mse: 0.5381\n",
      "Epoch 00950: saving model to Regression_Model/bl6.mle.linear-0950.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 951/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 952/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 953/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5425 - mse: 0.5359 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 954/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5464 - mse: 0.5398 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 955/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5375 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 956/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 957/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 958/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 959/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 960/3000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.5442 - mse: 0.5376\n",
      "Epoch 00960: saving model to Regression_Model/bl6.mle.linear-0960.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 961/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5399 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 962/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 963/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5445 - mse: 0.5379 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 964/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 965/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 966/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5450 - mse: 0.5383 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 967/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5376 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 968/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5382 - val_loss: 0.4832 - val_mse: 0.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5435 - mse: 0.5369 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 970/3000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.5465 - mse: 0.5399\n",
      "Epoch 00970: saving model to Regression_Model/bl6.mle.linear-0970.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5463 - mse: 0.5397 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 971/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5483 - mse: 0.5417 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 972/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5409 - mse: 0.5342 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 973/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5461 - mse: 0.5395 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 974/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5468 - mse: 0.5401 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 975/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 976/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5446 - mse: 0.5380 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 977/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5370 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 978/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 979/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5476 - mse: 0.5409 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 980/3000\n",
      "1387/1397 [============================>.] - ETA: 0s - loss: 0.5464 - mse: 0.5398\n",
      "Epoch 00980: saving model to Regression_Model/bl6.mle.linear-0980.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5462 - mse: 0.5395 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 981/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5479 - mse: 0.5412 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 982/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5468 - mse: 0.5401 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 983/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 984/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5416 - mse: 0.5350 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 985/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5446 - mse: 0.5379 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 986/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5452 - mse: 0.5385 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 987/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5449 - mse: 0.5383 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 988/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5366 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 989/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5371 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 990/3000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.5442 - mse: 0.5375\n",
      "Epoch 00990: saving model to Regression_Model/bl6.mle.linear-0990.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 991/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5464 - mse: 0.5398 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 992/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5481 - mse: 0.5415 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 993/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5473 - mse: 0.5407 - val_loss: 0.4833 - val_mse: 0.4766\n",
      "Epoch 994/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5424 - mse: 0.5358 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 995/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5430 - mse: 0.5363 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 996/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5400 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 997/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5366 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 998/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5430 - mse: 0.5364 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 999/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5478 - mse: 0.5412 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1000/3000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5440 - mse: 0.5374\n",
      "Epoch 01000: saving model to Regression_Model/bl6.mle.linear-1000.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1001/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5376 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1002/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5452 - mse: 0.5386 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1003/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1004/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5471 - mse: 0.5405 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1005/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5478 - mse: 0.5411 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1006/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5423 - mse: 0.5357 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1007/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5418 - mse: 0.5352 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1008/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5405 - mse: 0.5339 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1009/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5463 - mse: 0.5396 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1010/3000\n",
      "1387/1397 [============================>.] - ETA: 0s - loss: 0.5493 - mse: 0.5427\n",
      "Epoch 01010: saving model to Regression_Model/bl6.mle.linear-1010.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5492 - mse: 0.5425 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1011/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1012/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1013/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5429 - mse: 0.5363 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1014/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5477 - mse: 0.5410 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1015/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5430 - mse: 0.5364 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1016/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5468 - mse: 0.5402 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1017/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5473 - mse: 0.5407 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1018/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5404 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1019/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5376 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1020/3000\n",
      "1380/1397 [============================>.] - ETA: 0s - loss: 0.5458 - mse: 0.5392\n",
      "Epoch 01020: saving model to Regression_Model/bl6.mle.linear-1020.ckpt\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5457 - mse: 0.5391 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1021/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5390 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1022/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5474 - mse: 0.5407 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1023/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5425 - mse: 0.5358 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1024/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5437 - mse: 0.5371 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1025/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1026/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5453 - mse: 0.5387 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1027/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5481 - mse: 0.5415 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1028/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1029/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5366 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1030/3000\n",
      "1386/1397 [============================>.] - ETA: 0s - loss: 0.5460 - mse: 0.5393\n",
      "Epoch 01030: saving model to Regression_Model/bl6.mle.linear-1030.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5466 - mse: 0.5399 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1031/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5447 - mse: 0.5381 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1032/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5439 - mse: 0.5373 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1033/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5472 - mse: 0.5406 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1034/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5437 - mse: 0.5370 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1035/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5480 - mse: 0.5414 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1036/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5465 - mse: 0.5398 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1037/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5370 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1038/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5400 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1039/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5432 - mse: 0.5366 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1040/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5467 - mse: 0.5400\n",
      "Epoch 01040: saving model to Regression_Model/bl6.mle.linear-1040.ckpt\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5472 - mse: 0.5406 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1041/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5411 - mse: 0.5344 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1042/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5414 - mse: 0.5347 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1043/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1044/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5447 - mse: 0.5380 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1045/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1046/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5419 - mse: 0.5352 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1047/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5420 - mse: 0.5354 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1048/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5412 - mse: 0.5346 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1049/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5381 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1050/3000\n",
      "1389/1397 [============================>.] - ETA: 0s - loss: 0.5441 - mse: 0.5374\n",
      "Epoch 01050: saving model to Regression_Model/bl6.mle.linear-1050.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1051/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5449 - mse: 0.5382 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1052/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5470 - mse: 0.5404 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1053/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5450 - mse: 0.5383 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1054/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5463 - mse: 0.5397 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1055/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5426 - mse: 0.5360 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1056/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5466 - mse: 0.5400 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1057/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5421 - mse: 0.5354 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1058/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5407 - mse: 0.5341 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1059/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5443 - mse: 0.5377 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1060/3000\n",
      "1390/1397 [============================>.] - ETA: 0s - loss: 0.5433 - mse: 0.5367\n",
      "Epoch 01060: saving model to Regression_Model/bl6.mle.linear-1060.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5431 - mse: 0.5365 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1061/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5436 - mse: 0.5369 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1062/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5454 - mse: 0.5388 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1063/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5394 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1064/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5423 - mse: 0.5357 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1065/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1066/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1067/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5456 - mse: 0.5389 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1068/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1069/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5473 - mse: 0.5407 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1070/3000\n",
      "1395/1397 [============================>.] - ETA: 0s - loss: 0.5456 - mse: 0.5390\n",
      "Epoch 01070: saving model to Regression_Model/bl6.mle.linear-1070.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5455 - mse: 0.5388 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1071/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5467 - mse: 0.5400 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1072/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5406 - mse: 0.5339 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1073/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5460 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1074/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1075/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1076/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5441 - mse: 0.5375 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1077/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5458 - mse: 0.5392 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1078/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1079/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5425 - mse: 0.5358 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1080/3000\n",
      "1386/1397 [============================>.] - ETA: 0s - loss: 0.5430 - mse: 0.5363\n",
      "Epoch 01080: saving model to Regression_Model/bl6.mle.linear-1080.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5433 - mse: 0.5367 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1081/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5374 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1082/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5493 - mse: 0.5426 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1083/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5459 - mse: 0.5393 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1084/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5444 - mse: 0.5378 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1085/3000\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5453 - mse: 0.5387 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1086/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5440 - mse: 0.5373 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1087/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5442 - mse: 0.5375 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1088/3000\n",
      "1397/1397 [==============================] - 7s 5ms/step - loss: 0.5490 - mse: 0.5424 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1089/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5448 - mse: 0.5381 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1090/3000\n",
      "1383/1397 [============================>.] - ETA: 0s - loss: 0.5468 - mse: 0.5402\n",
      "Epoch 01090: saving model to Regression_Model/bl6.mle.linear-1090.ckpt\n",
      "1397/1397 [==============================] - 6s 5ms/step - loss: 0.5462 - mse: 0.5396 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1091/3000\n",
      "1397/1397 [==============================] - 6s 4ms/step - loss: 0.5455 - mse: 0.5389 - val_loss: 0.4832 - val_mse: 0.4766\n",
      "Epoch 1092/3000\n",
      " 620/1397 [============>.................] - ETA: 2s - loss: 0.5517 - mse: 0.5451"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=3000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-2900.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testid='bl6.mle.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
