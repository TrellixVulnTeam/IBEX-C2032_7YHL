{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:scikit-learn version 0.21.3 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
      "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import coremltools\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation,concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Add,Lambda,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD,Adam,schedules\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, MaxPooling1D,MaxPooling1D,GlobalMaxPooling1D,SpatialDropout1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.initializers import Ones, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNormalization(Layer):\n",
    "\tdef __init__(self,groups=32,axis=-1,epsilon=1e-5,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,\n",
    "\t\t\t\t gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs):\n",
    "\t\tsuper(GroupNormalization, self).__init__(**kwargs)\n",
    "\t\tself.supports_masking = True\n",
    "\t\tself.groups = groups\n",
    "\t\tself.axis = axis\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.center = center\n",
    "\t\tself.scale = scale\n",
    "\t\tself.beta_initializer = initializers.get(beta_initializer)\n",
    "\t\tself.gamma_initializer = initializers.get(gamma_initializer)\n",
    "\t\tself.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "\t\tself.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "\t\tself.beta_constraint = constraints.get(beta_constraint)\n",
    "\t\tself.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tdim = input_shape[self.axis]\n",
    "\n",
    "\t\tif dim is None:\n",
    "\t\t\traise ValueError('Axis '+str(self.axis)+' of input tensor should have a defined dimension but the layer received an input with shape '+str(input_shape)+'.')\n",
    "\n",
    "\t\tif dim < self.groups:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') cannot be more than the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tif dim % self.groups != 0:\n",
    "\t\t\traise ValueError('Number of groups ('+str(self.groups)+') must be a multiple of the number of channels ('+str(dim)+').')\n",
    "\n",
    "\t\tself.input_spec = InputSpec(ndim=len(input_shape),axes={self.axis: dim})\n",
    "\t\tshape = (dim,)\n",
    "\n",
    "\t\tif self.scale:\n",
    "\t\t\tself.gamma = self.add_weight(shape=shape,name='gamma',initializer=self.gamma_initializer,regularizer=self.gamma_regularizer,constraint=self.gamma_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.gamma = None\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tself.beta = self.add_weight(shape=shape,name='beta',initializer=self.beta_initializer,regularizer=self.beta_regularizer,constraint=self.beta_constraint)\n",
    "\t\telse:\n",
    "\t\t\tself.beta = None\n",
    "\n",
    "\t\tself.built = True\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tinput_shape = K.int_shape(inputs)\n",
    "\t\ttensor_input_shape = K.shape(inputs)\n",
    "\n",
    "\t\t# Prepare broadcasting shape.\n",
    "\t\treduction_axes = list(range(len(input_shape)))\n",
    "\t\tdel reduction_axes[self.axis]\n",
    "\t\tbroadcast_shape = [1] * len(input_shape)\n",
    "\t\tbroadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tbroadcast_shape.insert(1, self.groups)\n",
    "\n",
    "\t\treshape_group_shape = K.shape(inputs)\n",
    "\t\tgroup_axes = [reshape_group_shape[i] for i in range(len(input_shape))]\n",
    "\t\tgroup_axes[self.axis] = input_shape[self.axis] // self.groups\n",
    "\t\tgroup_axes.insert(1, self.groups)\n",
    "\n",
    "\t\t# reshape inputs to new group shape\n",
    "\t\tgroup_shape = [group_axes[0], self.groups] + group_axes[2:]\n",
    "\t\tgroup_shape = K.stack(group_shape)\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\n",
    "\t\tgroup_reduction_axes = list(range(len(group_axes)))\n",
    "\t\tgroup_reduction_axes = group_reduction_axes[2:]\n",
    "\n",
    "\t\tmean = K.mean(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tvariance = K.var(inputs, axis=group_reduction_axes, keepdims=True)\n",
    "\t\tinputs = (inputs - mean) / (K.sqrt(variance + self.epsilon))\n",
    "\n",
    "\t\t# prepare broadcast shape\n",
    "\t\tinputs = K.reshape(inputs, group_shape)\n",
    "\t\toutputs = inputs\n",
    "\n",
    "\t\t# In this case we must explicitly broadcast all parameters.\n",
    "\t\tif self.scale:\n",
    "\t\t\tbroadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
    "\t\t\toutputs = outputs * broadcast_gamma\n",
    "\n",
    "\t\tif self.center:\n",
    "\t\t\tbroadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "\t\t\toutputs = outputs + broadcast_beta\n",
    "\n",
    "\t\toutputs = K.reshape(outputs, tensor_input_shape)\n",
    "\n",
    "\t\treturn outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(inputs):\n",
    "    x = Conv1D(filters= 16, kernel_size= 12, padding = 'valid', kernel_regularizer = regularizers.l2(1e-4), bias_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = GroupNormalization(groups = 4, axis = -1)(x) \n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 12)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32,  kernel_regularizer = regularizers.l2(1e-4),bias_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_CNN(length):\n",
    "\n",
    "    input_shape1 = (length,1)\n",
    "    cov_input = Input(shape = input_shape1,name=\"cov_input\")\n",
    "    input_layers = cov_input\n",
    "\n",
    "    x = CNN(cov_input)\n",
    "    outLayer= Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_layers, outputs=outLayer)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Regression_CNN(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cov_input (InputLayer)       [(None, 1001, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 990, 16)           208       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 990, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 82, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1312)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                42016     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,257\n",
      "Trainable params: 42,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data_regression import prep_data,DataGenerator,EvaDataGenerator,get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 14753\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels,train_id,valid_data,valid_labels,valid_id = prep_data('usage_data/BL6_REP1.pAs.predict.coverage.txt',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.log(train_data+1)\n",
    "    train_labels = np.log(train_labels)\n",
    "    valid_data = np.log(valid_data+1)\n",
    "    valid_labels = np.log(valid_labels)\n",
    "    data_mean = np.mean(train_data)\n",
    "    data_std  = np.std(train_data)\n",
    "    label_mean = np.mean(train_labels)\n",
    "    label_std  = np.std(train_labels)\n",
    "    \n",
    "    data_max = np.max(train_data)\n",
    "    \n",
    "    #train_data = (train_data-data_mean)/data_std\n",
    "    #train_labels = (train_labels-label_mean)/label_std\n",
    "    \n",
    "    train_data = train_data/data_max\n",
    "    \n",
    "    \n",
    "    valid_data  = (valid_data-data_mean)/data_std\n",
    "    valid_labels = (valid_labels-label_mean)/label_std\n",
    "    return data_mean,data_std,data_max,label_mean,label_std,train_data,train_labels,valid_data,valid_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean,data_std,data_max,label_mean,label_std, train_x,train_y,valid_x,valid_y = normalization(train_data,train_labels,valid_data,valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.47435 2.5292199\n",
      "5.729239 1.606415\n"
     ]
    }
   ],
   "source": [
    "print(data_mean,data_std)\n",
    "print(label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6be1b68ac8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxU1Z338c+vqjfohbVZm01ABRcQexCVqIxL0BgxicmYRbM5xEl8jMmT8WX2xSyTZTIzmTFhcMkkGRPjYyQhils0BhNFAUVkF1mbtdmEZun19/xxbzdFUw23oZvquvV9v1796rrLqT6H5dunzj33HnN3REQkvhKZroCIiHQuBb2ISMwp6EVEYk5BLyIScwp6EZGYy8t0BdLp27evDx8+PNPVEBHJGgsXLtzh7uXpjnXJoB8+fDgLFizIdDVERLKGma1v65iGbkREYk5BLyIScwp6EZGYU9CLiMScgl5EJOYU9CIiMaegFxGJOQV9J5m3ZifLNu/tsPdbvX0ff1lV3WHv15U9s2wbm/YczHQ1RGKjS94wlc121NTy2/kb+eFTKwFY9y/vOub5z6/cTl1DE1edNeCY513x47kAvPXda0gmrGMq2wW9uW0f//jL4Ga5vITxickj+NI1YzJcK5HsFqse/TnfeIqP/fwVMrWYysd//gqV3/5TS8in2neonscXbzmibg2NTXzs5/OZ/quFNDQ2cdP9L/OvTx9d9lB9Y8vrt6prOqfyXcRrG/YAcP34QTS5M3PuGvYeqs9wrUSyW6x69GMGlvH8ymrW7zzA8L7Fp/Rn79pfx59XVnPJ6eV89vJRPPC3dSzd9HbL8Z88+yb3vrCW+26u5Iqx/dny9kEu/N5zLcdHffkJAF54cwf/Oy+4k7msWz63TB7Bqm2Hw/29P32RBV+5gqL85Clq2am1qGoPJYV5/PgD45lyZj8++9Aitr19iLKi/ExXTSRrxapH3/wRf+W2fR32nks2vR3pE8KasKf9iYuHc/6w3vQpLmBnTR0Pz9/IlB89z70vrAVoGWdfsG43AGbw7nGDjniv3sUF/N3w3qzfeYCv/mEpvwqD//xhvaipbeDMrz7J8LseZ8vb2T2Ovb+2gT+v2M66Hftb9r26fjfnD+tFImEMKCsC4HevbspUFUViIVY9+qG9uwOwaXfHBOCijXu4/p6/kTC49PRyHLjh/AquPXfQUedu3H0AgIpeQR0mndaHX760nq/NXsKh+qaW85qHXv7zuTcBmPfFy+lfVsSYgaXc98Jadu2v4x2jy/nGdWexa38dh+ob+c7jy3n8jS388hMTOevrT7W816OvbuIzU0Z1SFtPtaYm530/e5EVW4NfytPGD+Kuq89k/c4DXDSyLwDjhvQEgvAXkRMXqUdvZlPNbKWZrTazu9Icn2Zmi81skZktMLPJKcfWmdkbzcc6svKt9eyWT37SqK6ppbHJqW1oPH6hY1i7IwjlJoc/r6zm+ZXVfOnRN9L28N+o2kthXoIhvbsBMPWsAbz//ArOHdyTn354Ai998e+5btwgqsJfQs3DMX1LCgH49GWj+Na0s4Cg5w5Bz35Qz2785wfP45UvX05xYR4/ev84rhjTHzhy7D7bbNx9gBVb99EtP8ngnt34w6LNXPi95zhY38jwvsEvy6L8JB+9cBiLN+3J2HUXkTg4bo/ezJLAPcCVQBUw38xmu/uylNOeBWa7u5vZucDDwJkpx6e4+44OrHdaiYTRt6SQLXsO8s5/n8vq7TX8+APjeO+EihN6v/U7D2AGy745lXlrd/LHRZt59LVNVO0+yJDw00OztTtqGN2/hMK8ZEtdfvj+cUecM7K8hD8u3szeQ/V0y09y9uCyI2bQvOucgQz5THfOrehxVLv6lQbDGDecX8EN51cw5qtPZnXQ//fcNQA8+I8XML6iJ4+8WsWdjywGYGCPbi3nnT6glEP1wUXri0b24T+efZM733kGH7t4REbqLZKNovToJwKr3X2Nu9cBDwHTUk9w9xo/3OUqBjLW/SovLeT3izazenvQY/7NKxvaVd7dWVy1h4N1jWzYeYCBZUV0K0gy5Yx+TDtvMADb9h46qtzB+ka65x/792bl8F64w8L1u6ltaGTSaX2OOG5mjBvSE7PjT58syk9Q29B03PMyxd1Zvb2G+sYmXtuwm8amI/9JzFuzE4DxFT1JJIwPVA7h3psrATh7cFnLedeNG0RFr278ZVU133tiBQfqGvnGH5d16D0KInEXZYx+MLAxZbsKuKD1SWb2HuB7QD8gdfK4A0+bmQP/7e4z0/0QM5sOTAcYOnRopMqnUx4OhUAwfPLciu3srKmlT8r+1hoam2hocu7/61qWbdnL44u3tBy7eNThMO7dvQAIZtg0e3H1Dp5cupW3DzZQXtr2zwAYP6Qn+UnjCw+/TpNDn+KCdrevWWFektr6rhn0jU3OvS+s4V+eWMG08YP4w6LNfOVdY7jlHacBwVz5NdXBBdhEyieaK8f2P+q+g9KifOb+8xRq6ho49xtPt+y/5icv8Nj/mczZg4/89CMiR4sS9Om6l0f12N19FjDLzC4B7gauCA9d7O6bzawf8IyZrXD3uWnKzwRmAlRWVp7wJ4Ie3Q5Pw7v1spE8uXQrv3hxHZ+/6oy0589ft4sP3TuP+sb0P/KG8w8P+/QqDt574frdLTc4/fiZVSwILxYO6dX/mHUrLszjvedV8NsFwe/Ncyp6RmzV0QrzEyd9DaIzNDY5l/zgzy13tv5h0WYAXlm7i3eeNYC5b1bz5JKtANz+99EuJCcSRllRPh+/eDgjy0voU1zAPz34KvPW7FTQi0QQJeirgCEp2xXA5rZOdve5ZjbSzPq6+w533xzu325mswiGgo4K+o5yxxWnc97Qnnxw4uFPBU8t3cbnrjydbz22jDEDy/hA5eHmfGP2UuobnVsmj+DxN7aw5e3DwzKfvmwk706ZYdN84fS/567hk5NH0K+siJ0pvfuCvOOPhH33vedwdkUPkmZMGHriQV+UlzxiNk9Xsaa65ojHF9w59Qx+8ORKnl62jaeXbWvZP2FoTz535enteu+vvzu4WO3uFOUnWKrhG5FIogT9fGC0mY0ANgE3Ah9KPcHMRgFvhRdjJwAFwE4zKwYS7r4vfH0V8K0ObUErQ/t056YLh7ds33B+BX9avo2V2/bx87+tA6CkMI9rzhnIgboGlm7ey6cvG8mdU8/kpguH8Z3Hl/O5K09nVL8S8pNHBndRfpKvvGsM3358Oa9Xvc2qbVWs3bGfgT2K2PL2oUhj5smEcdOkYSfdzpraBp5cuvWY57g7j766idH9Szj3JD49RLX3UD1X/lvwO/zvhvfiM1NGcdkZ/fjBk0fe7fvKly6nZ/eCSNci0jEzKnp1Z9Zrm7h4VN8jPnWJyNGO2wV19wbgNuApYDnwsLsvNbNbzezW8LT3AUvMbBHBDJ1/CC/O9gf+amavA68Aj7v7k53RkLYM692dPQfqWbLpcO9vSXjH6vqdwdz3MQODi3/D+hQz8+ZKxgwsOyrkmzVPbXxtw25++NRKzGiZy36grqHT2tFac695z4E6tu87xNaUTyKH6hup3lfLfz23mv/7/17nw/e93On1uXfuGiZ86xkASovyePhTF3LZGf0AuG3KKEoL8+hdXMBnpoykX1lRpE8/x/LDG84F4Bcvrjup9xHJBZFumHL3OcCcVvtmpLz+PvD9NOXWAONa7z+V+od3Vy5cvwsIZuVs2BUE/PItQfiP7l8S+f1Ki4I/sp8+/xYAc/95SstwT0XP7m2W62jXjRvE7Nc3M+eNrXxp1hsAXHhaHy4f048Zf3mLHTWHh5T2HWpg1mtVvOe8ju/57t5fxxNLtvKdOctb9v3xtslH9Na/8M4z+MI7018jOVHnDe3F+8+v4M8rt3fo+4rEUawegZBO/x5B0K/cuo/CvARnDihtCfpV22rITxqjytsT9Icv9paXFlLRqxuVw3ox86bzuevqM49RsmN9Phzfbg55gJfW7OTbjy8/IuTfG04J/dxvX2dVBz4aotl9f11zRB2AU/acoYE9u7Fzfx11XXiaqUhXEP+gLwsuoL65rYbSojyG9u7eEvTb9x2ivKSQvDaGadJJHXJ4/guXYWYkEsZVZw2g10lMl2yv4X2L+eTkwzcN3XHFaH70/nFMHNH7iPPelzJ+/djrwTX0vYfqeXLJliOeMXOitu2tPWL7zqkd23M/lnMH98Ad/vZWp9+LJ5LVYvWsm3SG9ykmmTD21TbQp6Q75aWF7DlQT0NjE9X7aikPh3ba48FbLmBkeQnFhZn94/vqtWOZfslprNq2j3eMLgdg/JAevPDmDsYOLKNbQZKxA8u4+/qz+ervl/Creev5/FVncN8La/nJs29y5oBSnrzjkhP++Y8t3swjC6tath+/fTJnDTp10x0vCu9x+PKjbzD3zint+oUtkktiH/RF+UnOGdyDRRv3UNvQRK/wpqeP3P8y89bs4n0n8HiEi0f17ehqnrD+ZUUt1yEARvUrZVS/0iPOuWnSMN7aXsP/vLiOpiZn1/6gF75i6z627zvU8niF9mp+7v7d15/NlDPKWx7odqp0L8jj9P4lrNpWw5LNexk/pPNnFolko5zoAt16aXBHZp+SAnp2D8bY560JLs5eO25gxup1Kg3uGTw/Zvbrm3n74OHZQRO/8ywbw6EsgPrGJp5eupXXN+457nvu2FfLxy8ezk2Thp3ykG/2HzeeB8D8tbsy8vNFskHse/QAU88eyM8//ncM6dWdfSmrFf3ghnO57PTyDNbs1CnrFvxV3/HbRbReiXDZlr0M6d2deWt28s0/LmP5lr0kE8aqb1+ddtnCv6yq5pllW9lf19hyE1mmND+a+jtzljPlzPKjPs2ISI4EPcCUcE43wAt3TqEwL0G/Exifz1apd9E2OYzuV8KGXQeobWhiQ3g/wb88saJlZk5jk7O/ruGolZ027jrARx94pWV7xCleyau14sI8vnbtWL712DJ+8eJ67r7+7IzWR6Qryomhm9aG9O6eUyEPcM05A5k2/vDjHAb17MbKb19Nj275LN+yl5vuf5lFG/dw06RhfP995wDB+q2V336Gy//1efbXBsM99/81WCnrQxcM5V3nDDziF2imfGLyCMYMLMv6FbdEOkvO9OhzXXlpIf9x43n8bfUOdtTUtazeNLK8mEdfC5bqG96nOx+9aHjLI4Cbz91RU8dZX3+KBV+5gv95cR0Thvbku+85J2NtSWdwzyJeemsn9Y1Nbd7VLJKrFPQ55t6bK1m7Y3/L0zd/cMM4Xt2wm/ykcdXYARQX5rVcnG19g1Vzb37a+MGnttIRTB7Vlz8t3843Zi/lO13sl5BIpqnrk2POG9qL906ooCS8B2BUvxI+UDmE95xX0XJfQPNz9Z9fWU3/skIeufVCIHieDcCZA7reBc+bLhxOftJ48OUNrNza8XcAi2QzBb0c5Yz+h4P8stP7UTm8N5edUU5DuEpUWbf8topmTDJhPHLrRQA8EH7yEJGAgl6OkkgYX7t2LBNH9Obr140FDk9jhK4Z9ADjhvTk2nMH8tsFG4+4N0Ak1ynoJa1PTB7Bw5+6kO4FwXDO5JS7gQd04RlLHwoXnJkVXmAWEQW9RHTVWQP4/JWn8+inL0p7E1VXcdGovowf0pPnVujxxSLNFPQS2e2Xj2bC0F6ZrsZxnT+sFyu27iVY+0ZEFPQSO8P7dOdQfRPfTVkMRSSXKegldqaePZCi/AT3vrCWJ97YkunqiGRcpKA3s6lmttLMVpvZXWmOTzOzxWa2yMwWmNnkqGVFOlp5aSG/+6dgquWLb+3McG1EMu+4QW9mSYIFv68GxgIfNLOxrU57Fhjn7uOBTwD3taOsSIc7a1APRpYXs6Om9vgni8RclB79RGC1u69x9zrgIWBa6gnuXuOHr3wVAx61rEhn6VtSyMtrd3HLL+YfsRKWSK6JEvSDgY0p21XhviOY2XvMbAXwOEGvPnLZsPz0cNhnQXV1dZS6ixzTu8cNYmCPIl7dsId/e2ZVpqsjkjFRgj7dpOmj5q25+yx3PxO4Hri7PWXD8jPdvdLdK8vLc2MxEOlcH5k0jMdvfwefuuQ0Nu05yNsH649fSCSGogR9FTAkZbsC2NzWye4+FxhpZn3bW1akMzQvc7h6e02GayKSGVGCfj4w2sxGmFkBcCMwO/UEMxtlZha+ngAUADujlBXpbKeVB6tgPbJw43HOFImn4z6P3t0bzOw24CkgCTzg7kvN7Nbw+AzgfcDNZlYPHAT+Ibw4m7ZsJ7VFJK0xA8swg7oG3SkruSnSwiPuPgeY02rfjJTX3we+H7WsyKl2er9Samo1Ri+5SXfGSk4oKcqjJlz3ViTXKOglJ5QU5rFuh55RL7lJQS85Y9Oeg+zUnbKSgxT0khMuH9MPgN0HNE4vuUdBLzlhYI9uAByqb8xwTUROPQW95IRu+UkADiroJQcp6CUndCsI/qkfrFPQS+5R0EtOKAp79Bq6kVykoJecUKShG8lhCnrJCd0LgqD/3aubMlwTkVMv0iMQRLLdgLIiSgrz2LBzP7Nf30xewrj09HKKC/VfQOJPPXrJCWbGJyePYN3OA9z+m9f49IOv8uDL6zNdLZFTQt0ZyRm3Xz6a68YPwh0+fN88vjtnBROG9qJyeO9MV02kU6lHLzkjmTBGlpcwql8JH5o4DIDfvKJn1Ev8qUcvOemzV4zm5bU7eataq05J/KlHLzlrZHkJb1XXEKyRIxJfCnrJWSP6FrPvUAO79tdluioinUpBLzmrrFs+APtrdROVxFukoDezqWa20sxWm9ldaY5/2MwWh18vmtm4lGPrzOwNM1tkZgs6svIiJ6MoP/jnf6hBQS/xdtyLsWaWBO4BrgSqgPlmNtvdl6Wctha41N13m9nVwEzggpTjU9x9RwfWW+SkFeXp+TeSG6L06CcCq919jbvXAQ8B01JPcPcX3X13uDkPqOjYaop0vMMPOmvKcE1EOleUoB8MpE42rgr3teWTwBMp2w48bWYLzWx6W4XMbLqZLTCzBdXV1RGqJXJyWoZu1KOXmIsyj97S7Es7H83MphAE/eSU3Re7+2Yz6wc8Y2Yr3H3uUW/oPpNgyIfKykrNd5NOp0cXS66I0qOvAoakbFcAm1ufZGbnAvcB09x9Z/N+d98cft8OzCIYChLJuMMXYzV0I/EWJejnA6PNbISZFQA3ArNTTzCzocCjwE3uviplf7GZlTa/Bq4ClnRU5UVORqEuxkqOOO7Qjbs3mNltwFNAEnjA3Zea2a3h8RnA14A+wE/NDKDB3SuB/sCscF8e8Gt3f7JTWiLSTs1DN7UKeom5SM+6cfc5wJxW+2akvL4FuCVNuTXAuNb7RbqCwxdjNXQj8aY7YyVn6WKs5AoFveSs/GSCZMJ0Z6zEnoJeclpRXkJDNxJ7CnrJaYX5SQ3dSOwp6CWnFeUlqNU8eok5Bb3ktCL16CUHKOglpwVDN+rRS7wp6CWnFeUnqNWsG4k5Bb3ktKI8Dd1I/CnoJacV5Wt6pcSfgl5ymi7GSi5Q0EtOK8pP6s5YiT0FveQ0Dd1ILlDQS04rzEvqMcUSewp6yWl5CaOhSStXSrwp6CWn5SUTNDQq6CXeFPSS0/KTRn2Txugl3hT0ktPyEgncoUnDNxJjkYLezKaa2UozW21md6U5/mEzWxx+vWhm46KWFcmkvKQBqFcvsXbcoDezJHAPcDUwFvigmY1tddpa4FJ3Pxe4G5jZjrIiGZOXCIJe4/QSZ1F69BOB1e6+xt3rgIeAaaknuPuL7r473JwHVEQtK5JJecngv4CCXuIsStAPBjambFeF+9rySeCJEywrckrlh0M3DRq6kRjLi3COpdmXtvtjZlMIgn7yCZSdDkwHGDp0aIRqiZy8vETYo9fFWImxKD36KmBIynYFsLn1SWZ2LnAfMM3dd7anLIC7z3T3SnevLC8vj1J3kZPWPEZf36gevcRXlKCfD4w2sxFmVgDcCMxOPcHMhgKPAje5+6r2lBXJpOZZNxqjlzg77tCNuzeY2W3AU0ASeMDdl5rZreHxGcDXgD7AT80MoCHsnact20ltEWm3louxGrqRGIsyRo+7zwHmtNo3I+X1LcAtUcuKdBX5CV2MlfiLFPQicZUMg/5XL62nX2nREcfecXpfJgztlYlqiXQoBb3ktKF9ulOUn+DBlzccdezFt3bw209dmIFaiXQsBb3ktDMHlLHsm1OP2j/9VwvZtOdgBmok0vH0UDPJeYmEHfVVVpTHvkP1ma6aSIdQ0IukUVKUR01tQ6arIdIhFPQiaZQW5VFzqAF3TbuU7KegF0mjpDCfhibXwuESCwp6kTRKi4J5CvtqNU4v2U9BL5JGS9Af0ji9ZD8FvUgaJYVB0Nco6CUGFPQiaZQW5QPw8tqdxzlTpOtT0IukMapfCQAbdh3IcE1ETp6CXiSN3sUF9Cst1OOLJRYU9CJtyE8mqFfQSwwo6EXakJ80rTwlsaCgF2lDfjKh59RLLCjoRdqQl0xQ16ChG8l+CnqRNhRo6EZiIlLQm9lUM1tpZqvN7K40x880s5fMrNbMvtDq2Doze8PMFpnZgo6quEhn09CNxMVxFx4xsyRwD3AlUAXMN7PZ7r4s5bRdwO3A9W28zRR333GylRU5lfKSRr2GbiQGovToJwKr3X2Nu9cBDwHTUk9w9+3uPh/QE6AkNvKTCerVo5cYiBL0g4GNKdtV4b6oHHjazBaa2fT2VE4kk4J59Ap6yX5R1oy1NPva83n2YnffbGb9gGfMbIW7zz3qhwS/BKYDDB06tB1vL9I58pOmO2MlFqL06KuAISnbFcDmqD/A3TeH37cDswiGgtKdN9PdK929sry8POrbi3SaZMJYsXUf+7WkoGS5KEE/HxhtZiPMrAC4EZgd5c3NrNjMSptfA1cBS060siKn0sAe3QDYUVOb4ZqInJzjDt24e4OZ3QY8BSSBB9x9qZndGh6fYWYDgAVAGdBkZncAY4G+wCwza/5Zv3b3JzunKSId69yKHgA0NGn4RrJblDF63H0OMKfVvhkpr7cSDOm0thcYdzIVFMmUvETwgbdRQS9ZTnfGirQhmQjmIeiCrGQ7Bb1IG/LCoFePXrKdgl6kDclk2KPXTVOS5RT0Im1Qj17iQkEv0oaWMXoFvWQ5Bb1IGzTrRuJCQS/SBvXoJS4U9CJtODxGr4uxkt0U9CJt0Dx6iQsFvUgb8pKadSPxoKAXaUOexuglJhT0Im1IataNxISCXqQN6tFLXCjoRdpw+GKsZt1IdlPQi7ShIC/47/H7RZsyXBORk6OgF2lD35JCAEoKIy3bINJlKehFjmHckJ7UaR69ZDkFvcgxFCRNY/SS9RT0IseQl0hQr6CXLBcp6M1sqpmtNLPVZnZXmuNnmtlLZlZrZl9oT1mRriw/L6GhG8l6xw16M0sC9wBXA2OBD5rZ2Fan7QJuB350AmVFuiwN3UgcROnRTwRWu/sad68DHgKmpZ7g7tvdfT5Q396yIl2Zhm4kDqIE/WBgY8p2VbgvishlzWy6mS0wswXV1dUR316kc+XnJfT0Ssl6UYLe0uyL+i8/cll3n+nule5eWV5eHvHtRTpXfsKoU49eslyUoK8ChqRsVwCbI77/yZQVybj8pIZuJPtFCfr5wGgzG2FmBcCNwOyI738yZUUyLj/PNHQjWe+493a7e4OZ3QY8BSSBB9x9qZndGh6fYWYDgAVAGdBkZncAY919b7qyndUYkY6Wl0hwoK6RxxZvZtJpfVoeiyCSTSI9xMPd5wBzWu2bkfJ6K8GwTKSyItmivLSQg/WN3Pbr17hp0jDuvv7sTFdJpN10Z6zIMfzTpSP50+cvpV8Y+CLZSEEvcgyJhDGqXwn5yQRNrrF6yU4KepEIEgmiTyoW6WIU9CIRGKYevWQtBb1IBAlTh16yl4JeJAIzQ2uES7ZS0ItEYAauoRvJUgp6kQgMUM5LtlLQi0RgZrhG6SVLKehFIkgYNOnZZpKlFPQiERjq0Uv2UtCLRBBcjM10LUROjIJeJAJNr5RspqAXiSBhoFumJFsp6EUiMEM9eslaCnqRCBJmumFKspaCXiQCQz16yV4KepEIghumRLJTpKA3s6lmttLMVpvZXWmOm5n9JDy+2MwmpBxbZ2ZvmNkiM1vQkZUXOVX0rBvJZsddM9bMksA9wJVAFTDfzGa7+7KU064GRodfFwA/C783m+LuOzqs1iKnWDBGn+laiJyYKD36icBqd1/j7nXAQ8C0VudMA37pgXlATzMb2MF1FcmYYIxeSS/ZKUrQDwY2pmxXhfuinuPA02a20Mymt/VDzGy6mS0wswXV1dURqiVy6qhHL9ksStBbmn2t/8kf65yL3X0CwfDOZ8zsknQ/xN1nunulu1eWl5dHqJbIKWTq0Uv2ihL0VcCQlO0KYHPUc9y9+ft2YBbBUJBIVjF0X6xkryhBPx8YbWYjzKwAuBGY3eqc2cDN4eybScDb7r7FzIrNrBTAzIqBq4AlHVh/kVNCN0xJNjvurBt3bzCz24CngCTwgLsvNbNbw+MzgDnANcBq4ADw8bB4f2CWmTX/rF+7+5Md3gqRTqanV0o2O27QA7j7HIIwT903I+W1A59JU24NMO4k6yiScQndMCVZTHfGikRguhgrWUxBLxKBaXqlZDEFvUgEhh6BINlLQS8SQcI0vVKyl4JeJIJgKUFFvWQnBb1IBAlNr5QspqAXiUSLg0v2UtCLRJDQ8+gliynoRSLQnbGSzRT0IhEYhmvejWQpBb1IBImEFgeX7KWgF4nA0NMrJXsp6EUi0Bi9ZDMFvUgEpqdXShZT0ItEoOmVks0U9CIRGLoYK9lLQS8SQbDwiJJespOCXiQKg6amTFdC5MRECnozm2pmK81stZndlea4mdlPwuOLzWxC1LIi2SARrHsskpWOG/RmlgTuAa4GxgIfNLOxrU67Ghgdfk0HftaOsiJdXjBGr6EbyU5RFgefCKwOF/rGzB4CpgHLUs6ZBvwyXCR8npn1NLOBwPAIZUW6vIQZ2/fVcuWP/5LpqkiM9epewMO3Xtjh7xsl6AcDG1O2q4ALIpwzOGJZAMxsOsGnAYYOHRqhWiKnznsmDKamtkEXZETzfhAAAASaSURBVKVTlRXld8r7Rgn6dIOTrf+1t3VOlLLBTveZwEyAyspK/W+SLmXSaX2YdFqfTFdD5IRECfoqYEjKdgWwOeI5BRHKiohIJ4oy62Y+MNrMRphZAXAjMLvVObOBm8PZN5OAt919S8SyIiLSiY7bo3f3BjO7DXgKSAIPuPtSM7s1PD4DmANcA6wGDgAfP1bZTmmJiIikZV3x+R2VlZW+YMGCTFdDRCRrmNlCd69Md0x3xoqIxJyCXkQk5hT0IiIxp6AXEYm5Lnkx1syqgfUnWLwvsKMDq9OVqG3ZK87tU9u6hmHuXp7uQJcM+pNhZgvauvKc7dS27BXn9qltXZ+GbkREYk5BLyISc3EM+pmZrkAnUtuyV5zbp7Z1cbEboxcRkSPFsUcvIiIpFPQiIjEXm6DP9kXIzWyImf3ZzJab2VIz+2y4v7eZPWNmb4bfe6WU+WLY3pVm9s7M1T4aM0ua2Wtm9li4Hae29TSzR8xsRfh3eGFc2mdmnwv/TS4xs9+YWVE2t83MHjCz7Wa2JGVfu9tjZueb2RvhsZ+YdeEV5N09678IHoH8FnAawWInrwNjM12vdrZhIDAhfF0KrCJYUP0HwF3h/ruA74evx4btLARGhO1PZrodx2nj54FfA4+F23Fq2y+AW8LXBUDPOLSPYDnQtUC3cPth4GPZ3DbgEmACsCRlX7vbA7wCXEiwkt4TwNWZbltbX3Hp0bcsYO7udUDzIuRZw923uPur4et9wHKC/2TTCEKE8Pv14etpwEPuXuvuawnWAph4amsdnZlVAO8C7kvZHZe2lRGEx/0A7l7n7nuISfsI1q3oZmZ5QHeCVeKytm3uPhfY1Wp3u9pjZgOBMnd/yYPU/2VKmS4nLkHf1uLkWcnMhgPnAS8D/T1YrYvwe7/wtGxr878DdwJNKfvi0rbTgGrg5+HQ1H1mVkwM2ufum4AfARuALQSrxz1NDNrWSnvbMzh83Xp/lxSXoI+8CHlXZ2YlwO+AO9x977FOTbOvS7bZzK4Ftrv7wqhF0uzrkm0L5REMBfzM3c8D9hN8/G9L1rQvHKueRjBsMQgoNrOPHKtImn1dsm0RtdWerGpnXII+ygLmXZ6Z5ROE/IPu/mi4e1v4MZHw+/Zwfza1+WLgOjNbRzCs9vdm9r/Eo20Q1LfK3V8Otx8hCP44tO8KYK27V7t7PfAocBHxaFuq9ranKnzden+XFJegz/pFyMMr9vcDy939xymHZgMfDV9/FPhDyv4bzazQzEYAowkuDnU57v5Fd69w9+EEfzfPuftHiEHbANx9K7DRzM4Id10OLCMe7dsATDKz7uG/0csJrh/FoW2p2tWecHhnn5lNCv9cbk4p0/Vk+mpwR30RLE6+iuCq+JczXZ8TqP9kgo9+i4FF4dc1QB/gWeDN8HvvlDJfDtu7ki58xb9VOy/j8Kyb2LQNGA8sCP/+fg/0ikv7gG8CK4AlwK8IZqBkbduA3xBcb6gn6Jl/8kTaA1SGfyZvAf9F+KSBrvilRyCIiMRcXIZuRESkDQp6EZGYU9CLiMScgl5EJOYU9CIiMaegFxGJOQW9iEjM/X8iE5/ZUaRpLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1101),train_x[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator =  DataGenerator(train_x,train_y,0)\n",
    "validation_generator = DataGenerator(train_x,train_y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6be1b04630>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = next(iter(training_generator))\n",
    "plt.plot(range(1001),a[0][:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = schedules.ExponentialDecay(5e-4,decay_steps=5000,decay_rate=0.96)\n",
    "#model.compile(loss='mean_squared_logarithmic_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])\n",
    "model.compile(loss='mean_squared_error', optimizer= SGD(momentum = 0.98, learning_rate = lr_schedule), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainid='mle.linear'\n",
    "checkpoint_path = \"Regression_Model/\"+trainid+\"-{epoch:04d}.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1,period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 368 steps, validate for 368 steps\n",
      "Epoch 1/3000\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 3.7830 - mse: 3.7749 - val_loss: 1.5511 - val_mse: 1.5423\n",
      "Epoch 2/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.6623 - mse: 1.6534 - val_loss: 1.4561 - val_mse: 1.4472\n",
      "Epoch 3/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5897 - mse: 1.5807 - val_loss: 1.4027 - val_mse: 1.3937\n",
      "Epoch 4/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5685 - mse: 1.5595 - val_loss: 1.3926 - val_mse: 1.3836\n",
      "Epoch 5/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5604 - mse: 1.5514 - val_loss: 1.3783 - val_mse: 1.3693\n",
      "Epoch 6/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5404 - mse: 1.5313 - val_loss: 1.4326 - val_mse: 1.4235\n",
      "Epoch 7/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5537 - mse: 1.5446 - val_loss: 1.4453 - val_mse: 1.4362\n",
      "Epoch 8/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5553 - mse: 1.5461 - val_loss: 1.3555 - val_mse: 1.3463\n",
      "Epoch 9/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5179 - mse: 1.5087 - val_loss: 1.3560 - val_mse: 1.3468\n",
      "Epoch 10/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 1.5080 - mse: 1.4988\n",
      "Epoch 00010: saving model to Regression_Model/mle.linear-0010.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 1.5091 - mse: 1.4999 - val_loss: 1.3741 - val_mse: 1.3648\n",
      "Epoch 11/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5113 - mse: 1.5020 - val_loss: 1.3237 - val_mse: 1.3144\n",
      "Epoch 12/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5171 - mse: 1.5078 - val_loss: 1.3543 - val_mse: 1.3450\n",
      "Epoch 13/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5062 - mse: 1.4969 - val_loss: 1.4174 - val_mse: 1.4080\n",
      "Epoch 14/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4983 - mse: 1.4889 - val_loss: 1.3464 - val_mse: 1.3370\n",
      "Epoch 15/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5039 - mse: 1.4945 - val_loss: 1.3324 - val_mse: 1.3231\n",
      "Epoch 16/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5366 - mse: 1.5272 - val_loss: 1.4166 - val_mse: 1.4071\n",
      "Epoch 17/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5334 - mse: 1.5239 - val_loss: 1.4390 - val_mse: 1.4295\n",
      "Epoch 18/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5291 - mse: 1.5196 - val_loss: 1.3923 - val_mse: 1.3828\n",
      "Epoch 19/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5167 - mse: 1.5072 - val_loss: 1.4009 - val_mse: 1.3915\n",
      "Epoch 20/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.4983 - mse: 1.4888\n",
      "Epoch 00020: saving model to Regression_Model/mle.linear-0020.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4997 - mse: 1.4902 - val_loss: 1.3265 - val_mse: 1.3170\n",
      "Epoch 21/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4980 - mse: 1.4885 - val_loss: 1.4110 - val_mse: 1.4016\n",
      "Epoch 22/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5555 - mse: 1.5459 - val_loss: 1.4738 - val_mse: 1.4643\n",
      "Epoch 23/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5050 - mse: 1.4954 - val_loss: 1.3613 - val_mse: 1.3518\n",
      "Epoch 24/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4931 - mse: 1.4835 - val_loss: 1.3110 - val_mse: 1.3014\n",
      "Epoch 25/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4869 - mse: 1.4773 - val_loss: 1.3236 - val_mse: 1.3140\n",
      "Epoch 26/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4854 - mse: 1.4758 - val_loss: 1.3803 - val_mse: 1.3707\n",
      "Epoch 27/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5010 - mse: 1.4914 - val_loss: 1.3354 - val_mse: 1.3258\n",
      "Epoch 28/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5055 - mse: 1.4959 - val_loss: 1.3717 - val_mse: 1.3621\n",
      "Epoch 29/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4851 - mse: 1.4754 - val_loss: 1.3490 - val_mse: 1.3394\n",
      "Epoch 30/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.4827 - mse: 1.4731\n",
      "Epoch 00030: saving model to Regression_Model/mle.linear-0030.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 1.4818 - mse: 1.4722 - val_loss: 1.3115 - val_mse: 1.3018\n",
      "Epoch 31/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4807 - mse: 1.4710 - val_loss: 1.3832 - val_mse: 1.3736\n",
      "Epoch 32/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5109 - mse: 1.5013 - val_loss: 1.3354 - val_mse: 1.3258\n",
      "Epoch 33/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4943 - mse: 1.4847 - val_loss: 1.4369 - val_mse: 1.4273\n",
      "Epoch 34/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5095 - mse: 1.4999 - val_loss: 1.3408 - val_mse: 1.3312\n",
      "Epoch 35/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4879 - mse: 1.4783 - val_loss: 1.3676 - val_mse: 1.3579\n",
      "Epoch 36/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4669 - mse: 1.4572 - val_loss: 1.3474 - val_mse: 1.3377\n",
      "Epoch 37/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4858 - mse: 1.4761 - val_loss: 1.3110 - val_mse: 1.3013\n",
      "Epoch 38/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4922 - mse: 1.4826 - val_loss: 1.3759 - val_mse: 1.3663\n",
      "Epoch 39/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4706 - mse: 1.4609 - val_loss: 1.3832 - val_mse: 1.3736\n",
      "Epoch 40/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.5029 - mse: 1.4933\n",
      "Epoch 00040: saving model to Regression_Model/mle.linear-0040.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4996 - mse: 1.4900 - val_loss: 1.4004 - val_mse: 1.3908\n",
      "Epoch 41/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5047 - mse: 1.4951 - val_loss: 1.3226 - val_mse: 1.3130\n",
      "Epoch 42/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5211 - mse: 1.5114 - val_loss: 1.3536 - val_mse: 1.3439\n",
      "Epoch 43/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4970 - mse: 1.4873 - val_loss: 1.4248 - val_mse: 1.4151\n",
      "Epoch 44/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4981 - mse: 1.4884 - val_loss: 1.3121 - val_mse: 1.3024\n",
      "Epoch 45/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4805 - mse: 1.4708 - val_loss: 1.3592 - val_mse: 1.3495\n",
      "Epoch 46/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4965 - mse: 1.4868 - val_loss: 1.3030 - val_mse: 1.2933\n",
      "Epoch 47/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4969 - mse: 1.4872 - val_loss: 1.3051 - val_mse: 1.2954\n",
      "Epoch 48/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4892 - mse: 1.4795 - val_loss: 1.3416 - val_mse: 1.3319\n",
      "Epoch 49/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4840 - mse: 1.4743 - val_loss: 1.2992 - val_mse: 1.2895\n",
      "Epoch 50/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.4669 - mse: 1.4572\n",
      "Epoch 00050: saving model to Regression_Model/mle.linear-0050.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4686 - mse: 1.4588 - val_loss: 1.3243 - val_mse: 1.3146\n",
      "Epoch 51/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4794 - mse: 1.4696 - val_loss: 1.2993 - val_mse: 1.2895\n",
      "Epoch 52/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4517 - mse: 1.4420 - val_loss: 1.3335 - val_mse: 1.3238\n",
      "Epoch 53/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4690 - mse: 1.4593 - val_loss: 1.2985 - val_mse: 1.2888\n",
      "Epoch 54/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4689 - mse: 1.4592 - val_loss: 1.3214 - val_mse: 1.3117\n",
      "Epoch 55/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4859 - mse: 1.4762 - val_loss: 1.2877 - val_mse: 1.2780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4637 - mse: 1.4540 - val_loss: 1.3450 - val_mse: 1.3353\n",
      "Epoch 57/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4880 - mse: 1.4783 - val_loss: 1.3244 - val_mse: 1.3146\n",
      "Epoch 58/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4735 - mse: 1.4637 - val_loss: 1.2922 - val_mse: 1.2825\n",
      "Epoch 59/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4909 - mse: 1.4812 - val_loss: 1.2929 - val_mse: 1.2832\n",
      "Epoch 60/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.4716 - mse: 1.4619\n",
      "Epoch 00060: saving model to Regression_Model/mle.linear-0060.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4675 - mse: 1.4578 - val_loss: 1.3069 - val_mse: 1.2972\n",
      "Epoch 61/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4732 - mse: 1.4635 - val_loss: 1.3419 - val_mse: 1.3322\n",
      "Epoch 62/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4749 - mse: 1.4652 - val_loss: 1.3908 - val_mse: 1.3811\n",
      "Epoch 63/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4800 - mse: 1.4703 - val_loss: 1.2893 - val_mse: 1.2796\n",
      "Epoch 64/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4651 - mse: 1.4554 - val_loss: 1.2987 - val_mse: 1.2890\n",
      "Epoch 65/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4958 - mse: 1.4862 - val_loss: 1.4572 - val_mse: 1.4475\n",
      "Epoch 66/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4866 - mse: 1.4769 - val_loss: 1.3036 - val_mse: 1.2939\n",
      "Epoch 67/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4944 - mse: 1.4847 - val_loss: 1.3828 - val_mse: 1.3731\n",
      "Epoch 68/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4623 - mse: 1.4526 - val_loss: 1.2823 - val_mse: 1.2726\n",
      "Epoch 69/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4759 - mse: 1.4662 - val_loss: 1.3510 - val_mse: 1.3413\n",
      "Epoch 70/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.4929 - mse: 1.4832\n",
      "Epoch 00070: saving model to Regression_Model/mle.linear-0070.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4926 - mse: 1.4829 - val_loss: 1.3580 - val_mse: 1.3483\n",
      "Epoch 71/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4801 - mse: 1.4703 - val_loss: 1.3649 - val_mse: 1.3551\n",
      "Epoch 72/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.5051 - mse: 1.4954 - val_loss: 1.3083 - val_mse: 1.2986\n",
      "Epoch 73/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4574 - mse: 1.4477 - val_loss: 1.3171 - val_mse: 1.3074\n",
      "Epoch 74/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4583 - mse: 1.4486 - val_loss: 1.3259 - val_mse: 1.3162\n",
      "Epoch 75/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4965 - mse: 1.4868 - val_loss: 1.3322 - val_mse: 1.3225\n",
      "Epoch 76/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4668 - mse: 1.4571 - val_loss: 1.3000 - val_mse: 1.2903\n",
      "Epoch 77/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4559 - mse: 1.4462 - val_loss: 1.3207 - val_mse: 1.3110\n",
      "Epoch 78/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4744 - mse: 1.4647 - val_loss: 1.3105 - val_mse: 1.3008\n",
      "Epoch 79/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4647 - mse: 1.4551 - val_loss: 1.3222 - val_mse: 1.3125\n",
      "Epoch 80/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.4893 - mse: 1.4796\n",
      "Epoch 00080: saving model to Regression_Model/mle.linear-0080.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 1.4850 - mse: 1.4753 - val_loss: 1.2978 - val_mse: 1.2882\n",
      "Epoch 81/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4826 - mse: 1.4730 - val_loss: 1.2947 - val_mse: 1.2850\n",
      "Epoch 82/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4762 - mse: 1.4666 - val_loss: 1.3138 - val_mse: 1.3042\n",
      "Epoch 83/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4711 - mse: 1.4614 - val_loss: 1.3046 - val_mse: 1.2949\n",
      "Epoch 84/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4514 - mse: 1.4417 - val_loss: 1.2866 - val_mse: 1.2770\n",
      "Epoch 85/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4774 - mse: 1.4677 - val_loss: 1.3202 - val_mse: 1.3105\n",
      "Epoch 86/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4653 - mse: 1.4556 - val_loss: 1.2807 - val_mse: 1.2710\n",
      "Epoch 87/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4784 - mse: 1.4687 - val_loss: 1.3354 - val_mse: 1.3257\n",
      "Epoch 88/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4667 - mse: 1.4570 - val_loss: 1.3417 - val_mse: 1.3320\n",
      "Epoch 89/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4595 - mse: 1.4498 - val_loss: 1.2755 - val_mse: 1.2658\n",
      "Epoch 90/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.4527 - mse: 1.4430\n",
      "Epoch 00090: saving model to Regression_Model/mle.linear-0090.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4492 - mse: 1.4395 - val_loss: 1.2961 - val_mse: 1.2864\n",
      "Epoch 91/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4910 - mse: 1.4813 - val_loss: 1.4717 - val_mse: 1.4620\n",
      "Epoch 92/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4708 - mse: 1.4611 - val_loss: 1.3403 - val_mse: 1.3306\n",
      "Epoch 93/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4774 - mse: 1.4677 - val_loss: 1.3388 - val_mse: 1.3291\n",
      "Epoch 94/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4647 - mse: 1.4550 - val_loss: 1.2888 - val_mse: 1.2791\n",
      "Epoch 95/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4624 - mse: 1.4527 - val_loss: 1.2944 - val_mse: 1.2847\n",
      "Epoch 96/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4807 - mse: 1.4709 - val_loss: 1.3146 - val_mse: 1.3048\n",
      "Epoch 97/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.4704 - mse: 1.4607 - val_loss: 1.2950 - val_mse: 1.2853\n",
      "Epoch 98/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4541 - mse: 1.4444 - val_loss: 1.2793 - val_mse: 1.2695\n",
      "Epoch 99/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4684 - mse: 1.4587 - val_loss: 1.3333 - val_mse: 1.3236\n",
      "Epoch 100/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.4749 - mse: 1.4652\n",
      "Epoch 00100: saving model to Regression_Model/mle.linear-0100.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4692 - mse: 1.4595 - val_loss: 1.2910 - val_mse: 1.2813\n",
      "Epoch 101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4492 - mse: 1.4395 - val_loss: 1.2808 - val_mse: 1.2712\n",
      "Epoch 102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4720 - mse: 1.4623 - val_loss: 1.2931 - val_mse: 1.2835\n",
      "Epoch 103/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4467 - mse: 1.4371 - val_loss: 1.3193 - val_mse: 1.3096\n",
      "Epoch 104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4638 - mse: 1.4542 - val_loss: 1.2799 - val_mse: 1.2702\n",
      "Epoch 105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4631 - mse: 1.4535 - val_loss: 1.3658 - val_mse: 1.3561\n",
      "Epoch 106/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4431 - mse: 1.4335 - val_loss: 1.2785 - val_mse: 1.2688\n",
      "Epoch 107/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4641 - mse: 1.4545 - val_loss: 1.2925 - val_mse: 1.2828\n",
      "Epoch 108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4511 - mse: 1.4415 - val_loss: 1.2895 - val_mse: 1.2799\n",
      "Epoch 109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4431 - mse: 1.4335 - val_loss: 1.2786 - val_mse: 1.2690\n",
      "Epoch 110/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.4735 - mse: 1.4639\n",
      "Epoch 00110: saving model to Regression_Model/mle.linear-0110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4703 - mse: 1.4607 - val_loss: 1.3110 - val_mse: 1.3014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4702 - mse: 1.4606 - val_loss: 1.2951 - val_mse: 1.2855\n",
      "Epoch 112/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4486 - mse: 1.4390 - val_loss: 1.3348 - val_mse: 1.3253\n",
      "Epoch 113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4413 - mse: 1.4317 - val_loss: 1.2801 - val_mse: 1.2705\n",
      "Epoch 114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4451 - mse: 1.4355 - val_loss: 1.2893 - val_mse: 1.2797\n",
      "Epoch 115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4461 - mse: 1.4365 - val_loss: 1.3531 - val_mse: 1.3435\n",
      "Epoch 116/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4608 - mse: 1.4512 - val_loss: 1.2833 - val_mse: 1.2737\n",
      "Epoch 117/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4725 - mse: 1.4629 - val_loss: 1.2836 - val_mse: 1.2740\n",
      "Epoch 118/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4503 - mse: 1.4407 - val_loss: 1.2690 - val_mse: 1.2594\n",
      "Epoch 119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4422 - mse: 1.4326 - val_loss: 1.3178 - val_mse: 1.3082\n",
      "Epoch 120/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.4538 - mse: 1.4442\n",
      "Epoch 00120: saving model to Regression_Model/mle.linear-0120.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4577 - mse: 1.4481 - val_loss: 1.3070 - val_mse: 1.2974\n",
      "Epoch 121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4471 - mse: 1.4375 - val_loss: 1.2825 - val_mse: 1.2729\n",
      "Epoch 122/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4613 - mse: 1.4517 - val_loss: 1.2838 - val_mse: 1.2742\n",
      "Epoch 123/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4338 - mse: 1.4242 - val_loss: 1.2854 - val_mse: 1.2758\n",
      "Epoch 124/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4491 - mse: 1.4396 - val_loss: 1.4081 - val_mse: 1.3985\n",
      "Epoch 125/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4404 - mse: 1.4309 - val_loss: 1.3147 - val_mse: 1.3052\n",
      "Epoch 126/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4772 - mse: 1.4677 - val_loss: 1.3331 - val_mse: 1.3236\n",
      "Epoch 127/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4485 - mse: 1.4390 - val_loss: 1.2963 - val_mse: 1.2868\n",
      "Epoch 128/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4408 - mse: 1.4312 - val_loss: 1.3171 - val_mse: 1.3076\n",
      "Epoch 129/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4532 - mse: 1.4436 - val_loss: 1.3160 - val_mse: 1.3064\n",
      "Epoch 130/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 1.4472 - mse: 1.4376\n",
      "Epoch 00130: saving model to Regression_Model/mle.linear-0130.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4456 - mse: 1.4360 - val_loss: 1.2796 - val_mse: 1.2701\n",
      "Epoch 131/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4510 - mse: 1.4415 - val_loss: 1.2662 - val_mse: 1.2566\n",
      "Epoch 132/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4326 - mse: 1.4231 - val_loss: 1.2680 - val_mse: 1.2584\n",
      "Epoch 133/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4606 - mse: 1.4510 - val_loss: 1.3271 - val_mse: 1.3175\n",
      "Epoch 134/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4515 - mse: 1.4420 - val_loss: 1.2925 - val_mse: 1.2829\n",
      "Epoch 135/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4534 - mse: 1.4439 - val_loss: 1.2862 - val_mse: 1.2766\n",
      "Epoch 136/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4698 - mse: 1.4603 - val_loss: 1.2812 - val_mse: 1.2717\n",
      "Epoch 137/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4441 - mse: 1.4346 - val_loss: 1.2756 - val_mse: 1.2661\n",
      "Epoch 138/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4569 - mse: 1.4474 - val_loss: 1.2787 - val_mse: 1.2692\n",
      "Epoch 139/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4272 - mse: 1.4177 - val_loss: 1.2808 - val_mse: 1.2713\n",
      "Epoch 140/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.4458 - mse: 1.4363\n",
      "Epoch 00140: saving model to Regression_Model/mle.linear-0140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4418 - mse: 1.4323 - val_loss: 1.3118 - val_mse: 1.3024\n",
      "Epoch 141/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4711 - mse: 1.4616 - val_loss: 1.2965 - val_mse: 1.2870\n",
      "Epoch 142/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4426 - mse: 1.4331 - val_loss: 1.2850 - val_mse: 1.2755\n",
      "Epoch 143/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4545 - mse: 1.4451 - val_loss: 1.2966 - val_mse: 1.2871\n",
      "Epoch 144/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4483 - mse: 1.4389 - val_loss: 1.2940 - val_mse: 1.2845\n",
      "Epoch 145/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4505 - mse: 1.4411 - val_loss: 1.3098 - val_mse: 1.3004\n",
      "Epoch 146/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4494 - mse: 1.4400 - val_loss: 1.3493 - val_mse: 1.3399\n",
      "Epoch 147/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4419 - mse: 1.4325 - val_loss: 1.2753 - val_mse: 1.2658\n",
      "Epoch 148/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4395 - mse: 1.4301 - val_loss: 1.3077 - val_mse: 1.2982\n",
      "Epoch 149/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4447 - mse: 1.4352 - val_loss: 1.3168 - val_mse: 1.3074\n",
      "Epoch 150/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.4576 - mse: 1.4482\n",
      "Epoch 00150: saving model to Regression_Model/mle.linear-0150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4655 - mse: 1.4560 - val_loss: 1.3231 - val_mse: 1.3137\n",
      "Epoch 151/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4384 - mse: 1.4290 - val_loss: 1.3145 - val_mse: 1.3050\n",
      "Epoch 152/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4510 - mse: 1.4416 - val_loss: 1.2619 - val_mse: 1.2525\n",
      "Epoch 153/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4354 - mse: 1.4260 - val_loss: 1.3371 - val_mse: 1.3276\n",
      "Epoch 154/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.4581 - mse: 1.4487 - val_loss: 1.3613 - val_mse: 1.3519\n",
      "Epoch 155/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4577 - mse: 1.4483 - val_loss: 1.2891 - val_mse: 1.2797\n",
      "Epoch 156/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4544 - mse: 1.4450 - val_loss: 1.2930 - val_mse: 1.2836\n",
      "Epoch 157/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4489 - mse: 1.4395 - val_loss: 1.2798 - val_mse: 1.2704\n",
      "Epoch 158/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4343 - mse: 1.4249 - val_loss: 1.2818 - val_mse: 1.2723\n",
      "Epoch 159/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4287 - mse: 1.4193 - val_loss: 1.3343 - val_mse: 1.3249\n",
      "Epoch 160/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.4684 - mse: 1.4590\n",
      "Epoch 00160: saving model to Regression_Model/mle.linear-0160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4633 - mse: 1.4538 - val_loss: 1.3027 - val_mse: 1.2933\n",
      "Epoch 161/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4580 - mse: 1.4486 - val_loss: 1.2856 - val_mse: 1.2762\n",
      "Epoch 162/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4770 - mse: 1.4675 - val_loss: 1.4058 - val_mse: 1.3964\n",
      "Epoch 163/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4569 - mse: 1.4474 - val_loss: 1.3200 - val_mse: 1.3106\n",
      "Epoch 164/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4378 - mse: 1.4284 - val_loss: 1.2753 - val_mse: 1.2659\n",
      "Epoch 165/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4550 - mse: 1.4456 - val_loss: 1.3069 - val_mse: 1.2975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4419 - mse: 1.4325 - val_loss: 1.3184 - val_mse: 1.3090\n",
      "Epoch 167/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4451 - mse: 1.4357 - val_loss: 1.3258 - val_mse: 1.3164\n",
      "Epoch 168/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4500 - mse: 1.4406 - val_loss: 1.2908 - val_mse: 1.2814\n",
      "Epoch 169/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4408 - mse: 1.4314 - val_loss: 1.3098 - val_mse: 1.3004\n",
      "Epoch 170/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.4402 - mse: 1.4308\n",
      "Epoch 00170: saving model to Regression_Model/mle.linear-0170.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4377 - mse: 1.4282 - val_loss: 1.2728 - val_mse: 1.2634\n",
      "Epoch 171/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4473 - mse: 1.4379 - val_loss: 1.2893 - val_mse: 1.2799\n",
      "Epoch 172/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4448 - mse: 1.4354 - val_loss: 1.3019 - val_mse: 1.2925\n",
      "Epoch 173/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4532 - mse: 1.4438 - val_loss: 1.2706 - val_mse: 1.2612\n",
      "Epoch 174/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4538 - mse: 1.4444 - val_loss: 1.2978 - val_mse: 1.2884\n",
      "Epoch 175/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4409 - mse: 1.4315 - val_loss: 1.3255 - val_mse: 1.3161\n",
      "Epoch 176/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4359 - mse: 1.4265 - val_loss: 1.3045 - val_mse: 1.2951\n",
      "Epoch 177/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4613 - mse: 1.4519 - val_loss: 1.3422 - val_mse: 1.3328\n",
      "Epoch 178/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4281 - mse: 1.4187 - val_loss: 1.2732 - val_mse: 1.2638\n",
      "Epoch 179/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4409 - mse: 1.4315 - val_loss: 1.3205 - val_mse: 1.3111\n",
      "Epoch 180/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.4469 - mse: 1.4375\n",
      "Epoch 00180: saving model to Regression_Model/mle.linear-0180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4524 - mse: 1.4430 - val_loss: 1.2962 - val_mse: 1.2868\n",
      "Epoch 181/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4515 - mse: 1.4422 - val_loss: 1.3137 - val_mse: 1.3043\n",
      "Epoch 182/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4298 - mse: 1.4204 - val_loss: 1.2886 - val_mse: 1.2792\n",
      "Epoch 183/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4289 - mse: 1.4195 - val_loss: 1.2753 - val_mse: 1.2659\n",
      "Epoch 184/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4235 - mse: 1.4142 - val_loss: 1.2802 - val_mse: 1.2708\n",
      "Epoch 185/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4564 - mse: 1.4470 - val_loss: 1.3952 - val_mse: 1.3858\n",
      "Epoch 186/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4701 - mse: 1.4608 - val_loss: 1.3013 - val_mse: 1.2919\n",
      "Epoch 187/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4184 - mse: 1.4090 - val_loss: 1.2862 - val_mse: 1.2768\n",
      "Epoch 188/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4343 - mse: 1.4249 - val_loss: 1.2614 - val_mse: 1.2520\n",
      "Epoch 189/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4499 - mse: 1.4406 - val_loss: 1.2759 - val_mse: 1.2665\n",
      "Epoch 190/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.4488 - mse: 1.4395\n",
      "Epoch 00190: saving model to Regression_Model/mle.linear-0190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4472 - mse: 1.4378 - val_loss: 1.2878 - val_mse: 1.2785\n",
      "Epoch 191/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4471 - mse: 1.4377 - val_loss: 1.2629 - val_mse: 1.2535\n",
      "Epoch 192/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4577 - mse: 1.4483 - val_loss: 1.2976 - val_mse: 1.2882\n",
      "Epoch 193/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4518 - mse: 1.4424 - val_loss: 1.3021 - val_mse: 1.2927\n",
      "Epoch 194/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4309 - mse: 1.4215 - val_loss: 1.2904 - val_mse: 1.2811\n",
      "Epoch 195/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4423 - mse: 1.4329 - val_loss: 1.2637 - val_mse: 1.2543\n",
      "Epoch 196/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4377 - mse: 1.4283 - val_loss: 1.3091 - val_mse: 1.2998\n",
      "Epoch 197/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4468 - mse: 1.4375 - val_loss: 1.2940 - val_mse: 1.2847\n",
      "Epoch 198/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4597 - mse: 1.4504 - val_loss: 1.2871 - val_mse: 1.2778\n",
      "Epoch 199/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4348 - mse: 1.4255 - val_loss: 1.3161 - val_mse: 1.3068\n",
      "Epoch 200/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.4425 - mse: 1.4332\n",
      "Epoch 00200: saving model to Regression_Model/mle.linear-0200.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4400 - mse: 1.4307 - val_loss: 1.2879 - val_mse: 1.2786\n",
      "Epoch 201/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4502 - mse: 1.4409 - val_loss: 1.3015 - val_mse: 1.2922\n",
      "Epoch 202/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4207 - mse: 1.4113 - val_loss: 1.2855 - val_mse: 1.2761\n",
      "Epoch 203/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4410 - mse: 1.4317 - val_loss: 1.2653 - val_mse: 1.2560\n",
      "Epoch 204/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4484 - mse: 1.4391 - val_loss: 1.3255 - val_mse: 1.3162\n",
      "Epoch 205/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4536 - mse: 1.4443 - val_loss: 1.2750 - val_mse: 1.2657\n",
      "Epoch 206/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4487 - mse: 1.4394 - val_loss: 1.2625 - val_mse: 1.2531\n",
      "Epoch 207/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4340 - mse: 1.4247 - val_loss: 1.2750 - val_mse: 1.2657\n",
      "Epoch 208/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4410 - mse: 1.4317 - val_loss: 1.2567 - val_mse: 1.2474\n",
      "Epoch 209/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4346 - mse: 1.4252 - val_loss: 1.2738 - val_mse: 1.2645\n",
      "Epoch 210/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.4151 - mse: 1.4058\n",
      "Epoch 00210: saving model to Regression_Model/mle.linear-0210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4170 - mse: 1.4077 - val_loss: 1.2820 - val_mse: 1.2726\n",
      "Epoch 211/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4420 - mse: 1.4327 - val_loss: 1.2810 - val_mse: 1.2717\n",
      "Epoch 212/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4311 - mse: 1.4218 - val_loss: 1.2713 - val_mse: 1.2620\n",
      "Epoch 213/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4292 - mse: 1.4199 - val_loss: 1.2575 - val_mse: 1.2482\n",
      "Epoch 214/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4392 - mse: 1.4299 - val_loss: 1.2949 - val_mse: 1.2856\n",
      "Epoch 215/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4329 - mse: 1.4236 - val_loss: 1.2595 - val_mse: 1.2501\n",
      "Epoch 216/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4236 - mse: 1.4143 - val_loss: 1.2785 - val_mse: 1.2692\n",
      "Epoch 217/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4400 - mse: 1.4307 - val_loss: 1.2769 - val_mse: 1.2676\n",
      "Epoch 218/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4575 - mse: 1.4482 - val_loss: 1.3429 - val_mse: 1.3336\n",
      "Epoch 219/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4452 - mse: 1.4359 - val_loss: 1.2658 - val_mse: 1.2565\n",
      "Epoch 220/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.4589 - mse: 1.4497\n",
      "Epoch 00220: saving model to Regression_Model/mle.linear-0220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4584 - mse: 1.4492 - val_loss: 1.2833 - val_mse: 1.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4413 - mse: 1.4320 - val_loss: 1.3209 - val_mse: 1.3116\n",
      "Epoch 222/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4271 - mse: 1.4178 - val_loss: 1.2688 - val_mse: 1.2596\n",
      "Epoch 223/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4553 - mse: 1.4461 - val_loss: 1.2664 - val_mse: 1.2572\n",
      "Epoch 224/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4159 - mse: 1.4066 - val_loss: 1.2587 - val_mse: 1.2495\n",
      "Epoch 225/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4323 - mse: 1.4230 - val_loss: 1.2646 - val_mse: 1.2553\n",
      "Epoch 226/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4271 - mse: 1.4178 - val_loss: 1.2635 - val_mse: 1.2543\n",
      "Epoch 227/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4495 - mse: 1.4403 - val_loss: 1.2790 - val_mse: 1.2697\n",
      "Epoch 228/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4391 - mse: 1.4298 - val_loss: 1.2804 - val_mse: 1.2712\n",
      "Epoch 229/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4357 - mse: 1.4265 - val_loss: 1.3102 - val_mse: 1.3010\n",
      "Epoch 230/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 1.4440 - mse: 1.4348\n",
      "Epoch 00230: saving model to Regression_Model/mle.linear-0230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4421 - mse: 1.4329 - val_loss: 1.2960 - val_mse: 1.2868\n",
      "Epoch 231/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4346 - mse: 1.4254 - val_loss: 1.2602 - val_mse: 1.2509\n",
      "Epoch 232/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4180 - mse: 1.4087 - val_loss: 1.2549 - val_mse: 1.2457\n",
      "Epoch 233/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4373 - mse: 1.4281 - val_loss: 1.2949 - val_mse: 1.2857\n",
      "Epoch 234/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4485 - mse: 1.4392 - val_loss: 1.3124 - val_mse: 1.3032\n",
      "Epoch 235/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4335 - mse: 1.4243 - val_loss: 1.2752 - val_mse: 1.2660\n",
      "Epoch 236/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4240 - mse: 1.4148 - val_loss: 1.2810 - val_mse: 1.2718\n",
      "Epoch 237/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4426 - mse: 1.4334 - val_loss: 1.2806 - val_mse: 1.2715\n",
      "Epoch 238/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4350 - mse: 1.4258 - val_loss: 1.2891 - val_mse: 1.2799\n",
      "Epoch 239/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4489 - mse: 1.4398 - val_loss: 1.3336 - val_mse: 1.3245\n",
      "Epoch 240/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 1.4329 - mse: 1.4237\n",
      "Epoch 00240: saving model to Regression_Model/mle.linear-0240.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4215 - mse: 1.4124 - val_loss: 1.2724 - val_mse: 1.2633\n",
      "Epoch 241/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4286 - mse: 1.4195 - val_loss: 1.3034 - val_mse: 1.2942\n",
      "Epoch 242/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4167 - mse: 1.4075 - val_loss: 1.2653 - val_mse: 1.2562\n",
      "Epoch 243/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4263 - mse: 1.4172 - val_loss: 1.2574 - val_mse: 1.2483\n",
      "Epoch 244/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4461 - mse: 1.4370 - val_loss: 1.3063 - val_mse: 1.2972\n",
      "Epoch 245/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4433 - mse: 1.4341 - val_loss: 1.2656 - val_mse: 1.2564\n",
      "Epoch 246/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4158 - mse: 1.4066 - val_loss: 1.2864 - val_mse: 1.2772\n",
      "Epoch 247/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4155 - mse: 1.4063 - val_loss: 1.2695 - val_mse: 1.2603\n",
      "Epoch 248/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4377 - mse: 1.4285 - val_loss: 1.2694 - val_mse: 1.2603\n",
      "Epoch 249/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4145 - mse: 1.4054 - val_loss: 1.2777 - val_mse: 1.2686\n",
      "Epoch 250/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.4368 - mse: 1.4276\n",
      "Epoch 00250: saving model to Regression_Model/mle.linear-0250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4406 - mse: 1.4315 - val_loss: 1.3088 - val_mse: 1.2997\n",
      "Epoch 251/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4315 - mse: 1.4224 - val_loss: 1.2663 - val_mse: 1.2572\n",
      "Epoch 252/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4552 - mse: 1.4461 - val_loss: 1.3040 - val_mse: 1.2949\n",
      "Epoch 253/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4572 - mse: 1.4480 - val_loss: 1.3172 - val_mse: 1.3081\n",
      "Epoch 254/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4460 - mse: 1.4368 - val_loss: 1.2809 - val_mse: 1.2718\n",
      "Epoch 255/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4289 - mse: 1.4198 - val_loss: 1.3110 - val_mse: 1.3019\n",
      "Epoch 256/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4468 - mse: 1.4377 - val_loss: 1.2689 - val_mse: 1.2597\n",
      "Epoch 257/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4346 - mse: 1.4255 - val_loss: 1.2732 - val_mse: 1.2641\n",
      "Epoch 258/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4402 - mse: 1.4311 - val_loss: 1.3258 - val_mse: 1.3167\n",
      "Epoch 259/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4335 - mse: 1.4243 - val_loss: 1.2692 - val_mse: 1.2601\n",
      "Epoch 260/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.4402 - mse: 1.4310\n",
      "Epoch 00260: saving model to Regression_Model/mle.linear-0260.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4353 - mse: 1.4262 - val_loss: 1.2872 - val_mse: 1.2781\n",
      "Epoch 261/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4388 - mse: 1.4297 - val_loss: 1.3046 - val_mse: 1.2955\n",
      "Epoch 262/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4232 - mse: 1.4141 - val_loss: 1.2595 - val_mse: 1.2503\n",
      "Epoch 263/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4415 - mse: 1.4324 - val_loss: 1.2802 - val_mse: 1.2711\n",
      "Epoch 264/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4195 - mse: 1.4104 - val_loss: 1.2679 - val_mse: 1.2588\n",
      "Epoch 265/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4296 - mse: 1.4205 - val_loss: 1.2803 - val_mse: 1.2712\n",
      "Epoch 266/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4465 - mse: 1.4374 - val_loss: 1.2661 - val_mse: 1.2570\n",
      "Epoch 267/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4216 - mse: 1.4125 - val_loss: 1.2875 - val_mse: 1.2784\n",
      "Epoch 268/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4526 - mse: 1.4435 - val_loss: 1.2688 - val_mse: 1.2597\n",
      "Epoch 269/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4388 - mse: 1.4298 - val_loss: 1.2740 - val_mse: 1.2649\n",
      "Epoch 270/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.4167 - mse: 1.4076\n",
      "Epoch 00270: saving model to Regression_Model/mle.linear-0270.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4228 - mse: 1.4137 - val_loss: 1.2754 - val_mse: 1.2664\n",
      "Epoch 271/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4410 - mse: 1.4320 - val_loss: 1.2820 - val_mse: 1.2729\n",
      "Epoch 272/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4224 - mse: 1.4133 - val_loss: 1.2760 - val_mse: 1.2669\n",
      "Epoch 273/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4353 - mse: 1.4262 - val_loss: 1.3172 - val_mse: 1.3081\n",
      "Epoch 274/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4287 - mse: 1.4196 - val_loss: 1.2821 - val_mse: 1.2730\n",
      "Epoch 275/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4325 - mse: 1.4234 - val_loss: 1.2746 - val_mse: 1.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4312 - mse: 1.4221 - val_loss: 1.2695 - val_mse: 1.2604\n",
      "Epoch 277/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4449 - mse: 1.4358 - val_loss: 1.2630 - val_mse: 1.2539\n",
      "Epoch 278/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4214 - mse: 1.4123 - val_loss: 1.2714 - val_mse: 1.2623\n",
      "Epoch 279/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4199 - mse: 1.4109 - val_loss: 1.2600 - val_mse: 1.2509\n",
      "Epoch 280/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.4441 - mse: 1.4350\n",
      "Epoch 00280: saving model to Regression_Model/mle.linear-0280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4411 - mse: 1.4321 - val_loss: 1.2616 - val_mse: 1.2525\n",
      "Epoch 281/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4296 - mse: 1.4206 - val_loss: 1.2605 - val_mse: 1.2515\n",
      "Epoch 282/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4416 - mse: 1.4326 - val_loss: 1.2662 - val_mse: 1.2572\n",
      "Epoch 283/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4284 - mse: 1.4194 - val_loss: 1.3441 - val_mse: 1.3351\n",
      "Epoch 284/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4612 - mse: 1.4522 - val_loss: 1.2581 - val_mse: 1.2490\n",
      "Epoch 285/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4266 - mse: 1.4176 - val_loss: 1.2854 - val_mse: 1.2763\n",
      "Epoch 286/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4482 - mse: 1.4392 - val_loss: 1.2616 - val_mse: 1.2526\n",
      "Epoch 287/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4316 - mse: 1.4226 - val_loss: 1.2857 - val_mse: 1.2766\n",
      "Epoch 288/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4558 - mse: 1.4467 - val_loss: 1.2811 - val_mse: 1.2721\n",
      "Epoch 289/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4138 - mse: 1.4048 - val_loss: 1.2717 - val_mse: 1.2626\n",
      "Epoch 290/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.4252 - mse: 1.4161\n",
      "Epoch 00290: saving model to Regression_Model/mle.linear-0290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4239 - mse: 1.4149 - val_loss: 1.2629 - val_mse: 1.2539\n",
      "Epoch 291/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4227 - mse: 1.4137 - val_loss: 1.2782 - val_mse: 1.2692\n",
      "Epoch 292/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4254 - mse: 1.4164 - val_loss: 1.2945 - val_mse: 1.2855\n",
      "Epoch 293/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4314 - mse: 1.4224 - val_loss: 1.2754 - val_mse: 1.2664\n",
      "Epoch 294/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4516 - mse: 1.4426 - val_loss: 1.2923 - val_mse: 1.2833\n",
      "Epoch 295/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4368 - mse: 1.4278 - val_loss: 1.2938 - val_mse: 1.2849\n",
      "Epoch 296/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4223 - mse: 1.4133 - val_loss: 1.3121 - val_mse: 1.3031\n",
      "Epoch 297/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4418 - mse: 1.4328 - val_loss: 1.4153 - val_mse: 1.4064\n",
      "Epoch 298/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4260 - mse: 1.4170 - val_loss: 1.2887 - val_mse: 1.2797\n",
      "Epoch 299/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4260 - mse: 1.4170 - val_loss: 1.2694 - val_mse: 1.2604\n",
      "Epoch 300/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.4289 - mse: 1.4199\n",
      "Epoch 00300: saving model to Regression_Model/mle.linear-0300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4291 - mse: 1.4201 - val_loss: 1.2720 - val_mse: 1.2631\n",
      "Epoch 301/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4258 - mse: 1.4168 - val_loss: 1.2772 - val_mse: 1.2682\n",
      "Epoch 302/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4211 - mse: 1.4122 - val_loss: 1.2596 - val_mse: 1.2507\n",
      "Epoch 303/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4329 - mse: 1.4239 - val_loss: 1.2588 - val_mse: 1.2498\n",
      "Epoch 304/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4154 - mse: 1.4065 - val_loss: 1.3003 - val_mse: 1.2913\n",
      "Epoch 305/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4309 - mse: 1.4220 - val_loss: 1.3132 - val_mse: 1.3043\n",
      "Epoch 306/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4194 - mse: 1.4105 - val_loss: 1.2642 - val_mse: 1.2553\n",
      "Epoch 307/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4207 - mse: 1.4117 - val_loss: 1.2647 - val_mse: 1.2558\n",
      "Epoch 308/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4196 - mse: 1.4106 - val_loss: 1.2672 - val_mse: 1.2582\n",
      "Epoch 309/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4335 - mse: 1.4245 - val_loss: 1.2902 - val_mse: 1.2813\n",
      "Epoch 310/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.4223 - mse: 1.4134\n",
      "Epoch 00310: saving model to Regression_Model/mle.linear-0310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4233 - mse: 1.4144 - val_loss: 1.2766 - val_mse: 1.2676\n",
      "Epoch 311/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4113 - mse: 1.4023 - val_loss: 1.2703 - val_mse: 1.2614\n",
      "Epoch 312/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4249 - mse: 1.4160 - val_loss: 1.2657 - val_mse: 1.2568\n",
      "Epoch 313/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4340 - mse: 1.4251 - val_loss: 1.3106 - val_mse: 1.3017\n",
      "Epoch 314/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4379 - mse: 1.4290 - val_loss: 1.2873 - val_mse: 1.2784\n",
      "Epoch 315/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4223 - mse: 1.4134 - val_loss: 1.3136 - val_mse: 1.3047\n",
      "Epoch 316/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4203 - mse: 1.4114 - val_loss: 1.2712 - val_mse: 1.2622\n",
      "Epoch 317/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4231 - mse: 1.4142 - val_loss: 1.2573 - val_mse: 1.2484\n",
      "Epoch 318/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4143 - mse: 1.4054 - val_loss: 1.2667 - val_mse: 1.2578\n",
      "Epoch 319/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4165 - mse: 1.4076 - val_loss: 1.2625 - val_mse: 1.2536\n",
      "Epoch 320/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.4180 - mse: 1.4091\n",
      "Epoch 00320: saving model to Regression_Model/mle.linear-0320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4134 - mse: 1.4045 - val_loss: 1.2876 - val_mse: 1.2787\n",
      "Epoch 321/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4266 - mse: 1.4177 - val_loss: 1.2592 - val_mse: 1.2503\n",
      "Epoch 322/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4220 - mse: 1.4131 - val_loss: 1.2747 - val_mse: 1.2658\n",
      "Epoch 323/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4308 - mse: 1.4219 - val_loss: 1.3259 - val_mse: 1.3170\n",
      "Epoch 324/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4298 - mse: 1.4209 - val_loss: 1.2657 - val_mse: 1.2568\n",
      "Epoch 325/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4374 - mse: 1.4285 - val_loss: 1.2724 - val_mse: 1.2635\n",
      "Epoch 326/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4183 - mse: 1.4095 - val_loss: 1.2863 - val_mse: 1.2775\n",
      "Epoch 327/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4245 - mse: 1.4156 - val_loss: 1.2819 - val_mse: 1.2730\n",
      "Epoch 328/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4118 - mse: 1.4029 - val_loss: 1.2532 - val_mse: 1.2443\n",
      "Epoch 329/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4253 - mse: 1.4164 - val_loss: 1.2975 - val_mse: 1.2886\n",
      "Epoch 330/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.4266 - mse: 1.4177\n",
      "Epoch 00330: saving model to Regression_Model/mle.linear-0330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4274 - mse: 1.4185 - val_loss: 1.2749 - val_mse: 1.2660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4134 - mse: 1.4045 - val_loss: 1.2569 - val_mse: 1.2481\n",
      "Epoch 332/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4208 - mse: 1.4119 - val_loss: 1.2968 - val_mse: 1.2880\n",
      "Epoch 333/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4266 - mse: 1.4178 - val_loss: 1.2650 - val_mse: 1.2562\n",
      "Epoch 334/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4254 - mse: 1.4166 - val_loss: 1.2660 - val_mse: 1.2571\n",
      "Epoch 335/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4175 - mse: 1.4086 - val_loss: 1.2645 - val_mse: 1.2556\n",
      "Epoch 336/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4253 - mse: 1.4165 - val_loss: 1.2593 - val_mse: 1.2504\n",
      "Epoch 337/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4389 - mse: 1.4300 - val_loss: 1.2639 - val_mse: 1.2551\n",
      "Epoch 338/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4160 - mse: 1.4071 - val_loss: 1.2594 - val_mse: 1.2505\n",
      "Epoch 339/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4283 - mse: 1.4194 - val_loss: 1.2678 - val_mse: 1.2590\n",
      "Epoch 340/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.4124 - mse: 1.4035\n",
      "Epoch 00340: saving model to Regression_Model/mle.linear-0340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4061 - mse: 1.3972 - val_loss: 1.2642 - val_mse: 1.2553\n",
      "Epoch 341/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4134 - mse: 1.4045 - val_loss: 1.2739 - val_mse: 1.2651\n",
      "Epoch 342/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4028 - mse: 1.3940 - val_loss: 1.2563 - val_mse: 1.2475\n",
      "Epoch 343/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4143 - mse: 1.4055 - val_loss: 1.2640 - val_mse: 1.2552\n",
      "Epoch 344/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4200 - mse: 1.4112 - val_loss: 1.2602 - val_mse: 1.2514\n",
      "Epoch 345/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4119 - mse: 1.4031 - val_loss: 1.2553 - val_mse: 1.2465\n",
      "Epoch 346/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4366 - mse: 1.4277 - val_loss: 1.2696 - val_mse: 1.2608\n",
      "Epoch 347/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4343 - mse: 1.4255 - val_loss: 1.2599 - val_mse: 1.2510\n",
      "Epoch 348/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4162 - mse: 1.4074 - val_loss: 1.2800 - val_mse: 1.2711\n",
      "Epoch 349/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4078 - mse: 1.3990 - val_loss: 1.2695 - val_mse: 1.2606\n",
      "Epoch 350/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.4028 - mse: 1.3939\n",
      "Epoch 00350: saving model to Regression_Model/mle.linear-0350.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 1.4019 - mse: 1.3931 - val_loss: 1.2889 - val_mse: 1.2801\n",
      "Epoch 351/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4078 - mse: 1.3990 - val_loss: 1.2584 - val_mse: 1.2496\n",
      "Epoch 352/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4374 - mse: 1.4286 - val_loss: 1.2515 - val_mse: 1.2427\n",
      "Epoch 353/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4149 - mse: 1.4061 - val_loss: 1.2703 - val_mse: 1.2615\n",
      "Epoch 354/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4345 - mse: 1.4257 - val_loss: 1.2714 - val_mse: 1.2626\n",
      "Epoch 355/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4243 - mse: 1.4154 - val_loss: 1.2575 - val_mse: 1.2487\n",
      "Epoch 356/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4182 - mse: 1.4094 - val_loss: 1.2881 - val_mse: 1.2793\n",
      "Epoch 357/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4366 - mse: 1.4278 - val_loss: 1.3283 - val_mse: 1.3195\n",
      "Epoch 358/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4054 - mse: 1.3966 - val_loss: 1.2601 - val_mse: 1.2513\n",
      "Epoch 359/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4210 - mse: 1.4122 - val_loss: 1.2583 - val_mse: 1.2495\n",
      "Epoch 360/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.4251 - mse: 1.4163\n",
      "Epoch 00360: saving model to Regression_Model/mle.linear-0360.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 1.4253 - mse: 1.4165 - val_loss: 1.2555 - val_mse: 1.2467\n",
      "Epoch 361/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3992 - mse: 1.3904 - val_loss: 1.2646 - val_mse: 1.2558\n",
      "Epoch 362/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4092 - mse: 1.4004 - val_loss: 1.2514 - val_mse: 1.2426\n",
      "Epoch 363/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4301 - mse: 1.4213 - val_loss: 1.2891 - val_mse: 1.2803\n",
      "Epoch 364/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4143 - mse: 1.4056 - val_loss: 1.2585 - val_mse: 1.2497\n",
      "Epoch 365/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4273 - mse: 1.4185 - val_loss: 1.2617 - val_mse: 1.2529\n",
      "Epoch 366/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4105 - mse: 1.4017 - val_loss: 1.2695 - val_mse: 1.2607\n",
      "Epoch 367/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4320 - mse: 1.4233 - val_loss: 1.2827 - val_mse: 1.2739\n",
      "Epoch 368/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4195 - mse: 1.4107 - val_loss: 1.2510 - val_mse: 1.2422\n",
      "Epoch 369/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4026 - mse: 1.3938 - val_loss: 1.2626 - val_mse: 1.2539\n",
      "Epoch 370/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.4103 - mse: 1.4016\n",
      "Epoch 00370: saving model to Regression_Model/mle.linear-0370.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4099 - mse: 1.4011 - val_loss: 1.2707 - val_mse: 1.2619\n",
      "Epoch 371/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4139 - mse: 1.4051 - val_loss: 1.2623 - val_mse: 1.2535\n",
      "Epoch 372/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4217 - mse: 1.4129 - val_loss: 1.2917 - val_mse: 1.2829\n",
      "Epoch 373/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3950 - mse: 1.3862 - val_loss: 1.2660 - val_mse: 1.2573\n",
      "Epoch 374/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4203 - mse: 1.4115 - val_loss: 1.2577 - val_mse: 1.2489\n",
      "Epoch 375/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4206 - mse: 1.4118 - val_loss: 1.2517 - val_mse: 1.2429\n",
      "Epoch 376/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4284 - mse: 1.4196 - val_loss: 1.2917 - val_mse: 1.2829\n",
      "Epoch 377/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4173 - mse: 1.4085 - val_loss: 1.3059 - val_mse: 1.2972\n",
      "Epoch 378/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4075 - mse: 1.3988 - val_loss: 1.2736 - val_mse: 1.2649\n",
      "Epoch 379/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4070 - mse: 1.3983 - val_loss: 1.2788 - val_mse: 1.2700\n",
      "Epoch 380/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 1.4030 - mse: 1.3942\n",
      "Epoch 00380: saving model to Regression_Model/mle.linear-0380.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4020 - mse: 1.3933 - val_loss: 1.2666 - val_mse: 1.2579\n",
      "Epoch 381/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4155 - mse: 1.4068 - val_loss: 1.2881 - val_mse: 1.2793\n",
      "Epoch 382/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4177 - mse: 1.4089 - val_loss: 1.3168 - val_mse: 1.3080\n",
      "Epoch 383/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4303 - mse: 1.4216 - val_loss: 1.2904 - val_mse: 1.2817\n",
      "Epoch 384/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4071 - mse: 1.3984 - val_loss: 1.2896 - val_mse: 1.2809\n",
      "Epoch 385/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4104 - mse: 1.4017 - val_loss: 1.2526 - val_mse: 1.2439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4160 - mse: 1.4072 - val_loss: 1.2567 - val_mse: 1.2479\n",
      "Epoch 387/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4103 - mse: 1.4016 - val_loss: 1.2613 - val_mse: 1.2526\n",
      "Epoch 388/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4152 - mse: 1.4065 - val_loss: 1.2451 - val_mse: 1.2363\n",
      "Epoch 389/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4187 - mse: 1.4100 - val_loss: 1.2670 - val_mse: 1.2583\n",
      "Epoch 390/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.4012 - mse: 1.3925\n",
      "Epoch 00390: saving model to Regression_Model/mle.linear-0390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4108 - mse: 1.4021 - val_loss: 1.2488 - val_mse: 1.2401\n",
      "Epoch 391/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4127 - mse: 1.4039 - val_loss: 1.2572 - val_mse: 1.2485\n",
      "Epoch 392/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4029 - mse: 1.3942 - val_loss: 1.2587 - val_mse: 1.2499\n",
      "Epoch 393/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4078 - mse: 1.3991 - val_loss: 1.2978 - val_mse: 1.2891\n",
      "Epoch 394/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4173 - mse: 1.4086 - val_loss: 1.2598 - val_mse: 1.2511\n",
      "Epoch 395/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4194 - mse: 1.4107 - val_loss: 1.2623 - val_mse: 1.2536\n",
      "Epoch 396/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4148 - mse: 1.4061 - val_loss: 1.2912 - val_mse: 1.2825\n",
      "Epoch 397/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4072 - mse: 1.3985 - val_loss: 1.2476 - val_mse: 1.2389\n",
      "Epoch 398/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4077 - mse: 1.3990 - val_loss: 1.2768 - val_mse: 1.2681\n",
      "Epoch 399/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4029 - mse: 1.3942 - val_loss: 1.2529 - val_mse: 1.2441\n",
      "Epoch 400/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 1.4167 - mse: 1.4080\n",
      "Epoch 00400: saving model to Regression_Model/mle.linear-0400.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4204 - mse: 1.4117 - val_loss: 1.2661 - val_mse: 1.2574\n",
      "Epoch 401/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4162 - mse: 1.4075 - val_loss: 1.2791 - val_mse: 1.2704\n",
      "Epoch 402/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4145 - mse: 1.4058 - val_loss: 1.2996 - val_mse: 1.2909\n",
      "Epoch 403/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4309 - mse: 1.4222 - val_loss: 1.3097 - val_mse: 1.3010\n",
      "Epoch 404/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4258 - mse: 1.4171 - val_loss: 1.2667 - val_mse: 1.2580\n",
      "Epoch 405/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4210 - mse: 1.4123 - val_loss: 1.2672 - val_mse: 1.2585\n",
      "Epoch 406/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4231 - mse: 1.4144 - val_loss: 1.2572 - val_mse: 1.2485\n",
      "Epoch 407/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4147 - mse: 1.4060 - val_loss: 1.2495 - val_mse: 1.2408\n",
      "Epoch 408/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4275 - mse: 1.4188 - val_loss: 1.2862 - val_mse: 1.2775\n",
      "Epoch 409/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4140 - mse: 1.4054 - val_loss: 1.2726 - val_mse: 1.2639\n",
      "Epoch 410/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.4069 - mse: 1.3983\n",
      "Epoch 00410: saving model to Regression_Model/mle.linear-0410.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4106 - mse: 1.4019 - val_loss: 1.2709 - val_mse: 1.2622\n",
      "Epoch 411/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4175 - mse: 1.4088 - val_loss: 1.2571 - val_mse: 1.2484\n",
      "Epoch 412/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4143 - mse: 1.4057 - val_loss: 1.2760 - val_mse: 1.2674\n",
      "Epoch 413/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4212 - mse: 1.4126 - val_loss: 1.2477 - val_mse: 1.2390\n",
      "Epoch 414/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4108 - mse: 1.4022 - val_loss: 1.2585 - val_mse: 1.2498\n",
      "Epoch 415/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4126 - mse: 1.4040 - val_loss: 1.2632 - val_mse: 1.2545\n",
      "Epoch 416/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4064 - mse: 1.3978 - val_loss: 1.2644 - val_mse: 1.2558\n",
      "Epoch 417/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4090 - mse: 1.4004 - val_loss: 1.2759 - val_mse: 1.2672\n",
      "Epoch 418/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3972 - mse: 1.3886 - val_loss: 1.2935 - val_mse: 1.2848\n",
      "Epoch 419/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4292 - mse: 1.4205 - val_loss: 1.2437 - val_mse: 1.2350\n",
      "Epoch 420/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 1.4170 - mse: 1.4084\n",
      "Epoch 00420: saving model to Regression_Model/mle.linear-0420.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4145 - mse: 1.4059 - val_loss: 1.2552 - val_mse: 1.2466\n",
      "Epoch 421/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4078 - mse: 1.3992 - val_loss: 1.2523 - val_mse: 1.2437\n",
      "Epoch 422/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4234 - mse: 1.4148 - val_loss: 1.2976 - val_mse: 1.2890\n",
      "Epoch 423/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4175 - mse: 1.4088 - val_loss: 1.2883 - val_mse: 1.2797\n",
      "Epoch 424/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4188 - mse: 1.4102 - val_loss: 1.2755 - val_mse: 1.2669\n",
      "Epoch 425/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4209 - mse: 1.4123 - val_loss: 1.2932 - val_mse: 1.2846\n",
      "Epoch 426/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4049 - mse: 1.3962 - val_loss: 1.2792 - val_mse: 1.2706\n",
      "Epoch 427/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4031 - mse: 1.3945 - val_loss: 1.2652 - val_mse: 1.2566\n",
      "Epoch 428/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4042 - mse: 1.3955 - val_loss: 1.2540 - val_mse: 1.2454\n",
      "Epoch 429/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4128 - mse: 1.4042 - val_loss: 1.2477 - val_mse: 1.2391\n",
      "Epoch 430/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.4268 - mse: 1.4182\n",
      "Epoch 00430: saving model to Regression_Model/mle.linear-0430.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4235 - mse: 1.4149 - val_loss: 1.2510 - val_mse: 1.2424\n",
      "Epoch 431/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4087 - mse: 1.4001 - val_loss: 1.2676 - val_mse: 1.2590\n",
      "Epoch 432/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4029 - mse: 1.3943 - val_loss: 1.2615 - val_mse: 1.2529\n",
      "Epoch 433/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3971 - mse: 1.3885 - val_loss: 1.2621 - val_mse: 1.2535\n",
      "Epoch 434/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4099 - mse: 1.4013 - val_loss: 1.2537 - val_mse: 1.2451\n",
      "Epoch 435/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4144 - mse: 1.4058 - val_loss: 1.2638 - val_mse: 1.2552\n",
      "Epoch 436/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4098 - mse: 1.4012 - val_loss: 1.2808 - val_mse: 1.2722\n",
      "Epoch 437/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4065 - mse: 1.3979 - val_loss: 1.2622 - val_mse: 1.2536\n",
      "Epoch 438/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4324 - mse: 1.4238 - val_loss: 1.2804 - val_mse: 1.2718\n",
      "Epoch 439/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4156 - mse: 1.4070 - val_loss: 1.2473 - val_mse: 1.2387\n",
      "Epoch 440/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.3954 - mse: 1.3868\n",
      "Epoch 00440: saving model to Regression_Model/mle.linear-0440.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3933 - mse: 1.3847 - val_loss: 1.2603 - val_mse: 1.2518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4164 - mse: 1.4078 - val_loss: 1.2541 - val_mse: 1.2455\n",
      "Epoch 442/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4206 - mse: 1.4120 - val_loss: 1.2625 - val_mse: 1.2539\n",
      "Epoch 443/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3955 - mse: 1.3869 - val_loss: 1.2506 - val_mse: 1.2421\n",
      "Epoch 444/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4270 - mse: 1.4184 - val_loss: 1.2634 - val_mse: 1.2549\n",
      "Epoch 445/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4100 - mse: 1.4014 - val_loss: 1.2450 - val_mse: 1.2364\n",
      "Epoch 446/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4127 - mse: 1.4042 - val_loss: 1.2529 - val_mse: 1.2443\n",
      "Epoch 447/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4148 - mse: 1.4062 - val_loss: 1.2483 - val_mse: 1.2397\n",
      "Epoch 448/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4081 - mse: 1.3995 - val_loss: 1.2604 - val_mse: 1.2519\n",
      "Epoch 449/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3947 - mse: 1.3861 - val_loss: 1.2693 - val_mse: 1.2607\n",
      "Epoch 450/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 1.4115 - mse: 1.4029\n",
      "Epoch 00450: saving model to Regression_Model/mle.linear-0450.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4048 - mse: 1.3962 - val_loss: 1.2590 - val_mse: 1.2504\n",
      "Epoch 451/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4164 - mse: 1.4079 - val_loss: 1.2619 - val_mse: 1.2534\n",
      "Epoch 452/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4125 - mse: 1.4039 - val_loss: 1.2576 - val_mse: 1.2490\n",
      "Epoch 453/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4340 - mse: 1.4254 - val_loss: 1.2519 - val_mse: 1.2433\n",
      "Epoch 454/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3995 - mse: 1.3909 - val_loss: 1.2726 - val_mse: 1.2640\n",
      "Epoch 455/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4060 - mse: 1.3974 - val_loss: 1.2540 - val_mse: 1.2455\n",
      "Epoch 456/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4175 - mse: 1.4089 - val_loss: 1.2559 - val_mse: 1.2474\n",
      "Epoch 457/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4112 - mse: 1.4027 - val_loss: 1.2665 - val_mse: 1.2580\n",
      "Epoch 458/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4020 - mse: 1.3935 - val_loss: 1.2876 - val_mse: 1.2791\n",
      "Epoch 459/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4130 - mse: 1.4045 - val_loss: 1.2514 - val_mse: 1.2428\n",
      "Epoch 460/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 1.3835 - mse: 1.3749\n",
      "Epoch 00460: saving model to Regression_Model/mle.linear-0460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3856 - mse: 1.3770 - val_loss: 1.2632 - val_mse: 1.2546\n",
      "Epoch 461/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4064 - mse: 1.3979 - val_loss: 1.2459 - val_mse: 1.2373\n",
      "Epoch 462/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4257 - mse: 1.4172 - val_loss: 1.2701 - val_mse: 1.2616\n",
      "Epoch 463/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4035 - mse: 1.3949 - val_loss: 1.2436 - val_mse: 1.2351\n",
      "Epoch 464/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4018 - mse: 1.3933 - val_loss: 1.2548 - val_mse: 1.2462\n",
      "Epoch 465/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4138 - mse: 1.4052 - val_loss: 1.2572 - val_mse: 1.2487\n",
      "Epoch 466/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4010 - mse: 1.3924 - val_loss: 1.2621 - val_mse: 1.2535\n",
      "Epoch 467/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4005 - mse: 1.3919 - val_loss: 1.2486 - val_mse: 1.2400\n",
      "Epoch 468/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4001 - mse: 1.3916 - val_loss: 1.2512 - val_mse: 1.2427\n",
      "Epoch 469/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3973 - mse: 1.3887 - val_loss: 1.2454 - val_mse: 1.2368\n",
      "Epoch 470/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.4174 - mse: 1.4088\n",
      "Epoch 00470: saving model to Regression_Model/mle.linear-0470.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4106 - mse: 1.4021 - val_loss: 1.2474 - val_mse: 1.2389\n",
      "Epoch 471/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3985 - mse: 1.3900 - val_loss: 1.2483 - val_mse: 1.2397\n",
      "Epoch 472/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4007 - mse: 1.3921 - val_loss: 1.2463 - val_mse: 1.2378\n",
      "Epoch 473/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3999 - mse: 1.3914 - val_loss: 1.2549 - val_mse: 1.2463\n",
      "Epoch 474/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4230 - mse: 1.4145 - val_loss: 1.2499 - val_mse: 1.2413\n",
      "Epoch 475/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4096 - mse: 1.4011 - val_loss: 1.2585 - val_mse: 1.2499\n",
      "Epoch 476/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4169 - mse: 1.4083 - val_loss: 1.2460 - val_mse: 1.2374\n",
      "Epoch 477/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4252 - mse: 1.4166 - val_loss: 1.2477 - val_mse: 1.2392\n",
      "Epoch 478/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3956 - mse: 1.3871 - val_loss: 1.2398 - val_mse: 1.2312\n",
      "Epoch 479/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4050 - mse: 1.3964 - val_loss: 1.2508 - val_mse: 1.2423\n",
      "Epoch 480/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.4099 - mse: 1.4014\n",
      "Epoch 00480: saving model to Regression_Model/mle.linear-0480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4049 - mse: 1.3963 - val_loss: 1.2558 - val_mse: 1.2472\n",
      "Epoch 481/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4074 - mse: 1.3989 - val_loss: 1.2634 - val_mse: 1.2549\n",
      "Epoch 482/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4240 - mse: 1.4154 - val_loss: 1.2673 - val_mse: 1.2588\n",
      "Epoch 483/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3993 - mse: 1.3907 - val_loss: 1.2569 - val_mse: 1.2483\n",
      "Epoch 484/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4081 - mse: 1.3995 - val_loss: 1.2526 - val_mse: 1.2440\n",
      "Epoch 485/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4176 - mse: 1.4091 - val_loss: 1.2560 - val_mse: 1.2474\n",
      "Epoch 486/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4087 - mse: 1.4001 - val_loss: 1.2489 - val_mse: 1.2404\n",
      "Epoch 487/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3877 - mse: 1.3791 - val_loss: 1.2557 - val_mse: 1.2472\n",
      "Epoch 488/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3914 - mse: 1.3829 - val_loss: 1.2490 - val_mse: 1.2404\n",
      "Epoch 489/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3798 - mse: 1.3712 - val_loss: 1.2433 - val_mse: 1.2347\n",
      "Epoch 490/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.3966 - mse: 1.3881\n",
      "Epoch 00490: saving model to Regression_Model/mle.linear-0490.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3927 - mse: 1.3841 - val_loss: 1.2487 - val_mse: 1.2401\n",
      "Epoch 491/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4103 - mse: 1.4017 - val_loss: 1.2624 - val_mse: 1.2539\n",
      "Epoch 492/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3966 - mse: 1.3880 - val_loss: 1.2446 - val_mse: 1.2361\n",
      "Epoch 493/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4106 - mse: 1.4020 - val_loss: 1.2592 - val_mse: 1.2506\n",
      "Epoch 494/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3924 - mse: 1.3838 - val_loss: 1.2566 - val_mse: 1.2481\n",
      "Epoch 495/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4095 - mse: 1.4010 - val_loss: 1.2868 - val_mse: 1.2783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4039 - mse: 1.3954 - val_loss: 1.2394 - val_mse: 1.2309\n",
      "Epoch 497/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3932 - mse: 1.3846 - val_loss: 1.2884 - val_mse: 1.2799\n",
      "Epoch 498/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4124 - mse: 1.4039 - val_loss: 1.2534 - val_mse: 1.2448\n",
      "Epoch 499/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4003 - mse: 1.3918 - val_loss: 1.2536 - val_mse: 1.2450\n",
      "Epoch 500/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 1.4026 - mse: 1.3941\n",
      "Epoch 00500: saving model to Regression_Model/mle.linear-0500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4039 - mse: 1.3953 - val_loss: 1.2696 - val_mse: 1.2610\n",
      "Epoch 501/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4264 - mse: 1.4178 - val_loss: 1.2777 - val_mse: 1.2692\n",
      "Epoch 502/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4067 - mse: 1.3982 - val_loss: 1.2528 - val_mse: 1.2443\n",
      "Epoch 503/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4049 - mse: 1.3964 - val_loss: 1.2574 - val_mse: 1.2489\n",
      "Epoch 504/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4140 - mse: 1.4055 - val_loss: 1.2504 - val_mse: 1.2419\n",
      "Epoch 505/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4017 - mse: 1.3932 - val_loss: 1.2608 - val_mse: 1.2523\n",
      "Epoch 506/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4086 - mse: 1.4000 - val_loss: 1.2499 - val_mse: 1.2414\n",
      "Epoch 507/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4049 - mse: 1.3964 - val_loss: 1.2769 - val_mse: 1.2684\n",
      "Epoch 508/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4193 - mse: 1.4108 - val_loss: 1.2621 - val_mse: 1.2536\n",
      "Epoch 509/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3937 - mse: 1.3851 - val_loss: 1.2490 - val_mse: 1.2404\n",
      "Epoch 510/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.4073 - mse: 1.3988\n",
      "Epoch 00510: saving model to Regression_Model/mle.linear-0510.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4080 - mse: 1.3995 - val_loss: 1.2586 - val_mse: 1.2500\n",
      "Epoch 511/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3966 - mse: 1.3881 - val_loss: 1.2677 - val_mse: 1.2592\n",
      "Epoch 512/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3803 - mse: 1.3717 - val_loss: 1.2678 - val_mse: 1.2592\n",
      "Epoch 513/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3913 - mse: 1.3828 - val_loss: 1.2616 - val_mse: 1.2530\n",
      "Epoch 514/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4114 - mse: 1.4029 - val_loss: 1.2449 - val_mse: 1.2364\n",
      "Epoch 515/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4057 - mse: 1.3972 - val_loss: 1.2683 - val_mse: 1.2597\n",
      "Epoch 516/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4026 - mse: 1.3941 - val_loss: 1.2564 - val_mse: 1.2479\n",
      "Epoch 517/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4180 - mse: 1.4095 - val_loss: 1.2844 - val_mse: 1.2759\n",
      "Epoch 518/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4238 - mse: 1.4152 - val_loss: 1.2559 - val_mse: 1.2474\n",
      "Epoch 519/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4056 - mse: 1.3971 - val_loss: 1.2492 - val_mse: 1.2407\n",
      "Epoch 520/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.4044 - mse: 1.3959\n",
      "Epoch 00520: saving model to Regression_Model/mle.linear-0520.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4035 - mse: 1.3950 - val_loss: 1.2564 - val_mse: 1.2479\n",
      "Epoch 521/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3974 - mse: 1.3889 - val_loss: 1.2423 - val_mse: 1.2338\n",
      "Epoch 522/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3864 - mse: 1.3778 - val_loss: 1.2744 - val_mse: 1.2658\n",
      "Epoch 523/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4090 - mse: 1.4004 - val_loss: 1.2411 - val_mse: 1.2325\n",
      "Epoch 524/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4051 - mse: 1.3966 - val_loss: 1.2578 - val_mse: 1.2493\n",
      "Epoch 525/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3879 - mse: 1.3793 - val_loss: 1.2479 - val_mse: 1.2394\n",
      "Epoch 526/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4193 - mse: 1.4108 - val_loss: 1.2772 - val_mse: 1.2686\n",
      "Epoch 527/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3941 - mse: 1.3856 - val_loss: 1.2553 - val_mse: 1.2468\n",
      "Epoch 528/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3905 - mse: 1.3819 - val_loss: 1.2586 - val_mse: 1.2501\n",
      "Epoch 529/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3970 - mse: 1.3884 - val_loss: 1.2595 - val_mse: 1.2510\n",
      "Epoch 530/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3909 - mse: 1.3824\n",
      "Epoch 00530: saving model to Regression_Model/mle.linear-0530.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3934 - mse: 1.3849 - val_loss: 1.2647 - val_mse: 1.2562\n",
      "Epoch 531/3000\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3989 - mse: 1.3904 - val_loss: 1.2593 - val_mse: 1.2507\n",
      "Epoch 532/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3843 - mse: 1.3758 - val_loss: 1.2423 - val_mse: 1.2338\n",
      "Epoch 533/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3983 - mse: 1.3898 - val_loss: 1.2446 - val_mse: 1.2361\n",
      "Epoch 534/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3822 - mse: 1.3737 - val_loss: 1.2465 - val_mse: 1.2379\n",
      "Epoch 535/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4204 - mse: 1.4119 - val_loss: 1.2496 - val_mse: 1.2411\n",
      "Epoch 536/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3975 - mse: 1.3889 - val_loss: 1.2646 - val_mse: 1.2561\n",
      "Epoch 537/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4111 - mse: 1.4026 - val_loss: 1.2471 - val_mse: 1.2386\n",
      "Epoch 538/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3999 - mse: 1.3914 - val_loss: 1.2394 - val_mse: 1.2309\n",
      "Epoch 539/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3945 - mse: 1.3859 - val_loss: 1.2619 - val_mse: 1.2534\n",
      "Epoch 540/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3955 - mse: 1.3870\n",
      "Epoch 00540: saving model to Regression_Model/mle.linear-0540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4019 - mse: 1.3934 - val_loss: 1.2501 - val_mse: 1.2416\n",
      "Epoch 541/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4034 - mse: 1.3949 - val_loss: 1.2379 - val_mse: 1.2294\n",
      "Epoch 542/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3974 - mse: 1.3889 - val_loss: 1.2459 - val_mse: 1.2374\n",
      "Epoch 543/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3959 - mse: 1.3874 - val_loss: 1.2460 - val_mse: 1.2374\n",
      "Epoch 544/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4016 - mse: 1.3930 - val_loss: 1.2493 - val_mse: 1.2407\n",
      "Epoch 545/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3910 - mse: 1.3825 - val_loss: 1.2424 - val_mse: 1.2339\n",
      "Epoch 546/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3888 - mse: 1.3803 - val_loss: 1.2412 - val_mse: 1.2327\n",
      "Epoch 547/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4051 - mse: 1.3966 - val_loss: 1.2766 - val_mse: 1.2681\n",
      "Epoch 548/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4086 - mse: 1.4001 - val_loss: 1.2573 - val_mse: 1.2488\n",
      "Epoch 549/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3861 - mse: 1.3776 - val_loss: 1.2524 - val_mse: 1.2439\n",
      "Epoch 550/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.4010 - mse: 1.3925\n",
      "Epoch 00550: saving model to Regression_Model/mle.linear-0550.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4077 - mse: 1.3992 - val_loss: 1.2561 - val_mse: 1.2476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 551/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3965 - mse: 1.3880 - val_loss: 1.2576 - val_mse: 1.2491\n",
      "Epoch 552/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4145 - mse: 1.4060 - val_loss: 1.2781 - val_mse: 1.2696\n",
      "Epoch 553/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4127 - mse: 1.4042 - val_loss: 1.2432 - val_mse: 1.2347\n",
      "Epoch 554/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4004 - mse: 1.3919 - val_loss: 1.2515 - val_mse: 1.2430\n",
      "Epoch 555/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4064 - mse: 1.3979 - val_loss: 1.2601 - val_mse: 1.2516\n",
      "Epoch 556/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3972 - mse: 1.3887 - val_loss: 1.2451 - val_mse: 1.2366\n",
      "Epoch 557/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4017 - mse: 1.3932 - val_loss: 1.2513 - val_mse: 1.2428\n",
      "Epoch 558/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4001 - mse: 1.3916 - val_loss: 1.2377 - val_mse: 1.2292\n",
      "Epoch 559/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4003 - mse: 1.3918 - val_loss: 1.2712 - val_mse: 1.2627\n",
      "Epoch 560/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 1.3870 - mse: 1.3785\n",
      "Epoch 00560: saving model to Regression_Model/mle.linear-0560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3934 - mse: 1.3849 - val_loss: 1.2449 - val_mse: 1.2364\n",
      "Epoch 561/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3825 - mse: 1.3741 - val_loss: 1.2547 - val_mse: 1.2462\n",
      "Epoch 562/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4030 - mse: 1.3945 - val_loss: 1.2489 - val_mse: 1.2404\n",
      "Epoch 563/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3936 - mse: 1.3851 - val_loss: 1.2517 - val_mse: 1.2432\n",
      "Epoch 564/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4003 - mse: 1.3918 - val_loss: 1.2481 - val_mse: 1.2396\n",
      "Epoch 565/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3906 - mse: 1.3821 - val_loss: 1.2583 - val_mse: 1.2499\n",
      "Epoch 566/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3906 - mse: 1.3822 - val_loss: 1.2537 - val_mse: 1.2452\n",
      "Epoch 567/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3990 - mse: 1.3905 - val_loss: 1.2446 - val_mse: 1.2361\n",
      "Epoch 568/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4008 - mse: 1.3923 - val_loss: 1.2491 - val_mse: 1.2407\n",
      "Epoch 569/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3995 - mse: 1.3910 - val_loss: 1.2499 - val_mse: 1.2414\n",
      "Epoch 570/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3801 - mse: 1.3716\n",
      "Epoch 00570: saving model to Regression_Model/mle.linear-0570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3849 - mse: 1.3765 - val_loss: 1.2520 - val_mse: 1.2436\n",
      "Epoch 571/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3866 - mse: 1.3782 - val_loss: 1.2411 - val_mse: 1.2326\n",
      "Epoch 572/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4018 - mse: 1.3934 - val_loss: 1.2415 - val_mse: 1.2331\n",
      "Epoch 573/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3758 - mse: 1.3674 - val_loss: 1.2645 - val_mse: 1.2560\n",
      "Epoch 574/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3896 - mse: 1.3812 - val_loss: 1.2476 - val_mse: 1.2392\n",
      "Epoch 575/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4030 - mse: 1.3946 - val_loss: 1.2671 - val_mse: 1.2586\n",
      "Epoch 576/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3921 - mse: 1.3836 - val_loss: 1.2646 - val_mse: 1.2561\n",
      "Epoch 577/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3865 - mse: 1.3780 - val_loss: 1.2575 - val_mse: 1.2491\n",
      "Epoch 578/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4056 - mse: 1.3971 - val_loss: 1.2487 - val_mse: 1.2402\n",
      "Epoch 579/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3949 - mse: 1.3865 - val_loss: 1.2563 - val_mse: 1.2478\n",
      "Epoch 580/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.4038 - mse: 1.3953\n",
      "Epoch 00580: saving model to Regression_Model/mle.linear-0580.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.4045 - mse: 1.3960 - val_loss: 1.2503 - val_mse: 1.2418\n",
      "Epoch 581/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3905 - mse: 1.3820 - val_loss: 1.2551 - val_mse: 1.2466\n",
      "Epoch 582/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3960 - mse: 1.3875 - val_loss: 1.2392 - val_mse: 1.2307\n",
      "Epoch 583/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3799 - mse: 1.3714 - val_loss: 1.2607 - val_mse: 1.2523\n",
      "Epoch 584/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4005 - mse: 1.3920 - val_loss: 1.2402 - val_mse: 1.2317\n",
      "Epoch 585/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3971 - mse: 1.3886 - val_loss: 1.2480 - val_mse: 1.2395\n",
      "Epoch 586/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3969 - mse: 1.3884 - val_loss: 1.2534 - val_mse: 1.2449\n",
      "Epoch 587/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3882 - mse: 1.3797 - val_loss: 1.2434 - val_mse: 1.2350\n",
      "Epoch 588/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4064 - mse: 1.3979 - val_loss: 1.2537 - val_mse: 1.2452\n",
      "Epoch 589/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3995 - mse: 1.3911 - val_loss: 1.2483 - val_mse: 1.2398\n",
      "Epoch 590/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3944 - mse: 1.3860\n",
      "Epoch 00590: saving model to Regression_Model/mle.linear-0590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4038 - mse: 1.3953 - val_loss: 1.2409 - val_mse: 1.2325\n",
      "Epoch 591/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3998 - mse: 1.3913 - val_loss: 1.2403 - val_mse: 1.2318\n",
      "Epoch 592/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3830 - mse: 1.3745 - val_loss: 1.2565 - val_mse: 1.2480\n",
      "Epoch 593/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3967 - mse: 1.3883 - val_loss: 1.2545 - val_mse: 1.2460\n",
      "Epoch 594/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3887 - mse: 1.3803 - val_loss: 1.2372 - val_mse: 1.2287\n",
      "Epoch 595/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3803 - mse: 1.3718 - val_loss: 1.2454 - val_mse: 1.2369\n",
      "Epoch 596/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3980 - mse: 1.3895 - val_loss: 1.2466 - val_mse: 1.2381\n",
      "Epoch 597/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4050 - mse: 1.3965 - val_loss: 1.2504 - val_mse: 1.2419\n",
      "Epoch 598/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3849 - mse: 1.3764 - val_loss: 1.2483 - val_mse: 1.2399\n",
      "Epoch 599/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4019 - mse: 1.3934 - val_loss: 1.2492 - val_mse: 1.2408\n",
      "Epoch 600/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 1.3819 - mse: 1.3734\n",
      "Epoch 00600: saving model to Regression_Model/mle.linear-0600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3811 - mse: 1.3726 - val_loss: 1.2468 - val_mse: 1.2383\n",
      "Epoch 601/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3920 - mse: 1.3836 - val_loss: 1.2412 - val_mse: 1.2328\n",
      "Epoch 602/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4035 - mse: 1.3950 - val_loss: 1.2374 - val_mse: 1.2290\n",
      "Epoch 603/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3973 - mse: 1.3889 - val_loss: 1.2554 - val_mse: 1.2469\n",
      "Epoch 604/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4080 - mse: 1.3995 - val_loss: 1.2392 - val_mse: 1.2307\n",
      "Epoch 605/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4015 - mse: 1.3931 - val_loss: 1.2378 - val_mse: 1.2293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 606/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3903 - mse: 1.3819 - val_loss: 1.2381 - val_mse: 1.2296\n",
      "Epoch 607/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3931 - mse: 1.3847 - val_loss: 1.2386 - val_mse: 1.2301\n",
      "Epoch 608/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3980 - mse: 1.3895 - val_loss: 1.2548 - val_mse: 1.2463\n",
      "Epoch 609/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3901 - mse: 1.3817 - val_loss: 1.2604 - val_mse: 1.2519\n",
      "Epoch 610/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.3847 - mse: 1.3762\n",
      "Epoch 00610: saving model to Regression_Model/mle.linear-0610.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3892 - mse: 1.3808 - val_loss: 1.2481 - val_mse: 1.2396\n",
      "Epoch 611/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3779 - mse: 1.3694 - val_loss: 1.2436 - val_mse: 1.2351\n",
      "Epoch 612/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4098 - mse: 1.4013 - val_loss: 1.2572 - val_mse: 1.2487\n",
      "Epoch 613/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4037 - mse: 1.3953 - val_loss: 1.2482 - val_mse: 1.2397\n",
      "Epoch 614/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3992 - mse: 1.3908 - val_loss: 1.2583 - val_mse: 1.2499\n",
      "Epoch 615/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4116 - mse: 1.4031 - val_loss: 1.2590 - val_mse: 1.2506\n",
      "Epoch 616/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3844 - mse: 1.3760 - val_loss: 1.2561 - val_mse: 1.2477\n",
      "Epoch 617/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4023 - mse: 1.3939 - val_loss: 1.2418 - val_mse: 1.2334\n",
      "Epoch 618/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3819 - mse: 1.3734 - val_loss: 1.2398 - val_mse: 1.2314\n",
      "Epoch 619/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3788 - mse: 1.3704 - val_loss: 1.2380 - val_mse: 1.2296\n",
      "Epoch 620/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 1.3873 - mse: 1.3788\n",
      "Epoch 00620: saving model to Regression_Model/mle.linear-0620.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3840 - mse: 1.3755 - val_loss: 1.2378 - val_mse: 1.2293\n",
      "Epoch 621/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4011 - mse: 1.3926 - val_loss: 1.2393 - val_mse: 1.2308\n",
      "Epoch 622/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4056 - mse: 1.3972 - val_loss: 1.2746 - val_mse: 1.2662\n",
      "Epoch 623/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3952 - mse: 1.3868 - val_loss: 1.2688 - val_mse: 1.2603\n",
      "Epoch 624/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3948 - mse: 1.3863 - val_loss: 1.2483 - val_mse: 1.2399\n",
      "Epoch 625/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3940 - mse: 1.3855 - val_loss: 1.2462 - val_mse: 1.2378\n",
      "Epoch 626/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3884 - mse: 1.3800 - val_loss: 1.2435 - val_mse: 1.2351\n",
      "Epoch 627/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3783 - mse: 1.3698 - val_loss: 1.2549 - val_mse: 1.2465\n",
      "Epoch 628/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4085 - mse: 1.4000 - val_loss: 1.2514 - val_mse: 1.2430\n",
      "Epoch 629/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4054 - mse: 1.3969 - val_loss: 1.2527 - val_mse: 1.2443\n",
      "Epoch 630/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3762 - mse: 1.3677\n",
      "Epoch 00630: saving model to Regression_Model/mle.linear-0630.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3795 - mse: 1.3710 - val_loss: 1.2573 - val_mse: 1.2488\n",
      "Epoch 631/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3989 - mse: 1.3905 - val_loss: 1.2462 - val_mse: 1.2378\n",
      "Epoch 632/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3899 - mse: 1.3814 - val_loss: 1.2417 - val_mse: 1.2332\n",
      "Epoch 633/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3815 - mse: 1.3730 - val_loss: 1.2426 - val_mse: 1.2342\n",
      "Epoch 634/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3815 - mse: 1.3731 - val_loss: 1.2474 - val_mse: 1.2389\n",
      "Epoch 635/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3848 - mse: 1.3764 - val_loss: 1.2567 - val_mse: 1.2482\n",
      "Epoch 636/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4070 - mse: 1.3986 - val_loss: 1.2441 - val_mse: 1.2357\n",
      "Epoch 637/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4069 - mse: 1.3984 - val_loss: 1.2405 - val_mse: 1.2321\n",
      "Epoch 638/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3857 - mse: 1.3773 - val_loss: 1.2598 - val_mse: 1.2514\n",
      "Epoch 639/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3836 - mse: 1.3752 - val_loss: 1.2411 - val_mse: 1.2327\n",
      "Epoch 640/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 1.3840 - mse: 1.3755\n",
      "Epoch 00640: saving model to Regression_Model/mle.linear-0640.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3841 - mse: 1.3757 - val_loss: 1.2487 - val_mse: 1.2403\n",
      "Epoch 641/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3921 - mse: 1.3836 - val_loss: 1.2458 - val_mse: 1.2374\n",
      "Epoch 642/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3946 - mse: 1.3861 - val_loss: 1.2483 - val_mse: 1.2398\n",
      "Epoch 643/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3821 - mse: 1.3737 - val_loss: 1.2467 - val_mse: 1.2383\n",
      "Epoch 644/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3708 - mse: 1.3624 - val_loss: 1.2353 - val_mse: 1.2269\n",
      "Epoch 645/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3914 - mse: 1.3830 - val_loss: 1.2377 - val_mse: 1.2293\n",
      "Epoch 646/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3859 - mse: 1.3774 - val_loss: 1.2579 - val_mse: 1.2495\n",
      "Epoch 647/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3891 - mse: 1.3806 - val_loss: 1.2612 - val_mse: 1.2527\n",
      "Epoch 648/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4221 - mse: 1.4137 - val_loss: 1.2454 - val_mse: 1.2370\n",
      "Epoch 649/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4024 - mse: 1.3940 - val_loss: 1.2429 - val_mse: 1.2345\n",
      "Epoch 650/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 1.3741 - mse: 1.3657\n",
      "Epoch 00650: saving model to Regression_Model/mle.linear-0650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3706 - mse: 1.3621 - val_loss: 1.2530 - val_mse: 1.2446\n",
      "Epoch 651/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3896 - mse: 1.3811 - val_loss: 1.2509 - val_mse: 1.2425\n",
      "Epoch 652/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3960 - mse: 1.3876 - val_loss: 1.2443 - val_mse: 1.2359\n",
      "Epoch 653/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3794 - mse: 1.3710 - val_loss: 1.2538 - val_mse: 1.2454\n",
      "Epoch 654/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3902 - mse: 1.3818 - val_loss: 1.2386 - val_mse: 1.2301\n",
      "Epoch 655/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3753 - mse: 1.3669 - val_loss: 1.2495 - val_mse: 1.2411\n",
      "Epoch 656/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3909 - mse: 1.3825 - val_loss: 1.2497 - val_mse: 1.2413\n",
      "Epoch 657/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4011 - mse: 1.3927 - val_loss: 1.2596 - val_mse: 1.2512\n",
      "Epoch 658/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3914 - mse: 1.3829 - val_loss: 1.2433 - val_mse: 1.2349\n",
      "Epoch 659/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3914 - mse: 1.3830 - val_loss: 1.2666 - val_mse: 1.2582\n",
      "Epoch 660/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.3954 - mse: 1.3869\n",
      "Epoch 00660: saving model to Regression_Model/mle.linear-0660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3940 - mse: 1.3856 - val_loss: 1.2417 - val_mse: 1.2332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3988 - mse: 1.3904 - val_loss: 1.2434 - val_mse: 1.2350\n",
      "Epoch 662/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3714 - mse: 1.3630 - val_loss: 1.2370 - val_mse: 1.2286\n",
      "Epoch 663/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3886 - mse: 1.3802 - val_loss: 1.2402 - val_mse: 1.2318\n",
      "Epoch 664/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3784 - mse: 1.3700 - val_loss: 1.2349 - val_mse: 1.2265\n",
      "Epoch 665/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3758 - mse: 1.3674 - val_loss: 1.2402 - val_mse: 1.2318\n",
      "Epoch 666/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3848 - mse: 1.3764 - val_loss: 1.2395 - val_mse: 1.2311\n",
      "Epoch 667/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3639 - val_loss: 1.2318 - val_mse: 1.2234\n",
      "Epoch 668/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3903 - mse: 1.3819 - val_loss: 1.2483 - val_mse: 1.2399\n",
      "Epoch 669/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3867 - mse: 1.3783 - val_loss: 1.2326 - val_mse: 1.2241\n",
      "Epoch 670/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3970 - mse: 1.3886\n",
      "Epoch 00670: saving model to Regression_Model/mle.linear-0670.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4042 - mse: 1.3958 - val_loss: 1.2453 - val_mse: 1.2369\n",
      "Epoch 671/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4046 - mse: 1.3962 - val_loss: 1.2421 - val_mse: 1.2337\n",
      "Epoch 672/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3939 - mse: 1.3855 - val_loss: 1.2589 - val_mse: 1.2505\n",
      "Epoch 673/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3827 - mse: 1.3743 - val_loss: 1.2390 - val_mse: 1.2306\n",
      "Epoch 674/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3855 - mse: 1.3771 - val_loss: 1.2455 - val_mse: 1.2371\n",
      "Epoch 675/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3974 - mse: 1.3890 - val_loss: 1.2402 - val_mse: 1.2318\n",
      "Epoch 676/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3850 - mse: 1.3766 - val_loss: 1.2568 - val_mse: 1.2484\n",
      "Epoch 677/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4052 - mse: 1.3968 - val_loss: 1.2352 - val_mse: 1.2268\n",
      "Epoch 678/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3839 - mse: 1.3755 - val_loss: 1.2584 - val_mse: 1.2500\n",
      "Epoch 679/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3664 - mse: 1.3579 - val_loss: 1.2524 - val_mse: 1.2440\n",
      "Epoch 680/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.3890 - mse: 1.3806\n",
      "Epoch 00680: saving model to Regression_Model/mle.linear-0680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3891 - mse: 1.3806 - val_loss: 1.2386 - val_mse: 1.2302\n",
      "Epoch 681/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4019 - mse: 1.3935 - val_loss: 1.2473 - val_mse: 1.2389\n",
      "Epoch 682/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3791 - mse: 1.3707 - val_loss: 1.2385 - val_mse: 1.2301\n",
      "Epoch 683/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3954 - mse: 1.3870 - val_loss: 1.2421 - val_mse: 1.2337\n",
      "Epoch 684/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3871 - mse: 1.3787 - val_loss: 1.2543 - val_mse: 1.2459\n",
      "Epoch 685/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3783 - mse: 1.3699 - val_loss: 1.2455 - val_mse: 1.2371\n",
      "Epoch 686/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3817 - mse: 1.3733 - val_loss: 1.2495 - val_mse: 1.2411\n",
      "Epoch 687/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3932 - mse: 1.3848 - val_loss: 1.2304 - val_mse: 1.2220\n",
      "Epoch 688/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3945 - mse: 1.3861 - val_loss: 1.2501 - val_mse: 1.2417\n",
      "Epoch 689/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3864 - mse: 1.3780 - val_loss: 1.2352 - val_mse: 1.2268\n",
      "Epoch 690/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3919 - mse: 1.3835\n",
      "Epoch 00690: saving model to Regression_Model/mle.linear-0690.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3905 - mse: 1.3821 - val_loss: 1.2391 - val_mse: 1.2307\n",
      "Epoch 691/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3919 - mse: 1.3835 - val_loss: 1.2575 - val_mse: 1.2492\n",
      "Epoch 692/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3760 - mse: 1.3676 - val_loss: 1.2459 - val_mse: 1.2375\n",
      "Epoch 693/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3812 - mse: 1.3728 - val_loss: 1.2513 - val_mse: 1.2429\n",
      "Epoch 694/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3802 - mse: 1.3718 - val_loss: 1.2447 - val_mse: 1.2363\n",
      "Epoch 695/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3884 - mse: 1.3800 - val_loss: 1.2387 - val_mse: 1.2303\n",
      "Epoch 696/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3904 - mse: 1.3820 - val_loss: 1.2330 - val_mse: 1.2246\n",
      "Epoch 697/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3844 - mse: 1.3760 - val_loss: 1.2490 - val_mse: 1.2406\n",
      "Epoch 698/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3709 - mse: 1.3625 - val_loss: 1.2445 - val_mse: 1.2361\n",
      "Epoch 699/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3885 - mse: 1.3801 - val_loss: 1.2427 - val_mse: 1.2344\n",
      "Epoch 700/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.4036 - mse: 1.3952\n",
      "Epoch 00700: saving model to Regression_Model/mle.linear-0700.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3993 - mse: 1.3909 - val_loss: 1.2385 - val_mse: 1.2301\n",
      "Epoch 701/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3913 - mse: 1.3829 - val_loss: 1.2351 - val_mse: 1.2267\n",
      "Epoch 702/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4025 - mse: 1.3941 - val_loss: 1.2356 - val_mse: 1.2272\n",
      "Epoch 703/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3911 - mse: 1.3827 - val_loss: 1.2332 - val_mse: 1.2248\n",
      "Epoch 704/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3788 - mse: 1.3704 - val_loss: 1.2512 - val_mse: 1.2428\n",
      "Epoch 705/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3805 - mse: 1.3721 - val_loss: 1.2561 - val_mse: 1.2477\n",
      "Epoch 706/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3977 - mse: 1.3893 - val_loss: 1.2329 - val_mse: 1.2245\n",
      "Epoch 707/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3681 - mse: 1.3597 - val_loss: 1.2359 - val_mse: 1.2275\n",
      "Epoch 708/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4018 - mse: 1.3934 - val_loss: 1.2458 - val_mse: 1.2375\n",
      "Epoch 709/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3918 - mse: 1.3834 - val_loss: 1.2306 - val_mse: 1.2222\n",
      "Epoch 710/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3894 - mse: 1.3810\n",
      "Epoch 00710: saving model to Regression_Model/mle.linear-0710.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3822 - mse: 1.3738 - val_loss: 1.2314 - val_mse: 1.2230\n",
      "Epoch 711/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3907 - mse: 1.3823 - val_loss: 1.2396 - val_mse: 1.2313\n",
      "Epoch 712/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3709 - mse: 1.3625 - val_loss: 1.2340 - val_mse: 1.2256\n",
      "Epoch 713/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4018 - mse: 1.3935 - val_loss: 1.2308 - val_mse: 1.2224\n",
      "Epoch 714/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3824 - mse: 1.3741 - val_loss: 1.2444 - val_mse: 1.2361\n",
      "Epoch 715/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3892 - mse: 1.3808 - val_loss: 1.2424 - val_mse: 1.2340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3993 - mse: 1.3909 - val_loss: 1.2471 - val_mse: 1.2387\n",
      "Epoch 717/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3840 - mse: 1.3756 - val_loss: 1.2422 - val_mse: 1.2338\n",
      "Epoch 718/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3933 - mse: 1.3850 - val_loss: 1.2454 - val_mse: 1.2370\n",
      "Epoch 719/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3762 - mse: 1.3678 - val_loss: 1.2441 - val_mse: 1.2357\n",
      "Epoch 720/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.3732 - mse: 1.3648\n",
      "Epoch 00720: saving model to Regression_Model/mle.linear-0720.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3804 - mse: 1.3720 - val_loss: 1.2274 - val_mse: 1.2190\n",
      "Epoch 721/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3933 - mse: 1.3849 - val_loss: 1.2409 - val_mse: 1.2325\n",
      "Epoch 722/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3796 - mse: 1.3713 - val_loss: 1.2392 - val_mse: 1.2309\n",
      "Epoch 723/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3712 - mse: 1.3629 - val_loss: 1.2313 - val_mse: 1.2229\n",
      "Epoch 724/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3784 - mse: 1.3700 - val_loss: 1.2462 - val_mse: 1.2378\n",
      "Epoch 725/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3965 - mse: 1.3881 - val_loss: 1.2449 - val_mse: 1.2365\n",
      "Epoch 726/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4058 - mse: 1.3974 - val_loss: 1.2443 - val_mse: 1.2359\n",
      "Epoch 727/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3979 - mse: 1.3895 - val_loss: 1.2356 - val_mse: 1.2273\n",
      "Epoch 728/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3800 - mse: 1.3716 - val_loss: 1.2492 - val_mse: 1.2409\n",
      "Epoch 729/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3709 - mse: 1.3626 - val_loss: 1.2375 - val_mse: 1.2292\n",
      "Epoch 730/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3877 - mse: 1.3793\n",
      "Epoch 00730: saving model to Regression_Model/mle.linear-0730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3876 - mse: 1.3793 - val_loss: 1.2363 - val_mse: 1.2279\n",
      "Epoch 731/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3688 - mse: 1.3605 - val_loss: 1.2422 - val_mse: 1.2339\n",
      "Epoch 732/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3693 - mse: 1.3609 - val_loss: 1.2337 - val_mse: 1.2254\n",
      "Epoch 733/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3814 - mse: 1.3730 - val_loss: 1.2432 - val_mse: 1.2348\n",
      "Epoch 734/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3789 - mse: 1.3706 - val_loss: 1.2393 - val_mse: 1.2310\n",
      "Epoch 735/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3840 - mse: 1.3757 - val_loss: 1.2388 - val_mse: 1.2304\n",
      "Epoch 736/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3923 - mse: 1.3839 - val_loss: 1.2402 - val_mse: 1.2319\n",
      "Epoch 737/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3714 - mse: 1.3630 - val_loss: 1.2330 - val_mse: 1.2247\n",
      "Epoch 738/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4054 - mse: 1.3970 - val_loss: 1.2443 - val_mse: 1.2359\n",
      "Epoch 739/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3805 - mse: 1.3721 - val_loss: 1.2531 - val_mse: 1.2447\n",
      "Epoch 740/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 1.3767 - mse: 1.3683\n",
      "Epoch 00740: saving model to Regression_Model/mle.linear-0740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3707 - mse: 1.3624 - val_loss: 1.2402 - val_mse: 1.2319\n",
      "Epoch 741/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3770 - mse: 1.3686 - val_loss: 1.2613 - val_mse: 1.2529\n",
      "Epoch 742/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3808 - mse: 1.3725 - val_loss: 1.2455 - val_mse: 1.2371\n",
      "Epoch 743/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3905 - mse: 1.3821 - val_loss: 1.2512 - val_mse: 1.2429\n",
      "Epoch 744/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3751 - mse: 1.3668 - val_loss: 1.2447 - val_mse: 1.2363\n",
      "Epoch 745/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3804 - mse: 1.3721 - val_loss: 1.2380 - val_mse: 1.2297\n",
      "Epoch 746/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3854 - mse: 1.3771 - val_loss: 1.2418 - val_mse: 1.2334\n",
      "Epoch 747/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3800 - mse: 1.3717 - val_loss: 1.2447 - val_mse: 1.2364\n",
      "Epoch 748/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3792 - mse: 1.3709 - val_loss: 1.2463 - val_mse: 1.2380\n",
      "Epoch 749/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3755 - mse: 1.3672 - val_loss: 1.2432 - val_mse: 1.2349\n",
      "Epoch 750/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3805 - mse: 1.3721\n",
      "Epoch 00750: saving model to Regression_Model/mle.linear-0750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3817 - mse: 1.3734 - val_loss: 1.2377 - val_mse: 1.2293\n",
      "Epoch 751/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3852 - mse: 1.3769 - val_loss: 1.2477 - val_mse: 1.2394\n",
      "Epoch 752/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3911 - mse: 1.3828 - val_loss: 1.2439 - val_mse: 1.2355\n",
      "Epoch 753/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3756 - mse: 1.3673 - val_loss: 1.2430 - val_mse: 1.2347\n",
      "Epoch 754/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3828 - mse: 1.3744 - val_loss: 1.2372 - val_mse: 1.2289\n",
      "Epoch 755/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3862 - mse: 1.3778 - val_loss: 1.2362 - val_mse: 1.2279\n",
      "Epoch 756/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3737 - mse: 1.3654 - val_loss: 1.2365 - val_mse: 1.2282\n",
      "Epoch 757/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3661 - mse: 1.3578 - val_loss: 1.2411 - val_mse: 1.2327\n",
      "Epoch 758/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3900 - mse: 1.3816 - val_loss: 1.2292 - val_mse: 1.2208\n",
      "Epoch 759/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3809 - mse: 1.3726 - val_loss: 1.2336 - val_mse: 1.2253\n",
      "Epoch 760/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.3828 - mse: 1.3744\n",
      "Epoch 00760: saving model to Regression_Model/mle.linear-0760.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3850 - mse: 1.3767 - val_loss: 1.2412 - val_mse: 1.2329\n",
      "Epoch 761/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3862 - mse: 1.3778 - val_loss: 1.2339 - val_mse: 1.2255\n",
      "Epoch 762/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4042 - mse: 1.3959 - val_loss: 1.2450 - val_mse: 1.2367\n",
      "Epoch 763/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3824 - mse: 1.3741 - val_loss: 1.2381 - val_mse: 1.2297\n",
      "Epoch 764/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3950 - mse: 1.3866 - val_loss: 1.2496 - val_mse: 1.2413\n",
      "Epoch 765/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3915 - mse: 1.3832 - val_loss: 1.2424 - val_mse: 1.2340\n",
      "Epoch 766/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3922 - mse: 1.3838 - val_loss: 1.2360 - val_mse: 1.2277\n",
      "Epoch 767/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3931 - mse: 1.3847 - val_loss: 1.2320 - val_mse: 1.2237\n",
      "Epoch 768/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3633 - mse: 1.3549 - val_loss: 1.2351 - val_mse: 1.2268\n",
      "Epoch 769/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3814 - mse: 1.3731 - val_loss: 1.2283 - val_mse: 1.2200\n",
      "Epoch 770/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 1.3943 - mse: 1.3860\n",
      "Epoch 00770: saving model to Regression_Model/mle.linear-0770.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3941 - mse: 1.3858 - val_loss: 1.2290 - val_mse: 1.2207\n",
      "Epoch 771/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3966 - mse: 1.3882 - val_loss: 1.2495 - val_mse: 1.2412\n",
      "Epoch 772/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3875 - mse: 1.3792 - val_loss: 1.2405 - val_mse: 1.2322\n",
      "Epoch 773/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3886 - mse: 1.3802 - val_loss: 1.2318 - val_mse: 1.2234\n",
      "Epoch 774/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3763 - mse: 1.3680 - val_loss: 1.2355 - val_mse: 1.2271\n",
      "Epoch 775/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4091 - mse: 1.4008 - val_loss: 1.2366 - val_mse: 1.2283\n",
      "Epoch 776/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3982 - mse: 1.3898 - val_loss: 1.2465 - val_mse: 1.2382\n",
      "Epoch 777/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3651 - mse: 1.3567 - val_loss: 1.2298 - val_mse: 1.2215\n",
      "Epoch 778/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3795 - mse: 1.3712 - val_loss: 1.2421 - val_mse: 1.2337\n",
      "Epoch 779/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3898 - mse: 1.3815 - val_loss: 1.2338 - val_mse: 1.2254\n",
      "Epoch 780/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.3832 - mse: 1.3749\n",
      "Epoch 00780: saving model to Regression_Model/mle.linear-0780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3927 - mse: 1.3844 - val_loss: 1.2371 - val_mse: 1.2288\n",
      "Epoch 781/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3963 - mse: 1.3880 - val_loss: 1.2340 - val_mse: 1.2257\n",
      "Epoch 782/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3847 - mse: 1.3763 - val_loss: 1.2355 - val_mse: 1.2271\n",
      "Epoch 783/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3736 - mse: 1.3653 - val_loss: 1.2356 - val_mse: 1.2273\n",
      "Epoch 784/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3823 - mse: 1.3740 - val_loss: 1.2364 - val_mse: 1.2281\n",
      "Epoch 785/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3709 - mse: 1.3626 - val_loss: 1.2300 - val_mse: 1.2216\n",
      "Epoch 786/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4009 - mse: 1.3925 - val_loss: 1.2298 - val_mse: 1.2215\n",
      "Epoch 787/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3753 - mse: 1.3670 - val_loss: 1.2337 - val_mse: 1.2253\n",
      "Epoch 788/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3780 - mse: 1.3697 - val_loss: 1.2396 - val_mse: 1.2313\n",
      "Epoch 789/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3878 - mse: 1.3795 - val_loss: 1.2362 - val_mse: 1.2278\n",
      "Epoch 790/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3881 - mse: 1.3798\n",
      "Epoch 00790: saving model to Regression_Model/mle.linear-0790.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3813 - mse: 1.3730 - val_loss: 1.2380 - val_mse: 1.2297\n",
      "Epoch 791/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3727 - mse: 1.3644 - val_loss: 1.2437 - val_mse: 1.2353\n",
      "Epoch 792/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4093 - mse: 1.4010 - val_loss: 1.2316 - val_mse: 1.2233\n",
      "Epoch 793/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3876 - mse: 1.3793 - val_loss: 1.2444 - val_mse: 1.2361\n",
      "Epoch 794/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3825 - mse: 1.3741 - val_loss: 1.2319 - val_mse: 1.2236\n",
      "Epoch 795/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3912 - mse: 1.3829 - val_loss: 1.2323 - val_mse: 1.2239\n",
      "Epoch 796/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3680 - mse: 1.3596 - val_loss: 1.2356 - val_mse: 1.2273\n",
      "Epoch 797/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3972 - mse: 1.3889 - val_loss: 1.2365 - val_mse: 1.2282\n",
      "Epoch 798/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3814 - mse: 1.3730 - val_loss: 1.2383 - val_mse: 1.2300\n",
      "Epoch 799/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3930 - mse: 1.3846 - val_loss: 1.2335 - val_mse: 1.2252\n",
      "Epoch 800/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 1.3888 - mse: 1.3805\n",
      "Epoch 00800: saving model to Regression_Model/mle.linear-0800.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3878 - mse: 1.3794 - val_loss: 1.2340 - val_mse: 1.2257\n",
      "Epoch 801/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3692 - mse: 1.3609 - val_loss: 1.2349 - val_mse: 1.2265\n",
      "Epoch 802/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3842 - mse: 1.3759 - val_loss: 1.2416 - val_mse: 1.2333\n",
      "Epoch 803/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3812 - mse: 1.3728 - val_loss: 1.2333 - val_mse: 1.2250\n",
      "Epoch 804/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3930 - mse: 1.3847 - val_loss: 1.2471 - val_mse: 1.2388\n",
      "Epoch 805/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3930 - mse: 1.3847 - val_loss: 1.2383 - val_mse: 1.2300\n",
      "Epoch 806/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3728 - mse: 1.3645 - val_loss: 1.2323 - val_mse: 1.2240\n",
      "Epoch 807/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3957 - mse: 1.3873 - val_loss: 1.2397 - val_mse: 1.2314\n",
      "Epoch 808/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3804 - mse: 1.3720 - val_loss: 1.2482 - val_mse: 1.2399\n",
      "Epoch 809/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4001 - mse: 1.3918 - val_loss: 1.2537 - val_mse: 1.2454\n",
      "Epoch 810/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.3827 - mse: 1.3744\n",
      "Epoch 00810: saving model to Regression_Model/mle.linear-0810.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3786 - mse: 1.3703 - val_loss: 1.2415 - val_mse: 1.2332\n",
      "Epoch 811/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3826 - mse: 1.3743 - val_loss: 1.2435 - val_mse: 1.2352\n",
      "Epoch 812/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3771 - mse: 1.3688 - val_loss: 1.2347 - val_mse: 1.2264\n",
      "Epoch 813/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3976 - mse: 1.3893 - val_loss: 1.2338 - val_mse: 1.2255\n",
      "Epoch 814/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3909 - mse: 1.3826 - val_loss: 1.2362 - val_mse: 1.2279\n",
      "Epoch 815/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3819 - mse: 1.3736 - val_loss: 1.2346 - val_mse: 1.2263\n",
      "Epoch 816/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3890 - mse: 1.3807 - val_loss: 1.2387 - val_mse: 1.2304\n",
      "Epoch 817/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3963 - mse: 1.3880 - val_loss: 1.2410 - val_mse: 1.2327\n",
      "Epoch 818/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3832 - mse: 1.3749 - val_loss: 1.2416 - val_mse: 1.2333\n",
      "Epoch 819/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3858 - mse: 1.3775 - val_loss: 1.2452 - val_mse: 1.2369\n",
      "Epoch 820/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.3735 - mse: 1.3652\n",
      "Epoch 00820: saving model to Regression_Model/mle.linear-0820.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3720 - mse: 1.3636 - val_loss: 1.2329 - val_mse: 1.2246\n",
      "Epoch 821/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3775 - mse: 1.3692 - val_loss: 1.2286 - val_mse: 1.2203\n",
      "Epoch 822/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3800 - mse: 1.3717 - val_loss: 1.2491 - val_mse: 1.2408\n",
      "Epoch 823/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3908 - mse: 1.3825 - val_loss: 1.2364 - val_mse: 1.2281\n",
      "Epoch 824/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3821 - mse: 1.3738 - val_loss: 1.2361 - val_mse: 1.2278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3668 - mse: 1.3585 - val_loss: 1.2347 - val_mse: 1.2264\n",
      "Epoch 826/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3813 - mse: 1.3730 - val_loss: 1.2320 - val_mse: 1.2237\n",
      "Epoch 827/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3791 - mse: 1.3708 - val_loss: 1.2262 - val_mse: 1.2179\n",
      "Epoch 828/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3799 - mse: 1.3716 - val_loss: 1.2378 - val_mse: 1.2295\n",
      "Epoch 829/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3731 - mse: 1.3648 - val_loss: 1.2325 - val_mse: 1.2242\n",
      "Epoch 830/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 1.3881 - mse: 1.3798\n",
      "Epoch 00830: saving model to Regression_Model/mle.linear-0830.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 1.3841 - mse: 1.3758 - val_loss: 1.2386 - val_mse: 1.2303\n",
      "Epoch 831/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3880 - mse: 1.3797 - val_loss: 1.2362 - val_mse: 1.2279\n",
      "Epoch 832/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3529 - mse: 1.3446 - val_loss: 1.2305 - val_mse: 1.2222\n",
      "Epoch 833/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3745 - mse: 1.3662 - val_loss: 1.2370 - val_mse: 1.2287\n",
      "Epoch 834/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3731 - mse: 1.3648 - val_loss: 1.2340 - val_mse: 1.2257\n",
      "Epoch 835/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3790 - mse: 1.3707 - val_loss: 1.2387 - val_mse: 1.2304\n",
      "Epoch 836/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3782 - mse: 1.3699 - val_loss: 1.2354 - val_mse: 1.2271\n",
      "Epoch 837/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3773 - mse: 1.3690 - val_loss: 1.2337 - val_mse: 1.2254\n",
      "Epoch 838/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3928 - mse: 1.3845 - val_loss: 1.2343 - val_mse: 1.2260\n",
      "Epoch 839/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3875 - mse: 1.3792 - val_loss: 1.2405 - val_mse: 1.2322\n",
      "Epoch 840/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.3800 - mse: 1.3717\n",
      "Epoch 00840: saving model to Regression_Model/mle.linear-0840.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3836 - mse: 1.3753 - val_loss: 1.2398 - val_mse: 1.2315\n",
      "Epoch 841/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3710 - mse: 1.3628 - val_loss: 1.2342 - val_mse: 1.2259\n",
      "Epoch 842/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3817 - mse: 1.3734 - val_loss: 1.2584 - val_mse: 1.2501\n",
      "Epoch 843/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3906 - mse: 1.3823 - val_loss: 1.2341 - val_mse: 1.2259\n",
      "Epoch 844/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3616 - mse: 1.3534 - val_loss: 1.2319 - val_mse: 1.2236\n",
      "Epoch 845/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3831 - mse: 1.3748 - val_loss: 1.2311 - val_mse: 1.2228\n",
      "Epoch 846/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3896 - mse: 1.3813 - val_loss: 1.2371 - val_mse: 1.2288\n",
      "Epoch 847/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3787 - mse: 1.3704 - val_loss: 1.2310 - val_mse: 1.2227\n",
      "Epoch 848/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3741 - mse: 1.3658 - val_loss: 1.2379 - val_mse: 1.2296\n",
      "Epoch 849/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3736 - mse: 1.3653 - val_loss: 1.2344 - val_mse: 1.2261\n",
      "Epoch 850/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 1.3814 - mse: 1.3732\n",
      "Epoch 00850: saving model to Regression_Model/mle.linear-0850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3766 - mse: 1.3683 - val_loss: 1.2375 - val_mse: 1.2292\n",
      "Epoch 851/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3860 - mse: 1.3777 - val_loss: 1.2304 - val_mse: 1.2221\n",
      "Epoch 852/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.4019 - mse: 1.3936 - val_loss: 1.2355 - val_mse: 1.2272\n",
      "Epoch 853/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3749 - mse: 1.3666 - val_loss: 1.2317 - val_mse: 1.2234\n",
      "Epoch 854/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3642 - mse: 1.3559 - val_loss: 1.2277 - val_mse: 1.2194\n",
      "Epoch 855/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3940 - mse: 1.3857 - val_loss: 1.2330 - val_mse: 1.2247\n",
      "Epoch 856/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3714 - mse: 1.3632 - val_loss: 1.2356 - val_mse: 1.2273\n",
      "Epoch 857/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3747 - mse: 1.3664 - val_loss: 1.2315 - val_mse: 1.2232\n",
      "Epoch 858/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3928 - mse: 1.3846 - val_loss: 1.2443 - val_mse: 1.2360\n",
      "Epoch 859/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3897 - mse: 1.3814 - val_loss: 1.2291 - val_mse: 1.2208\n",
      "Epoch 860/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.3664 - mse: 1.3581\n",
      "Epoch 00860: saving model to Regression_Model/mle.linear-0860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3694 - mse: 1.3611 - val_loss: 1.2361 - val_mse: 1.2278\n",
      "Epoch 861/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3989 - mse: 1.3906 - val_loss: 1.2388 - val_mse: 1.2306\n",
      "Epoch 862/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3623 - mse: 1.3541 - val_loss: 1.2327 - val_mse: 1.2244\n",
      "Epoch 863/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3824 - mse: 1.3741 - val_loss: 1.2396 - val_mse: 1.2313\n",
      "Epoch 864/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3674 - mse: 1.3591 - val_loss: 1.2455 - val_mse: 1.2373\n",
      "Epoch 865/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3820 - mse: 1.3737 - val_loss: 1.2338 - val_mse: 1.2255\n",
      "Epoch 866/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3787 - mse: 1.3705 - val_loss: 1.2364 - val_mse: 1.2281\n",
      "Epoch 867/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3646 - mse: 1.3563 - val_loss: 1.2307 - val_mse: 1.2224\n",
      "Epoch 868/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3770 - mse: 1.3687 - val_loss: 1.2301 - val_mse: 1.2218\n",
      "Epoch 869/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3680 - mse: 1.3597 - val_loss: 1.2457 - val_mse: 1.2374\n",
      "Epoch 870/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 1.3775 - mse: 1.3693\n",
      "Epoch 00870: saving model to Regression_Model/mle.linear-0870.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3827 - mse: 1.3744 - val_loss: 1.2298 - val_mse: 1.2215\n",
      "Epoch 871/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3914 - mse: 1.3831 - val_loss: 1.2287 - val_mse: 1.2204\n",
      "Epoch 872/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3776 - mse: 1.3694 - val_loss: 1.2316 - val_mse: 1.2234\n",
      "Epoch 873/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3777 - mse: 1.3694 - val_loss: 1.2324 - val_mse: 1.2242\n",
      "Epoch 874/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3817 - mse: 1.3734 - val_loss: 1.2297 - val_mse: 1.2215\n",
      "Epoch 875/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3844 - mse: 1.3761 - val_loss: 1.2325 - val_mse: 1.2243\n",
      "Epoch 876/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3937 - mse: 1.3854 - val_loss: 1.2391 - val_mse: 1.2309\n",
      "Epoch 877/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3791 - mse: 1.3708 - val_loss: 1.2362 - val_mse: 1.2279\n",
      "Epoch 878/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3949 - mse: 1.3867 - val_loss: 1.2386 - val_mse: 1.2303\n",
      "Epoch 879/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3832 - mse: 1.3749 - val_loss: 1.2312 - val_mse: 1.2230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.3975 - mse: 1.3892\n",
      "Epoch 00880: saving model to Regression_Model/mle.linear-0880.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3948 - mse: 1.3865 - val_loss: 1.2393 - val_mse: 1.2311\n",
      "Epoch 881/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3655 - mse: 1.3573 - val_loss: 1.2316 - val_mse: 1.2234\n",
      "Epoch 882/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3879 - mse: 1.3796 - val_loss: 1.2387 - val_mse: 1.2304\n",
      "Epoch 883/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3849 - mse: 1.3767 - val_loss: 1.2342 - val_mse: 1.2259\n",
      "Epoch 884/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3875 - mse: 1.3792 - val_loss: 1.2349 - val_mse: 1.2266\n",
      "Epoch 885/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3688 - mse: 1.3605 - val_loss: 1.2415 - val_mse: 1.2332\n",
      "Epoch 886/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3679 - mse: 1.3596 - val_loss: 1.2363 - val_mse: 1.2280\n",
      "Epoch 887/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3683 - mse: 1.3601 - val_loss: 1.2405 - val_mse: 1.2322\n",
      "Epoch 888/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3808 - mse: 1.3726 - val_loss: 1.2331 - val_mse: 1.2249\n",
      "Epoch 889/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3659 - mse: 1.3576 - val_loss: 1.2303 - val_mse: 1.2220\n",
      "Epoch 890/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 1.3766 - mse: 1.3684\n",
      "Epoch 00890: saving model to Regression_Model/mle.linear-0890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3742 - mse: 1.3659 - val_loss: 1.2359 - val_mse: 1.2277\n",
      "Epoch 891/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3892 - mse: 1.3809 - val_loss: 1.2360 - val_mse: 1.2278\n",
      "Epoch 892/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3813 - mse: 1.3730 - val_loss: 1.2313 - val_mse: 1.2230\n",
      "Epoch 893/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3883 - mse: 1.3800 - val_loss: 1.2357 - val_mse: 1.2275\n",
      "Epoch 894/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3944 - mse: 1.3861 - val_loss: 1.2358 - val_mse: 1.2276\n",
      "Epoch 895/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3819 - mse: 1.3736 - val_loss: 1.2379 - val_mse: 1.2297\n",
      "Epoch 896/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3739 - mse: 1.3657 - val_loss: 1.2278 - val_mse: 1.2195\n",
      "Epoch 897/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3903 - mse: 1.3820 - val_loss: 1.2395 - val_mse: 1.2312\n",
      "Epoch 898/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3649 - mse: 1.3566 - val_loss: 1.2285 - val_mse: 1.2202\n",
      "Epoch 899/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3725 - mse: 1.3642 - val_loss: 1.2375 - val_mse: 1.2293\n",
      "Epoch 900/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.3779 - mse: 1.3696\n",
      "Epoch 00900: saving model to Regression_Model/mle.linear-0900.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3792 - mse: 1.3710 - val_loss: 1.2370 - val_mse: 1.2287\n",
      "Epoch 901/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.4047 - mse: 1.3964 - val_loss: 1.2323 - val_mse: 1.2240\n",
      "Epoch 902/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3751 - mse: 1.3669 - val_loss: 1.2305 - val_mse: 1.2223\n",
      "Epoch 903/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3854 - mse: 1.3771 - val_loss: 1.2428 - val_mse: 1.2345\n",
      "Epoch 904/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3669 - mse: 1.3586 - val_loss: 1.2322 - val_mse: 1.2239\n",
      "Epoch 905/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3862 - mse: 1.3779 - val_loss: 1.2277 - val_mse: 1.2195\n",
      "Epoch 906/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3836 - mse: 1.3754 - val_loss: 1.2292 - val_mse: 1.2209\n",
      "Epoch 907/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3751 - mse: 1.3669 - val_loss: 1.2320 - val_mse: 1.2238\n",
      "Epoch 908/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3611 - mse: 1.3528 - val_loss: 1.2323 - val_mse: 1.2241\n",
      "Epoch 909/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3818 - mse: 1.3735 - val_loss: 1.2377 - val_mse: 1.2295\n",
      "Epoch 910/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.3578 - mse: 1.3496\n",
      "Epoch 00910: saving model to Regression_Model/mle.linear-0910.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3548 - mse: 1.3465 - val_loss: 1.2250 - val_mse: 1.2167\n",
      "Epoch 911/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3824 - mse: 1.3742 - val_loss: 1.2332 - val_mse: 1.2249\n",
      "Epoch 912/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3668 - mse: 1.3585 - val_loss: 1.2270 - val_mse: 1.2188\n",
      "Epoch 913/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3535 - mse: 1.3452 - val_loss: 1.2305 - val_mse: 1.2222\n",
      "Epoch 914/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3800 - mse: 1.3717 - val_loss: 1.2278 - val_mse: 1.2195\n",
      "Epoch 915/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3795 - mse: 1.3712 - val_loss: 1.2365 - val_mse: 1.2282\n",
      "Epoch 916/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3702 - mse: 1.3619 - val_loss: 1.2336 - val_mse: 1.2254\n",
      "Epoch 917/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3641 - val_loss: 1.2342 - val_mse: 1.2260\n",
      "Epoch 918/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3933 - mse: 1.3851 - val_loss: 1.2359 - val_mse: 1.2276\n",
      "Epoch 919/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3732 - mse: 1.3650 - val_loss: 1.2288 - val_mse: 1.2206\n",
      "Epoch 920/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.3819 - mse: 1.3736\n",
      "Epoch 00920: saving model to Regression_Model/mle.linear-0920.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3775 - mse: 1.3693 - val_loss: 1.2309 - val_mse: 1.2227\n",
      "Epoch 921/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3793 - mse: 1.3711 - val_loss: 1.2404 - val_mse: 1.2321\n",
      "Epoch 922/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3723 - mse: 1.3641 - val_loss: 1.2328 - val_mse: 1.2246\n",
      "Epoch 923/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3711 - mse: 1.3629 - val_loss: 1.2340 - val_mse: 1.2258\n",
      "Epoch 924/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3783 - mse: 1.3700 - val_loss: 1.2341 - val_mse: 1.2258\n",
      "Epoch 925/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3740 - mse: 1.3658 - val_loss: 1.2267 - val_mse: 1.2185\n",
      "Epoch 926/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3878 - mse: 1.3795 - val_loss: 1.2301 - val_mse: 1.2218\n",
      "Epoch 927/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3821 - mse: 1.3739 - val_loss: 1.2280 - val_mse: 1.2198\n",
      "Epoch 928/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3785 - mse: 1.3703 - val_loss: 1.2298 - val_mse: 1.2216\n",
      "Epoch 929/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3686 - mse: 1.3604 - val_loss: 1.2375 - val_mse: 1.2293\n",
      "Epoch 930/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 1.3736 - mse: 1.3654\n",
      "Epoch 00930: saving model to Regression_Model/mle.linear-0930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3693 - mse: 1.3611 - val_loss: 1.2359 - val_mse: 1.2276\n",
      "Epoch 931/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3745 - mse: 1.3663 - val_loss: 1.2337 - val_mse: 1.2255\n",
      "Epoch 932/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3972 - mse: 1.3889 - val_loss: 1.2386 - val_mse: 1.2303\n",
      "Epoch 933/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3949 - mse: 1.3867 - val_loss: 1.2341 - val_mse: 1.2259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 934/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3780 - mse: 1.3698 - val_loss: 1.2472 - val_mse: 1.2390\n",
      "Epoch 935/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3743 - mse: 1.3661 - val_loss: 1.2371 - val_mse: 1.2289\n",
      "Epoch 936/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3733 - mse: 1.3651 - val_loss: 1.2396 - val_mse: 1.2314\n",
      "Epoch 937/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3804 - mse: 1.3721 - val_loss: 1.2296 - val_mse: 1.2214\n",
      "Epoch 938/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3898 - mse: 1.3816 - val_loss: 1.2376 - val_mse: 1.2294\n",
      "Epoch 939/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3816 - mse: 1.3733 - val_loss: 1.2377 - val_mse: 1.2294\n",
      "Epoch 940/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.3678 - mse: 1.3596\n",
      "Epoch 00940: saving model to Regression_Model/mle.linear-0940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3676 - mse: 1.3594 - val_loss: 1.2353 - val_mse: 1.2271\n",
      "Epoch 941/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3782 - mse: 1.3700 - val_loss: 1.2285 - val_mse: 1.2203\n",
      "Epoch 942/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3744 - mse: 1.3662 - val_loss: 1.2266 - val_mse: 1.2184\n",
      "Epoch 943/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3874 - mse: 1.3791 - val_loss: 1.2336 - val_mse: 1.2254\n",
      "Epoch 944/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3837 - mse: 1.3755 - val_loss: 1.2284 - val_mse: 1.2202\n",
      "Epoch 945/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3654 - mse: 1.3571 - val_loss: 1.2358 - val_mse: 1.2276\n",
      "Epoch 946/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3712 - mse: 1.3629 - val_loss: 1.2346 - val_mse: 1.2263\n",
      "Epoch 947/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3713 - mse: 1.3630 - val_loss: 1.2309 - val_mse: 1.2227\n",
      "Epoch 948/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3947 - mse: 1.3865 - val_loss: 1.2351 - val_mse: 1.2268\n",
      "Epoch 949/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3942 - mse: 1.3860 - val_loss: 1.2304 - val_mse: 1.2221\n",
      "Epoch 950/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 1.3787 - mse: 1.3704\n",
      "Epoch 00950: saving model to Regression_Model/mle.linear-0950.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3783 - mse: 1.3701 - val_loss: 1.2301 - val_mse: 1.2219\n",
      "Epoch 951/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3938 - mse: 1.3855 - val_loss: 1.2329 - val_mse: 1.2246\n",
      "Epoch 952/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3809 - mse: 1.3727 - val_loss: 1.2453 - val_mse: 1.2370\n",
      "Epoch 953/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3727 - mse: 1.3645 - val_loss: 1.2357 - val_mse: 1.2275\n",
      "Epoch 954/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3737 - mse: 1.3655 - val_loss: 1.2314 - val_mse: 1.2232\n",
      "Epoch 955/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3697 - mse: 1.3615 - val_loss: 1.2320 - val_mse: 1.2238\n",
      "Epoch 956/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3686 - mse: 1.3604 - val_loss: 1.2345 - val_mse: 1.2263\n",
      "Epoch 957/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3791 - mse: 1.3709 - val_loss: 1.2345 - val_mse: 1.2263\n",
      "Epoch 958/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3868 - mse: 1.3786 - val_loss: 1.2352 - val_mse: 1.2270\n",
      "Epoch 959/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3856 - mse: 1.3774 - val_loss: 1.2332 - val_mse: 1.2249\n",
      "Epoch 960/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3699 - mse: 1.3616\n",
      "Epoch 00960: saving model to Regression_Model/mle.linear-0960.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3680 - mse: 1.3598 - val_loss: 1.2314 - val_mse: 1.2232\n",
      "Epoch 961/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3812 - mse: 1.3730 - val_loss: 1.2302 - val_mse: 1.2220\n",
      "Epoch 962/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3915 - mse: 1.3833 - val_loss: 1.2310 - val_mse: 1.2228\n",
      "Epoch 963/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3920 - mse: 1.3838 - val_loss: 1.2327 - val_mse: 1.2245\n",
      "Epoch 964/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3760 - mse: 1.3678 - val_loss: 1.2288 - val_mse: 1.2206\n",
      "Epoch 965/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3641 - val_loss: 1.2322 - val_mse: 1.2240\n",
      "Epoch 966/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3769 - mse: 1.3687 - val_loss: 1.2352 - val_mse: 1.2269\n",
      "Epoch 967/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3760 - mse: 1.3678 - val_loss: 1.2361 - val_mse: 1.2279\n",
      "Epoch 968/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3909 - mse: 1.3827 - val_loss: 1.2298 - val_mse: 1.2216\n",
      "Epoch 969/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3867 - mse: 1.3785 - val_loss: 1.2322 - val_mse: 1.2240\n",
      "Epoch 970/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.3757 - mse: 1.3675\n",
      "Epoch 00970: saving model to Regression_Model/mle.linear-0970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3749 - mse: 1.3666 - val_loss: 1.2235 - val_mse: 1.2152\n",
      "Epoch 971/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3774 - mse: 1.3692 - val_loss: 1.2299 - val_mse: 1.2217\n",
      "Epoch 972/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3853 - mse: 1.3771 - val_loss: 1.2297 - val_mse: 1.2215\n",
      "Epoch 973/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3800 - mse: 1.3718 - val_loss: 1.2254 - val_mse: 1.2172\n",
      "Epoch 974/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3799 - mse: 1.3716 - val_loss: 1.2296 - val_mse: 1.2214\n",
      "Epoch 975/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3719 - mse: 1.3637 - val_loss: 1.2394 - val_mse: 1.2312\n",
      "Epoch 976/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3642 - mse: 1.3560 - val_loss: 1.2289 - val_mse: 1.2206\n",
      "Epoch 977/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3879 - mse: 1.3797 - val_loss: 1.2319 - val_mse: 1.2237\n",
      "Epoch 978/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3804 - mse: 1.3722 - val_loss: 1.2365 - val_mse: 1.2283\n",
      "Epoch 979/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3887 - mse: 1.3805 - val_loss: 1.2323 - val_mse: 1.2241\n",
      "Epoch 980/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.3802 - mse: 1.3720\n",
      "Epoch 00980: saving model to Regression_Model/mle.linear-0980.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 1.3789 - mse: 1.3707 - val_loss: 1.2304 - val_mse: 1.2222\n",
      "Epoch 981/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3907 - mse: 1.3825 - val_loss: 1.2337 - val_mse: 1.2255\n",
      "Epoch 982/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3658 - mse: 1.3576 - val_loss: 1.2399 - val_mse: 1.2317\n",
      "Epoch 983/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3712 - mse: 1.3630 - val_loss: 1.2326 - val_mse: 1.2244\n",
      "Epoch 984/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3889 - mse: 1.3807 - val_loss: 1.2357 - val_mse: 1.2275\n",
      "Epoch 985/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3764 - mse: 1.3682 - val_loss: 1.2270 - val_mse: 1.2188\n",
      "Epoch 986/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3899 - mse: 1.3817 - val_loss: 1.2376 - val_mse: 1.2294\n",
      "Epoch 987/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3657 - mse: 1.3575 - val_loss: 1.2242 - val_mse: 1.2160\n",
      "Epoch 988/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3827 - mse: 1.3745 - val_loss: 1.2286 - val_mse: 1.2204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3771 - mse: 1.3689 - val_loss: 1.2336 - val_mse: 1.2254\n",
      "Epoch 990/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.3819 - mse: 1.3737\n",
      "Epoch 00990: saving model to Regression_Model/mle.linear-0990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3754 - mse: 1.3672 - val_loss: 1.2302 - val_mse: 1.2220\n",
      "Epoch 991/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3934 - mse: 1.3852 - val_loss: 1.2301 - val_mse: 1.2219\n",
      "Epoch 992/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3899 - mse: 1.3817 - val_loss: 1.2320 - val_mse: 1.2238\n",
      "Epoch 993/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3763 - mse: 1.3681 - val_loss: 1.2300 - val_mse: 1.2218\n",
      "Epoch 994/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3697 - mse: 1.3615 - val_loss: 1.2419 - val_mse: 1.2337\n",
      "Epoch 995/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3645 - mse: 1.3563 - val_loss: 1.2279 - val_mse: 1.2197\n",
      "Epoch 996/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3704 - mse: 1.3621 - val_loss: 1.2260 - val_mse: 1.2178\n",
      "Epoch 997/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3838 - mse: 1.3756 - val_loss: 1.2293 - val_mse: 1.2211\n",
      "Epoch 998/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3878 - mse: 1.3796 - val_loss: 1.2339 - val_mse: 1.2257\n",
      "Epoch 999/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3663 - mse: 1.3581 - val_loss: 1.2331 - val_mse: 1.2249\n",
      "Epoch 1000/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.3863 - mse: 1.3781\n",
      "Epoch 01000: saving model to Regression_Model/mle.linear-1000.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3894 - mse: 1.3812 - val_loss: 1.2334 - val_mse: 1.2252\n",
      "Epoch 1001/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3749 - mse: 1.3667 - val_loss: 1.2327 - val_mse: 1.2245\n",
      "Epoch 1002/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3780 - mse: 1.3698 - val_loss: 1.2354 - val_mse: 1.2273\n",
      "Epoch 1003/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3773 - mse: 1.3691 - val_loss: 1.2294 - val_mse: 1.2212\n",
      "Epoch 1004/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3840 - mse: 1.3758 - val_loss: 1.2331 - val_mse: 1.2249\n",
      "Epoch 1005/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3807 - mse: 1.3725 - val_loss: 1.2352 - val_mse: 1.2270\n",
      "Epoch 1006/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3668 - mse: 1.3586 - val_loss: 1.2357 - val_mse: 1.2275\n",
      "Epoch 1007/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3716 - mse: 1.3634 - val_loss: 1.2279 - val_mse: 1.2197\n",
      "Epoch 1008/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3830 - mse: 1.3748 - val_loss: 1.2268 - val_mse: 1.2186\n",
      "Epoch 1009/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3919 - mse: 1.3837 - val_loss: 1.2355 - val_mse: 1.2273\n",
      "Epoch 1010/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.3700 - mse: 1.3618\n",
      "Epoch 01010: saving model to Regression_Model/mle.linear-1010.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3776 - mse: 1.3694 - val_loss: 1.2321 - val_mse: 1.2239\n",
      "Epoch 1011/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3752 - mse: 1.3670 - val_loss: 1.2286 - val_mse: 1.2205\n",
      "Epoch 1012/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3606 - mse: 1.3524 - val_loss: 1.2284 - val_mse: 1.2202\n",
      "Epoch 1013/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3800 - mse: 1.3718 - val_loss: 1.2266 - val_mse: 1.2184\n",
      "Epoch 1014/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3851 - mse: 1.3769 - val_loss: 1.2281 - val_mse: 1.2199\n",
      "Epoch 1015/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3809 - mse: 1.3727 - val_loss: 1.2377 - val_mse: 1.2295\n",
      "Epoch 1016/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3786 - mse: 1.3704 - val_loss: 1.2333 - val_mse: 1.2251\n",
      "Epoch 1017/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3808 - mse: 1.3726 - val_loss: 1.2336 - val_mse: 1.2254\n",
      "Epoch 1018/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3617 - mse: 1.3535 - val_loss: 1.2334 - val_mse: 1.2252\n",
      "Epoch 1019/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3667 - mse: 1.3585 - val_loss: 1.2309 - val_mse: 1.2228\n",
      "Epoch 1020/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.3745 - mse: 1.3663\n",
      "Epoch 01020: saving model to Regression_Model/mle.linear-1020.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3825 - mse: 1.3743 - val_loss: 1.2321 - val_mse: 1.2239\n",
      "Epoch 1021/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3857 - mse: 1.3775 - val_loss: 1.2300 - val_mse: 1.2218\n",
      "Epoch 1022/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3700 - mse: 1.3618 - val_loss: 1.2321 - val_mse: 1.2239\n",
      "Epoch 1023/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3956 - mse: 1.3874 - val_loss: 1.2334 - val_mse: 1.2252\n",
      "Epoch 1024/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3650 - mse: 1.3568 - val_loss: 1.2330 - val_mse: 1.2248\n",
      "Epoch 1025/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3713 - mse: 1.3632 - val_loss: 1.2390 - val_mse: 1.2308\n",
      "Epoch 1026/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3707 - mse: 1.3625 - val_loss: 1.2314 - val_mse: 1.2232\n",
      "Epoch 1027/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3861 - mse: 1.3779 - val_loss: 1.2317 - val_mse: 1.2235\n",
      "Epoch 1028/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3496 - mse: 1.3414 - val_loss: 1.2299 - val_mse: 1.2217\n",
      "Epoch 1029/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3797 - mse: 1.3715 - val_loss: 1.2316 - val_mse: 1.2234\n",
      "Epoch 1030/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 1.3587 - mse: 1.3505\n",
      "Epoch 01030: saving model to Regression_Model/mle.linear-1030.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3645 - mse: 1.3563 - val_loss: 1.2348 - val_mse: 1.2266\n",
      "Epoch 1031/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3680 - mse: 1.3598 - val_loss: 1.2317 - val_mse: 1.2235\n",
      "Epoch 1032/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3742 - mse: 1.3660 - val_loss: 1.2300 - val_mse: 1.2218\n",
      "Epoch 1033/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3812 - mse: 1.3730 - val_loss: 1.2335 - val_mse: 1.2253\n",
      "Epoch 1034/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3725 - mse: 1.3643 - val_loss: 1.2293 - val_mse: 1.2211\n",
      "Epoch 1035/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3926 - mse: 1.3845 - val_loss: 1.2357 - val_mse: 1.2275\n",
      "Epoch 1036/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3767 - mse: 1.3685 - val_loss: 1.2334 - val_mse: 1.2253\n",
      "Epoch 1037/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3653 - mse: 1.3571 - val_loss: 1.2280 - val_mse: 1.2198\n",
      "Epoch 1038/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3829 - mse: 1.3747 - val_loss: 1.2328 - val_mse: 1.2246\n",
      "Epoch 1039/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3946 - mse: 1.3864 - val_loss: 1.2325 - val_mse: 1.2243\n",
      "Epoch 1040/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.3647 - mse: 1.3565\n",
      "Epoch 01040: saving model to Regression_Model/mle.linear-1040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3640 - mse: 1.3559 - val_loss: 1.2337 - val_mse: 1.2256\n",
      "Epoch 1041/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3796 - mse: 1.3714 - val_loss: 1.2269 - val_mse: 1.2187\n",
      "Epoch 1042/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3823 - mse: 1.3741 - val_loss: 1.2290 - val_mse: 1.2208\n",
      "Epoch 1043/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3643 - mse: 1.3561 - val_loss: 1.2321 - val_mse: 1.2239\n",
      "Epoch 1044/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3935 - mse: 1.3853 - val_loss: 1.2332 - val_mse: 1.2251\n",
      "Epoch 1045/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3727 - mse: 1.3645 - val_loss: 1.2336 - val_mse: 1.2254\n",
      "Epoch 1046/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3727 - mse: 1.3645 - val_loss: 1.2314 - val_mse: 1.2232\n",
      "Epoch 1047/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3853 - mse: 1.3771 - val_loss: 1.2306 - val_mse: 1.2224\n",
      "Epoch 1048/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3696 - mse: 1.3615 - val_loss: 1.2291 - val_mse: 1.2209\n",
      "Epoch 1049/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3831 - mse: 1.3749 - val_loss: 1.2319 - val_mse: 1.2237\n",
      "Epoch 1050/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.3664 - mse: 1.3582\n",
      "Epoch 01050: saving model to Regression_Model/mle.linear-1050.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3625 - mse: 1.3543 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1051/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3905 - mse: 1.3823 - val_loss: 1.2263 - val_mse: 1.2182\n",
      "Epoch 1052/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3867 - mse: 1.3785 - val_loss: 1.2280 - val_mse: 1.2198\n",
      "Epoch 1053/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3776 - mse: 1.3695 - val_loss: 1.2303 - val_mse: 1.2221\n",
      "Epoch 1054/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3771 - mse: 1.3689 - val_loss: 1.2274 - val_mse: 1.2192\n",
      "Epoch 1055/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3773 - mse: 1.3691 - val_loss: 1.2349 - val_mse: 1.2267\n",
      "Epoch 1056/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3777 - mse: 1.3695 - val_loss: 1.2273 - val_mse: 1.2191\n",
      "Epoch 1057/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3670 - mse: 1.3588 - val_loss: 1.2317 - val_mse: 1.2235\n",
      "Epoch 1058/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3930 - mse: 1.3848 - val_loss: 1.2315 - val_mse: 1.2233\n",
      "Epoch 1059/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3887 - mse: 1.3805 - val_loss: 1.2314 - val_mse: 1.2233\n",
      "Epoch 1060/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.3722 - mse: 1.3640\n",
      "Epoch 01060: saving model to Regression_Model/mle.linear-1060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3685 - mse: 1.3603 - val_loss: 1.2303 - val_mse: 1.2221\n",
      "Epoch 1061/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3748 - mse: 1.3666 - val_loss: 1.2256 - val_mse: 1.2174\n",
      "Epoch 1062/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3995 - mse: 1.3913 - val_loss: 1.2302 - val_mse: 1.2220\n",
      "Epoch 1063/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3929 - mse: 1.3847 - val_loss: 1.2321 - val_mse: 1.2240\n",
      "Epoch 1064/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3730 - mse: 1.3648 - val_loss: 1.2330 - val_mse: 1.2248\n",
      "Epoch 1065/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3780 - mse: 1.3698 - val_loss: 1.2346 - val_mse: 1.2264\n",
      "Epoch 1066/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3716 - mse: 1.3635 - val_loss: 1.2361 - val_mse: 1.2280\n",
      "Epoch 1067/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3775 - mse: 1.3693 - val_loss: 1.2302 - val_mse: 1.2220\n",
      "Epoch 1068/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3746 - mse: 1.3664 - val_loss: 1.2309 - val_mse: 1.2228\n",
      "Epoch 1069/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3855 - mse: 1.3774 - val_loss: 1.2296 - val_mse: 1.2214\n",
      "Epoch 1070/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.3709 - mse: 1.3627\n",
      "Epoch 01070: saving model to Regression_Model/mle.linear-1070.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3726 - mse: 1.3644 - val_loss: 1.2367 - val_mse: 1.2285\n",
      "Epoch 1071/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3769 - mse: 1.3687 - val_loss: 1.2341 - val_mse: 1.2260\n",
      "Epoch 1072/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3807 - mse: 1.3725 - val_loss: 1.2297 - val_mse: 1.2216\n",
      "Epoch 1073/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3646 - mse: 1.3564 - val_loss: 1.2273 - val_mse: 1.2191\n",
      "Epoch 1074/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3802 - mse: 1.3720 - val_loss: 1.2307 - val_mse: 1.2225\n",
      "Epoch 1075/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3763 - mse: 1.3681 - val_loss: 1.2383 - val_mse: 1.2302\n",
      "Epoch 1076/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3750 - mse: 1.3669 - val_loss: 1.2321 - val_mse: 1.2239\n",
      "Epoch 1077/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3702 - mse: 1.3621 - val_loss: 1.2281 - val_mse: 1.2199\n",
      "Epoch 1078/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3642 - val_loss: 1.2376 - val_mse: 1.2294\n",
      "Epoch 1079/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3729 - mse: 1.3647 - val_loss: 1.2385 - val_mse: 1.2303\n",
      "Epoch 1080/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 1.3676 - mse: 1.3594\n",
      "Epoch 01080: saving model to Regression_Model/mle.linear-1080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3713 - mse: 1.3631 - val_loss: 1.2367 - val_mse: 1.2285\n",
      "Epoch 1081/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3791 - mse: 1.3710 - val_loss: 1.2363 - val_mse: 1.2281\n",
      "Epoch 1082/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3735 - mse: 1.3654 - val_loss: 1.2286 - val_mse: 1.2205\n",
      "Epoch 1083/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3876 - mse: 1.3794 - val_loss: 1.2319 - val_mse: 1.2237\n",
      "Epoch 1084/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3692 - mse: 1.3610 - val_loss: 1.2302 - val_mse: 1.2221\n",
      "Epoch 1085/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3823 - mse: 1.3742 - val_loss: 1.2333 - val_mse: 1.2251\n",
      "Epoch 1086/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3953 - mse: 1.3872 - val_loss: 1.2412 - val_mse: 1.2331\n",
      "Epoch 1087/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3775 - mse: 1.3693 - val_loss: 1.2302 - val_mse: 1.2220\n",
      "Epoch 1088/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3599 - mse: 1.3518 - val_loss: 1.2351 - val_mse: 1.2270\n",
      "Epoch 1089/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3851 - mse: 1.3770 - val_loss: 1.2295 - val_mse: 1.2213\n",
      "Epoch 1090/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 1.3743 - mse: 1.3661\n",
      "Epoch 01090: saving model to Regression_Model/mle.linear-1090.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 1.3783 - mse: 1.3702 - val_loss: 1.2312 - val_mse: 1.2230\n",
      "Epoch 1091/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3648 - mse: 1.3567 - val_loss: 1.2254 - val_mse: 1.2173\n",
      "Epoch 1092/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3782 - mse: 1.3701 - val_loss: 1.2324 - val_mse: 1.2242\n",
      "Epoch 1093/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3671 - mse: 1.3590 - val_loss: 1.2307 - val_mse: 1.2225\n",
      "Epoch 1094/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3815 - mse: 1.3734 - val_loss: 1.2283 - val_mse: 1.2201\n",
      "Epoch 1095/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3798 - mse: 1.3716 - val_loss: 1.2339 - val_mse: 1.2258\n",
      "Epoch 1096/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3788 - mse: 1.3706 - val_loss: 1.2302 - val_mse: 1.2220\n",
      "Epoch 1097/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3808 - mse: 1.3727 - val_loss: 1.2288 - val_mse: 1.2206\n",
      "Epoch 1098/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3895 - mse: 1.3813 - val_loss: 1.2355 - val_mse: 1.2273\n",
      "Epoch 1099/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3865 - mse: 1.3783 - val_loss: 1.2282 - val_mse: 1.2200\n",
      "Epoch 1100/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3671 - mse: 1.3590\n",
      "Epoch 01100: saving model to Regression_Model/mle.linear-1100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3634 - mse: 1.3552 - val_loss: 1.2273 - val_mse: 1.2192\n",
      "Epoch 1101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3905 - mse: 1.3824 - val_loss: 1.2324 - val_mse: 1.2243\n",
      "Epoch 1102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3848 - mse: 1.3767 - val_loss: 1.2330 - val_mse: 1.2249\n",
      "Epoch 1103/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3769 - mse: 1.3687 - val_loss: 1.2297 - val_mse: 1.2216\n",
      "Epoch 1104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3767 - mse: 1.3685 - val_loss: 1.2314 - val_mse: 1.2232\n",
      "Epoch 1105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3779 - mse: 1.3697 - val_loss: 1.2313 - val_mse: 1.2232\n",
      "Epoch 1106/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3683 - mse: 1.3601 - val_loss: 1.2273 - val_mse: 1.2191\n",
      "Epoch 1107/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3977 - mse: 1.3895 - val_loss: 1.2361 - val_mse: 1.2280\n",
      "Epoch 1108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3762 - mse: 1.3681 - val_loss: 1.2286 - val_mse: 1.2204\n",
      "Epoch 1109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3837 - mse: 1.3755 - val_loss: 1.2339 - val_mse: 1.2258\n",
      "Epoch 1110/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.3851 - mse: 1.3769\n",
      "Epoch 01110: saving model to Regression_Model/mle.linear-1110.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 1.3896 - mse: 1.3815 - val_loss: 1.2290 - val_mse: 1.2208\n",
      "Epoch 1111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3671 - mse: 1.3590 - val_loss: 1.2311 - val_mse: 1.2230\n",
      "Epoch 1112/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3816 - mse: 1.3734 - val_loss: 1.2286 - val_mse: 1.2205\n",
      "Epoch 1113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3652 - mse: 1.3570 - val_loss: 1.2253 - val_mse: 1.2171\n",
      "Epoch 1114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3614 - mse: 1.3533 - val_loss: 1.2307 - val_mse: 1.2225\n",
      "Epoch 1115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3761 - mse: 1.3679 - val_loss: 1.2404 - val_mse: 1.2322\n",
      "Epoch 1116/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3779 - mse: 1.3698 - val_loss: 1.2262 - val_mse: 1.2181\n",
      "Epoch 1117/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3972 - mse: 1.3890 - val_loss: 1.2333 - val_mse: 1.2251\n",
      "Epoch 1118/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3634 - mse: 1.3552 - val_loss: 1.2295 - val_mse: 1.2213\n",
      "Epoch 1119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3696 - mse: 1.3614 - val_loss: 1.2288 - val_mse: 1.2207\n",
      "Epoch 1120/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.3849 - mse: 1.3768\n",
      "Epoch 01120: saving model to Regression_Model/mle.linear-1120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3839 - mse: 1.3758 - val_loss: 1.2295 - val_mse: 1.2214\n",
      "Epoch 1121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3517 - mse: 1.3435 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1122/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3680 - mse: 1.3598 - val_loss: 1.2268 - val_mse: 1.2187\n",
      "Epoch 1123/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3651 - mse: 1.3570 - val_loss: 1.2302 - val_mse: 1.2221\n",
      "Epoch 1124/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3835 - mse: 1.3753 - val_loss: 1.2320 - val_mse: 1.2239\n",
      "Epoch 1125/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3889 - mse: 1.3808 - val_loss: 1.2321 - val_mse: 1.2240\n",
      "Epoch 1126/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3705 - mse: 1.3624 - val_loss: 1.2293 - val_mse: 1.2212\n",
      "Epoch 1127/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3859 - mse: 1.3777 - val_loss: 1.2319 - val_mse: 1.2238\n",
      "Epoch 1128/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3933 - mse: 1.3851 - val_loss: 1.2280 - val_mse: 1.2198\n",
      "Epoch 1129/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3606 - mse: 1.3524 - val_loss: 1.2308 - val_mse: 1.2226\n",
      "Epoch 1130/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3800 - mse: 1.3719\n",
      "Epoch 01130: saving model to Regression_Model/mle.linear-1130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3836 - mse: 1.3755 - val_loss: 1.2284 - val_mse: 1.2202\n",
      "Epoch 1131/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3561 - mse: 1.3480 - val_loss: 1.2236 - val_mse: 1.2155\n",
      "Epoch 1132/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3643 - mse: 1.3561 - val_loss: 1.2238 - val_mse: 1.2156\n",
      "Epoch 1133/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3832 - mse: 1.3751 - val_loss: 1.2283 - val_mse: 1.2202\n",
      "Epoch 1134/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3718 - mse: 1.3636 - val_loss: 1.2290 - val_mse: 1.2208\n",
      "Epoch 1135/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3645 - mse: 1.3564 - val_loss: 1.2263 - val_mse: 1.2182\n",
      "Epoch 1136/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3760 - mse: 1.3678 - val_loss: 1.2287 - val_mse: 1.2206\n",
      "Epoch 1137/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3633 - mse: 1.3552 - val_loss: 1.2243 - val_mse: 1.2161\n",
      "Epoch 1138/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3704 - mse: 1.3622 - val_loss: 1.2250 - val_mse: 1.2168\n",
      "Epoch 1139/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3741 - mse: 1.3659 - val_loss: 1.2313 - val_mse: 1.2232\n",
      "Epoch 1140/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3721 - mse: 1.3640\n",
      "Epoch 01140: saving model to Regression_Model/mle.linear-1140.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3679 - mse: 1.3598 - val_loss: 1.2280 - val_mse: 1.2199\n",
      "Epoch 1141/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3820 - mse: 1.3738 - val_loss: 1.2297 - val_mse: 1.2215\n",
      "Epoch 1142/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3765 - mse: 1.3684 - val_loss: 1.2268 - val_mse: 1.2187\n",
      "Epoch 1143/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3727 - mse: 1.3646 - val_loss: 1.2297 - val_mse: 1.2215\n",
      "Epoch 1144/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3508 - mse: 1.3427 - val_loss: 1.2269 - val_mse: 1.2187\n",
      "Epoch 1145/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3779 - mse: 1.3697 - val_loss: 1.2255 - val_mse: 1.2173\n",
      "Epoch 1146/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3674 - mse: 1.3592 - val_loss: 1.2288 - val_mse: 1.2207\n",
      "Epoch 1147/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3878 - mse: 1.3797 - val_loss: 1.2292 - val_mse: 1.2211\n",
      "Epoch 1148/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3848 - mse: 1.3767 - val_loss: 1.2333 - val_mse: 1.2252\n",
      "Epoch 1149/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3779 - mse: 1.3697 - val_loss: 1.2296 - val_mse: 1.2214\n",
      "Epoch 1150/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/368 [============================>.] - ETA: 0s - loss: 1.3677 - mse: 1.3596\n",
      "Epoch 01150: saving model to Regression_Model/mle.linear-1150.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3681 - mse: 1.3600 - val_loss: 1.2284 - val_mse: 1.2203\n",
      "Epoch 1151/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3592 - mse: 1.3511 - val_loss: 1.2291 - val_mse: 1.2209\n",
      "Epoch 1152/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3754 - mse: 1.3672 - val_loss: 1.2316 - val_mse: 1.2235\n",
      "Epoch 1153/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3728 - mse: 1.3647 - val_loss: 1.2303 - val_mse: 1.2221\n",
      "Epoch 1154/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3756 - mse: 1.3675 - val_loss: 1.2272 - val_mse: 1.2191\n",
      "Epoch 1155/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3978 - mse: 1.3896 - val_loss: 1.2317 - val_mse: 1.2235\n",
      "Epoch 1156/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3679 - mse: 1.3597 - val_loss: 1.2297 - val_mse: 1.2216\n",
      "Epoch 1157/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3648 - mse: 1.3567 - val_loss: 1.2286 - val_mse: 1.2204\n",
      "Epoch 1158/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3730 - mse: 1.3649 - val_loss: 1.2261 - val_mse: 1.2180\n",
      "Epoch 1159/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3781 - mse: 1.3700 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1160/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3893 - mse: 1.3811\n",
      "Epoch 01160: saving model to Regression_Model/mle.linear-1160.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3888 - mse: 1.3807 - val_loss: 1.2294 - val_mse: 1.2213\n",
      "Epoch 1161/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3826 - mse: 1.3745 - val_loss: 1.2316 - val_mse: 1.2235\n",
      "Epoch 1162/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3676 - mse: 1.3595 - val_loss: 1.2285 - val_mse: 1.2203\n",
      "Epoch 1163/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3769 - mse: 1.3688 - val_loss: 1.2335 - val_mse: 1.2253\n",
      "Epoch 1164/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3746 - mse: 1.3665 - val_loss: 1.2267 - val_mse: 1.2185\n",
      "Epoch 1165/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3778 - mse: 1.3696 - val_loss: 1.2287 - val_mse: 1.2206\n",
      "Epoch 1166/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3770 - mse: 1.3689 - val_loss: 1.2248 - val_mse: 1.2166\n",
      "Epoch 1167/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3772 - mse: 1.3691 - val_loss: 1.2312 - val_mse: 1.2231\n",
      "Epoch 1168/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3688 - mse: 1.3607 - val_loss: 1.2302 - val_mse: 1.2221\n",
      "Epoch 1169/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3547 - mse: 1.3465 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1170/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.3818 - mse: 1.3737\n",
      "Epoch 01170: saving model to Regression_Model/mle.linear-1170.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3777 - mse: 1.3696 - val_loss: 1.2264 - val_mse: 1.2182\n",
      "Epoch 1171/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3799 - mse: 1.3718 - val_loss: 1.2342 - val_mse: 1.2261\n",
      "Epoch 1172/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3632 - mse: 1.3550 - val_loss: 1.2294 - val_mse: 1.2212\n",
      "Epoch 1173/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3746 - mse: 1.3665 - val_loss: 1.2290 - val_mse: 1.2208\n",
      "Epoch 1174/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3733 - mse: 1.3652 - val_loss: 1.2320 - val_mse: 1.2239\n",
      "Epoch 1175/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3760 - mse: 1.3679 - val_loss: 1.2289 - val_mse: 1.2208\n",
      "Epoch 1176/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3664 - mse: 1.3582 - val_loss: 1.2279 - val_mse: 1.2197\n",
      "Epoch 1177/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3845 - mse: 1.3763 - val_loss: 1.2269 - val_mse: 1.2187\n",
      "Epoch 1178/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3802 - mse: 1.3720 - val_loss: 1.2337 - val_mse: 1.2256\n",
      "Epoch 1179/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3849 - mse: 1.3768 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1180/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.3656 - mse: 1.3575\n",
      "Epoch 01180: saving model to Regression_Model/mle.linear-1180.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3594 - mse: 1.3513 - val_loss: 1.2241 - val_mse: 1.2159\n",
      "Epoch 1181/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3868 - mse: 1.3787 - val_loss: 1.2296 - val_mse: 1.2214\n",
      "Epoch 1182/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3677 - mse: 1.3595 - val_loss: 1.2268 - val_mse: 1.2187\n",
      "Epoch 1183/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3797 - mse: 1.3716 - val_loss: 1.2309 - val_mse: 1.2227\n",
      "Epoch 1184/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3723 - mse: 1.3642 - val_loss: 1.2251 - val_mse: 1.2170\n",
      "Epoch 1185/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3821 - mse: 1.3740 - val_loss: 1.2266 - val_mse: 1.2185\n",
      "Epoch 1186/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3643 - mse: 1.3562 - val_loss: 1.2270 - val_mse: 1.2188\n",
      "Epoch 1187/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3895 - mse: 1.3814 - val_loss: 1.2269 - val_mse: 1.2187\n",
      "Epoch 1188/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3642 - mse: 1.3561 - val_loss: 1.2302 - val_mse: 1.2221\n",
      "Epoch 1189/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3804 - mse: 1.3723 - val_loss: 1.2341 - val_mse: 1.2259\n",
      "Epoch 1190/3000\n",
      "348/368 [===========================>..] - ETA: 0s - loss: 1.3665 - mse: 1.3584\n",
      "Epoch 01190: saving model to Regression_Model/mle.linear-1190.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3749 - mse: 1.3668 - val_loss: 1.2278 - val_mse: 1.2197\n",
      "Epoch 1191/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3732 - mse: 1.3651 - val_loss: 1.2324 - val_mse: 1.2243\n",
      "Epoch 1192/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3858 - mse: 1.3777 - val_loss: 1.2296 - val_mse: 1.2214\n",
      "Epoch 1193/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3771 - mse: 1.3690 - val_loss: 1.2298 - val_mse: 1.2217\n",
      "Epoch 1194/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3863 - mse: 1.3782 - val_loss: 1.2288 - val_mse: 1.2206\n",
      "Epoch 1195/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3773 - mse: 1.3692 - val_loss: 1.2300 - val_mse: 1.2219\n",
      "Epoch 1196/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3575 - mse: 1.3493 - val_loss: 1.2330 - val_mse: 1.2249\n",
      "Epoch 1197/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3668 - mse: 1.3587 - val_loss: 1.2292 - val_mse: 1.2211\n",
      "Epoch 1198/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3820 - mse: 1.3739 - val_loss: 1.2251 - val_mse: 1.2170\n",
      "Epoch 1199/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3685 - mse: 1.3603 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1200/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 1.3888 - mse: 1.3807\n",
      "Epoch 01200: saving model to Regression_Model/mle.linear-1200.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3909 - mse: 1.3828 - val_loss: 1.2289 - val_mse: 1.2208\n",
      "Epoch 1201/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3740 - mse: 1.3659 - val_loss: 1.2301 - val_mse: 1.2220\n",
      "Epoch 1202/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3776 - mse: 1.3695 - val_loss: 1.2320 - val_mse: 1.2238\n",
      "Epoch 1203/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3698 - mse: 1.3617 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1204/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3628 - mse: 1.3546 - val_loss: 1.2222 - val_mse: 1.2140\n",
      "Epoch 1205/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3807 - mse: 1.3726 - val_loss: 1.2324 - val_mse: 1.2242\n",
      "Epoch 1206/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3658 - mse: 1.3577 - val_loss: 1.2346 - val_mse: 1.2264\n",
      "Epoch 1207/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3811 - mse: 1.3730 - val_loss: 1.2262 - val_mse: 1.2181\n",
      "Epoch 1208/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3711 - mse: 1.3630 - val_loss: 1.2268 - val_mse: 1.2187\n",
      "Epoch 1209/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3628 - mse: 1.3547 - val_loss: 1.2263 - val_mse: 1.2182\n",
      "Epoch 1210/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.3741 - mse: 1.3660\n",
      "Epoch 01210: saving model to Regression_Model/mle.linear-1210.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3799 - mse: 1.3718 - val_loss: 1.2278 - val_mse: 1.2197\n",
      "Epoch 1211/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3654 - mse: 1.3572 - val_loss: 1.2315 - val_mse: 1.2234\n",
      "Epoch 1212/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3665 - mse: 1.3584 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1213/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3763 - mse: 1.3681 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1214/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3692 - mse: 1.3611 - val_loss: 1.2272 - val_mse: 1.2190\n",
      "Epoch 1215/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3738 - mse: 1.3657 - val_loss: 1.2248 - val_mse: 1.2166\n",
      "Epoch 1216/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3642 - val_loss: 1.2268 - val_mse: 1.2187\n",
      "Epoch 1217/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3777 - mse: 1.3696 - val_loss: 1.2344 - val_mse: 1.2263\n",
      "Epoch 1218/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3686 - mse: 1.3605 - val_loss: 1.2292 - val_mse: 1.2210\n",
      "Epoch 1219/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3586 - mse: 1.3505 - val_loss: 1.2323 - val_mse: 1.2242\n",
      "Epoch 1220/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 1.3595 - mse: 1.3514\n",
      "Epoch 01220: saving model to Regression_Model/mle.linear-1220.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3630 - mse: 1.3549 - val_loss: 1.2302 - val_mse: 1.2221\n",
      "Epoch 1221/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3674 - mse: 1.3593 - val_loss: 1.2257 - val_mse: 1.2176\n",
      "Epoch 1222/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3585 - mse: 1.3504 - val_loss: 1.2225 - val_mse: 1.2143\n",
      "Epoch 1223/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3767 - mse: 1.3686 - val_loss: 1.2258 - val_mse: 1.2176\n",
      "Epoch 1224/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3681 - mse: 1.3600 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1225/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3818 - mse: 1.3736 - val_loss: 1.2271 - val_mse: 1.2190\n",
      "Epoch 1226/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3698 - mse: 1.3617 - val_loss: 1.2335 - val_mse: 1.2254\n",
      "Epoch 1227/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3912 - mse: 1.3831 - val_loss: 1.2235 - val_mse: 1.2154\n",
      "Epoch 1228/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3725 - mse: 1.3643 - val_loss: 1.2271 - val_mse: 1.2190\n",
      "Epoch 1229/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3816 - mse: 1.3734 - val_loss: 1.2289 - val_mse: 1.2208\n",
      "Epoch 1230/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.3666 - mse: 1.3585\n",
      "Epoch 01230: saving model to Regression_Model/mle.linear-1230.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3695 - mse: 1.3614 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1231/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3686 - mse: 1.3604 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1232/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3706 - mse: 1.3625 - val_loss: 1.2261 - val_mse: 1.2180\n",
      "Epoch 1233/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3716 - mse: 1.3635 - val_loss: 1.2309 - val_mse: 1.2228\n",
      "Epoch 1234/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3629 - mse: 1.3548 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1235/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3608 - mse: 1.3527 - val_loss: 1.2275 - val_mse: 1.2194\n",
      "Epoch 1236/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3613 - mse: 1.3532 - val_loss: 1.2281 - val_mse: 1.2200\n",
      "Epoch 1237/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3594 - mse: 1.3513 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 1238/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3700 - mse: 1.3619 - val_loss: 1.2232 - val_mse: 1.2151\n",
      "Epoch 1239/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3648 - mse: 1.3567 - val_loss: 1.2278 - val_mse: 1.2197\n",
      "Epoch 1240/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3687 - mse: 1.3605\n",
      "Epoch 01240: saving model to Regression_Model/mle.linear-1240.ckpt\n",
      "368/368 [==============================] - 3s 7ms/step - loss: 1.3703 - mse: 1.3622 - val_loss: 1.2278 - val_mse: 1.2197\n",
      "Epoch 1241/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3785 - mse: 1.3704 - val_loss: 1.2289 - val_mse: 1.2208\n",
      "Epoch 1242/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3756 - mse: 1.3675 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1243/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3721 - mse: 1.3640 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1244/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3778 - mse: 1.3697 - val_loss: 1.2280 - val_mse: 1.2199\n",
      "Epoch 1245/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3542 - mse: 1.3461 - val_loss: 1.2206 - val_mse: 1.2125\n",
      "Epoch 1246/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3594 - mse: 1.3513 - val_loss: 1.2238 - val_mse: 1.2157\n",
      "Epoch 1247/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3739 - mse: 1.3658 - val_loss: 1.2275 - val_mse: 1.2194\n",
      "Epoch 1248/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3636 - mse: 1.3555 - val_loss: 1.2261 - val_mse: 1.2180\n",
      "Epoch 1249/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3741 - mse: 1.3660 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1250/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.3907 - mse: 1.3826\n",
      "Epoch 01250: saving model to Regression_Model/mle.linear-1250.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3813 - mse: 1.3732 - val_loss: 1.2273 - val_mse: 1.2192\n",
      "Epoch 1251/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3543 - mse: 1.3462 - val_loss: 1.2229 - val_mse: 1.2148\n",
      "Epoch 1252/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3743 - mse: 1.3662 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1253/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3680 - mse: 1.3598 - val_loss: 1.2280 - val_mse: 1.2198\n",
      "Epoch 1254/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3717 - mse: 1.3636 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1255/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3646 - mse: 1.3565 - val_loss: 1.2273 - val_mse: 1.2192\n",
      "Epoch 1256/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3857 - mse: 1.3775 - val_loss: 1.2251 - val_mse: 1.2170\n",
      "Epoch 1257/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3980 - mse: 1.3899 - val_loss: 1.2262 - val_mse: 1.2181\n",
      "Epoch 1258/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3806 - mse: 1.3725 - val_loss: 1.2278 - val_mse: 1.2197\n",
      "Epoch 1259/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3766 - mse: 1.3685 - val_loss: 1.2286 - val_mse: 1.2205\n",
      "Epoch 1260/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3824 - mse: 1.3743\n",
      "Epoch 01260: saving model to Regression_Model/mle.linear-1260.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3811 - mse: 1.3730 - val_loss: 1.2311 - val_mse: 1.2230\n",
      "Epoch 1261/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3785 - mse: 1.3704 - val_loss: 1.2264 - val_mse: 1.2183\n",
      "Epoch 1262/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3934 - mse: 1.3853 - val_loss: 1.2288 - val_mse: 1.2207\n",
      "Epoch 1263/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3627 - mse: 1.3546 - val_loss: 1.2267 - val_mse: 1.2186\n",
      "Epoch 1264/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3840 - mse: 1.3759 - val_loss: 1.2312 - val_mse: 1.2231\n",
      "Epoch 1265/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3835 - mse: 1.3754 - val_loss: 1.2295 - val_mse: 1.2214\n",
      "Epoch 1266/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3720 - mse: 1.3639 - val_loss: 1.2316 - val_mse: 1.2235\n",
      "Epoch 1267/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3877 - mse: 1.3796 - val_loss: 1.2285 - val_mse: 1.2204\n",
      "Epoch 1268/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3834 - mse: 1.3753 - val_loss: 1.2312 - val_mse: 1.2231\n",
      "Epoch 1269/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3712 - mse: 1.3631 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1270/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.3746 - mse: 1.3665\n",
      "Epoch 01270: saving model to Regression_Model/mle.linear-1270.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3730 - mse: 1.3649 - val_loss: 1.2268 - val_mse: 1.2187\n",
      "Epoch 1271/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3670 - mse: 1.3589 - val_loss: 1.2284 - val_mse: 1.2203\n",
      "Epoch 1272/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3712 - mse: 1.3631 - val_loss: 1.2294 - val_mse: 1.2213\n",
      "Epoch 1273/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3835 - mse: 1.3754 - val_loss: 1.2334 - val_mse: 1.2253\n",
      "Epoch 1274/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3852 - mse: 1.3771 - val_loss: 1.2281 - val_mse: 1.2200\n",
      "Epoch 1275/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3701 - mse: 1.3620 - val_loss: 1.2267 - val_mse: 1.2186\n",
      "Epoch 1276/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3677 - mse: 1.3596 - val_loss: 1.2289 - val_mse: 1.2208\n",
      "Epoch 1277/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3761 - mse: 1.3680 - val_loss: 1.2274 - val_mse: 1.2193\n",
      "Epoch 1278/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3688 - mse: 1.3607 - val_loss: 1.2273 - val_mse: 1.2192\n",
      "Epoch 1279/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3741 - mse: 1.3660 - val_loss: 1.2249 - val_mse: 1.2168\n",
      "Epoch 1280/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.3781 - mse: 1.3700\n",
      "Epoch 01280: saving model to Regression_Model/mle.linear-1280.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3730 - mse: 1.3649 - val_loss: 1.2266 - val_mse: 1.2185\n",
      "Epoch 1281/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3808 - mse: 1.3727 - val_loss: 1.2300 - val_mse: 1.2219\n",
      "Epoch 1282/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3743 - mse: 1.3662 - val_loss: 1.2269 - val_mse: 1.2188\n",
      "Epoch 1283/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3677 - mse: 1.3596 - val_loss: 1.2302 - val_mse: 1.2221\n",
      "Epoch 1284/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3751 - mse: 1.3670 - val_loss: 1.2236 - val_mse: 1.2155\n",
      "Epoch 1285/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3858 - mse: 1.3777 - val_loss: 1.2291 - val_mse: 1.2210\n",
      "Epoch 1286/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3626 - mse: 1.3545 - val_loss: 1.2298 - val_mse: 1.2217\n",
      "Epoch 1287/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3674 - mse: 1.3593 - val_loss: 1.2267 - val_mse: 1.2186\n",
      "Epoch 1288/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3691 - mse: 1.3610 - val_loss: 1.2260 - val_mse: 1.2179\n",
      "Epoch 1289/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3675 - mse: 1.3594 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1290/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3575 - mse: 1.3494\n",
      "Epoch 01290: saving model to Regression_Model/mle.linear-1290.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3684 - mse: 1.3603 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 1291/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3808 - mse: 1.3727 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1292/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3802 - mse: 1.3721 - val_loss: 1.2303 - val_mse: 1.2222\n",
      "Epoch 1293/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3740 - mse: 1.3659 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1294/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.4040 - mse: 1.3959 - val_loss: 1.2315 - val_mse: 1.2234\n",
      "Epoch 1295/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3642 - mse: 1.3561 - val_loss: 1.2266 - val_mse: 1.2185\n",
      "Epoch 1296/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3823 - mse: 1.3742 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1297/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3712 - mse: 1.3631 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1298/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3651 - mse: 1.3570 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1299/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3681 - mse: 1.3600 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1300/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 1.3776 - mse: 1.3695\n",
      "Epoch 01300: saving model to Regression_Model/mle.linear-1300.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3768 - mse: 1.3687 - val_loss: 1.2314 - val_mse: 1.2234\n",
      "Epoch 1301/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3868 - mse: 1.3788 - val_loss: 1.2289 - val_mse: 1.2208\n",
      "Epoch 1302/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3719 - mse: 1.3638 - val_loss: 1.2272 - val_mse: 1.2191\n",
      "Epoch 1303/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3875 - mse: 1.3794 - val_loss: 1.2297 - val_mse: 1.2216\n",
      "Epoch 1304/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3651 - mse: 1.3570 - val_loss: 1.2276 - val_mse: 1.2195\n",
      "Epoch 1305/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3812 - mse: 1.3731 - val_loss: 1.2343 - val_mse: 1.2262\n",
      "Epoch 1306/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3692 - mse: 1.3611 - val_loss: 1.2284 - val_mse: 1.2203\n",
      "Epoch 1307/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3609 - mse: 1.3528 - val_loss: 1.2285 - val_mse: 1.2204\n",
      "Epoch 1308/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3666 - mse: 1.3586 - val_loss: 1.2257 - val_mse: 1.2176\n",
      "Epoch 1309/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3669 - mse: 1.3589 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1310/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.3805 - mse: 1.3724\n",
      "Epoch 01310: saving model to Regression_Model/mle.linear-1310.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3708 - mse: 1.3627 - val_loss: 1.2269 - val_mse: 1.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1311/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3731 - mse: 1.3650 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1312/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3864 - mse: 1.3783 - val_loss: 1.2287 - val_mse: 1.2206\n",
      "Epoch 1313/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3682 - mse: 1.3601 - val_loss: 1.2252 - val_mse: 1.2171\n",
      "Epoch 1314/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3780 - mse: 1.3700 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1315/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3861 - mse: 1.3780 - val_loss: 1.2301 - val_mse: 1.2220\n",
      "Epoch 1316/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3514 - mse: 1.3433 - val_loss: 1.2276 - val_mse: 1.2196\n",
      "Epoch 1317/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3682 - mse: 1.3601 - val_loss: 1.2270 - val_mse: 1.2189\n",
      "Epoch 1318/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3789 - mse: 1.3708 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1319/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3913 - mse: 1.3833 - val_loss: 1.2288 - val_mse: 1.2207\n",
      "Epoch 1320/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.3632 - mse: 1.3551\n",
      "Epoch 01320: saving model to Regression_Model/mle.linear-1320.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3667 - mse: 1.3586 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1321/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3533 - mse: 1.3452 - val_loss: 1.2229 - val_mse: 1.2148\n",
      "Epoch 1322/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3860 - mse: 1.3779 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1323/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3719 - mse: 1.3638 - val_loss: 1.2274 - val_mse: 1.2193\n",
      "Epoch 1324/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3663 - mse: 1.3582 - val_loss: 1.2264 - val_mse: 1.2183\n",
      "Epoch 1325/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3807 - mse: 1.3727 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 1326/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3800 - mse: 1.3719 - val_loss: 1.2294 - val_mse: 1.2213\n",
      "Epoch 1327/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3678 - mse: 1.3597 - val_loss: 1.2286 - val_mse: 1.2206\n",
      "Epoch 1328/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3727 - mse: 1.3646 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1329/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3726 - mse: 1.3645 - val_loss: 1.2292 - val_mse: 1.2211\n",
      "Epoch 1330/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3676 - mse: 1.3595\n",
      "Epoch 01330: saving model to Regression_Model/mle.linear-1330.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3713 - mse: 1.3632 - val_loss: 1.2287 - val_mse: 1.2206\n",
      "Epoch 1331/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3698 - mse: 1.3617 - val_loss: 1.2274 - val_mse: 1.2193\n",
      "Epoch 1332/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3618 - mse: 1.3537 - val_loss: 1.2270 - val_mse: 1.2190\n",
      "Epoch 1333/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3713 - mse: 1.3632 - val_loss: 1.2307 - val_mse: 1.2226\n",
      "Epoch 1334/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3672 - mse: 1.3592 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1335/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3732 - mse: 1.3652 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1336/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3632 - mse: 1.3551 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1337/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3593 - mse: 1.3512 - val_loss: 1.2254 - val_mse: 1.2173\n",
      "Epoch 1338/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3770 - mse: 1.3689 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1339/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3631 - mse: 1.3550 - val_loss: 1.2223 - val_mse: 1.2142\n",
      "Epoch 1340/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.3787 - mse: 1.3706\n",
      "Epoch 01340: saving model to Regression_Model/mle.linear-1340.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3756 - mse: 1.3675 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1341/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3577 - mse: 1.3496 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1342/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3630 - mse: 1.3549 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1343/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3856 - mse: 1.3776 - val_loss: 1.2275 - val_mse: 1.2194\n",
      "Epoch 1344/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3719 - mse: 1.3638 - val_loss: 1.2277 - val_mse: 1.2197\n",
      "Epoch 1345/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3548 - mse: 1.3467 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1346/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3647 - mse: 1.3566 - val_loss: 1.2275 - val_mse: 1.2194\n",
      "Epoch 1347/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3639 - mse: 1.3558 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1348/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3754 - mse: 1.3673 - val_loss: 1.2262 - val_mse: 1.2181\n",
      "Epoch 1349/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3688 - mse: 1.3607 - val_loss: 1.2292 - val_mse: 1.2211\n",
      "Epoch 1350/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3735 - mse: 1.3654\n",
      "Epoch 01350: saving model to Regression_Model/mle.linear-1350.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3674 - mse: 1.3594 - val_loss: 1.2281 - val_mse: 1.2200\n",
      "Epoch 1351/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3747 - mse: 1.3666 - val_loss: 1.2293 - val_mse: 1.2212\n",
      "Epoch 1352/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3671 - mse: 1.3591 - val_loss: 1.2319 - val_mse: 1.2238\n",
      "Epoch 1353/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3697 - mse: 1.3616 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1354/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3663 - mse: 1.3582 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1355/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3722 - mse: 1.3642 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 1356/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3735 - mse: 1.3654 - val_loss: 1.2257 - val_mse: 1.2176\n",
      "Epoch 1357/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3636 - mse: 1.3555 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1358/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3635 - mse: 1.3555 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1359/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3827 - mse: 1.3747 - val_loss: 1.2267 - val_mse: 1.2187\n",
      "Epoch 1360/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3720 - mse: 1.3639\n",
      "Epoch 01360: saving model to Regression_Model/mle.linear-1360.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3736 - mse: 1.3655 - val_loss: 1.2269 - val_mse: 1.2188\n",
      "Epoch 1361/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3584 - mse: 1.3504 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1362/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3608 - mse: 1.3527 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1363/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3814 - mse: 1.3734 - val_loss: 1.2232 - val_mse: 1.2152\n",
      "Epoch 1364/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3666 - mse: 1.3585 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1365/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3614 - mse: 1.3534 - val_loss: 1.2260 - val_mse: 1.2179\n",
      "Epoch 1366/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3802 - mse: 1.3721 - val_loss: 1.2268 - val_mse: 1.2187\n",
      "Epoch 1367/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3852 - mse: 1.3771 - val_loss: 1.2236 - val_mse: 1.2155\n",
      "Epoch 1368/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3738 - mse: 1.3657 - val_loss: 1.2262 - val_mse: 1.2182\n",
      "Epoch 1369/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3840 - mse: 1.3759 - val_loss: 1.2293 - val_mse: 1.2212\n",
      "Epoch 1370/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.3612 - mse: 1.3531\n",
      "Epoch 01370: saving model to Regression_Model/mle.linear-1370.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 1.3605 - mse: 1.3525 - val_loss: 1.2287 - val_mse: 1.2206\n",
      "Epoch 1371/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3792 - mse: 1.3711 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1372/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3699 - mse: 1.3618 - val_loss: 1.2260 - val_mse: 1.2179\n",
      "Epoch 1373/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3748 - mse: 1.3667 - val_loss: 1.2292 - val_mse: 1.2212\n",
      "Epoch 1374/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3864 - mse: 1.3783 - val_loss: 1.2281 - val_mse: 1.2200\n",
      "Epoch 1375/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3602 - mse: 1.3521 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1376/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3644 - mse: 1.3563 - val_loss: 1.2275 - val_mse: 1.2194\n",
      "Epoch 1377/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3831 - mse: 1.3750 - val_loss: 1.2310 - val_mse: 1.2230\n",
      "Epoch 1378/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3491 - mse: 1.3410 - val_loss: 1.2252 - val_mse: 1.2171\n",
      "Epoch 1379/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3527 - mse: 1.3446 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 1380/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.3626 - mse: 1.3545\n",
      "Epoch 01380: saving model to Regression_Model/mle.linear-1380.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3627 - mse: 1.3546 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1381/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3605 - mse: 1.3524 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1382/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3839 - mse: 1.3758 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1383/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3736 - mse: 1.3655 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1384/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3538 - mse: 1.3457 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1385/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3706 - mse: 1.3625 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1386/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3739 - mse: 1.3658 - val_loss: 1.2232 - val_mse: 1.2151\n",
      "Epoch 1387/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3538 - mse: 1.3457 - val_loss: 1.2231 - val_mse: 1.2151\n",
      "Epoch 1388/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3452 - mse: 1.3371 - val_loss: 1.2235 - val_mse: 1.2154\n",
      "Epoch 1389/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3819 - mse: 1.3738 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1390/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.3633 - mse: 1.3552\n",
      "Epoch 01390: saving model to Regression_Model/mle.linear-1390.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3735 - mse: 1.3654 - val_loss: 1.2224 - val_mse: 1.2144\n",
      "Epoch 1391/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3715 - mse: 1.3634 - val_loss: 1.2272 - val_mse: 1.2192\n",
      "Epoch 1392/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3748 - mse: 1.3668 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1393/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3732 - mse: 1.3651 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1394/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3781 - mse: 1.3700 - val_loss: 1.2287 - val_mse: 1.2207\n",
      "Epoch 1395/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3637 - mse: 1.3556 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1396/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3732 - mse: 1.3651 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1397/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3827 - mse: 1.3746 - val_loss: 1.2271 - val_mse: 1.2191\n",
      "Epoch 1398/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3697 - mse: 1.3617 - val_loss: 1.2281 - val_mse: 1.2201\n",
      "Epoch 1399/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3864 - mse: 1.3783 - val_loss: 1.2280 - val_mse: 1.2199\n",
      "Epoch 1400/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.3609 - mse: 1.3529\n",
      "Epoch 01400: saving model to Regression_Model/mle.linear-1400.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3643 - mse: 1.3562 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1401/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3708 - mse: 1.3627 - val_loss: 1.2283 - val_mse: 1.2202\n",
      "Epoch 1402/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3733 - mse: 1.3652 - val_loss: 1.2273 - val_mse: 1.2192\n",
      "Epoch 1403/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3842 - mse: 1.3761 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1404/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3699 - mse: 1.3618 - val_loss: 1.2272 - val_mse: 1.2192\n",
      "Epoch 1405/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3782 - mse: 1.3701 - val_loss: 1.2247 - val_mse: 1.2166\n",
      "Epoch 1406/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3790 - mse: 1.3710 - val_loss: 1.2302 - val_mse: 1.2221\n",
      "Epoch 1407/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3675 - mse: 1.3594 - val_loss: 1.2278 - val_mse: 1.2197\n",
      "Epoch 1408/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3753 - mse: 1.3672 - val_loss: 1.2277 - val_mse: 1.2197\n",
      "Epoch 1409/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3650 - mse: 1.3570 - val_loss: 1.2257 - val_mse: 1.2176\n",
      "Epoch 1410/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3805 - mse: 1.3724\n",
      "Epoch 01410: saving model to Regression_Model/mle.linear-1410.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3735 - mse: 1.3655 - val_loss: 1.2269 - val_mse: 1.2188\n",
      "Epoch 1411/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3599 - mse: 1.3519 - val_loss: 1.2288 - val_mse: 1.2207\n",
      "Epoch 1412/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3787 - mse: 1.3706 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1413/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3640 - mse: 1.3559 - val_loss: 1.2234 - val_mse: 1.2153\n",
      "Epoch 1414/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3658 - mse: 1.3577 - val_loss: 1.2288 - val_mse: 1.2207\n",
      "Epoch 1415/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3692 - mse: 1.3611 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1416/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3653 - mse: 1.3572 - val_loss: 1.2258 - val_mse: 1.2177\n",
      "Epoch 1417/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3781 - mse: 1.3700 - val_loss: 1.2276 - val_mse: 1.2195\n",
      "Epoch 1418/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3664 - mse: 1.3584 - val_loss: 1.2254 - val_mse: 1.2173\n",
      "Epoch 1419/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3758 - mse: 1.3678 - val_loss: 1.2263 - val_mse: 1.2182\n",
      "Epoch 1420/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3764 - mse: 1.3683\n",
      "Epoch 01420: saving model to Regression_Model/mle.linear-1420.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3711 - mse: 1.3631 - val_loss: 1.2269 - val_mse: 1.2189\n",
      "Epoch 1421/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3316 - mse: 1.3235 - val_loss: 1.2219 - val_mse: 1.2138\n",
      "Epoch 1422/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3628 - mse: 1.3547 - val_loss: 1.2259 - val_mse: 1.2179\n",
      "Epoch 1423/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3631 - mse: 1.3551 - val_loss: 1.2263 - val_mse: 1.2182\n",
      "Epoch 1424/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3702 - mse: 1.3621 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1425/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3653 - mse: 1.3572 - val_loss: 1.2263 - val_mse: 1.2182\n",
      "Epoch 1426/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3903 - mse: 1.3822 - val_loss: 1.2278 - val_mse: 1.2197\n",
      "Epoch 1427/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3787 - mse: 1.3706 - val_loss: 1.2254 - val_mse: 1.2173\n",
      "Epoch 1428/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3703 - mse: 1.3622 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1429/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3665 - mse: 1.3584 - val_loss: 1.2231 - val_mse: 1.2151\n",
      "Epoch 1430/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3868 - mse: 1.3787\n",
      "Epoch 01430: saving model to Regression_Model/mle.linear-1430.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3802 - mse: 1.3721 - val_loss: 1.2283 - val_mse: 1.2202\n",
      "Epoch 1431/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3677 - mse: 1.3597 - val_loss: 1.2284 - val_mse: 1.2203\n",
      "Epoch 1432/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3566 - mse: 1.3486 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1433/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3785 - mse: 1.3704 - val_loss: 1.2237 - val_mse: 1.2156\n",
      "Epoch 1434/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3757 - mse: 1.3677 - val_loss: 1.2262 - val_mse: 1.2181\n",
      "Epoch 1435/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3767 - mse: 1.3686 - val_loss: 1.2262 - val_mse: 1.2182\n",
      "Epoch 1436/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3766 - mse: 1.3685 - val_loss: 1.2280 - val_mse: 1.2199\n",
      "Epoch 1437/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3773 - mse: 1.3693 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1438/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3636 - mse: 1.3555 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1439/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3638 - mse: 1.3557 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1440/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 1.3817 - mse: 1.3737\n",
      "Epoch 01440: saving model to Regression_Model/mle.linear-1440.ckpt\n",
      "368/368 [==============================] - 3s 9ms/step - loss: 1.3811 - mse: 1.3731 - val_loss: 1.2257 - val_mse: 1.2177\n",
      "Epoch 1441/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3655 - mse: 1.3575 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1442/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3569 - mse: 1.3488 - val_loss: 1.2261 - val_mse: 1.2180\n",
      "Epoch 1443/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3717 - mse: 1.3637 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1444/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3864 - mse: 1.3783 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1445/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3637 - mse: 1.3556 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1446/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3605 - mse: 1.3524 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1447/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3601 - mse: 1.3520 - val_loss: 1.2238 - val_mse: 1.2157\n",
      "Epoch 1448/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3720 - mse: 1.3640 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 1449/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3808 - mse: 1.3728 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1450/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3836 - mse: 1.3756\n",
      "Epoch 01450: saving model to Regression_Model/mle.linear-1450.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3782 - mse: 1.3702 - val_loss: 1.2232 - val_mse: 1.2151\n",
      "Epoch 1451/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3654 - mse: 1.3574 - val_loss: 1.2217 - val_mse: 1.2136\n",
      "Epoch 1452/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3711 - mse: 1.3631 - val_loss: 1.2268 - val_mse: 1.2187\n",
      "Epoch 1453/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3755 - mse: 1.3674 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1454/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3668 - mse: 1.3587 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1455/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3638 - mse: 1.3557 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1456/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3849 - mse: 1.3768 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1457/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3856 - mse: 1.3775 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1458/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3786 - mse: 1.3705 - val_loss: 1.2280 - val_mse: 1.2199\n",
      "Epoch 1459/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3640 - mse: 1.3559 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 1460/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.3724 - mse: 1.3643\n",
      "Epoch 01460: saving model to Regression_Model/mle.linear-1460.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3721 - mse: 1.3640 - val_loss: 1.2251 - val_mse: 1.2170\n",
      "Epoch 1461/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3673 - mse: 1.3592 - val_loss: 1.2226 - val_mse: 1.2145\n",
      "Epoch 1462/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3620 - mse: 1.3540 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1463/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3714 - mse: 1.3633 - val_loss: 1.2235 - val_mse: 1.2154\n",
      "Epoch 1464/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3703 - mse: 1.3623 - val_loss: 1.2241 - val_mse: 1.2160\n",
      "Epoch 1465/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3828 - mse: 1.3748 - val_loss: 1.2265 - val_mse: 1.2185\n",
      "Epoch 1466/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3832 - mse: 1.3752 - val_loss: 1.2285 - val_mse: 1.2204\n",
      "Epoch 1467/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3749 - mse: 1.3669 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1468/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3722 - mse: 1.3642 - val_loss: 1.2247 - val_mse: 1.2166\n",
      "Epoch 1469/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3653 - mse: 1.3573 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 1470/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.3770 - mse: 1.3689\n",
      "Epoch 01470: saving model to Regression_Model/mle.linear-1470.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 1.3848 - mse: 1.3767 - val_loss: 1.2288 - val_mse: 1.2208\n",
      "Epoch 1471/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3862 - mse: 1.3781 - val_loss: 1.2271 - val_mse: 1.2190\n",
      "Epoch 1472/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3553 - mse: 1.3473 - val_loss: 1.2232 - val_mse: 1.2152\n",
      "Epoch 1473/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3771 - mse: 1.3691 - val_loss: 1.2228 - val_mse: 1.2148\n",
      "Epoch 1474/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3562 - mse: 1.3482 - val_loss: 1.2260 - val_mse: 1.2180\n",
      "Epoch 1475/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3806 - mse: 1.3726 - val_loss: 1.2276 - val_mse: 1.2195\n",
      "Epoch 1476/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3821 - mse: 1.3740 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1477/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3664 - mse: 1.3583 - val_loss: 1.2232 - val_mse: 1.2151\n",
      "Epoch 1478/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3821 - mse: 1.3740 - val_loss: 1.2264 - val_mse: 1.2183\n",
      "Epoch 1479/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3657 - mse: 1.3576 - val_loss: 1.2263 - val_mse: 1.2183\n",
      "Epoch 1480/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.3639 - mse: 1.3559\n",
      "Epoch 01480: saving model to Regression_Model/mle.linear-1480.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3638 - mse: 1.3558 - val_loss: 1.2253 - val_mse: 1.2173\n",
      "Epoch 1481/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3832 - mse: 1.3751 - val_loss: 1.2262 - val_mse: 1.2181\n",
      "Epoch 1482/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3859 - mse: 1.3779 - val_loss: 1.2271 - val_mse: 1.2190\n",
      "Epoch 1483/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3579 - mse: 1.3499 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1484/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3758 - mse: 1.3677 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1485/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3665 - mse: 1.3584 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1486/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3523 - mse: 1.3442 - val_loss: 1.2279 - val_mse: 1.2198\n",
      "Epoch 1487/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3624 - mse: 1.3544 - val_loss: 1.2235 - val_mse: 1.2154\n",
      "Epoch 1488/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3621 - mse: 1.3540 - val_loss: 1.2272 - val_mse: 1.2192\n",
      "Epoch 1489/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3946 - mse: 1.3865 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1490/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3682 - mse: 1.3602\n",
      "Epoch 01490: saving model to Regression_Model/mle.linear-1490.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3711 - mse: 1.3631 - val_loss: 1.2275 - val_mse: 1.2195\n",
      "Epoch 1491/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3734 - mse: 1.3653 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1492/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3630 - mse: 1.3550 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1493/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3696 - mse: 1.3615 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1494/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3814 - mse: 1.3734 - val_loss: 1.2281 - val_mse: 1.2201\n",
      "Epoch 1495/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3680 - mse: 1.3600 - val_loss: 1.2280 - val_mse: 1.2200\n",
      "Epoch 1496/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3632 - mse: 1.3552 - val_loss: 1.2276 - val_mse: 1.2196\n",
      "Epoch 1497/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3803 - mse: 1.3723 - val_loss: 1.2288 - val_mse: 1.2207\n",
      "Epoch 1498/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3689 - mse: 1.3609 - val_loss: 1.2270 - val_mse: 1.2189\n",
      "Epoch 1499/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3573 - mse: 1.3493 - val_loss: 1.2231 - val_mse: 1.2150\n",
      "Epoch 1500/3000\n",
      "360/368 [============================>.] - ETA: 0s - loss: 1.3829 - mse: 1.3748\n",
      "Epoch 01500: saving model to Regression_Model/mle.linear-1500.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3783 - mse: 1.3702 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1501/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3768 - mse: 1.3687 - val_loss: 1.2235 - val_mse: 1.2154\n",
      "Epoch 1502/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3731 - mse: 1.3651 - val_loss: 1.2228 - val_mse: 1.2148\n",
      "Epoch 1503/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3463 - mse: 1.3383 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1504/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3732 - mse: 1.3651 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1505/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3865 - mse: 1.3784 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1506/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3582 - mse: 1.3501 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1507/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3736 - mse: 1.3656 - val_loss: 1.2260 - val_mse: 1.2179\n",
      "Epoch 1508/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3567 - mse: 1.3486 - val_loss: 1.2252 - val_mse: 1.2171\n",
      "Epoch 1509/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3729 - mse: 1.3649 - val_loss: 1.2258 - val_mse: 1.2178\n",
      "Epoch 1510/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.3747 - mse: 1.3666\n",
      "Epoch 01510: saving model to Regression_Model/mle.linear-1510.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 1.3677 - mse: 1.3596 - val_loss: 1.2265 - val_mse: 1.2185\n",
      "Epoch 1511/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3850 - mse: 1.3769 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1512/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3791 - mse: 1.3710 - val_loss: 1.2258 - val_mse: 1.2178\n",
      "Epoch 1513/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3630 - mse: 1.3550 - val_loss: 1.2266 - val_mse: 1.2185\n",
      "Epoch 1514/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3575 - mse: 1.3494 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1515/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3763 - mse: 1.3682 - val_loss: 1.2266 - val_mse: 1.2185\n",
      "Epoch 1516/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3697 - mse: 1.3617 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1517/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3643 - mse: 1.3563 - val_loss: 1.2258 - val_mse: 1.2178\n",
      "Epoch 1518/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3839 - mse: 1.3758 - val_loss: 1.2260 - val_mse: 1.2179\n",
      "Epoch 1519/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3944 - mse: 1.3863 - val_loss: 1.2260 - val_mse: 1.2180\n",
      "Epoch 1520/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3671 - mse: 1.3590\n",
      "Epoch 01520: saving model to Regression_Model/mle.linear-1520.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3637 - mse: 1.3556 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1521/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3733 - mse: 1.3653 - val_loss: 1.2269 - val_mse: 1.2188\n",
      "Epoch 1522/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3790 - mse: 1.3710 - val_loss: 1.2262 - val_mse: 1.2182\n",
      "Epoch 1523/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3653 - mse: 1.3572 - val_loss: 1.2258 - val_mse: 1.2178\n",
      "Epoch 1524/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3689 - mse: 1.3609 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1525/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3731 - mse: 1.3651 - val_loss: 1.2267 - val_mse: 1.2186\n",
      "Epoch 1526/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3738 - mse: 1.3657 - val_loss: 1.2253 - val_mse: 1.2173\n",
      "Epoch 1527/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3605 - mse: 1.3524 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1528/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3705 - mse: 1.3625 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1529/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3889 - mse: 1.3809 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1530/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3898 - mse: 1.3817\n",
      "Epoch 01530: saving model to Regression_Model/mle.linear-1530.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3903 - mse: 1.3823 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1531/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3704 - mse: 1.3624 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1532/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3782 - mse: 1.3702 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1533/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3918 - mse: 1.3838 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1534/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3794 - mse: 1.3714 - val_loss: 1.2249 - val_mse: 1.2168\n",
      "Epoch 1535/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3591 - mse: 1.3511 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1536/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3628 - mse: 1.3547 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1537/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3767 - mse: 1.3686 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1538/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3599 - mse: 1.3519 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1539/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3643 - mse: 1.3563 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1540/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.3706 - mse: 1.3625\n",
      "Epoch 01540: saving model to Regression_Model/mle.linear-1540.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3840 - mse: 1.3759 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1541/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3740 - mse: 1.3659 - val_loss: 1.2253 - val_mse: 1.2173\n",
      "Epoch 1542/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3714 - mse: 1.3633 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1543/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3635 - mse: 1.3555 - val_loss: 1.2238 - val_mse: 1.2157\n",
      "Epoch 1544/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3449 - mse: 1.3369 - val_loss: 1.2217 - val_mse: 1.2137\n",
      "Epoch 1545/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3768 - mse: 1.3688 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1546/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3813 - mse: 1.3732 - val_loss: 1.2260 - val_mse: 1.2179\n",
      "Epoch 1547/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3817 - mse: 1.3736 - val_loss: 1.2249 - val_mse: 1.2168\n",
      "Epoch 1548/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3777 - mse: 1.3697 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1549/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3661 - mse: 1.3581 - val_loss: 1.2232 - val_mse: 1.2151\n",
      "Epoch 1550/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3638 - mse: 1.3557\n",
      "Epoch 01550: saving model to Regression_Model/mle.linear-1550.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3689 - mse: 1.3608 - val_loss: 1.2231 - val_mse: 1.2151\n",
      "Epoch 1551/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3646 - mse: 1.3566 - val_loss: 1.2269 - val_mse: 1.2188\n",
      "Epoch 1552/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3791 - mse: 1.3710 - val_loss: 1.2234 - val_mse: 1.2154\n",
      "Epoch 1553/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3641 - mse: 1.3561 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1554/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3442 - mse: 1.3361 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1555/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3644 - mse: 1.3563 - val_loss: 1.2231 - val_mse: 1.2151\n",
      "Epoch 1556/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3699 - mse: 1.3619 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 1557/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3700 - mse: 1.3619 - val_loss: 1.2250 - val_mse: 1.2169\n",
      "Epoch 1558/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3716 - mse: 1.3635 - val_loss: 1.2257 - val_mse: 1.2176\n",
      "Epoch 1559/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3834 - mse: 1.3754 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1560/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.3870 - mse: 1.3789\n",
      "Epoch 01560: saving model to Regression_Model/mle.linear-1560.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3852 - mse: 1.3771 - val_loss: 1.2257 - val_mse: 1.2177\n",
      "Epoch 1561/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3710 - mse: 1.3630 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1562/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3728 - mse: 1.3647 - val_loss: 1.2289 - val_mse: 1.2208\n",
      "Epoch 1563/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3694 - mse: 1.3614 - val_loss: 1.2228 - val_mse: 1.2148\n",
      "Epoch 1564/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3773 - mse: 1.3692 - val_loss: 1.2258 - val_mse: 1.2178\n",
      "Epoch 1565/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3705 - mse: 1.3624 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1566/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3695 - mse: 1.3614 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1567/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3797 - mse: 1.3717 - val_loss: 1.2257 - val_mse: 1.2177\n",
      "Epoch 1568/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3719 - mse: 1.3638 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1569/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3748 - mse: 1.3667 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1570/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3812 - mse: 1.3732\n",
      "Epoch 01570: saving model to Regression_Model/mle.linear-1570.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3809 - mse: 1.3729 - val_loss: 1.2268 - val_mse: 1.2188\n",
      "Epoch 1571/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3777 - mse: 1.3696 - val_loss: 1.2254 - val_mse: 1.2173\n",
      "Epoch 1572/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3689 - mse: 1.3608 - val_loss: 1.2280 - val_mse: 1.2200\n",
      "Epoch 1573/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3814 - mse: 1.3734 - val_loss: 1.2274 - val_mse: 1.2194\n",
      "Epoch 1574/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3621 - mse: 1.3541 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1575/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3873 - mse: 1.3793 - val_loss: 1.2267 - val_mse: 1.2186\n",
      "Epoch 1576/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3807 - mse: 1.3727 - val_loss: 1.2238 - val_mse: 1.2157\n",
      "Epoch 1577/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3763 - mse: 1.3682 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1578/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3795 - mse: 1.3714 - val_loss: 1.2280 - val_mse: 1.2200\n",
      "Epoch 1579/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3517 - mse: 1.3436 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1580/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/368 [============================>.] - ETA: 0s - loss: 1.3624 - mse: 1.3543\n",
      "Epoch 01580: saving model to Regression_Model/mle.linear-1580.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3581 - mse: 1.3501 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1581/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3590 - mse: 1.3509 - val_loss: 1.2220 - val_mse: 1.2140\n",
      "Epoch 1582/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3580 - mse: 1.3500 - val_loss: 1.2228 - val_mse: 1.2148\n",
      "Epoch 1583/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3821 - mse: 1.3741 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1584/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3878 - mse: 1.3797 - val_loss: 1.2262 - val_mse: 1.2181\n",
      "Epoch 1585/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3685 - mse: 1.3605 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1586/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3645 - mse: 1.3564 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 1587/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3569 - mse: 1.3489 - val_loss: 1.2258 - val_mse: 1.2178\n",
      "Epoch 1588/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3658 - mse: 1.3578 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1589/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3669 - mse: 1.3589 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1590/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.3813 - mse: 1.3732\n",
      "Epoch 01590: saving model to Regression_Model/mle.linear-1590.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3836 - mse: 1.3756 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1591/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3545 - mse: 1.3464 - val_loss: 1.2229 - val_mse: 1.2149\n",
      "Epoch 1592/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3755 - mse: 1.3675 - val_loss: 1.2262 - val_mse: 1.2182\n",
      "Epoch 1593/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3746 - mse: 1.3665 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1594/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3815 - mse: 1.3734 - val_loss: 1.2236 - val_mse: 1.2155\n",
      "Epoch 1595/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3985 - mse: 1.3904 - val_loss: 1.2261 - val_mse: 1.2181\n",
      "Epoch 1596/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3841 - mse: 1.3760 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1597/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3535 - mse: 1.3454 - val_loss: 1.2249 - val_mse: 1.2168\n",
      "Epoch 1598/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3730 - mse: 1.3649 - val_loss: 1.2265 - val_mse: 1.2185\n",
      "Epoch 1599/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3597 - mse: 1.3516 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1600/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.3748 - mse: 1.3667\n",
      "Epoch 01600: saving model to Regression_Model/mle.linear-1600.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3642 - val_loss: 1.2258 - val_mse: 1.2177\n",
      "Epoch 1601/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3872 - mse: 1.3791 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1602/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3604 - mse: 1.3524 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 1603/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3763 - mse: 1.3682 - val_loss: 1.2277 - val_mse: 1.2196\n",
      "Epoch 1604/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3745 - mse: 1.3664 - val_loss: 1.2263 - val_mse: 1.2183\n",
      "Epoch 1605/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3743 - mse: 1.3663 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1606/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3633 - mse: 1.3553 - val_loss: 1.2247 - val_mse: 1.2166\n",
      "Epoch 1607/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3737 - mse: 1.3657 - val_loss: 1.2232 - val_mse: 1.2152\n",
      "Epoch 1608/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3689 - mse: 1.3609 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1609/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3669 - mse: 1.3588 - val_loss: 1.2254 - val_mse: 1.2173\n",
      "Epoch 1610/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.3788 - mse: 1.3707\n",
      "Epoch 01610: saving model to Regression_Model/mle.linear-1610.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3784 - mse: 1.3704 - val_loss: 1.2264 - val_mse: 1.2184\n",
      "Epoch 1611/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3553 - mse: 1.3473 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1612/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3602 - mse: 1.3522 - val_loss: 1.2254 - val_mse: 1.2173\n",
      "Epoch 1613/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3893 - mse: 1.3812 - val_loss: 1.2237 - val_mse: 1.2156\n",
      "Epoch 1614/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3663 - mse: 1.3583 - val_loss: 1.2252 - val_mse: 1.2171\n",
      "Epoch 1615/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3559 - mse: 1.3478 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1616/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3591 - mse: 1.3511 - val_loss: 1.2267 - val_mse: 1.2187\n",
      "Epoch 1617/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3645 - mse: 1.3565 - val_loss: 1.2272 - val_mse: 1.2191\n",
      "Epoch 1618/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3731 - mse: 1.3651 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1619/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3820 - mse: 1.3739 - val_loss: 1.2260 - val_mse: 1.2180\n",
      "Epoch 1620/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 1.3745 - mse: 1.3664\n",
      "Epoch 01620: saving model to Regression_Model/mle.linear-1620.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3643 - mse: 1.3563 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1621/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3682 - mse: 1.3602 - val_loss: 1.2257 - val_mse: 1.2177\n",
      "Epoch 1622/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3768 - mse: 1.3688 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1623/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3571 - mse: 1.3490 - val_loss: 1.2241 - val_mse: 1.2160\n",
      "Epoch 1624/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3817 - mse: 1.3737 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1625/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3603 - mse: 1.3522 - val_loss: 1.2265 - val_mse: 1.2185\n",
      "Epoch 1626/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3866 - mse: 1.3786 - val_loss: 1.2263 - val_mse: 1.2183\n",
      "Epoch 1627/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3620 - mse: 1.3540 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1628/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3789 - mse: 1.3709 - val_loss: 1.2262 - val_mse: 1.2181\n",
      "Epoch 1629/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3675 - mse: 1.3595 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1630/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3571 - mse: 1.3491\n",
      "Epoch 01630: saving model to Regression_Model/mle.linear-1630.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3564 - mse: 1.3483 - val_loss: 1.2247 - val_mse: 1.2166\n",
      "Epoch 1631/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3841 - mse: 1.3760 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1632/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3542 - mse: 1.3462 - val_loss: 1.2267 - val_mse: 1.2186\n",
      "Epoch 1633/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3732 - mse: 1.3651 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1634/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3638 - mse: 1.3558 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1635/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3581 - mse: 1.3501 - val_loss: 1.2241 - val_mse: 1.2160\n",
      "Epoch 1636/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3705 - mse: 1.3625 - val_loss: 1.2236 - val_mse: 1.2155\n",
      "Epoch 1637/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3588 - mse: 1.3508 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 1638/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3728 - mse: 1.3647 - val_loss: 1.2235 - val_mse: 1.2154\n",
      "Epoch 1639/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3636 - mse: 1.3556 - val_loss: 1.2224 - val_mse: 1.2144\n",
      "Epoch 1640/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3709 - mse: 1.3628\n",
      "Epoch 01640: saving model to Regression_Model/mle.linear-1640.ckpt\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 1.3683 - mse: 1.3602 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1641/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3684 - mse: 1.3604 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1642/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3709 - mse: 1.3628 - val_loss: 1.2231 - val_mse: 1.2151\n",
      "Epoch 1643/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3722 - mse: 1.3642 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 1644/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3757 - mse: 1.3676 - val_loss: 1.2252 - val_mse: 1.2171\n",
      "Epoch 1645/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3746 - mse: 1.3666 - val_loss: 1.2257 - val_mse: 1.2177\n",
      "Epoch 1646/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3692 - mse: 1.3612 - val_loss: 1.2264 - val_mse: 1.2184\n",
      "Epoch 1647/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3618 - mse: 1.3537 - val_loss: 1.2236 - val_mse: 1.2155\n",
      "Epoch 1648/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3613 - mse: 1.3533 - val_loss: 1.2232 - val_mse: 1.2152\n",
      "Epoch 1649/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3771 - mse: 1.3690 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1650/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.3683 - mse: 1.3602\n",
      "Epoch 01650: saving model to Regression_Model/mle.linear-1650.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3706 - mse: 1.3625 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1651/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3711 - mse: 1.3631 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1652/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3621 - mse: 1.3540 - val_loss: 1.2238 - val_mse: 1.2157\n",
      "Epoch 1653/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3762 - mse: 1.3681 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1654/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3636 - mse: 1.3556 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1655/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3691 - mse: 1.3610 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1656/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3668 - mse: 1.3588 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1657/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3793 - mse: 1.3713 - val_loss: 1.2260 - val_mse: 1.2179\n",
      "Epoch 1658/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3553 - mse: 1.3472 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1659/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3703 - mse: 1.3623 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1660/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 1.3621 - mse: 1.3541\n",
      "Epoch 01660: saving model to Regression_Model/mle.linear-1660.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3675 - mse: 1.3594 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1661/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3632 - mse: 1.3551 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1662/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3884 - mse: 1.3803 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1663/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3684 - mse: 1.3603 - val_loss: 1.2263 - val_mse: 1.2183\n",
      "Epoch 1664/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3783 - mse: 1.3702 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 1665/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3759 - mse: 1.3679 - val_loss: 1.2259 - val_mse: 1.2179\n",
      "Epoch 1666/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3797 - mse: 1.3717 - val_loss: 1.2275 - val_mse: 1.2194\n",
      "Epoch 1667/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3798 - mse: 1.3717 - val_loss: 1.2276 - val_mse: 1.2196\n",
      "Epoch 1668/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3707 - mse: 1.3626 - val_loss: 1.2259 - val_mse: 1.2178\n",
      "Epoch 1669/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3636 - mse: 1.3556 - val_loss: 1.2252 - val_mse: 1.2171\n",
      "Epoch 1670/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.3706 - mse: 1.3626\n",
      "Epoch 01670: saving model to Regression_Model/mle.linear-1670.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3685 - mse: 1.3605 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1671/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3604 - mse: 1.3524 - val_loss: 1.2257 - val_mse: 1.2176\n",
      "Epoch 1672/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3833 - mse: 1.3753 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1673/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3789 - mse: 1.3709 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1674/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3732 - mse: 1.3652 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 1675/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3663 - mse: 1.3583 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1676/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3942 - mse: 1.3862 - val_loss: 1.2261 - val_mse: 1.2180\n",
      "Epoch 1677/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3642 - val_loss: 1.2258 - val_mse: 1.2178\n",
      "Epoch 1678/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3712 - mse: 1.3632 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1679/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3724 - mse: 1.3643 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1680/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3722 - mse: 1.3642\n",
      "Epoch 01680: saving model to Regression_Model/mle.linear-1680.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3653 - mse: 1.3573 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1681/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3583 - mse: 1.3503 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1682/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3615 - mse: 1.3534 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1683/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3635 - mse: 1.3554 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 1684/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3859 - mse: 1.3779 - val_loss: 1.2268 - val_mse: 1.2188\n",
      "Epoch 1685/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3812 - mse: 1.3732 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1686/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3580 - mse: 1.3500 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1687/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3654 - mse: 1.3574 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1688/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3803 - mse: 1.3723 - val_loss: 1.2264 - val_mse: 1.2184\n",
      "Epoch 1689/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3849 - mse: 1.3769 - val_loss: 1.2265 - val_mse: 1.2184\n",
      "Epoch 1690/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3599 - mse: 1.3519\n",
      "Epoch 01690: saving model to Regression_Model/mle.linear-1690.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3626 - mse: 1.3545 - val_loss: 1.2263 - val_mse: 1.2183\n",
      "Epoch 1691/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3795 - mse: 1.3714 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1692/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3605 - mse: 1.3525 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 1693/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3760 - mse: 1.3679 - val_loss: 1.2253 - val_mse: 1.2173\n",
      "Epoch 1694/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3723 - mse: 1.3642 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1695/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3652 - mse: 1.3571 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1696/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3670 - mse: 1.3590 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1697/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3780 - mse: 1.3700 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1698/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3606 - mse: 1.3526 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1699/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3758 - mse: 1.3677 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1700/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.3677 - mse: 1.3597\n",
      "Epoch 01700: saving model to Regression_Model/mle.linear-1700.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3665 - mse: 1.3585 - val_loss: 1.2253 - val_mse: 1.2173\n",
      "Epoch 1701/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3751 - mse: 1.3671 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1702/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3678 - mse: 1.3597 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1703/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3721 - mse: 1.3641 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1704/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3549 - mse: 1.3469 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1705/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3789 - mse: 1.3708 - val_loss: 1.2268 - val_mse: 1.2187\n",
      "Epoch 1706/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3760 - mse: 1.3680 - val_loss: 1.2279 - val_mse: 1.2199\n",
      "Epoch 1707/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3733 - mse: 1.3653 - val_loss: 1.2263 - val_mse: 1.2183\n",
      "Epoch 1708/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3607 - mse: 1.3527 - val_loss: 1.2263 - val_mse: 1.2183\n",
      "Epoch 1709/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3702 - mse: 1.3621 - val_loss: 1.2250 - val_mse: 1.2169\n",
      "Epoch 1710/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3591 - mse: 1.3510\n",
      "Epoch 01710: saving model to Regression_Model/mle.linear-1710.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3673 - mse: 1.3593 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1711/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3699 - mse: 1.3619 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1712/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3697 - mse: 1.3617 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1713/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3574 - mse: 1.3494 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1714/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3600 - mse: 1.3520 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1715/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3560 - mse: 1.3480 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1716/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3667 - mse: 1.3587 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1717/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3748 - mse: 1.3667 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 1718/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3745 - mse: 1.3665 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 1719/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3592 - mse: 1.3512 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1720/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.3700 - mse: 1.3620\n",
      "Epoch 01720: saving model to Regression_Model/mle.linear-1720.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3661 - mse: 1.3581 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1721/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3521 - mse: 1.3441 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1722/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3832 - mse: 1.3752 - val_loss: 1.2250 - val_mse: 1.2169\n",
      "Epoch 1723/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3738 - mse: 1.3658 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1724/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3614 - mse: 1.3534 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1725/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3645 - mse: 1.3565 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1726/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3642 - mse: 1.3562 - val_loss: 1.2239 - val_mse: 1.2158\n",
      "Epoch 1727/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3739 - mse: 1.3659 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1728/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3726 - mse: 1.3645 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 1729/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3643 - mse: 1.3563 - val_loss: 1.2264 - val_mse: 1.2184\n",
      "Epoch 1730/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.3581 - mse: 1.3501\n",
      "Epoch 01730: saving model to Regression_Model/mle.linear-1730.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3575 - mse: 1.3494 - val_loss: 1.2262 - val_mse: 1.2182\n",
      "Epoch 1731/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3644 - mse: 1.3563 - val_loss: 1.2254 - val_mse: 1.2173\n",
      "Epoch 1732/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3855 - mse: 1.3775 - val_loss: 1.2260 - val_mse: 1.2180\n",
      "Epoch 1733/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3631 - mse: 1.3551 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1734/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3632 - mse: 1.3551 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1735/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3712 - mse: 1.3631 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1736/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3844 - mse: 1.3764 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1737/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3725 - mse: 1.3644 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 1738/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3714 - mse: 1.3634 - val_loss: 1.2250 - val_mse: 1.2169\n",
      "Epoch 1739/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3655 - mse: 1.3574 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1740/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.3742 - mse: 1.3661\n",
      "Epoch 01740: saving model to Regression_Model/mle.linear-1740.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3720 - mse: 1.3640 - val_loss: 1.2238 - val_mse: 1.2158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1741/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3868 - mse: 1.3788 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1742/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3753 - mse: 1.3672 - val_loss: 1.2253 - val_mse: 1.2173\n",
      "Epoch 1743/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3755 - mse: 1.3675 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1744/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3542 - mse: 1.3462 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1745/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3673 - mse: 1.3593 - val_loss: 1.2251 - val_mse: 1.2170\n",
      "Epoch 1746/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3775 - mse: 1.3695 - val_loss: 1.2266 - val_mse: 1.2186\n",
      "Epoch 1747/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3728 - mse: 1.3647 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1748/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3609 - mse: 1.3529 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1749/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3782 - mse: 1.3702 - val_loss: 1.2258 - val_mse: 1.2178\n",
      "Epoch 1750/3000\n",
      "355/368 [===========================>..] - ETA: 0s - loss: 1.3832 - mse: 1.3752\n",
      "Epoch 01750: saving model to Regression_Model/mle.linear-1750.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3831 - mse: 1.3751 - val_loss: 1.2264 - val_mse: 1.2183\n",
      "Epoch 1751/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3552 - mse: 1.3472 - val_loss: 1.2262 - val_mse: 1.2182\n",
      "Epoch 1752/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3842 - mse: 1.3762 - val_loss: 1.2263 - val_mse: 1.2183\n",
      "Epoch 1753/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3823 - mse: 1.3743 - val_loss: 1.2259 - val_mse: 1.2179\n",
      "Epoch 1754/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3562 - mse: 1.3481 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1755/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3653 - mse: 1.3572 - val_loss: 1.2251 - val_mse: 1.2170\n",
      "Epoch 1756/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3785 - mse: 1.3705 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1757/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3626 - mse: 1.3546 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1758/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3730 - mse: 1.3650 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 1759/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3755 - mse: 1.3675 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1760/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3843 - mse: 1.3763\n",
      "Epoch 01760: saving model to Regression_Model/mle.linear-1760.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3826 - mse: 1.3746 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1761/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3768 - mse: 1.3687 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1762/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3761 - mse: 1.3681 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1763/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3702 - mse: 1.3622 - val_loss: 1.2249 - val_mse: 1.2168\n",
      "Epoch 1764/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3633 - mse: 1.3552 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1765/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3796 - mse: 1.3716 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1766/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3536 - mse: 1.3455 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1767/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3754 - mse: 1.3674 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1768/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3741 - mse: 1.3661 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1769/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3798 - mse: 1.3717 - val_loss: 1.2250 - val_mse: 1.2169\n",
      "Epoch 1770/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 1.3729 - mse: 1.3649\n",
      "Epoch 01770: saving model to Regression_Model/mle.linear-1770.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3643 - val_loss: 1.2251 - val_mse: 1.2170\n",
      "Epoch 1771/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3680 - mse: 1.3600 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1772/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3782 - mse: 1.3702 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1773/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3699 - mse: 1.3619 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1774/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3610 - mse: 1.3530 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1775/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3764 - mse: 1.3683 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1776/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3663 - mse: 1.3583 - val_loss: 1.2257 - val_mse: 1.2176\n",
      "Epoch 1777/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3568 - mse: 1.3488 - val_loss: 1.2237 - val_mse: 1.2156\n",
      "Epoch 1778/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3737 - mse: 1.3656 - val_loss: 1.2231 - val_mse: 1.2151\n",
      "Epoch 1779/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3723 - mse: 1.3642 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1780/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 1.3573 - mse: 1.3492\n",
      "Epoch 01780: saving model to Regression_Model/mle.linear-1780.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3570 - mse: 1.3490 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1781/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3881 - mse: 1.3801 - val_loss: 1.2257 - val_mse: 1.2177\n",
      "Epoch 1782/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3598 - mse: 1.3518 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1783/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3643 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1784/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3809 - mse: 1.3728 - val_loss: 1.2269 - val_mse: 1.2189\n",
      "Epoch 1785/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3758 - mse: 1.3678 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1786/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3597 - mse: 1.3517 - val_loss: 1.2236 - val_mse: 1.2155\n",
      "Epoch 1787/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3730 - mse: 1.3650 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1788/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3836 - mse: 1.3756 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1789/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3569 - mse: 1.3489 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1790/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 1.3602 - mse: 1.3522\n",
      "Epoch 01790: saving model to Regression_Model/mle.linear-1790.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3623 - mse: 1.3543 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1791/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3642 - mse: 1.3562 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 1792/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3670 - mse: 1.3590 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1793/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3623 - mse: 1.3543 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 1794/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3872 - mse: 1.3792 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1795/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3494 - mse: 1.3414 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1796/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3562 - mse: 1.3481 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1797/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3782 - mse: 1.3702 - val_loss: 1.2252 - val_mse: 1.2171\n",
      "Epoch 1798/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3817 - mse: 1.3737 - val_loss: 1.2258 - val_mse: 1.2178\n",
      "Epoch 1799/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3698 - mse: 1.3618 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 1800/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 1.3622 - mse: 1.3542\n",
      "Epoch 01800: saving model to Regression_Model/mle.linear-1800.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3614 - mse: 1.3534 - val_loss: 1.2237 - val_mse: 1.2156\n",
      "Epoch 1801/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3568 - mse: 1.3488 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1802/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3733 - mse: 1.3652 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1803/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3627 - mse: 1.3547 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1804/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3753 - mse: 1.3673 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1805/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3622 - mse: 1.3541 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1806/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3756 - mse: 1.3676 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1807/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3661 - mse: 1.3581 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1808/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3844 - mse: 1.3764 - val_loss: 1.2256 - val_mse: 1.2175\n",
      "Epoch 1809/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3817 - mse: 1.3737 - val_loss: 1.2255 - val_mse: 1.2174\n",
      "Epoch 1810/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.3728 - mse: 1.3648\n",
      "Epoch 01810: saving model to Regression_Model/mle.linear-1810.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3727 - mse: 1.3647 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 1811/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3926 - mse: 1.3846 - val_loss: 1.2262 - val_mse: 1.2182\n",
      "Epoch 1812/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3861 - mse: 1.3780 - val_loss: 1.2268 - val_mse: 1.2188\n",
      "Epoch 1813/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3624 - mse: 1.3543 - val_loss: 1.2257 - val_mse: 1.2176\n",
      "Epoch 1814/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3672 - mse: 1.3592 - val_loss: 1.2253 - val_mse: 1.2173\n",
      "Epoch 1815/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3641 - mse: 1.3560 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1816/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3670 - mse: 1.3589 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1817/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3604 - mse: 1.3523 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1818/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3615 - mse: 1.3535 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1819/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3531 - mse: 1.3451 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1820/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3584 - mse: 1.3504\n",
      "Epoch 01820: saving model to Regression_Model/mle.linear-1820.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3577 - mse: 1.3497 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1821/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3755 - mse: 1.3674 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1822/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3562 - mse: 1.3482 - val_loss: 1.2239 - val_mse: 1.2158\n",
      "Epoch 1823/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3742 - mse: 1.3662 - val_loss: 1.2253 - val_mse: 1.2173\n",
      "Epoch 1824/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3760 - mse: 1.3679 - val_loss: 1.2252 - val_mse: 1.2171\n",
      "Epoch 1825/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3689 - mse: 1.3608 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1826/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3620 - mse: 1.3540 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1827/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3717 - mse: 1.3637 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1828/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3764 - mse: 1.3684 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1829/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3700 - mse: 1.3620 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1830/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3807 - mse: 1.3727\n",
      "Epoch 01830: saving model to Regression_Model/mle.linear-1830.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3732 - mse: 1.3652 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1831/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3733 - mse: 1.3653 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1832/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3643 - mse: 1.3563 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1833/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3610 - mse: 1.3529 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1834/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3594 - mse: 1.3514 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1835/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3785 - mse: 1.3705 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 1836/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3644 - mse: 1.3563 - val_loss: 1.2232 - val_mse: 1.2151\n",
      "Epoch 1837/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3673 - mse: 1.3593 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 1838/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3751 - mse: 1.3671 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1839/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3778 - mse: 1.3697 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1840/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 1.3698 - mse: 1.3617\n",
      "Epoch 01840: saving model to Regression_Model/mle.linear-1840.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3689 - mse: 1.3608 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1841/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3611 - mse: 1.3531 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1842/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3852 - mse: 1.3772 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1843/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3762 - mse: 1.3682 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1844/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3733 - mse: 1.3653 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1845/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3644 - mse: 1.3563 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1846/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3647 - mse: 1.3567 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1847/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3750 - mse: 1.3670 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 1848/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3640 - mse: 1.3560 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 1849/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3835 - mse: 1.3754 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1850/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.3689 - mse: 1.3609\n",
      "Epoch 01850: saving model to Regression_Model/mle.linear-1850.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3709 - mse: 1.3629 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1851/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3582 - mse: 1.3501 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 1852/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3695 - mse: 1.3614 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 1853/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3598 - mse: 1.3518 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1854/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3674 - mse: 1.3593 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1855/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3895 - mse: 1.3815 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1856/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3596 - mse: 1.3515 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1857/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3526 - mse: 1.3445 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1858/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3759 - mse: 1.3678 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1859/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3705 - mse: 1.3625 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 1860/3000\n",
      "362/368 [============================>.] - ETA: 0s - loss: 1.3640 - mse: 1.3559\n",
      "Epoch 01860: saving model to Regression_Model/mle.linear-1860.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3696 - mse: 1.3616 - val_loss: 1.2250 - val_mse: 1.2169\n",
      "Epoch 1861/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3763 - mse: 1.3683 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1862/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3714 - mse: 1.3634 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1863/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3678 - mse: 1.3598 - val_loss: 1.2236 - val_mse: 1.2155\n",
      "Epoch 1864/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3668 - mse: 1.3588 - val_loss: 1.2231 - val_mse: 1.2151\n",
      "Epoch 1865/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3857 - mse: 1.3777 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1866/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3719 - mse: 1.3639 - val_loss: 1.2237 - val_mse: 1.2156\n",
      "Epoch 1867/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3625 - mse: 1.3545 - val_loss: 1.2232 - val_mse: 1.2152\n",
      "Epoch 1868/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3644 - mse: 1.3564 - val_loss: 1.2234 - val_mse: 1.2154\n",
      "Epoch 1869/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3842 - mse: 1.3762 - val_loss: 1.2236 - val_mse: 1.2155\n",
      "Epoch 1870/3000\n",
      "353/368 [===========================>..] - ETA: 0s - loss: 1.3702 - mse: 1.3621\n",
      "Epoch 01870: saving model to Regression_Model/mle.linear-1870.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3628 - mse: 1.3548 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 1871/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3731 - mse: 1.3650 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1872/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3648 - mse: 1.3568 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 1873/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3664 - mse: 1.3584 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1874/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3655 - mse: 1.3575 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1875/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3779 - mse: 1.3698 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 1876/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3683 - mse: 1.3603 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 1877/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3609 - mse: 1.3529 - val_loss: 1.2231 - val_mse: 1.2150\n",
      "Epoch 1878/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3612 - mse: 1.3531 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1879/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3738 - mse: 1.3657 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1880/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 1.3732 - mse: 1.3651\n",
      "Epoch 01880: saving model to Regression_Model/mle.linear-1880.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3739 - mse: 1.3659 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 1881/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3643 - mse: 1.3562 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1882/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3716 - mse: 1.3636 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1883/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3709 - mse: 1.3629 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1884/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3797 - mse: 1.3716 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 1885/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3731 - mse: 1.3651 - val_loss: 1.2232 - val_mse: 1.2152\n",
      "Epoch 1886/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3909 - mse: 1.3828 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1887/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3680 - mse: 1.3600 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1888/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3735 - mse: 1.3655 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1889/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3694 - mse: 1.3613 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1890/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.3730 - mse: 1.3649\n",
      "Epoch 01890: saving model to Regression_Model/mle.linear-1890.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3751 - mse: 1.3671 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1891/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3777 - mse: 1.3697 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 1892/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3581 - mse: 1.3501 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1893/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3479 - mse: 1.3399 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1894/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3608 - mse: 1.3527 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1895/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3572 - mse: 1.3492 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1896/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3769 - mse: 1.3689 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 1897/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3752 - mse: 1.3671 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1898/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3831 - mse: 1.3751 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1899/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3708 - mse: 1.3627 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1900/3000\n",
      "361/368 [============================>.] - ETA: 0s - loss: 1.3571 - mse: 1.3490\n",
      "Epoch 01900: saving model to Regression_Model/mle.linear-1900.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 1.3534 - mse: 1.3453 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 1901/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3821 - mse: 1.3741 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1902/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3652 - mse: 1.3572 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1903/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3624 - mse: 1.3544 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1904/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3801 - mse: 1.3721 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 1905/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3645 - mse: 1.3565 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1906/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3750 - mse: 1.3670 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1907/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3615 - mse: 1.3535 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1908/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3671 - mse: 1.3591 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1909/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3761 - mse: 1.3681 - val_loss: 1.2234 - val_mse: 1.2154\n",
      "Epoch 1910/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.3757 - mse: 1.3676\n",
      "Epoch 01910: saving model to Regression_Model/mle.linear-1910.ckpt\n",
      "368/368 [==============================] - 3s 8ms/step - loss: 1.3732 - mse: 1.3651 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1911/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3653 - mse: 1.3573 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1912/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3747 - mse: 1.3667 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1913/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3711 - mse: 1.3631 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1914/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3884 - mse: 1.3804 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1915/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3697 - mse: 1.3616 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1916/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3570 - mse: 1.3490 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1917/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3650 - mse: 1.3570 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1918/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3679 - mse: 1.3599 - val_loss: 1.2234 - val_mse: 1.2154\n",
      "Epoch 1919/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3699 - mse: 1.3618 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 1920/3000\n",
      "364/368 [============================>.] - ETA: 0s - loss: 1.3731 - mse: 1.3651\n",
      "Epoch 01920: saving model to Regression_Model/mle.linear-1920.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3686 - mse: 1.3606 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1921/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3751 - mse: 1.3671 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1922/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3708 - mse: 1.3628 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 1923/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3673 - mse: 1.3593 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 1924/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3751 - mse: 1.3670 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 1925/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3482 - mse: 1.3401 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1926/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3875 - mse: 1.3795 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1927/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3729 - mse: 1.3648 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1928/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3836 - mse: 1.3756 - val_loss: 1.2257 - val_mse: 1.2177\n",
      "Epoch 1929/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3708 - mse: 1.3627 - val_loss: 1.2257 - val_mse: 1.2176\n",
      "Epoch 1930/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.3936 - mse: 1.3856\n",
      "Epoch 01930: saving model to Regression_Model/mle.linear-1930.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3922 - mse: 1.3842 - val_loss: 1.2256 - val_mse: 1.2176\n",
      "Epoch 1931/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3690 - mse: 1.3609 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1932/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3724 - mse: 1.3644 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1933/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3599 - mse: 1.3519 - val_loss: 1.2234 - val_mse: 1.2154\n",
      "Epoch 1934/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3649 - mse: 1.3569 - val_loss: 1.2227 - val_mse: 1.2147\n",
      "Epoch 1935/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3842 - mse: 1.3762 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 1936/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3589 - mse: 1.3509 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 1937/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3705 - mse: 1.3625 - val_loss: 1.2239 - val_mse: 1.2158\n",
      "Epoch 1938/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3770 - mse: 1.3689 - val_loss: 1.2239 - val_mse: 1.2158\n",
      "Epoch 1939/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3489 - mse: 1.3409 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1940/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 1.3734 - mse: 1.3654\n",
      "Epoch 01940: saving model to Regression_Model/mle.linear-1940.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3815 - mse: 1.3735 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1941/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3535 - mse: 1.3455 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1942/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3652 - mse: 1.3572 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1943/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3743 - mse: 1.3663 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1944/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3779 - mse: 1.3698 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1945/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3658 - mse: 1.3578 - val_loss: 1.2254 - val_mse: 1.2173\n",
      "Epoch 1946/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3673 - mse: 1.3592 - val_loss: 1.2252 - val_mse: 1.2171\n",
      "Epoch 1947/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3558 - mse: 1.3478 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1948/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3644 - mse: 1.3564 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1949/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3689 - mse: 1.3608 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1950/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.3796 - mse: 1.3715\n",
      "Epoch 01950: saving model to Regression_Model/mle.linear-1950.ckpt\n",
      "368/368 [==============================] - 5s 13ms/step - loss: 1.3775 - mse: 1.3694 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 1951/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3537 - mse: 1.3456 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1952/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3702 - mse: 1.3622 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 1953/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3830 - mse: 1.3750 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1954/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3689 - mse: 1.3609 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 1955/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3601 - mse: 1.3521 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1956/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3721 - mse: 1.3640 - val_loss: 1.2238 - val_mse: 1.2157\n",
      "Epoch 1957/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3730 - mse: 1.3650 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 1958/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3752 - mse: 1.3672 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 1959/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3614 - mse: 1.3534 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 1960/3000\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 1.3733 - mse: 1.3652\n",
      "Epoch 01960: saving model to Regression_Model/mle.linear-1960.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3782 - mse: 1.3701 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1961/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3595 - mse: 1.3515 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1962/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3474 - mse: 1.3393 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 1963/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3633 - mse: 1.3553 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 1964/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3795 - mse: 1.3714 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1965/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3555 - mse: 1.3475 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1966/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3689 - mse: 1.3609 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1967/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3654 - mse: 1.3573 - val_loss: 1.2239 - val_mse: 1.2158\n",
      "Epoch 1968/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3714 - mse: 1.3633 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1969/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3662 - mse: 1.3581 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1970/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3830 - mse: 1.3750\n",
      "Epoch 01970: saving model to Regression_Model/mle.linear-1970.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3821 - mse: 1.3741 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 1971/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3851 - mse: 1.3771 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1972/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3732 - mse: 1.3651 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 1973/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3727 - mse: 1.3647 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 1974/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3406 - mse: 1.3325 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 1975/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3669 - mse: 1.3589 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 1976/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3720 - mse: 1.3639 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1977/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3620 - mse: 1.3540 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 1978/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3838 - mse: 1.3758 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 1979/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3749 - mse: 1.3669 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1980/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.3523 - mse: 1.3442\n",
      "Epoch 01980: saving model to Regression_Model/mle.linear-1980.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3567 - mse: 1.3487 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1981/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3798 - mse: 1.3717 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1982/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3577 - mse: 1.3496 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1983/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3608 - mse: 1.3528 - val_loss: 1.2241 - val_mse: 1.2160\n",
      "Epoch 1984/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3704 - mse: 1.3624 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 1985/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3418 - mse: 1.3338 - val_loss: 1.2231 - val_mse: 1.2151\n",
      "Epoch 1986/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3724 - mse: 1.3644 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1987/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3592 - mse: 1.3512 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 1988/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3665 - mse: 1.3585 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 1989/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3525 - mse: 1.3444 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 1990/3000\n",
      "354/368 [===========================>..] - ETA: 0s - loss: 1.3691 - mse: 1.3611\n",
      "Epoch 01990: saving model to Regression_Model/mle.linear-1990.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3710 - mse: 1.3630 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 1991/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3821 - mse: 1.3741 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 1992/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3792 - mse: 1.3712 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 1993/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3643 - mse: 1.3563 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 1994/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3626 - mse: 1.3546 - val_loss: 1.2238 - val_mse: 1.2157\n",
      "Epoch 1995/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3736 - mse: 1.3656 - val_loss: 1.2239 - val_mse: 1.2158\n",
      "Epoch 1996/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3553 - mse: 1.3472 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 1997/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3744 - mse: 1.3664 - val_loss: 1.2241 - val_mse: 1.2160\n",
      "Epoch 1998/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3774 - mse: 1.3694 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 1999/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3590 - mse: 1.3510 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 2000/3000\n",
      "356/368 [============================>.] - ETA: 0s - loss: 1.3766 - mse: 1.3686\n",
      "Epoch 02000: saving model to Regression_Model/mle.linear-2000.ckpt\n",
      "368/368 [==============================] - 2s 7ms/step - loss: 1.3679 - mse: 1.3598 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 2001/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3826 - mse: 1.3746 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 2002/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3813 - mse: 1.3733 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 2003/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3693 - mse: 1.3612 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 2004/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3740 - mse: 1.3659 - val_loss: 1.2251 - val_mse: 1.2170\n",
      "Epoch 2005/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3767 - mse: 1.3687 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 2006/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3743 - mse: 1.3663 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 2007/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3840 - mse: 1.3760 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 2008/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3517 - mse: 1.3437 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 2009/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3775 - mse: 1.3695 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2010/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/368 [============================>.] - ETA: 0s - loss: 1.3809 - mse: 1.3729\n",
      "Epoch 02010: saving model to Regression_Model/mle.linear-2010.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3829 - mse: 1.3749 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 2011/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3695 - mse: 1.3614 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 2012/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3670 - mse: 1.3590 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 2013/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3826 - mse: 1.3746 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2014/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3634 - mse: 1.3554 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 2015/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3778 - mse: 1.3698 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 2016/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3639 - mse: 1.3559 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 2017/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3683 - mse: 1.3603 - val_loss: 1.2239 - val_mse: 1.2158\n",
      "Epoch 2018/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3672 - mse: 1.3592 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 2019/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3540 - mse: 1.3460 - val_loss: 1.2235 - val_mse: 1.2154\n",
      "Epoch 2020/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 1.3628 - mse: 1.3548\n",
      "Epoch 02020: saving model to Regression_Model/mle.linear-2020.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3630 - mse: 1.3549 - val_loss: 1.2239 - val_mse: 1.2158\n",
      "Epoch 2021/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3523 - mse: 1.3443 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 2022/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3634 - mse: 1.3554 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 2023/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3944 - mse: 1.3864 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 2024/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3877 - mse: 1.3797 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 2025/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3688 - mse: 1.3608 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 2026/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3685 - mse: 1.3605 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 2027/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3673 - mse: 1.3593 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 2028/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3827 - mse: 1.3747 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 2029/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3768 - mse: 1.3688 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 2030/3000\n",
      "351/368 [===========================>..] - ETA: 0s - loss: 1.3803 - mse: 1.3723\n",
      "Epoch 02030: saving model to Regression_Model/mle.linear-2030.ckpt\n",
      "368/368 [==============================] - 2s 6ms/step - loss: 1.3829 - mse: 1.3748 - val_loss: 1.2255 - val_mse: 1.2175\n",
      "Epoch 2031/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3595 - mse: 1.3515 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 2032/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3852 - mse: 1.3771 - val_loss: 1.2254 - val_mse: 1.2174\n",
      "Epoch 2033/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3630 - mse: 1.3550 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 2034/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3565 - mse: 1.3485 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2035/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3670 - mse: 1.3590 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 2036/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3740 - mse: 1.3659 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 2037/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3752 - mse: 1.3672 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 2038/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3663 - mse: 1.3583 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 2039/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3633 - mse: 1.3553 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 2040/3000\n",
      "365/368 [============================>.] - ETA: 0s - loss: 1.3860 - mse: 1.3780\n",
      "Epoch 02040: saving model to Regression_Model/mle.linear-2040.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3848 - mse: 1.3767 - val_loss: 1.2247 - val_mse: 1.2166\n",
      "Epoch 2041/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3863 - mse: 1.3783 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 2042/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3658 - mse: 1.3578 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 2043/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3722 - mse: 1.3642 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 2044/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3958 - mse: 1.3877 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 2045/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3646 - mse: 1.3566 - val_loss: 1.2241 - val_mse: 1.2160\n",
      "Epoch 2046/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3683 - mse: 1.3602 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 2047/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3597 - mse: 1.3517 - val_loss: 1.2239 - val_mse: 1.2158\n",
      "Epoch 2048/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3749 - mse: 1.3668 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 2049/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3592 - mse: 1.3512 - val_loss: 1.2237 - val_mse: 1.2156\n",
      "Epoch 2050/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.3612 - mse: 1.3532\n",
      "Epoch 02050: saving model to Regression_Model/mle.linear-2050.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3605 - mse: 1.3524 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 2051/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3713 - mse: 1.3632 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 2052/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3669 - mse: 1.3589 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 2053/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3656 - mse: 1.3575 - val_loss: 1.2234 - val_mse: 1.2154\n",
      "Epoch 2054/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3724 - mse: 1.3644 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 2055/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3736 - mse: 1.3655 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 2056/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3621 - mse: 1.3541 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 2057/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3458 - mse: 1.3378 - val_loss: 1.2234 - val_mse: 1.2154\n",
      "Epoch 2058/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3872 - mse: 1.3792 - val_loss: 1.2232 - val_mse: 1.2151\n",
      "Epoch 2059/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3618 - mse: 1.3538 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 2060/3000\n",
      "350/368 [===========================>..] - ETA: 0s - loss: 1.3606 - mse: 1.3526\n",
      "Epoch 02060: saving model to Regression_Model/mle.linear-2060.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3646 - mse: 1.3566 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 2061/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3685 - mse: 1.3604 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 2062/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3684 - mse: 1.3604 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 2063/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3639 - mse: 1.3558 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 2064/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3556 - mse: 1.3476 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 2065/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3703 - mse: 1.3623 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2066/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3624 - mse: 1.3544 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 2067/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3612 - mse: 1.3531 - val_loss: 1.2232 - val_mse: 1.2151\n",
      "Epoch 2068/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3716 - mse: 1.3635 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 2069/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3761 - mse: 1.3680 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 2070/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 1.3543 - mse: 1.3463\n",
      "Epoch 02070: saving model to Regression_Model/mle.linear-2070.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3610 - mse: 1.3530 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2071/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3671 - mse: 1.3591 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 2072/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3767 - mse: 1.3687 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2073/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3702 - mse: 1.3622 - val_loss: 1.2235 - val_mse: 1.2155\n",
      "Epoch 2074/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3659 - mse: 1.3579 - val_loss: 1.2238 - val_mse: 1.2157\n",
      "Epoch 2075/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3825 - mse: 1.3745 - val_loss: 1.2230 - val_mse: 1.2150\n",
      "Epoch 2076/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3623 - mse: 1.3543 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2077/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3846 - mse: 1.3766 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 2078/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3816 - mse: 1.3736 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 2079/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3775 - mse: 1.3695 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 2080/3000\n",
      "366/368 [============================>.] - ETA: 0s - loss: 1.3660 - mse: 1.3580\n",
      "Epoch 02080: saving model to Regression_Model/mle.linear-2080.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3659 - mse: 1.3578 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 2081/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3696 - mse: 1.3615 - val_loss: 1.2236 - val_mse: 1.2156\n",
      "Epoch 2082/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3808 - mse: 1.3727 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 2083/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3723 - mse: 1.3643 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 2084/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3700 - mse: 1.3620 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 2085/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3739 - mse: 1.3658 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 2086/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3669 - mse: 1.3588 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 2087/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3758 - mse: 1.3677 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 2088/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3529 - mse: 1.3449 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 2089/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3824 - mse: 1.3744 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 2090/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.3505 - mse: 1.3425\n",
      "Epoch 02090: saving model to Regression_Model/mle.linear-2090.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3580 - mse: 1.3500 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 2091/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3869 - mse: 1.3789 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 2092/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3642 - mse: 1.3562 - val_loss: 1.2238 - val_mse: 1.2158\n",
      "Epoch 2093/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3628 - mse: 1.3547 - val_loss: 1.2237 - val_mse: 1.2157\n",
      "Epoch 2094/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3753 - mse: 1.3672 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 2095/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3689 - mse: 1.3609 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 2096/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3571 - mse: 1.3491 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2097/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3659 - mse: 1.3579 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2098/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3676 - mse: 1.3595 - val_loss: 1.2233 - val_mse: 1.2153\n",
      "Epoch 2099/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3787 - mse: 1.3707 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 2100/3000\n",
      "363/368 [============================>.] - ETA: 0s - loss: 1.3699 - mse: 1.3619\n",
      "Epoch 02100: saving model to Regression_Model/mle.linear-2100.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3699 - mse: 1.3618 - val_loss: 1.2240 - val_mse: 1.2159\n",
      "Epoch 2101/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3832 - mse: 1.3752 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 2102/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3764 - mse: 1.3684 - val_loss: 1.2251 - val_mse: 1.2171\n",
      "Epoch 2103/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3600 - mse: 1.3520 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 2104/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3786 - mse: 1.3705 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2105/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3729 - mse: 1.3649 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 2106/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3739 - mse: 1.3659 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 2107/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3659 - mse: 1.3579 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 2108/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3696 - mse: 1.3616 - val_loss: 1.2250 - val_mse: 1.2170\n",
      "Epoch 2109/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3557 - mse: 1.3476 - val_loss: 1.2250 - val_mse: 1.2169\n",
      "Epoch 2110/3000\n",
      "359/368 [============================>.] - ETA: 0s - loss: 1.3511 - mse: 1.3431\n",
      "Epoch 02110: saving model to Regression_Model/mle.linear-2110.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3532 - mse: 1.3452 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 2111/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3800 - mse: 1.3720 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 2112/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3501 - mse: 1.3421 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 2113/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3786 - mse: 1.3706 - val_loss: 1.2245 - val_mse: 1.2164\n",
      "Epoch 2114/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3831 - mse: 1.3751 - val_loss: 1.2242 - val_mse: 1.2161\n",
      "Epoch 2115/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3701 - mse: 1.3620 - val_loss: 1.2248 - val_mse: 1.2167\n",
      "Epoch 2116/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3789 - mse: 1.3709 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 2117/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3900 - mse: 1.3820 - val_loss: 1.2253 - val_mse: 1.2172\n",
      "Epoch 2118/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3926 - mse: 1.3846 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 2119/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3795 - mse: 1.3715 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 2120/3000\n",
      "367/368 [============================>.] - ETA: 0s - loss: 1.3843 - mse: 1.3763\n",
      "Epoch 02120: saving model to Regression_Model/mle.linear-2120.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3850 - mse: 1.3770 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 2121/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3739 - mse: 1.3659 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 2122/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3636 - mse: 1.3556 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 2123/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3838 - mse: 1.3758 - val_loss: 1.2252 - val_mse: 1.2172\n",
      "Epoch 2124/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3662 - mse: 1.3582 - val_loss: 1.2249 - val_mse: 1.2168\n",
      "Epoch 2125/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3745 - mse: 1.3665 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 2126/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3591 - mse: 1.3511 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 2127/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3801 - mse: 1.3721 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 2128/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3907 - mse: 1.3826 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 2129/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3733 - mse: 1.3653 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 2130/3000\n",
      "349/368 [===========================>..] - ETA: 0s - loss: 1.3492 - mse: 1.3412\n",
      "Epoch 02130: saving model to Regression_Model/mle.linear-2130.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3488 - mse: 1.3407 - val_loss: 1.2244 - val_mse: 1.2164\n",
      "Epoch 2131/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3705 - mse: 1.3625 - val_loss: 1.2249 - val_mse: 1.2169\n",
      "Epoch 2132/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3693 - mse: 1.3613 - val_loss: 1.2247 - val_mse: 1.2167\n",
      "Epoch 2133/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3734 - mse: 1.3654 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 2134/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3586 - mse: 1.3506 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 2135/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3693 - mse: 1.3612 - val_loss: 1.2246 - val_mse: 1.2165\n",
      "Epoch 2136/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3748 - mse: 1.3668 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 2137/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3770 - mse: 1.3690 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 2138/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3522 - mse: 1.3442 - val_loss: 1.2242 - val_mse: 1.2162\n",
      "Epoch 2139/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3678 - mse: 1.3598 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 2140/3000\n",
      "357/368 [============================>.] - ETA: 0s - loss: 1.3876 - mse: 1.3795\n",
      "Epoch 02140: saving model to Regression_Model/mle.linear-2140.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3815 - mse: 1.3735 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 2141/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3679 - mse: 1.3599 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 2142/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3620 - mse: 1.3540 - val_loss: 1.2248 - val_mse: 1.2168\n",
      "Epoch 2143/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3651 - mse: 1.3570 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 2144/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3650 - mse: 1.3570 - val_loss: 1.2243 - val_mse: 1.2163\n",
      "Epoch 2145/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3682 - mse: 1.3602 - val_loss: 1.2246 - val_mse: 1.2166\n",
      "Epoch 2146/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3668 - mse: 1.3588 - val_loss: 1.2244 - val_mse: 1.2163\n",
      "Epoch 2147/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3865 - mse: 1.3784 - val_loss: 1.2245 - val_mse: 1.2165\n",
      "Epoch 2148/3000\n",
      "368/368 [==============================] - 2s 4ms/step - loss: 1.3649 - mse: 1.3569 - val_loss: 1.2243 - val_mse: 1.2162\n",
      "Epoch 2149/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3519 - mse: 1.3439 - val_loss: 1.2241 - val_mse: 1.2161\n",
      "Epoch 2150/3000\n",
      "358/368 [============================>.] - ETA: 0s - loss: 1.3537 - mse: 1.3457\n",
      "Epoch 02150: saving model to Regression_Model/mle.linear-2150.ckpt\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3540 - mse: 1.3460 - val_loss: 1.2240 - val_mse: 1.2160\n",
      "Epoch 2151/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3622 - mse: 1.3542 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2152/3000\n",
      "368/368 [==============================] - 2s 5ms/step - loss: 1.3646 - mse: 1.3566 - val_loss: 1.2239 - val_mse: 1.2159\n",
      "Epoch 2153/3000\n",
      " 96/368 [======>.......................] - ETA: 0s - loss: 1.3747 - mse: 1.3666"
     ]
    }
   ],
   "source": [
    " history = model.fit(training_generator,epochs=3000,validation_data=validation_generator,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], color='red', label='Loss of validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,y,pasid,trainid,dataset,label_mean,label_std):\n",
    "    test_generator = EvaDataGenerator(x)\n",
    "    model = Regression_CNN(1001);\n",
    "    MODEL_PATH = 'Regression_Model/'+trainid+'-2550.ckpt'\n",
    "    model.load_weights(MODEL_PATH)\n",
    "    print('load weight success')\n",
    "    pred = model.predict_generator(test_generator)\n",
    "    OUT=open(dataset+'.'+trainid,'w')\n",
    "    OUT.write(\"pas_id\\tpredict\\tpolyA\\tpredict_readCount\\tpolyA_readCount\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        predict = pred[i][0]\n",
    "        predict_readCount = np.exp(predict*label_std+label_mean)\n",
    "        truth = y[i]\n",
    "        truth_readCount   = np.exp(truth*label_std+label_mean)\n",
    "        OUT.write('%s\\t%s\\t%s\\t%s\\t%s\\n'%(pasid[i],predict,truth,predict_readCount,truth_readCount))\n",
    "    OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testid='mle.linear'\n",
    "evaluate(train_x,train_y,train_id,testid,'train',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(valid_x,valid_y,valid_id,testid,'valid',label_mean,label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(train_x,train_y,0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1,labels,pasid = get_data('usage_data/BL6_REP1.pAs.predict.coverage.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,random_state=len(labels)+1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = list(kf.split(labels))\n",
    "train_index,valid_index = folds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT=open('test','w')\n",
    "OUT.write(\"RNA_readCount\\n\")\n",
    "for coverage in valid_data:\n",
    "    mean = np.mean(coverage)\n",
    "    OUT.write('%s\\n'%(mean))\n",
    "    #for i in coverage:\n",
    "     #   OUT.write('%s\\n'%(i[0]))\n",
    "OUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
