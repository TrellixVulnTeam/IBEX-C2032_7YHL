#!/usr/bin/env python3

import numpy as np
import os
import sys
import argparse
import glob
from sklearn.model_selection import KFold

def get_files(root_dir,block_dir,RoundName,label):
	Round = int(RoundName[-1])
	blockfiles = glob.glob(block_dir+"/chr*")
	blockfiles = np.array(sorted(blockfiles))
	if(label=='positive'):
		root_dir = root_dir+'/positive/'+RoundName[0:-2]
	else:
		root_dir = root_dir+'/negative/'+RoundName
	files = []
	for f in blockfiles:
		f2 = f.replace(block_dir,root_dir)
		files.append(f2)
	files = np.array(files)
	np.random.seed(0)
	####Chose 21 blocks as Test Set
	test_index = np.random.choice(range(len(files)),21,replace=False)
	####The remaining sets as train and valid sets
	new_files = np.delete(files,test_index)
	#### 5 Fold cross validation
	kf = KFold(n_splits = 5,random_state=0,shuffle=True)
	train_round = []
	valid_round = []
	for train,valid in kf.split(new_files):
		train_round.append(train)
		valid_round.append(valid)

	train_sets = new_files[train_round[Round]]
	valid_sets = new_files[valid_round[Round]]
	test_sets  = files[test_index]

	return train_sets,valid_sets,test_sets


def get_data(root_dir,block_dir,polyA_file,RoundName,label,split):
	"""
	Process all files in the input directory to read sequences.
	Sequences are encoded with one-hot.
	data_root: input directory
	label: the label (True or False) for the sequences in the input directory
	"""
	data1 = [] # seq
	data2 = [] # coverage
	data3 = [] # polyA containing reads 
	
	train_sets,valid_sets,_ = get_files(root_dir,block_dir,RoundName,label)


	sets = None
	if split == 'train':
		sets = train_sets
	elif split == 'valid':
		sets = valid_sets

	polyA_dict = dict()
	with open(polyA_file,'r') as f:
		for line in f:
			line=line.rstrip('\n').split('\t')
			polyA_dict[line[0]] = line[1]

			
	for file_path in sets:
		with open(file_path,'r') as f:
			for line in f:
				line=line.rstrip('\n').split('\t')
				if (line[0]!='#pas_id')&(line[0]!='pas_id'):
					SEQUENCE=list(line[7])
					SEQUENCE=SEQUENCE[0:176]
					alphabet = np.array(['A', 'T', 'C', 'G'])
					seq = np.array(SEQUENCE, dtype = '|U1').reshape(-1, 1)
					seq_data = (seq == alphabet).astype(np.float32)
					data1.append(seq_data)
					COVERAGE=[float(x) for x in line[8:184]]
					data2.append(COVERAGE)
					chromosome=line[2]
					position=int(line[3])
					strand=line[4]
					polyACount = [0.0 for i in range(len(COVERAGE))]
					for i in range(len(COVERAGE)):
						if (strand == "+"):
							pos = position-100+i
						else:
							pos = position+100-i
						pasid = chromosome+':'+str(pos)+':'+strand
						if pasid in polyA_dict.keys():
							polyACount[i] = float(polyA_dict[pasid])

					data3.append(polyACount)

	data1 = np.stack(data1).reshape([-1, 176, 4])
	data2 = np.stack(data2).reshape([-1, 176, 1])
	data3 = np.stack(data3).reshape([-1, 176, 1])



	if label == "positive":
		labels = np.ones(data1.shape[0])
	else:
		labels = np.zeros(data1.shape[0])
	return data1, data2, data3, labels


def shuffle(dataset1, dataset2, dataset3, labels, randomState=None):
	"""
	Shuffle sequences and labels jointly
	"""
	if randomState is None:
		permutation = np.random.permutation(labels.shape[0])
	else:
		permutation = randomState.permutation(labels.shape[0])
	shuffled_data1 = dataset1[permutation,:,:]
	shuffled_data2 = dataset2[permutation,:,:]
	shuffled_data3 = dataset3[permutation,:,:]
	shuffled_labels = labels[permutation]
	return shuffled_data1, shuffled_data2, shuffled_data3, shuffled_labels


def prep_data(ROOT_DIR,BLOCK_DIR,polyA_file,ROUNDNAME,NUM_FOLDS,subset,OUT=None):
	pos_data1, pos_data2, pos_data3, pos_labels = get_data(ROOT_DIR,BLOCK_DIR,polyA_file,ROUNDNAME, 'positive',subset)
	neg_data1, neg_data2, neg_data3, neg_labels = get_data(ROOT_DIR,BLOCK_DIR,polyA_file,ROUNDNAME, 'negative',subset)
	data1 = np.concatenate((pos_data1, neg_data1), axis=0)
	data2 = np.concatenate((pos_data2, neg_data2), axis=0)
	data3 = np.concatenate((pos_data3, neg_data3), axis=0)
	labels = np.concatenate((pos_labels, neg_labels), axis=0)


	data1,data2,data3,labels = shuffle(data1, data2 ,data3, labels)
	dataset = ({"seq_input": data1, "cov_input": data2,"pol_input": data3}, labels)

	#Assert(pos_sets,neg_sets)

	print('Size of %s dataset: %d'%(subset,labels.shape[0]))

	if OUT is not None:
		np.savez(OUT, **dataset)
		print('Finish writing dataset to %s'%OUT)



	return dataset

def Assert(pos_sets,neg_sets):
	n = len(pos_sets)
	m = len(neg_sets)
	if(m!=n):
		print("Warning! Size of positive and negative datasets is different!")

	else:
		indicator = 0
		for i in range(n):
			pos_file = pos_sets[i]
			neg_file = neg_sets[i]
			pos_baseName = pos_file.split('/')[-1]
			neg_baseName = neg_file.split('/')[-1]
			if(pos_baseName != neg_baseName):
				print('Warning! Name of positive and negative file is different')
				indicator = 1
		if(indicator==0):
			print('Positive and negative dataset is normal')

if __name__ == "__main__":
	### Argument Parser
	parser = argparse.ArgumentParser()
	parser.add_argument('--root_dir', help='Directory of files containing positive and negative files')
	parser.add_argument('--block_dir', help='Directory of files containing scan transcriptime files')
	parser.add_argument('--round',help='Round of training')
	parser.add_argument('--out', help='Save the processed dataset to')
	parser.add_argument('--polyAfile', help='polyA file from RAN-Seq conataining position and polyA read counts')
	parser.add_argument('--nfolds', default=5, type=int, help='Seperate the data into how many folds')
	opts = parser.parse_args()

	############Global Parameters ############
	NUM_FOLDS = opts.nfolds
	ROOT_DIR  = opts.root_dir
	BLOCK_DIR  = opts.block_dir
	ROUNDNAME  = opts.round
	polyA_file = opts.polyAfile
	OUT       = opts.out
	############Global  Parameters ############
	prep_data(ROOT_DIR,BLOCK_DIR,polyA_file,ROUNDNAME,NUM_FOLDS,OUT)
