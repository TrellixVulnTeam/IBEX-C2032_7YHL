#!/usr/bin/env python3

import numpy as np
import tensorflow as tf
import sys, os
import argparse
from sklearn import metrics
from model_seqcov_varilen import Net

############ Parameters ############
PREFIX='Optimize'
RUN_TIME=50
BATCH_SIZE = 64
PATCH_SIZE = 10
DEPTH = 32
NUM_HIDDEN = 64
SEQ_LEN = 201 + 2*PATCH_SIZE-2
NUM_CHANNELS = 4
NUM_LABELS = 2
NUM_EPOCHS = 30
############ **************** ############

def pad_dataset1(dataset, labels):
    ''' Pad sequences to (length + 2*DEPTH - 2) wtih 0.25 '''
    new_dataset = np.ones([dataset.shape[0], dataset.shape[1]+2*PATCH_SIZE-2, dataset.shape[2], dataset.shape[3]], dtype = np.float32) * 0.25
    new_dataset[:, PATCH_SIZE-1:-(PATCH_SIZE-1), :, :] = dataset
    labels = (np.arange(NUM_LABELS) == labels[:,None]).astype(np.float32)
    return new_dataset, labels

def pad_dataset2(dataset, labels):
    ''' Pad sequences to (length + 2*DEPTH - 2) wtih mean(coverage) '''
    new_dataset = np.ones([dataset.shape[0], dataset.shape[1]+2*PATCH_SIZE-2, dataset.shape[2], dataset.shape[3]], dtype = np.float32) * np.mean(dataset)
    new_dataset[:, PATCH_SIZE-1:-(PATCH_SIZE-1), :, :] = dataset
    labels = (np.arange(NUM_LABELS) == labels[:,None]).astype(np.float32)
    return new_dataset, labels

def get_accuracy(predictions, labels):
      return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))
          / predictions.shape[0])

def perf_measure(y_actual, y_hat):
    TP = 0
    FP = 0
    TN = 0
    FN = 0

    for i in range(len(y_hat)): 
        if y_actual[i]==y_hat[i]==0:
               TP += 1
        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:
               FN += 1
        if y_actual[i]==y_hat[i]==1:
               TN += 1
        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:
               FP += 1

    return(TP, FP, TN, FN)

if __name__ == '__main__':
    
    #for up in [100,50,20]:
    #    for down in [100,50,20]:
    for up in [100]:
        for down in [50]:
    
            WW=open('out/%s_UP%s_DOWN%s_USAGE0.2_TRIMMED0_%s_summary.txt'%(PREFIX,str(up),str(down),str(RUN_TIME)),'w')
            WW.write('runtime\ttrain_acc\tvalid_acc\tTP\tFP\tTN\tFN\terror_rate\taccuracy_score\tmicro_precision_score\tmacro_precision_score\tmicro_recall_score\tmacro_recall_score\tf1_score\tcohen_kappa_score\troc_auc_score\n')
            data='data/optimize/all_data_up%s_down%s_usage0.2_trimmed0.npz'%(str(up),str(down))
            
            # Load and pad data
            data = np.load(data)
            train_data1, train_labels = pad_dataset1(data['train_dataset1'], data['train_labels'])
            train_data2, train_labels = pad_dataset2(data['train_dataset2'], data['train_labels'])
            valid_data1, valid_labels = pad_dataset1(data['valid_dataset1'], data['valid_labels'])
            valid_data2, valid_labels = pad_dataset2(data['valid_dataset2'], data['valid_labels'])
            
            for current_run in range(RUN_TIME):

                TRAIN_ID='%s_UP%s_DOWN%s_USAGE0.2_TRIMMED0_%s_%s'%(PREFIX,str(up),str(down),str(RUN_TIME),str(current_run))
                
                print(TRAIN_ID)
                
                with tf.device('/cpu:0'):
                    
                    out='out/%s'%TRAIN_ID
                    hparam={'tf_learning_rate': 0.001257480894209189, 'tf_momentum': 0.9800240743506459, 'tf_motif_init_weight': 0.12476684341236771, 'tf_fc_init_weight': 0.02674129616233189, 'tf_motif_weight_decay': 0.00044213243479539205, 'tf_fc_weight_decay': 0.00032473212014796254, 'tf_keep_prob': 0.5}
                    pretrained=None

                    # Build model and trainning graph
                    hyper_dict = hparam if hparam is not None else None
                    model = Net(hyper_dict,up,down)
                    model.build_training_graph()

                    # Building record file
                    with open('out/%s_par.txt'%TRAIN_ID,'w') as w:
                        w.write('#'+str(model.hyper_dict)+'\n')

                    W=open('out/%s.txt'%TRAIN_ID,'w')
                    W.write('epoch\ttrain_acc\tvalid_acc\tTP\tFP\tTN\tFN\terror_rate\taccuracy_score\tmicro_precision_score\tmacro_precision_score\tmicro_recall_score\tmacro_recall_score\tf1_score\tcohen_kappa_score\troc_auc_score\n')


                    # Kick off training
                    config = tf.ConfigProto(allow_soft_placement=True)
                    sess = tf.Session(config=config)
                    sess.run(tf.global_variables_initializer())

                    if pretrained is not None:
                        model.load_weights(pretrained, sess)
                        print('Fine-tuning the pre-trained model %s'%pretrained)
                    else:
                        print('Initialized')
                    pred = model.get_prediction(sess, valid_data1, valid_data2, False)
                    print('Validation accuracy at the beginning: %.5f%%' % get_accuracy(pred, valid_labels))

                    train_results, valid_results = [], []
                    save_weights = []
                    TPs,FPs,TNs,FNs=[],[],[],[]
                    error_rates,accuracy_scores,micro_precision_scores,macro_precision_scores=[],[],[],[]
                    micro_recall_scores,macro_recall_scores,f1_scores,cohen_kappa_scores=[],[],[],[]
                    roc_auc_scores=[]


                    for epoch in range(NUM_EPOCHS):
                        permutation = np.random.permutation(train_labels.shape[0])
                        shuffled_dataset1 = train_data1[permutation, :, :]
                        shuffled_dataset2 = train_data2[permutation, :, :]
                        shuffled_labels = train_labels[permutation, :]

                        accuracy = 0.
                        for step in range(shuffled_labels.shape[0] // BATCH_SIZE):
                            offset = step * BATCH_SIZE
                            batch_data1 = train_data1[offset:(offset+BATCH_SIZE), :, :, :]
                            batch_data2 = train_data2[offset:(offset+BATCH_SIZE), :, :, :]
                            batch_labels = train_labels[offset:(offset+BATCH_SIZE), :]
                            fd = {
                                model.dataset1: batch_data1, 
                                model.dataset2: batch_data2,
                                model.labels: batch_labels,
                                model.istrain: True
                            }
                            _, pred = sess.run([model.optimizeOp, model.prediction], feed_dict=fd)
                            accuracy += get_accuracy(pred, batch_labels)
                            sess.run(model.stepOp)

                        accuracy = accuracy / (shuffled_labels.shape[0] // BATCH_SIZE)
                        train_results.append(accuracy)
                        pred = model.get_prediction(sess, valid_data1, valid_data2, False)
                        valid_results.append(get_accuracy(pred, valid_labels))

                        # Run Evaluation
                        preds_new=np.argmax(pred, 1)
                        labels_new=np.argmax(valid_labels, 1)

                        TP,FP,TN,FN=perf_measure(labels_new,preds_new)
                        error_rate=1-(TP+TN)/(TP+TN+FP+FN)
                        accuracy_score=metrics.accuracy_score(labels_new,preds_new)
                        micro_precision_score=metrics.precision_score(labels_new,preds_new, average='micro')
                        macro_precision_score=metrics.precision_score(labels_new,preds_new, average='macro')
                        micro_recall_score=metrics.recall_score(labels_new,preds_new, average='micro')
                        macro_recall_score=metrics.recall_score(labels_new,preds_new, average='macro')
                        f1_score=metrics.f1_score(labels_new,preds_new, average='weighted') 
                        cohen_kappa_score=metrics.cohen_kappa_score(labels_new,preds_new)
                        roc_auc_score=metrics.roc_auc_score(labels_new,preds_new)

                        TPs.append(TP)
                        FPs.append(FP)
                        TNs.append(TN)
                        FNs.append(FN)
                        error_rates.append(error_rate)
                        accuracy_scores.append(accuracy_score)
                        micro_precision_scores.append(micro_precision_score)
                        macro_precision_scores.append(macro_precision_score)
                        micro_recall_scores.append(micro_recall_score)
                        macro_recall_scores.append(macro_recall_score)
                        f1_scores.append(f1_score)
                        cohen_kappa_scores.append(cohen_kappa_score)
                        roc_auc_scores.append(roc_auc_score)


                        W.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n'%(str(epoch),str(train_results[-1]),\
                        str(valid_results[-1]),str(TP),str(FP)\
                       ,str(TN),str(FN),str(error_rate),str(accuracy_score),str(micro_precision_score),str(macro_precision_score),\
                        str(micro_recall_score),str(macro_recall_score),str(f1_score),str(cohen_kappa_score),\
                        str(roc_auc_score)))

                        print('Epoch: %d'%epoch)
                        print('Training accuracy at epoch %d: %.5f%%' % (epoch, train_results[-1]))
                        print('Validation accuracy: %.5f%%' % valid_results[-1])

                        # Early stopping based on validation results
                        if epoch > 10 and valid_results[-11] > max(valid_results[-10:]):
                            train_results = train_results[:-10]
                            valid_results = valid_results[:-10]
                            print('\n\n########################\nFinal result:')
                            print("Best valid epoch: %d"%(len(train_results)-1))
                            print("Training accuracy: %.5f%%"%train_results[-1])
                            print("Validation accuracy: %.5f%%"%valid_results[-1])

                            # Summary
                            WW.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n'%(str(current_run),str(train_results[-1]),\
                            str(valid_results[-1]),str(TPs[:-10][-1]),str(FPs[:-10][-1])\
                           ,str(TNs[:-10][-1]),str(FNs[:-10][-1]),str(error_rates[:-10][-1]),str(accuracy_scores[:-10][-1]),str(micro_precision_scores[:-10][-1]),str(macro_precision_scores[:-10][-1]),\
                            str(micro_recall_scores[:-10][-1]),str(macro_recall_scores[:-10][-1]),str(f1_scores[:-10][-1]),str(cohen_kappa_scores[:-10][-1]),\
                            str(roc_auc_scores[:-10][-1])))

                            if out is not None:
                                np.savez(out, **save_weights[0])
                            break

                        # Model saving
                        sw = sess.run(model.weights)
                        save_weights.append(sw)
                        if epoch > 10:
                            save_weights.pop(0)

                        if epoch == NUM_EPOCHS-1:
                            print('\n\n########################\nFinal result:')
                            print("Best valid epoch: %d"%(len(train_results)-1))
                            print("Training accuracy: %.5f%%"%train_results[-1])
                            print("Validation accuracy: %.5f%%"%valid_results[-1])

                            # Summary
                            WW.write('%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n'%(str(current_run),str(train_results[-1]),\
                            str(valid_results[-1]),str(TPs[-1]),str(FPs[-1])\
                           ,str(TNs[-1]),str(FNs[-1]),str(error_rates[-1]),str(accuracy_scores[-1]),str(micro_precision_scores[-1]),str(macro_precision_scores[-1]),\
                            str(micro_recall_scores[-1]),str(macro_recall_scores[-1]),str(f1_scores[-1]),str(cohen_kappa_scores[-1]),\
                            str(roc_auc_scores[-1])))

                            if out is not None:
                                np.savez(out, **save_weights[-1])

                    W.close()
                    print('TRAIN_ID: %s'%TRAIN_ID)

            WW.close()





